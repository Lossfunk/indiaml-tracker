accept_type,author_list,filename,majority_authors_from_india,paper_content,paper_id,paper_title,pdf_url,top_author_from_india
poster,"[{'name': 'SUBBA REDDY OOTA', 'openreview_id': '~SUBBA_REDDY_OOTA1', 'affiliation_name': 'INRIA', 'affiliation_domain': 'inria.fr', 'affiliation_country': 'FR'}, {'name': 'Khushbu Pahwa', 'openreview_id': '~Khushbu_Pahwa1', 'affiliation_name': 'Amazon', 'affiliation_domain': 'amazon.com', 'affiliation_country': 'US'}, {'name': 'Mounika Marreddy', 'openreview_id': '~mounika_marreddy1', 'affiliation_name': 'International Institute of Information Technology Hyderabad, Dhirubhai Ambani Institute Of Information and Communication Technology', 'affiliation_domain': 'iiit.ac.in', 'affiliation_country': 'IN'}, {'name': 'Maneesh Kumar Singh', 'openreview_id': '~Maneesh_Kumar_Singh1', 'affiliation_name': 'Spector Inc', 'affiliation_domain': 'spector.com', 'affiliation_country': 'US'}, {'name': 'Manish Gupta', 'openreview_id': '~Manish_Gupta1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper investigates how accurately multi-modal Transformer models predict brain activity in response to multi-modal stimuli, such as movies.  It compares the performance of cross-modal and jointly pre-trained models against unimodal models, aiming to discern which model type best aligns with fMRI data.  The study further analyzes which brain regions process unimodal versus multi-modal information by examining the contributions of individual modalities to multi-modal alignment.
",0dELcFHig2,Multi-modal brain encoding models for multi-modal stimuli,https://openreview.net/pdf/dfadf0e343816bc9190d426ff8cef5c30e58f921.pdf,False
poster,"[{'name': 'Utsav Singh', 'openreview_id': '~Utsav_Singh1', 'affiliation_name': 'Indian Institute of Technology, Kanpur', 'affiliation_domain': 'iitk.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Vinay_P_Namboodiri1', 'affiliation_name': 'University of Bath', 'affiliation_domain': 'bath.ac.uk', 'affiliation_country': 'GB'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper presents PEAR, a two-phase approach for hierarchical reinforcement learning (HRL).  PEAR leverages adaptive relabeling of expert demonstrations to generate efficient subgoal supervision.  The method then optimizes the HRL agent using a combination of reinforcement learning and imitation learning, resulting in a practical HRL framework that performs well on challenging robotic control tasks.
",0nJEgNpb4l,PEAR: Primitive Enabled Adaptive Relabeling for Boosting Hierarchical Reinforcement Learning,https://openreview.net/pdf/12d3031a9f935c986708176a7e99e20965bed69f.pdf,True
poster,"[{'name': 'Prithaj Banerjee', 'openreview_id': '~Prithaj_Banerjee1', 'affiliation_name': 'Indian Institute of Technology, Madras', 'affiliation_domain': 'iitm.ac.in', 'affiliation_country': 'IN'}, {'name': 'Harish G. Ramaswamy', 'openreview_id': '~Harish_Guruprasad_Ramaswamy1', 'affiliation_name': 'Indian Institute of Technology Madras,', 'affiliation_domain': 'iitm.ac.in', 'affiliation_country': 'IN'}, {'name': 'Mahesh Lorik Yadav', 'openreview_id': '~Mahesh_Lorik_Yadav1', 'affiliation_name': 'Indian Institute of Technology Madras', 'affiliation_domain': 'iitm.ac.in', 'affiliation_country': 'IN'}, {'name': 'Chandra Shekar Lakshminarayanan', 'openreview_id': '~Chandra_Shekar_Lakshminarayanan2', 'affiliation_name': 'Indian Institute of Technology, Madras', 'affiliation_domain': 'iitm.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper investigates the feature learning mechanism in deep neural networks, focusing on how discontinuities in the true label function influence model learning.  It introduces a novel deep architecture, the Deep Linearly Gated Network (DLGN), to analyze this mechanism.  The study aims to demonstrate the movement of model function discontinuities towards label function discontinuities during training and provide a means for mechanistic interpretability.
",52UtL8uA35,Deep Networks Learn Features From Local Discontinuities in the Label Function,https://openreview.net/pdf/5ddcb1a74b2e9e4e8ed76a05e032a40ee172bf40.pdf,True
poster,"[{'name': 'Ayan Sengupta', 'openreview_id': '~Ayan_Sengupta1', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Siddhant Chaudhary', 'openreview_id': '~Siddhant_Chaudhary1', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Tanmoy Chakraborty', 'openreview_id': '~Tanmoy_Chakraborty2', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper introduces PruneNet, a novel model compression method for large language models (LLMs).  PruneNet learns a pruning policy to compress models without external calibration data, achieving high performance with reduced computational requirements.  The method outperforms existing techniques in preserving zero-shot performance and robustness on multitask language understanding tasks, demonstrating its superior efficiency and effectiveness.
",5RZoYIT3u6,You Only Prune Once: Designing Calibration-Free Model Compression With Policy Learning,https://openreview.net/pdf/a4ec37f08d2849b2cd4d8f203d00b3bf1aa3f16a.pdf,True
poster,"[{'name': 'Vaibhav Raj', 'openreview_id': '~Vaibhav_Raj1', 'affiliation_name': 'Department of Computer Science and Engineering, IIT Bombay', 'affiliation_domain': 'cse.iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Indradyumna Roy', 'openreview_id': '~Indradyumna_Roy1', 'affiliation_name': 'Indian Institute of Technology Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Ashwin Ramachandran', 'openreview_id': '~Ashwin_Ramachandran1', 'affiliation_name': 'Department of Computer Science and Engineering, IIT Bombay', 'affiliation_domain': 'ucsd.edu', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Soumen_Chakrabarti1', 'affiliation_name': 'Indian Institute of Technology Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Abir De', 'openreview_id': '~Abir_De1', 'affiliation_name': 'Indian Institute of Technology Bombay,', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper investigates the design space of neural graph representations for subgraph matching.  It aims to systematically explore various design choices in neural graph matching networks, including interaction methods (attention vs. permutation-based) and node/edge alignment strategies.  The authors analyze existing methods and identify unexplored combinations, seeking to reveal better performance and general design principles for neural graph matching.
",5pd78GmXC6,Charting the Design Space of Neural Graph Representations for Subgraph Matching,https://openreview.net/pdf/53d17f44d595659cf050490be6c4b87018988e38.pdf,True
poster,"[{'name': 'Mridul Gupta', 'openreview_id': '~Mridul_Gupta2', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Samyak Jain', 'openreview_id': '~Samyak_Jain5', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Vansh Ramani', 'openreview_id': '~Vansh_Ramani1', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'HARIPRASAD KODAMANA', 'openreview_id': '~HARIPRASAD_KODAMANA1', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Sayan_Ranu2', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper introduces Bonsai, a novel, linear-time graph condensation method for node classification in Graph Neural Networks (GNNs).  Bonsai overcomes limitations of existing methods by using exemplar computation trees, enabling model-agnostic condensation and avoiding training on the full dataset.  The approach is mathematically sound, resulting in better performance and significantly faster training than existing techniques.
",5x88lQ2MsH,Bonsai: Gradient-free Graph Condensation for Node Classification,https://openreview.net/pdf/cda993376dcff91230258e560227e99852269d47.pdf,True
poster,"[{'name': 'Ravindran Kannan', 'openreview_id': '~Ravindran_Kannan1', 'affiliation_name': 'University of California, Berkeley', 'affiliation_domain': 'berkeley.edu', 'affiliation_country': 'US'}, {'name': 'Chiranjib Bhattacharyya', 'openreview_id': '~Chiranjib_Bhattacharyya1', 'affiliation_name': 'Indian Institute of Science, Indian institute of science, Bangalore', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': 'Praneeth Kacham', 'openreview_id': '~Praneeth_Kacham1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~David_Woodruff1', 'affiliation_name': 'Carnegie Mellon University', 'affiliation_domain': 'cmu.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper presents LEVATTENTION, a novel algorithm for efficiently computing attention scores in transformer models.  The method aims to identify significant attention scores—those exceeding a threshold—in linear time, bypassing the quadratic time complexity of standard attention mechanisms.  Crucially, the algorithm achieves this without making assumptions about the input data, requiring only resources that scale polynomially with the input dimensions and a small constant for the significant scores.
",90DC0IvlSs,"LevAttention: Time, Space and Streaming Efficient Algorithm for Heavy Attentions",https://openreview.net/pdf/023378fee6afaa67593d97cb2bb8eb8142dfe1e9.pdf,False
poster,"[{'name': 'Zhenyu Sun', 'openreview_id': '~Zhenyu_Sun1', 'affiliation_name': 'Northwestern University, Northwestern University', 'affiliation_domain': 'u.northwestern.edu', 'affiliation_country': 'US'}, {'name': 'Ziyang Zhang', 'openreview_id': '~ziyang_zhang13', 'affiliation_name': 'Northwestern University', 'affiliation_domain': 'northwestern.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Zheng_Xu2', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': 'Pranay Sharma', 'openreview_id': '~Pranay_Sharma2', 'affiliation_name': 'Indian Institute of Technology, Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Ermin_Wei1', 'affiliation_name': 'Northwestern University', 'affiliation_domain': 'northwestern.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper investigates the impact of non-uniform and correlated client participation on federated learning algorithm convergence.  It develops a theoretical framework modeling client participation as a Markov chain, focusing on the case where clients have a minimum waiting period before re-participating.  The research aims to demonstrate how increasing this minimum separation reduces bias and to develop a debiasing algorithm for FedAvg that converges to the optimal solution even with unknown client availability.
",9h45qxXEx0,Debiasing Federated Learning with Correlated Client Participation,https://openreview.net/pdf/3a19cb16b6fde3039612026f7a6e3609f550c3f3.pdf,False
poster,"[{'name': 'Aniket Vashishtha', 'openreview_id': '~Aniket_Vashishtha1', 'affiliation_name': 'University of Illinois at Urbana-Champaign', 'affiliation_domain': 'illinois.edu', 'affiliation_country': 'US'}, {'name': 'Abbavaram Gowtham Reddy', 'openreview_id': '~Abbavaram_Gowtham_Reddy1', 'affiliation_name': 'CISPA Helmholtz Center for Information Security', 'affiliation_domain': 'cispa.de', 'affiliation_country': 'DE'}, {'name': 'Abhinav Kumar', 'openreview_id': '~Abhinav_Kumar3', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}, {'name': 'Saketh Bachu', 'openreview_id': '~Saketh_Bachu1', 'affiliation_name': 'University of California, Riverside', 'affiliation_domain': 'ucr.edu', 'affiliation_country': 'US'}, {'name': 'Vineeth N. Balasubramanian', 'openreview_id': '~Vineeth_N._Balasubramanian2', 'affiliation_name': 'Research, Microsoft', 'affiliation_domain': 'research.microsoft.com', 'affiliation_country': 'IN'}, {'name': 'Amit Sharma', 'openreview_id': '~Amit_Sharma3', 'affiliation_name': 'Microsoft Research', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper investigates using Large Language Models (LLMs) to infer causal relationships.  It argues that focusing on causal order, rather than a full causal graph, provides a more reliable output interface for imperfect experts like LLMs.  A novel querying strategy, the ""triplet method,"" is proposed to improve accuracy and reduce errors in causal order inference, even when using LLMs as imperfect experts.
",9juyeCqL0u,Causal Order: The Key to Leveraging Imperfect Experts in Causal Inference,https://openreview.net/pdf/19538e9c6965f0b37491c400db41cbc256d992c2.pdf,False
poster,"[{'name': 'KISHALAY DAS', 'openreview_id': '~KISHALAY_DAS1', 'affiliation_name': 'Indian Institute of Technology Kharagpur,', 'affiliation_domain': 'iitkgp.ac.in', 'affiliation_country': 'IN'}, {'name': 'Subhojyoti Khastagir', 'openreview_id': '~Subhojyoti_Khastagir1', 'affiliation_name': 'Indian Institute of Technology, Kharagpur', 'affiliation_domain': 'iitkgp.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Pawan_Goyal1', 'affiliation_name': 'IIT Kharagpur', 'affiliation_domain': 'cse.iitkgp.ac.in', 'affiliation_country': 'IN'}, {'name': 'Seung-Cheol Lee', 'openreview_id': '~Seung-Cheol_Lee1', 'affiliation_name': 'Indo Korea Science and Technology Center, Bangalore, India', 'affiliation_domain': 'ikst.res.in', 'affiliation_country': 'IN'}, {'name': 'Satadeep Bhattacharjee', 'openreview_id': '~Satadeep_Bhattacharjee1', 'affiliation_name': 'Indo Korea Science and Technology Center', 'affiliation_domain': 'UNK', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Niloy_Ganguly1', 'affiliation_name': 'Indian Institute of Technology Kharagpur,', 'affiliation_domain': 'iitkgp.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper introduces TGDMat, a novel diffusion model for generating 3D periodic materials.  It aims to improve upon existing models by learning the joint distribution of atom types, coordinates, and lattice structure in an end-to-end framework, incorporating global structural knowledge through textual descriptions.  The results demonstrate superior performance on both material generation and prediction tasks compared to existing baselines.
",AkBrb7yQ0G,Periodic Materials Generation using Text-Guided Joint Diffusion Model,https://openreview.net/pdf/8ad46240b718392d7de78aefb2230245544e7a1f.pdf,True
poster,"[{'name': 'Priyank Pathak', 'openreview_id': '~Priyank_Pathak1', 'affiliation_name': 'University of Central Florida', 'affiliation_domain': 'ucf.edu', 'affiliation_country': 'US'}, {'name': 'Shyam Marjit', 'openreview_id': '~Shyam_Marjit1', 'affiliation_name': 'Indian Institute of Science, Indian institute of science, Bangalore', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': 'Shruti Vyas', 'openreview_id': '~Shruti_Vyas1', 'affiliation_name': 'University of Central Florida', 'affiliation_domain': 'ucf.edu', 'affiliation_country': 'US'}, {'name': 'Yogesh S Rawat', 'openreview_id': '~Yogesh_S_Rawat1', 'affiliation_name': 'University of Central Florida', 'affiliation_domain': 'ucf.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper introduces LR0.FM, a benchmark to evaluate the zero-shot classification performance of foundation models on low-resolution images.  It assesses the impact of resolution on the performance of 10 models across 66 backbones and 15 datasets.  The study aims to determine the robustness of these models to lower resolution and identify factors influencing this performance, including model size, pre-training dataset characteristics, and finetuning impact.
",AsFxRSLtqR,LR0.FM: LOW-RESOLUTION ZERO-SHOT CLASSIFICATION BENCHMARK FOR FOUNDATION MODELS,https://openreview.net/pdf/4e0dd81f6d23c736f87d3dee4272d5e4f0812e16.pdf,False
poster,"[{'name': 'Indradyumna Roy', 'openreview_id': '~Indradyumna_Roy1', 'affiliation_name': 'Indian Institute of Technology Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Eeshaan Jain', 'openreview_id': '~Eeshaan_Jain1', 'affiliation_name': 'EPFL - EPF Lausanne', 'affiliation_domain': 'epfl.ch', 'affiliation_country': 'CH'}, {'name': '', 'openreview_id': '~Soumen_Chakrabarti1', 'affiliation_name': 'Indian Institute of Technology Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Abir De', 'openreview_id': '~Abir_De1', 'affiliation_name': 'Indian Institute of Technology Bombay,', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper introduces a differentiable estimator for predicting a graph's clique number.  The approach formulates the maximum clique problem as finding dense submatrices within a permuted adjacency matrix, using a differentiable mechanism to search for optimal permutations.  The method is designed for situations where explicit clique demonstrations are unavailable but clique size estimation is crucial.
",DFSb67ksVr,Clique Number Estimation via Differentiable Functions of Adjacency Matrix Permutations,https://openreview.net/pdf/c827a3961d4fc71d35f295fe47af1a56513b177c.pdf,True
poster,"[{'name': 'Divya Jyoti Bajpai', 'openreview_id': '~Divya_Jyoti_Bajpai1', 'affiliation_name': 'Indian Institute of Technology, Bombay, Dhirubhai Ambani Institute Of Information and Communication Technology', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Manjesh Kumar Hanawal', 'openreview_id': '~Manjesh_Kumar_Hanawal1', 'affiliation_name': 'Indian Institute of Technology Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper proposes a new method, BEEM, to improve the performance of early exit deep neural networks (DNNs).  BEEM leverages multi-exit classifiers as ""experts"" to aggregate confidence scores, considering only consistent predictions from neighboring experts.  The goal is to achieve faster inference speed with comparable or improved accuracy compared to traditional DNN inference, utilizing the COCO and GLUE datasets.
",EzrZX9bd4G,BEEM: Boosting Performance of Early Exit DNNs using Multi-Exit Classifiers as Experts,https://openreview.net/pdf/debbb712eb9e26bf61695ebf77801a55131c9e21.pdf,True
poster,"[{'name': 'Xue Han', 'openreview_id': '~Xue_Han3', 'affiliation_name': 'China Mobile Research Institute', 'affiliation_domain': 'chinamobile.com', 'affiliation_country': 'CN'}, {'name': 'Yitong Wang', 'openreview_id': '~Yitong_Wang2', 'affiliation_name': 'China Mobile Research Institute', 'affiliation_domain': 'chinamobile.com', 'affiliation_country': 'CN'}, {'name': 'Junlan Feng', 'openreview_id': '~Junlan_Feng3', 'affiliation_name': 'China Mobile', 'affiliation_domain': 'ioa.ac.cn', 'affiliation_country': 'CN'}, {'name': 'wenchun.gao', 'openreview_id': '~wenchun.gao2', 'affiliation_name': 'China Mobile Communications Company Limited Research Institute', 'affiliation_domain': 'chinamobile.com', 'affiliation_country': 'CN'}, {'name': 'Qian Hu', 'openreview_id': '~Qian_Hu5', 'affiliation_name': 'CMRI', 'affiliation_domain': 'chinamobile.com', 'affiliation_country': 'IN'}, {'name': 'Chao Deng', 'openreview_id': '~Chao_Deng4', 'affiliation_name': 'China Mobile Research Institute', 'affiliation_domain': 'jiutian.10086.cn', 'affiliation_country': 'CN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper introduces LOIRE, a lifelong learning framework for pre-trained language models (PLMs).  LOIRE aims to efficiently adapt PLMs to new, incremental data without complete retraining, thereby reducing computational costs while maintaining performance.  The framework employs novel growth operators and a refined growth schedule, addressing limitations of existing approaches.
",F5PlYMC5ik,LOIRE: LifelOng learning on Incremental data via pre-trained language model gRowth Efficiently,https://openreview.net/pdf/b87c8fd1af16706a48a7227e5f6a4de6a18727e1.pdf,False
poster,"[{'name': 'Alexey Gorbatovski', 'openreview_id': '~Alexey_Gorbatovski1', 'affiliation_name': 'T-Tech', 'affiliation_domain': 't-tech.dev', 'affiliation_country': 'RU'}, {'name': 'Boris Shaposhnikov', 'openreview_id': '~Boris_Shaposhnikov1', 'affiliation_name': 'T-Tech', 'affiliation_domain': 'UNK', 'affiliation_country': 'IN'}, {'name': 'Alexey Malakhov', 'openreview_id': '~Alexey_Malakhov1', 'affiliation_name': 'Financial University', 'affiliation_domain': 'edu.fa.ru', 'affiliation_country': 'RU'}, {'name': 'Nikita Surnachev', 'openreview_id': '~Nikita_Surnachev1', 'affiliation_name': 'T-Tech', 'affiliation_domain': 'UNK', 'affiliation_country': 'IN'}, {'name': 'Yaroslav Aksenov', 'openreview_id': '~Yaroslav_Aksenov1', 'affiliation_name': 'T-Tech', 'affiliation_domain': 'UNK', 'affiliation_country': 'IN'}, {'name': 'Ian Maksimov', 'openreview_id': '~Ian_Maksimov1', 'affiliation_name': 'Higher School of Economics, Higher School of Economics', 'affiliation_domain': 'cs.hse.ru', 'affiliation_country': 'RU'}, {'name': 'Nikita Balagansky', 'openreview_id': '~Nikita_Balagansky3', 'affiliation_name': 'Moscow Institute of Physics and Technology', 'affiliation_domain': 'phystech.edu', 'affiliation_country': 'RU'}, {'name': 'Daniil Gavrilov', 'openreview_id': '~Daniil_Gavrilov1', 'affiliation_name': 'T-Bank', 'affiliation_domain': 'tbank.ru', 'affiliation_country': 'RU'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper introduces a novel Trust Region approach to aligning large language models (LLMs).  The approach dynamically updates the reference policy during training, mitigating overoptimization issues often encountered in offline alignment methods.  The authors demonstrate improved performance in various tasks, including dialogue and summarization, and in general-purpose assistant setups, surpassing conventional methods.
",H0qIWXXLUR,Learn Your Reference Model for Real Good Alignment,https://openreview.net/pdf/ad56fa8ef01bdd6f6903602f1532fbfa1424352e.pdf,False
poster,"[{'name': 'Harshit Varma', 'openreview_id': '~Harshit_Varma1', 'affiliation_name': 'Inception Labs', 'affiliation_domain': 'inceptionai.xyz', 'affiliation_country': 'US'}, {'name': 'Dheeraj Mysore Nagaraj', 'openreview_id': '~Dheeraj_Mysore_Nagaraj1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Karthikeyan_Shanmugam1', 'affiliation_name': 'Google Deepmind', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper introduces the Glauber Generative Model (GGM), a novel discrete diffusion model for generating samples from a given distribution.  Unlike prior methods that use regression or variational approximations, GGM learns a denoising Markov chain by solving binary classification tasks.  The authors demonstrate GGM's effectiveness in language modeling and image generation, outperforming existing discrete diffusion models in language and achieving strong results for image generation.
",HyjIEf90Tn,Glauber Generative Model: Discrete Diffusion Models via Binary Classification,https://openreview.net/pdf/ed0abd318619dfe4330271693402f90d85304fa5.pdf,False
poster,"[{'name': 'Sravanti Addepalli', 'openreview_id': '~Sravanti_Addepalli1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': 'Yerram Varun', 'openreview_id': '~Yerram_Varun1', 'affiliation_name': 'Research, Google', 'affiliation_domain': 'research.google.com', 'affiliation_country': 'IN'}, {'name': 'Arun Suggala', 'openreview_id': '~Arun_Suggala1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Karthikeyan_Shanmugam1', 'affiliation_name': 'Google Deepmind', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Prateek_Jain1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This research investigates the vulnerability of safety-trained large language models (LLMs) to natural, semantically related prompts.  The paper aims to evaluate whether these models, despite alignment techniques, remain safe against prompts that are not specifically crafted as adversarial attacks.  A novel method, Response Guided Question Augmentation (ReG-QA), is proposed to systematically generate such prompts and assess the models' robustness.
",LO4MEPoqrG,Does Safety Training of LLMs Generalize to Semantically Related Natural Prompts?,https://openreview.net/pdf/f432171f3c6052c0ec517871292566b7399bd96f.pdf,True
poster,"[{'name': 'Sohan Patnaik', 'openreview_id': '~Sohan_Patnaik1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': 'Milan Aggarwal', 'openreview_id': '~Milan_Aggarwal2', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'US'}, {'name': 'Sumit Bhatia', 'openreview_id': '~Sumit_Bhatia1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Balaji_Krishnamurthy1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper introduces COALITION, a framework designed to enhance the rationale-generating capabilities of smaller language models (SLMs).  The approach leverages two variants of the same SLM interacting to generate and refine rationales, ultimately improving the SLM's ability to produce accurate answers.  The framework, trained via Selective Rationale Optimization, aims to address the limitations of relying on larger, often opaque language models for training smaller models and improve their performance on tasks like mathematical problems, commonsense reasoning, and natural language inference.
",NHxwxc3ql6,It Helps to Take a Second Opinion: Teaching Smaller LLMs To Deliberate Mutually via Selective Rationale Optimisation,https://openreview.net/pdf/799ba059f2d6b50ca4668376ba1cdd8d72138627.pdf,True
poster,"[{'name': 'Somesh Kumar Singh', 'openreview_id': '~Somesh_Kumar_Singh2', 'affiliation_name': 'Indraprastha Institute of Information Technology, Delhi', 'affiliation_domain': 'iiitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Yaman Kumar Singla', 'openreview_id': '~Yaman_Kumar_Singla1', 'affiliation_name': 'Adobe ', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': 'Harini S I', 'openreview_id': '~Harini_S_I1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Balaji_Krishnamurthy1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper introduces PersuasionBench and PersuasionArena, large-scale benchmarks and arenas to evaluate the persuasive abilities of large language models (LLMs).  The research aims to measure both simulative and generative persuasion capabilities,  highlighting that persuasiveness correlates with model size but can be enhanced through targeted training in smaller models.
",NfCEVihkdC,Measuring And Improving Persuasiveness Of Large Language Models,https://openreview.net/pdf/ac884658f87199ebcb457a610bf628ecf481891f.pdf,True
poster,"[{'name': 'Prateek Garg', 'openreview_id': '~Prateek_Garg3', 'affiliation_name': 'Indian Institute of Technology Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Lokesh Nagalapatti', 'openreview_id': '~Lokesh_Nagalapatti1', 'affiliation_name': 'Indian Institute of Technology, Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Sunita Sarawagi', 'openreview_id': '~Sunita_Sarawagi1', 'affiliation_name': 'IIT Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper introduces GenRe, a generative model for algorithmic recourse.  GenRe aims to jointly train recourse objectives (proximity, plausibility, and validity) for improved recommendations, unlike previous methods that optimize these separately.  The authors show that GenRe, using a forward sampling approach during inference, outperforms existing baselines in terms of cost, plausibility, and validity of generated recourse suggestions.
",NtwFghsJne,From Search to Sampling: Generative Models for Robust Algorithmic Recourse,https://openreview.net/pdf/c6c8ec06c7f9ef53d5ac4216c2471b1d20415fd0.pdf,True
poster,"[{'name': 'Megh Shukla', 'openreview_id': '~Megh_Shukla1', 'affiliation_name': 'EPFL - EPF Lausanne', 'affiliation_domain': 'epfl.ch', 'affiliation_country': 'CH'}, {'name': 'Aziz Shameem', 'openreview_id': '~Aziz_Shameem1', 'affiliation_name': 'Indian Institute of Technology, Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Mathieu_Salzmann1', 'affiliation_name': 'Swiss Data Science Center', 'affiliation_domain': 'epfl.ch', 'affiliation_country': 'CH'}, {'name': 'Alexandre Alahi', 'openreview_id': '~Alexandre_Alahi3', 'affiliation_name': 'EPFL', 'affiliation_domain': 'epfl.ch', 'affiliation_country': 'CH'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper investigates self-supervised covariance estimation in deep heteroscedastic regression.  It aims to develop methods to learn the covariance of a target distribution without explicit ground-truth labels, focusing on two key questions regarding supervision and pseudo-label generation.  The paper proposes a 2-Wasserstein distance-based approach, alongside a heuristic algorithm for generating pseudo-labels, demonstrating improved accuracy and efficiency compared to existing unsupervised methods.
",Q1kPHLUbhi,Towards Self-Supervised Covariance Estimation in Deep Heteroscedastic Regression,https://openreview.net/pdf/d8c57b3404d90a6681d8c4293f83c6935ad162c6.pdf,False
spotlight,"[{'name': 'Ayush Kaushal', 'openreview_id': '~Ayush_Kaushal1', 'affiliation_name': 'Mila - Quebec Artificial Intelligence Institute', 'affiliation_domain': 'mila.quebec', 'affiliation_country': 'CA'}, {'name': 'Tejas Vaidhya', 'openreview_id': '~Tejas_Vaidhya1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Arnab Kumar Mondal', 'openreview_id': '~Arnab_Kumar_Mondal1', 'affiliation_name': 'Apple', 'affiliation_domain': 'apple.com', 'affiliation_country': 'US'}, {'name': 'Tejas Pandey', 'openreview_id': '~Tejas_Pandey2', 'affiliation_name': 'Indian Institute of Technology Kharagpur', 'affiliation_domain': 'iitkgp.ac.in', 'affiliation_country': 'IN'}, {'name': 'Aaryan Bhagat', 'openreview_id': '~Aaryan_Bhagat1', 'affiliation_name': 'University of California, Riverside', 'affiliation_domain': 'ucr.edu', 'affiliation_country': 'US'}, {'name': 'Irina Rish', 'openreview_id': '~Irina_Rish1', 'affiliation_name': 'University of Montreal', 'affiliation_domain': 'mila.quebec', 'affiliation_country': 'CA'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper investigates the pretraining of ternary language models (TriLMs) as a more efficient alternative to traditional floating-point models for large language models (LLMs).  It presents the Spectra LLM suite, a collection of models with varying bit-widths, to demonstrate that TriLMs, at scales exceeding a billion parameters, consistently outperform comparable quantized and floating-point models.  The research aims to show the feasibility and scalability of low-bitwidth LLMs for deployment in memory-constrained environments.
",TJo6aQb7mK,Surprising Effectiveness of pretraining Ternary  Language Model at Scale,https://openreview.net/pdf/b7f47612d7d5627f433233234f8b7f7779ca9daf.pdf,False
poster,"[{'name': 'Varun Khurana', 'openreview_id': '~Varun_Khurana1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': 'Yaman Kumar Singla', 'openreview_id': '~Yaman_Kumar_Singla1', 'affiliation_name': 'Adobe ', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': 'Jayakumar Subramanian', 'openreview_id': '~Jayakumar_Subramanian1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Changyou_Chen1', 'affiliation_name': 'State University of New York, Buffalo', 'affiliation_domain': 'buffalo.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Rajiv_Ratn_Shah1', 'affiliation_name': 'Indraprastha Institute of Information Technology, Delhi', 'affiliation_domain': 'iiitd.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~zhiqiang_xu1', 'affiliation_name': 'Mohamed bin Zayed University of Artificial Intelligence', 'affiliation_domain': 'mbzuai.ac.ae', 'affiliation_country': 'CN'}, {'name': '', 'openreview_id': '~Balaji_Krishnamurthy1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper introduces a new dataset, EngagingImageNet, and a model, EngageNet, to measure and improve viewer engagement in text-to-image generation models.  It argues existing metrics fail to capture this crucial aspect, and proposes methods to condition image generation for better user outcomes.  The authors aim to create a benchmark, the Engagement Arena, to spur further research in this field.
",TmCcNuo03f,Measuring And Improving Engagement of Text-to-Image Generation Models,https://openreview.net/pdf/8a918fd68fecd9209403ab6e44f832e47c2e540b.pdf,True
poster,"[{'name': 'Jianing Chu', 'openreview_id': '~Jianing_Chu1', 'affiliation_name': 'Amazon', 'affiliation_domain': 'amazon.com', 'affiliation_country': 'US'}, {'name': 'Shu Yang', 'openreview_id': '~Shu_Yang4', 'affiliation_name': 'North Carolina State University', 'affiliation_domain': 'ncsu.edu', 'affiliation_country': 'US'}, {'name': 'Wenbin Lu', 'openreview_id': '~Wenbin_Lu1', 'affiliation_name': 'North Carolina State University', 'affiliation_domain': 'ncsu.edu', 'affiliation_country': 'US'}, {'name': 'PULAK GHOSH', 'openreview_id': '~PULAK_GHOSH1', 'affiliation_name': 'Indian Institute of Management', 'affiliation_domain': 'iimk.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,,UWdPsY7agk,Efficient Causal Decision Making with One-sided Feedback,https://openreview.net/pdf/41f6f38a0ce451f61d1bb9e2dcf372abdfaacbbe.pdf,False
poster,"[{'name': 'Aishwarya Jayagopal', 'openreview_id': '~Aishwarya_Jayagopal1', 'affiliation_name': 'National University of Singapore', 'affiliation_domain': 'u.nus.edu', 'affiliation_country': 'SG'}, {'name': 'Yanrong Zhang', 'openreview_id': '~Yanrong_Zhang1', 'affiliation_name': 'National University of Singapore', 'affiliation_domain': 'nus.edu.sg', 'affiliation_country': 'SG'}, {'name': 'Robert John Walsh', 'openreview_id': '~Robert_John_Walsh1', 'affiliation_name': 'National University Cancer Institute, Singapore', 'affiliation_domain': 'nuhs.edu.sg', 'affiliation_country': 'SG'}, {'name': 'Tuan Zea Tan', 'openreview_id': '~Tuan_Zea_Tan1', 'affiliation_name': 'National University of Singapore', 'affiliation_domain': 'nus.edu.sg', 'affiliation_country': 'SG'}, {'name': 'Anand D Jeyasekharan', 'openreview_id': '~Anand_D_Jeyasekharan1', 'affiliation_name': 'National University of Singapore', 'affiliation_domain': 'nus.edu', 'affiliation_country': 'SG'}, {'name': 'Vaibhav Rajan', 'openreview_id': '~Vaibhav_Rajan2', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper introduces GANDALF, a novel framework for personalized cancer treatment.  It aims to improve drug response prediction models by addressing the limitations of existing methods, which fail to account for patient-specific genomic characteristics.  GANDALF directly augments patient genomic data, incorporating domain-specific features, and outperforms prior state-of-the-art models on public datasets.
",WwmtcGr4lP,GANDALF: Generative AttentioN based Data Augmentation and predictive modeLing Framework for personalized cancer treatment,https://openreview.net/pdf/10101e6245c7f0b239cbda68df0276f6a7a30441.pdf,False
poster,"[{'name': 'Huihan Li', 'openreview_id': '~Huihan_Li1', 'affiliation_name': 'University of Southern California', 'affiliation_domain': 'usc.edu', 'affiliation_country': 'US'}, {'name': 'Arnav Goel', 'openreview_id': '~Arnav_Goel1', 'affiliation_name': 'Indraprastha Institute of Information Technology, Delhi', 'affiliation_domain': 'iiitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Keyu He', 'openreview_id': '~Keyu_He1', 'affiliation_name': 'University of Southern California', 'affiliation_domain': 'usc.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Xiang_Ren1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This research investigates how large language models (LLMs) exhibit cultural biases in generative tasks due to uneven cultural representation in their pretraining data.  The study analyzes how models associate entities with cultures based on pretraining data, proposing MEMOED, a framework to identify memorized cultural associations.  Findings show that more frequent cultures in pretraining data lead to more memorized symbol generations, highlighting a bias toward high-frequency terms regardless of cultural relevance.
",XrsOu4KgDE,Attributing Culture-Conditioned Generations to Pretraining Corpora,https://openreview.net/pdf/d4ad6ebf55597935dddd75a72863d66152715ca2.pdf,False
poster,"[{'name': 'Prakash Chandra Chhipa', 'openreview_id': '~Prakash_Chandra_Chhipa1', 'affiliation_name': 'Luleå University of Technology', 'affiliation_domain': 'ltu.se', 'affiliation_country': 'SE'}, {'name': 'Gautam Vashishtha', 'openreview_id': '~Gautam_Vashishtha1', 'affiliation_name': 'Skan.ai', 'affiliation_domain': 'skan.ai', 'affiliation_country': 'IN'}, {'name': 'Settur Jithamanyu', 'openreview_id': '~Settur_Jithamanyu1', 'affiliation_name': 'Indian Institute of Technology, Madras', 'affiliation_domain': 'iitm.ac.in', 'affiliation_country': 'IN'}, {'name': 'Rajkumar Saini', 'openreview_id': '~Rajkumar_Saini1', 'affiliation_name': 'Lulea university of technology ', 'affiliation_domain': 'ltu.se', 'affiliation_country': 'SE'}, {'name': 'Mubarak Shah', 'openreview_id': '~Mubarak_Shah3', 'affiliation_name': 'Amazon', 'affiliation_domain': 'amazon.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Marcus_Liwicki1', 'affiliation_name': 'Luleå University of Technology', 'affiliation_domain': 'ltu.se', 'affiliation_country': 'SE'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper introduces ASTrA, a novel self-supervised adversarial training framework.  It addresses limitations of existing methods by proposing a learnable, adaptive attack strategy network.  ASTrA aims to improve adversarial robustness by dynamically adjusting attack parameters during training without relying on labeled data or additional hyperparameters.
",ZbkqhKbggH,ASTrA: Adversarial Self-supervised Training with Adaptive-Attacks,https://openreview.net/pdf/2ac81185cb98c88c3dafbbbc2c090fb8c2620808.pdf,False
poster,"[{'name': 'Juan A. Rodriguez', 'openreview_id': '~Juan_A._Rodriguez1', 'affiliation_name': 'ServiceNow Research', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'Xiangru Jian', 'openreview_id': '~Xiangru_Jian1', 'affiliation_name': 'ServiceNow Research', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'Siba Smarak Panigrahi', 'openreview_id': '~Siba_Smarak_Panigrahi1', 'affiliation_name': 'EPFL - EPF Lausanne', 'affiliation_domain': 'epfl.ch', 'affiliation_country': 'CH'}, {'name': 'Tianyu Zhang', 'openreview_id': '~Tianyu_Zhang6', 'affiliation_name': 'Montreal Institute for Learning Algorithms, University of Montreal, University of Montreal', 'affiliation_domain': 'mila.umontreal.ca', 'affiliation_country': 'CA'}, {'name': 'Aarash Feizi', 'openreview_id': '~Aarash_Feizi1', 'affiliation_name': 'McGill University', 'affiliation_domain': 'mcgill.ca', 'affiliation_country': 'CA'}, {'name': 'Abhay Puri', 'openreview_id': '~Abhay_Puri1', 'affiliation_name': 'ServiceNow Research', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'Akshay Kalkunte Suresh', 'openreview_id': '~Akshay_Kalkunte_Suresh2', 'affiliation_name': 'ServiceNow Inc', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'US'}, {'name': 'François Savard', 'openreview_id': '~François_Savard1', 'affiliation_name': 'ServiceNow Inc', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'Ahmed Masry', 'openreview_id': '~Ahmed_Masry1', 'affiliation_name': 'York University', 'affiliation_domain': 'yorku.ca', 'affiliation_country': 'CA'}, {'name': 'Shravan Nayak', 'openreview_id': '~Shravan_Nayak1', 'affiliation_name': 'Université de Montréal', 'affiliation_domain': 'umontreal.ca', 'affiliation_country': 'CA'}, {'name': 'Rabiul Awal', 'openreview_id': '~Rabiul_Awal1', 'affiliation_name': 'Mila - Quebec AI Institute', 'affiliation_domain': 'mila.quebec', 'affiliation_country': 'CA'}, {'name': 'Mahsa Massoud', 'openreview_id': '~Mahsa_Massoud1', 'affiliation_name': 'McGill University, McGill University', 'affiliation_domain': 'mail.mcgill.ca', 'affiliation_country': 'CA'}, {'name': 'Amirhossein Abaskohi', 'openreview_id': '~Amirhossein_Abaskohi1', 'affiliation_name': 'ServiceNow Inc', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'Zichao Li', 'openreview_id': '~Zichao_Li3', 'affiliation_name': 'McGill University', 'affiliation_domain': 'mcgill.ca', 'affiliation_country': 'CA'}, {'name': 'Suyuchen Wang', 'openreview_id': '~Suyuchen_Wang1', 'affiliation_name': 'Université de Montréal', 'affiliation_domain': 'umontreal.ca', 'affiliation_country': 'CA'}, {'name': 'Pierre-Andre Noel', 'openreview_id': '~Pierre-Andre_Noel1', 'affiliation_name': 'ServiceNow', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'Mats Leon Richter', 'openreview_id': '~Mats_Leon_Richter1', 'affiliation_name': 'Montreal Institute for Learning Algorithms, University of Montreal, Université de Montréal', 'affiliation_domain': 'mila.umontreal.ca', 'affiliation_country': 'CA'}, {'name': 'Saverio Vadacchino', 'openreview_id': '~Saverio_Vadacchino1', 'affiliation_name': 'ServiceNow', 'affiliation_domain': 'UNK', 'affiliation_country': 'US'}, {'name': 'Shubham Agarwal', 'openreview_id': '~Shubham_Agarwal3', 'affiliation_name': 'Krutrim AI', 'affiliation_domain': 'olakrutrim.com', 'affiliation_country': 'IN'}, {'name': 'Sanket Biswas', 'openreview_id': '~Sanket_Biswas1', 'affiliation_name': 'Computer Vision Center, Universitat Autónoma de Barcelona', 'affiliation_domain': 'cvc.uab.es', 'affiliation_country': 'ES'}, {'name': 'Sara Shanian', 'openreview_id': '~Sara_Shanian1', 'affiliation_name': 'ServiceNow Inc', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'Ying Zhang', 'openreview_id': '~Ying_Zhang1', 'affiliation_name': 'ServiceNow Inc.', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'Sathwik Tejaswi Madhusudhan', 'openreview_id': '~Sathwik_Tejaswi_Madhusudhan2', 'affiliation_name': 'ServiceNow Inc', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'US'}, {'name': 'Joao Monteiro', 'openreview_id': '~Joao_Monteiro1', 'affiliation_name': 'Autodesk', 'affiliation_domain': 'autodesk.com', 'affiliation_country': 'GB'}, {'name': 'Krishnamurthy Dj Dvijotham', 'openreview_id': '~Krishnamurthy_Dj_Dvijotham1', 'affiliation_name': 'ServiceNow', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'US'}, {'name': 'Torsten Scholak', 'openreview_id': '~Torsten_Scholak1', 'affiliation_name': 'ServiceNow Research', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'Nicolas Chapados', 'openreview_id': '~Nicolas_Chapados1', 'affiliation_name': 'ServiceNow Research', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'Sepideh Kharaghani', 'openreview_id': '~Sepideh_Kharaghani1', 'affiliation_name': 'Servicenow', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'Sean Hughes', 'openreview_id': '~Sean_Hughes1', 'affiliation_name': 'ServiceNow', 'affiliation_domain': 'UNK', 'affiliation_country': 'US'}, {'name': 'M. Tamer Özsu', 'openreview_id': '~M._Özsu1', 'affiliation_name': 'University of Waterloo', 'affiliation_domain': 'cs.uwaterloo.ca', 'affiliation_country': 'CA'}, {'name': 'Siva Reddy', 'openreview_id': '~Siva_Reddy1', 'affiliation_name': 'ServiceNow Inc', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': '', 'openreview_id': '~Marco_Pedersoli1', 'affiliation_name': 'École de technologie supérieure, Université du Québec', 'affiliation_domain': 'etsmtl.ca', 'affiliation_country': 'CA'}, {'name': 'Yoshua Bengio', 'openreview_id': '~Yoshua_Bengio1', 'affiliation_name': 'University of Montreal', 'affiliation_domain': 'umontreal.ca', 'affiliation_country': 'CA'}, {'name': 'Christopher Pal', 'openreview_id': '~Christopher_Pal1', 'affiliation_name': 'Polytechnique Montreal', 'affiliation_domain': 'polymtl.ca', 'affiliation_country': 'CA'}, {'name': '', 'openreview_id': '~Issam_H._Laradji1', 'affiliation_name': 'ServiceNow', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'US'}, {'name': 'Spandana Gella', 'openreview_id': '~Spandana_Gella2', 'affiliation_name': 'ServiceNow Inc', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'Perouz Taslakian', 'openreview_id': '~Perouz_Taslakian1', 'affiliation_name': 'ServiceNow', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'David Vazquez', 'openreview_id': '~David_Vazquez1', 'affiliation_name': 'ServiceNow research', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'Sai Rajeswar', 'openreview_id': '~Sai_Rajeswar2', 'affiliation_name': 'ServiceNow', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper introduces BigDocs-7.5M, an open-access dataset of 7.5 million multimodal documents designed for training multimodal AI models on document and code tasks.  It also presents BigDocs-Bench, a benchmark suite of 10 novel tasks, which assess model performance in real-world document reasoning and code generation.  The authors aim to improve open access to training data and facilitate the development and improvement of multimodal AI tools through this open dataset and benchmark.
",b1ivBPLb1n,BigDocs: An Open Dataset for Training Multimodal Models on Document and Code Tasks,https://openreview.net/pdf/88f0ac24696ee7a61302f3a92c952793719808be.pdf,False
spotlight,"[{'name': 'Onkar Kishor Susladkar', 'openreview_id': '~Onkar_Kishor_Susladkar1', 'affiliation_name': 'Indian Institute of Technology, Roorkee', 'affiliation_domain': 'iitr.ac.in', 'affiliation_country': 'IN'}, {'name': 'Jishu Sen Gupta', 'openreview_id': '~Jishu_Sen_Gupta1', 'affiliation_name': 'Indian Institute of Technology (Banaras Hindu University) Varanasi', 'affiliation_domain': 'iitbhu.ac.in', 'affiliation_country': 'IN'}, {'name': 'Chirag Sehgal', 'openreview_id': '~Chirag_Sehgal1', 'affiliation_name': 'Delhi Technological University (Delhi College of Engineering)', 'affiliation_domain': 'dtu.ac.in', 'affiliation_country': 'IN'}, {'name': 'Sparsh Mittal', 'openreview_id': '~Sparsh_Mittal1', 'affiliation_name': 'Indian Institution Technology Roorkee', 'affiliation_domain': 'iitr.ac.in', 'affiliation_country': 'IN'}, {'name': 'Rekha Singhal', 'openreview_id': '~Rekha_Singhal1', 'affiliation_name': 'Tata Consultancy Services Limited, India', 'affiliation_domain': 'tcs.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper introduces MotionAura, a novel text-to-video generation model leveraging discrete diffusion models.  The model utilizes a pre-trained 3D VAE to predict discrete tokens, resulting in temporally coherent videos aligned with text prompts.  The paper also presents a spectral transformer-based denoising network for improved video generation and inpainting.
",bW9fGYo44s,MotionAura: Generating High-Quality and Motion Consistent Videos using Discrete Diffusion,https://openreview.net/pdf/45b7da6fce6fc272027212b6c17632d43a4c1530.pdf,True
poster,"[{'name': 'Somesh Kumar Singh', 'openreview_id': '~Somesh_Kumar_Singh2', 'affiliation_name': 'Indraprastha Institute of Information Technology, Delhi', 'affiliation_domain': 'iiitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Harini S I', 'openreview_id': '~Harini_S_I1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': 'Yaman Kumar Singla', 'openreview_id': '~Yaman_Kumar_Singla1', 'affiliation_name': 'Adobe ', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Changyou_Chen1', 'affiliation_name': 'State University of New York, Buffalo', 'affiliation_domain': 'buffalo.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Rajiv_Ratn_Shah1', 'affiliation_name': 'Indraprastha Institute of Information Technology, Delhi', 'affiliation_domain': 'iiitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Veeky Baths', 'openreview_id': '~Veeky_Baths1', 'affiliation_name': 'UNK', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': '', 'openreview_id': '~Balaji_Krishnamurthy1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This research investigates improving vision-language model (VLM) content understanding by incorporating receiver behavior, such as likes and comments.  The authors demonstrate that training VLMs on these behaviors enhances VLM performance across various content understanding tasks.  This approach leverages readily available, publicly-sourced receiver behavior data, offering a performance boost and a potential free resource for VLM improvement.
",ff2V3UR9sC,Teaching Human Behavior Improves Content Understanding Abilities Of VLMs,https://openreview.net/pdf/c838bbe0a12f56b1fde9d76191b41894a12cd638.pdf,True
poster,"[{'name': 'Arhaan Ahmad', 'openreview_id': '~Arhaan_Ahmad1', 'affiliation_name': 'Indian Institute of Technology, Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Tanay Vineet Tayal', 'openreview_id': '~Tanay_Vineet_Tayal1', 'affiliation_name': 'Indian Institute of Technology, Bombay, Dhirubhai Ambani Institute Of Information and Communication Technology', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Ashutosh Gupta', 'openreview_id': '~Ashutosh_Gupta2', 'affiliation_name': 'IIT Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~S._Akshay1', 'affiliation_name': 'Indian Institute of Technology Bombay, Indian Institute of Technology, Bombay', 'affiliation_domain': 'cse.iitb.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper develops a formal verification framework for analyzing feature sensitivity in additive decision tree ensembles, considering the confidence of the model's output.  It demonstrates the theoretical (NP-)hardness of this problem and provides a pseudo-Boolean constraint encoding for a tunable sensitivity analysis algorithm, balancing accuracy and runtime.  The authors evaluate their approach on existing GBDT benchmarks, showing improved performance compared to existing methods.
",h0vC0fm1q7,Sensitivity Verification for Additive Decision Tree Ensembles,https://openreview.net/pdf/0baccd0626487637d58895c5bf4daa1f701f0d6f.pdf,True
poster,"[{'name': 'Aditya Ramesh', 'openreview_id': '~Aditya_Ramesh3', 'affiliation_name': 'Fujitsu Research and Development Center Co. Ltm.', 'affiliation_domain': 'fujitsu.com', 'affiliation_country': 'IN'}, {'name': 'Shivam Bhardwaj', 'openreview_id': '~Shivam_Bhardwaj1', 'affiliation_name': 'Fujitsu Research and Development Center Co. Ltm.', 'affiliation_domain': 'fujitsu.com', 'affiliation_country': 'IN'}, {'name': 'Aditya Saibewar', 'openreview_id': '~Aditya_Saibewar1', 'affiliation_name': 'Fujitsu Research and Development Center Co. Ltm.', 'affiliation_domain': 'fujitsu.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Manohar_Kaul1', 'affiliation_name': 'Fujitsu Research and Development Center Co. Ltm.', 'affiliation_domain': 'fujitsu.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper introduces a novel jailbreak attack on large language models (LLMs).  It leverages a multi-armed bandit (MAB) approach to create sequential context-switching queries (CSQs) that systematically weaken the model's safety boundaries.  The authors demonstrate significantly improved attack success rates compared to existing methods.
",jCDF7G3LpF,EFFICIENT JAILBREAK ATTACK SEQUENCES ON LARGE LANGUAGE MODELS VIA MULTI-ARMED BANDIT-BASED CONTEXT SWITCHING,https://openreview.net/pdf/bc16e7d0bc5f4d8c4b1a1d6e943556544f77ff36.pdf,True
spotlight,"[{'name': 'Angelika Romanou', 'openreview_id': '~Angelika_Romanou1', 'affiliation_name': 'Swiss Federal Institute of Technology Lausanne', 'affiliation_domain': 'epfl.ch', 'affiliation_country': 'CH'}, {'name': 'Negar Foroutan', 'openreview_id': '~Negar_Foroutan1', 'affiliation_name': 'School of Computer and Communication Sciences, EPFL - EPF Lausanne', 'affiliation_domain': 'ic.epfl.ch', 'affiliation_country': 'CH'}, {'name': 'Anna Sotnikova', 'openreview_id': '~Anna_Sotnikova1', 'affiliation_name': 'EPFL - EPF Lausanne', 'affiliation_domain': 'epfl.ch', 'affiliation_country': 'CH'}, {'name': 'Sree Harsha Nelaturu', 'openreview_id': '~Sree_Harsha_Nelaturu1', 'affiliation_name': 'CISPA Helmholtz Center for Information Security', 'affiliation_domain': 'cispa.de', 'affiliation_country': 'DE'}, {'name': 'Shivalika Singh', 'openreview_id': '~Shivalika_Singh1', 'affiliation_name': 'Cohere For AI', 'affiliation_domain': 'UNK', 'affiliation_country': 'CA'}, {'name': 'Rishabh Maheshwary', 'openreview_id': '~Rishabh_Maheshwary2', 'affiliation_name': 'ServiceNow', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'IN'}, {'name': 'Micol Altomare', 'openreview_id': '~Micol_Altomare1', 'affiliation_name': 'University of Toronto', 'affiliation_domain': 'utoronto.ca', 'affiliation_country': 'CA'}, {'name': 'Zeming Chen', 'openreview_id': '~Zeming_Chen1', 'affiliation_name': 'Swiss Federal Institute of Technology Lausanne (EPFL)', 'affiliation_domain': 'epfl.ch', 'affiliation_country': 'CH'}, {'name': 'Mohamed A. Haggag', 'openreview_id': '~Mohamed_A._Haggag1', 'affiliation_name': 'Georgia Institute of Technology', 'affiliation_domain': 'UNK', 'affiliation_country': 'US'}, {'name': 'Snegha A', 'openreview_id': '~Snegha_A1', 'affiliation_name': 'Indian Institute of Technology, Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Alfonso Amayuelas', 'openreview_id': '~Alfonso_Amayuelas2', 'affiliation_name': 'University of California, Santa Barbara', 'affiliation_domain': 'ucsb.edu', 'affiliation_country': 'US'}, {'name': 'Azril Hafizi Amirudin', 'openreview_id': '~Azril_Hafizi_Amirudin1', 'affiliation_name': 'University of the People', 'affiliation_domain': 'uopeople.edu', 'affiliation_country': 'US'}, {'name': 'Danylo Boiko', 'openreview_id': '~Danylo_Boiko1', 'affiliation_name': 'Taras Shevchenko National University of Kyiv', 'affiliation_domain': 'knu.ua', 'affiliation_country': 'UA'}, {'name': 'Michael Chang', 'openreview_id': '~Michael_Chang2', 'affiliation_name': 'Trulioo', 'affiliation_domain': 'trulioo.com', 'affiliation_country': 'CA'}, {'name': 'Jenny Chim', 'openreview_id': '~Jenny_Chim1', 'affiliation_name': 'UNK', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': 'Gal Cohen', 'openreview_id': '~Gal_Cohen2', 'affiliation_name': 'University of Toronto', 'affiliation_domain': 'utoronto.ca', 'affiliation_country': 'CA'}, {'name': 'Aditya Kumar Dalmia', 'openreview_id': '~Aditya_Kumar_Dalmia1', 'affiliation_name': 'NeuralSpace, Inc.', 'affiliation_domain': 'neuralspace.ai', 'affiliation_country': 'IN'}, {'name': 'Abraham Diress', 'openreview_id': '~Abraham_Diress1', 'affiliation_name': 'UNK', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': 'Sharad Duwal', 'openreview_id': '~Sharad_Duwal1', 'affiliation_name': 'Fatima Fellowship', 'affiliation_domain': 'fatimafellowship.com', 'affiliation_country': 'US'}, {'name': 'Daniil Dzenhaliou', 'openreview_id': '~Daniil_Dzenhaliou1', 'affiliation_name': 'EPFL - EPF Lausanne', 'affiliation_domain': 'epfl.ch', 'affiliation_country': 'CH'}, {'name': 'Daniel Fernando Erazo Florez', 'openreview_id': '~Daniel_Fernando_Erazo_Florez1', 'affiliation_name': 'Universidad del Valle del Cauca', 'affiliation_domain': 'univalle.edu.co', 'affiliation_country': 'CO'}, {'name': 'Fabian Farestam', 'openreview_id': '~Fabian_Farestam1', 'affiliation_name': 'ETHZ - ETH Zurich', 'affiliation_domain': 'ethz.ch', 'affiliation_country': 'CH'}, {'name': 'Joseph Marvin Imperial', 'openreview_id': '~Joseph_Marvin_Imperial1', 'affiliation_name': 'University of Bath', 'affiliation_domain': 'bath.ac.uk', 'affiliation_country': 'GB'}, {'name': 'Shayekh Bin Islam', 'openreview_id': '~Shayekh_Bin_Islam1', 'affiliation_name': 'Qatar Computing Research Institute', 'affiliation_domain': 'qcri.org', 'affiliation_country': 'QA'}, {'name': 'Perttu Isotalo', 'openreview_id': '~Perttu_Isotalo1', 'affiliation_name': 'Turing College', 'affiliation_domain': 'turingcollege.com', 'affiliation_country': 'LT'}, {'name': 'Maral Jabbarishiviari', 'openreview_id': '~Maral_Jabbarishiviari1', 'affiliation_name': 'UNK', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': 'Börje F. Karlsson', 'openreview_id': '~Börje_F._Karlsson1', 'affiliation_name': 'Beijing Academy of Artificial Intelligence (BAAI)', 'affiliation_domain': 'baai.ac.cn', 'affiliation_country': 'CN'}, {'name': 'Eldar Khalilov', 'openreview_id': '~Eldar_Khalilov1', 'affiliation_name': 'UNK', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': '', 'openreview_id': '~Christopher_Klamm1', 'affiliation_name': 'Universität Mannheim', 'affiliation_domain': 'uni-mannheim.de', 'affiliation_country': 'DE'}, {'name': 'Fajri Koto', 'openreview_id': '~Fajri_Koto1', 'affiliation_name': 'Mohamed bin Zayed University of Artificial Intelligence', 'affiliation_domain': 'mbzuai.ac.ae', 'affiliation_country': 'AE'}, {'name': 'Dominik Krzemiński', 'openreview_id': '~Dominik_Krzemiński1', 'affiliation_name': 'UNK', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': 'Gabriel Adriano de Melo', 'openreview_id': '~Gabriel_Adriano_de_Melo1', 'affiliation_name': 'Instituto Tecnológico de Aeronáutica', 'affiliation_domain': 'ita.br', 'affiliation_country': 'BR'}, {'name': 'Syrielle Montariol', 'openreview_id': '~Syrielle_Montariol1', 'affiliation_name': 'EPFL - EPF Lausanne', 'affiliation_domain': 'epfl.ch', 'affiliation_country': 'CH'}, {'name': 'Yiyang Nan', 'openreview_id': '~Yiyang_Nan1', 'affiliation_name': 'UNK', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': 'Joel Niklaus', 'openreview_id': '~Joel_Niklaus1', 'affiliation_name': 'Harvey', 'affiliation_domain': 'harvey.ai', 'affiliation_country': 'US'}, {'name': 'Jekaterina Novikova', 'openreview_id': '~Jekaterina_Novikova1', 'affiliation_name': 'Winterlight Labs', 'affiliation_domain': 'winterlightlabs.com', 'affiliation_country': 'CA'}, {'name': 'Johan Obando-Ceron', 'openreview_id': '~Johan_Samir_Obando_Ceron1', 'affiliation_name': 'Mila - Quebec AI Institute, Université de Montréal', 'affiliation_domain': 'mila.umontreal.ca', 'affiliation_country': 'CA'}, {'name': 'Debjit Paul', 'openreview_id': '~Debjit_Paul2', 'affiliation_name': 'EPFL - EPF Lausanne', 'affiliation_domain': 'epfl.ch', 'affiliation_country': 'CH'}, {'name': 'Jebish Purbey', 'openreview_id': '~Jebish_Purbey1', 'affiliation_name': 'Tribhuvan University', 'affiliation_domain': 'pcampus.edu.np', 'affiliation_country': 'NP'}, {'name': 'Swati Rajwal', 'openreview_id': '~Swati_Rajwal2', 'affiliation_name': 'Emory University', 'affiliation_domain': 'emory.edu', 'affiliation_country': 'US'}, {'name': 'Selvan Sunitha Ravi', 'openreview_id': '~Selvan_Sunitha_Ravi1', 'affiliation_name': 'UNK', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': 'Sara Rydell', 'openreview_id': '~Sara_Rydell1', 'affiliation_name': 'KTH Royal Institute of Technology', 'affiliation_domain': 'kth.se', 'affiliation_country': 'SE'}, {'name': 'Roshan Santhosh', 'openreview_id': '~Roshan_Santhosh1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'US'}, {'name': 'Drishti Sharma', 'openreview_id': '~Drishti_Sharma2', 'affiliation_name': 'Cohere', 'affiliation_domain': 'cohere.ai', 'affiliation_country': 'IN'}, {'name': 'Marjana Prifti Skenduli', 'openreview_id': '~Marjana_Prifti_Skenduli1', 'affiliation_name': 'University of New York Tirana', 'affiliation_domain': 'unyt.edu.al', 'affiliation_country': 'AL'}, {'name': 'Arshia Soltani Moakhar', 'openreview_id': '~Arshia_Soltani_Moakhar1', 'affiliation_name': 'University of Maryland, College Park', 'affiliation_domain': 'umd.edu', 'affiliation_country': 'US'}, {'name': 'Bardia soltani moakhar', 'openreview_id': '~Bardia_soltani_moakhar1', 'affiliation_name': 'Sharif University of Technology', 'affiliation_domain': 'sharif.ir', 'affiliation_country': 'IR'}, {'name': 'Ayush Kumar Tarun', 'openreview_id': '~Ayush_Kumar_Tarun1', 'affiliation_name': 'EPFL - EPF Lausanne', 'affiliation_domain': 'epfl.ch', 'affiliation_country': 'CH'}, {'name': 'Azmine Toushik Wasi', 'openreview_id': '~Azmine_Toushik_Wasi1', 'affiliation_name': 'Shahjalal University of Science and Technology', 'affiliation_domain': 'sust.edu', 'affiliation_country': 'BD'}, {'name': 'Thenuka Ovin Weerasinghe', 'openreview_id': '~Thenuka_Ovin_Weerasinghe1', 'affiliation_name': 'UNK', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': 'Serhan Yilmaz', 'openreview_id': '~Serhan_Yilmaz1', 'affiliation_name': 'Technische Universität Darmstadt', 'affiliation_domain': 'tu-darmstadt.de', 'affiliation_country': 'DE'}, {'name': 'Mike Zhang', 'openreview_id': '~Mike_Zhang1', 'affiliation_name': 'Aalborg University (Copenhagen)', 'affiliation_domain': 'cs.aau.dk', 'affiliation_country': 'DK'}, {'name': 'Imanol Schlag', 'openreview_id': '~Imanol_Schlag3', 'affiliation_name': 'ETHZ - ETH Zurich', 'affiliation_domain': 'ethz.ch', 'affiliation_country': 'CH'}, {'name': 'Marzieh Fadaee', 'openreview_id': '~Marzieh_Fadaee2', 'affiliation_name': 'Cohere For AI', 'affiliation_domain': 'cohere.com', 'affiliation_country': 'NL'}, {'name': 'Sara Hooker', 'openreview_id': '~Sara_Hooker2', 'affiliation_name': 'Cohere For AI', 'affiliation_domain': 'cohere.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Antoine_Bosselut1', 'affiliation_name': 'Swiss Federal Institute of Technology Lausanne', 'affiliation_domain': 'epfl.ch', 'affiliation_country': 'CH'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper aims to develop a comprehensive evaluation resource, INCLUDE, for multilingual large language models (LLMs).  INCLUDE  will assess LLM performance across 44 languages by using a knowledge- and reasoning-centric benchmark based on regional exam questions.  The resource is designed to address the lack of high-quality evaluation data in languages other than English, promoting fairer and more equitable LLM deployment globally.
",k3gCieTXeY,INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge,https://openreview.net/pdf/4735757bbe8999ee1c4990094d9326caa8c46a64.pdf,False
poster,"[{'name': 'Arkaprava Majumdar', 'openreview_id': '~Arkaprava_Majumdar1', 'affiliation_name': 'Indian Institute of Technology, Hyderabad', 'affiliation_domain': 'iith.ac.in', 'affiliation_country': 'IN'}, {'name': 'M Anand Krishna', 'openreview_id': '~M_Anand_Krishna1', 'affiliation_name': 'Indian Institute of Technology, Hyderabad, Dhirubhai Ambani Institute Of Information and Communication Technology', 'affiliation_domain': 'iith.ac.in', 'affiliation_country': 'IN'}, {'name': 'P. K. Srijith', 'openreview_id': '~P._K._Srijith1', 'affiliation_name': 'Indian Institute of Technology Hyderabad', 'affiliation_domain': 'iith.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper introduces a novel deep learning method, the neural wave equation, for sequence labeling tasks involving irregularly sampled data.  It aims to improve upon existing neural ODE-based architectures by allowing continuous modeling of depth and time, thereby enhancing flexibility and adaptability to varying data complexities.  The authors demonstrate the method's superior performance on several sequence labeling problems compared to previous models.
",kbeX97jExm,Neural Wave Equation for Irregularly Sampled Sequence Data,https://openreview.net/pdf/8ed140ad99d8ff52315acf85732ba20a69b155a7.pdf,True
poster,"[{'name': 'Lokesh Nagalapatti', 'openreview_id': '~Lokesh_Nagalapatti1', 'affiliation_name': 'Indian Institute of Technology, Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Ashutosh Srivastava', 'openreview_id': '~Ashutosh_Srivastava2', 'affiliation_name': 'International Institute of Information Technology, Hyderabad, International Institute of Information Technology Hyderabad', 'affiliation_domain': 'students.iiit.ac.in', 'affiliation_country': 'IN'}, {'name': 'Sunita Sarawagi', 'openreview_id': '~Sunita_Sarawagi1', 'affiliation_name': 'IIT Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Amit Sharma', 'openreview_id': '~Amit_Sharma3', 'affiliation_name': 'Microsoft Research', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper introduces In-Distribution Interventions (IDI), a novel algorithm for robustly diagnosing root causes of anomalies in complex systems.  IDI predicts root causes by considering both anomalous node values and the effect of intervening on these values to resolve the anomaly, avoiding the unreliability of counterfactual estimates from historical data.  Experiments on synthetic and real datasets demonstrate IDI's superior accuracy compared to existing methods in identifying true root causes.
",l11DZY5Nxu,Robust Root Cause Diagnosis using In-Distribution Interventions,https://openreview.net/pdf/704fab6788807803612ad2b12344cc35a2a74913.pdf,True
poster,"[{'name': 'Sujoy Bhore', 'openreview_id': '~Sujoy_Bhore1', 'affiliation_name': 'Indian Institute of Technology Bombay, Indian Institute of Technology, Bombay', 'affiliation_domain': 'cse.iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Devdan Dey', 'openreview_id': '~Devdan_Dey1', 'affiliation_name': 'Indian Institute of Technology, Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Satyam Singh', 'openreview_id': '~Satyam_Singh1', 'affiliation_name': 'Indian Institute of Technology Bombay, Indian Institute of Technology, Bombay', 'affiliation_domain': 'cse.iitb.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,,nNiWRRj6r9,ONLINE EPSILON NET & PIERCING SET FOR GEOMETRIC CONCEPTS,https://openreview.net/pdf/696d482ba820dd1fb2c61d652aea1b70e1287ef9.pdf,True
oral,"[{'name': 'Esben Kran', 'openreview_id': '~Esben_Kran1', 'affiliation_name': 'Apart Research', 'affiliation_domain': 'apartresearch.com', 'affiliation_country': 'US'}, {'name': 'Hieu Minh Nguyen', 'openreview_id': '~Hieu_Minh_Nguyen2', 'affiliation_name': 'University of Science and Technology of Hanoi', 'affiliation_domain': 'usth.edu.vn', 'affiliation_country': 'VN'}, {'name': 'Akash Kundu', 'openreview_id': '~Akash_Kundu2', 'affiliation_name': 'Heritage Institute of Technology', 'affiliation_domain': 'heritageit.edu', 'affiliation_country': 'IN'}, {'name': 'Sami Jawhar', 'openreview_id': '~Sami_Jawhar1', 'affiliation_name': 'METR', 'affiliation_domain': 'metr.org', 'affiliation_country': 'US'}, {'name': 'Jinsuk Park', 'openreview_id': '~Jinsuk_Park1', 'affiliation_name': 'Independent', 'affiliation_domain': 'UNK', 'affiliation_country': 'US'}, {'name': 'Mateusz Maria Jurewicz', 'openreview_id': '~Mateusz_Maria_Jurewicz1', 'affiliation_name': 'Independent', 'affiliation_domain': 'UNK', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper introduces DarkBench, a benchmark to identify and quantify ""dark patterns""—manipulative design techniques—in large language models (LLMs).  The benchmark evaluates six categories of dark patterns in responses from 14 LLMs from leading companies.  The study aims to highlight the prevalence of these patterns and encourage developers to mitigate their use in AI systems, promoting ethical AI development.
",odjMSBSWRt,DarkBench: Benchmarking Dark Patterns in Large Language Models,https://openreview.net/pdf/66d66215ed6e8821cf14e0c9c0e83be089660c40.pdf,False
poster,"[{'name': 'Peihao Wang', 'openreview_id': '~Peihao_Wang1', 'affiliation_name': 'University of Texas, Austin', 'affiliation_domain': 'utexas.edu', 'affiliation_country': 'US'}, {'name': 'Ruisi Cai', 'openreview_id': '~Ruisi_Cai1', 'affiliation_name': 'University of Texas at Austin', 'affiliation_domain': 'utexas.edu', 'affiliation_country': 'US'}, {'name': 'Jiajun Zhu', 'openreview_id': '~Jiajun_Zhu1', 'affiliation_name': 'Zhejiang University', 'affiliation_domain': 'zju.edu.cn', 'affiliation_country': 'CN'}, {'name': 'Pragya Srivastava', 'openreview_id': '~Pragya_Srivastava1', 'affiliation_name': 'Google DeepMind', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': 'Zhangyang Wang', 'openreview_id': '~Zhangyang_Wang1', 'affiliation_name': 'University of Texas at Austin', 'affiliation_domain': 'utexas.edu', 'affiliation_country': 'US'}, {'name': 'Pan Li', 'openreview_id': '~Pan_Li2', 'affiliation_name': 'Georgia Institute of Technology', 'affiliation_domain': 'gatech.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper investigates the limitations of State Space Models (SSMs) related to recency bias and over-smoothing.  It argues that these inherent limitations hinder scalability.  The authors propose a polarization technique to address these issues and improve long-range associative recall accuracy in SSMs.
",pymXpl4qvi,Understanding and Mitigating Bottlenecks of State Space Models through the Lens of Recency and Over-smoothing,https://openreview.net/pdf/982acd7979eff95835985d1c18fb057152350bf1.pdf,False
poster,"[{'name': 'Kartik Thakral', 'openreview_id': '~Kartik_Thakral1', 'affiliation_name': 'Indian Institute of Technology Jodhpur, India', 'affiliation_domain': 'iitj.ac.in', 'affiliation_country': 'IN'}, {'name': 'Rishabh Ranjan', 'openreview_id': '~Rishabh_Ranjan4', 'affiliation_name': 'Indian Institute of Technology Jodhpur, India', 'affiliation_domain': 'iitj.ac.in', 'affiliation_country': 'IN'}, {'name': 'Akanksha Singh', 'openreview_id': '~Akanksha_Singh1', 'affiliation_name': 'Indian Institute of Technology, Madras', 'affiliation_domain': 'iitm.ac.in', 'affiliation_country': 'IN'}, {'name': 'Akshat Jain', 'openreview_id': '~Akshat_Jain2', 'affiliation_name': 'IIT Jodhpur', 'affiliation_domain': 'iitj.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Mayank_Vatsa1', 'affiliation_name': 'Indian Institute of Technology Jodhpur, India', 'affiliation_domain': 'iitj.ac.in', 'affiliation_country': 'IN'}, {'name': 'Richa Singh', 'openreview_id': '~Richa_Singh1', 'affiliation_name': 'Indian Institute of Technology Jodhpur, India', 'affiliation_domain': 'iitj.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"The paper introduces ILLUSION, a large-scale, multi-modal deepfake dataset.  It comprises 1.3 million samples spanning audio-visual forgeries, 26 languages, and various manipulation protocols to address the limitations of existing datasets.  The goal is to create a dataset robust enough to evaluate and advance deepfake detection research, bridging the gap between synthetic and real-world complexities.
",qnlG3zPQUy,"ILLUSION: Unveiling Truth with a Comprehensive Multi-Modal, Multi-Lingual Deepfake Dataset",https://openreview.net/pdf/b4b0f39d84d66fbd58c0ce677e7f47db34c37ab8.pdf,True
oral,"[{'name': 'Daniel Paleka', 'openreview_id': '~Daniel_Paleka1', 'affiliation_name': 'Department of Computer Science, ETHZ - ETH Zurich', 'affiliation_domain': 'inf.ethz.ch', 'affiliation_country': 'CH'}, {'name': 'Abhimanyu Pallavi Sudhir', 'openreview_id': '~Abhimanyu_Pallavi_Sudhir1', 'affiliation_name': 'University of Warwick', 'affiliation_domain': 'warwick.ac.uk', 'affiliation_country': 'GB'}, {'name': 'Alejandro Alvarez', 'openreview_id': '~Alejandro_Alvarez1', 'affiliation_name': 'Independent', 'affiliation_domain': 'gmail.com', 'affiliation_country': 'US'}, {'name': 'Vineeth Bhat', 'openreview_id': '~Vineeth_Bhat1', 'affiliation_name': 'International Institute of Information Technology, Hyderabad, International Institute of Information Technology Hyderabad', 'affiliation_domain': 'students.iiit.ac.in', 'affiliation_country': 'IN'}, {'name': 'Adam Shen', 'openreview_id': '~Adam_Shen1', 'affiliation_name': 'Columbia University', 'affiliation_domain': 'columbia.edu', 'affiliation_country': 'US'}, {'name': 'Evan Wang', 'openreview_id': '~Evan_Wang2', 'affiliation_name': 'Cornell University', 'affiliation_domain': 'cornell.edu', 'affiliation_country': 'US'}, {'name': 'Florian Tramèr', 'openreview_id': '~Florian_Tramèr1', 'affiliation_name': 'ETHZ - ETH Zurich', 'affiliation_domain': 'ethz.ch', 'affiliation_country': 'CH'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper introduces consistency metrics to evaluate large language model (LLM) forecasters, addressing the challenge of instantaneously evaluating their predictions.  The authors propose a new metric based on arbitrage and develop an automated evaluation system to assess the logical consistency of forecasts.  The study validates these metrics against ground-truth Brier scores, demonstrating their potential for efficient and reliable LLM forecasting evaluation, particularly for long-term predictions.
",r5IXBlTCGc,Consistency Checks for Language Model Forecasters,https://openreview.net/pdf/389d3f91440e04c180ab71609410dccb834213d4.pdf,False
poster,"[{'name': '', 'openreview_id': '~Manohar_Kaul1', 'affiliation_name': 'Fujitsu Research and Development Center Co. Ltm.', 'affiliation_domain': 'fujitsu.com', 'affiliation_country': 'IN'}, {'name': 'Aditya Saibewar', 'openreview_id': '~Aditya_Saibewar1', 'affiliation_name': 'Fujitsu Research and Development Center Co. Ltm.', 'affiliation_domain': 'fujitsu.com', 'affiliation_country': 'IN'}, {'name': 'Sadbhavana Babar', 'openreview_id': '~Sadbhavana_Babar1', 'affiliation_name': 'Fujitsu Research and Development Center Co. Ltm.', 'affiliation_domain': 'fujitsu.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This research paper proposes a novel defense mechanism for large language models (LLMs) against socially engineered attacks.  It leverages hypergraphs and the Gromov-Hausdorff distance to create a metric space representing prompts, enabling a safety filter to distinguish between benign and malicious prompts.  The method is designed to address the growing threat of sophisticated, human-like attacks and exhibits improved performance compared to existing, more generic defenses.
",rnJxelIZrq,Beyond Mere Token Analysis: A Hypergraph Metric Space Framework for Defending Against Socially Engineered LLM Attacks,https://openreview.net/pdf/cedd874528d6099323a83a93e025814f28b8e16e.pdf,True
spotlight,"[{'name': 'Colin White', 'openreview_id': '~Colin_White1', 'affiliation_name': 'Facebook', 'affiliation_domain': 'meta.com', 'affiliation_country': 'US'}, {'name': 'Manley Roberts', 'openreview_id': '~Manley_Roberts1', 'affiliation_name': 'Abridge', 'affiliation_domain': 'abridge.com', 'affiliation_country': 'US'}, {'name': 'Arka Pal', 'openreview_id': '~Arka_Pal2', 'affiliation_name': 'Ritual AI', 'affiliation_domain': 'ritual.ai', 'affiliation_country': 'US'}, {'name': 'Benjamin Feuer', 'openreview_id': '~Benjamin_Feuer1', 'affiliation_name': 'New York University', 'affiliation_domain': 'nyu.edu', 'affiliation_country': 'US'}, {'name': 'Siddhartha Jain', 'openreview_id': '~Siddhartha_Jain1', 'affiliation_name': 'NVIDIA', 'affiliation_domain': 'nvidia.com', 'affiliation_country': 'US'}, {'name': 'Ravid Shwartz-Ziv', 'openreview_id': '~Ravid_Shwartz-Ziv2', 'affiliation_name': 'NYU', 'affiliation_domain': 'UNK', 'affiliation_country': 'US'}, {'name': 'Neel Jain', 'openreview_id': '~Neel_Jain1', 'affiliation_name': 'University of Maryland, College Park', 'affiliation_domain': 'umd.edu', 'affiliation_country': 'US'}, {'name': 'Khalid Saifullah', 'openreview_id': '~Khalid_Saifullah1', 'affiliation_name': 'University of Maryland, College Park', 'affiliation_domain': 'umd.edu', 'affiliation_country': 'US'}, {'name': 'Sreemanti Dey', 'openreview_id': '~Sreemanti_Dey1', 'affiliation_name': 'Abacus.AI', 'affiliation_domain': 'UNK', 'affiliation_country': 'US'}, {'name': 'Shubh-Agrawal', 'openreview_id': '~Shubh-Agrawal1', 'affiliation_name': 'Abacus.ai', 'affiliation_domain': 'abacus.ai', 'affiliation_country': 'IN'}, {'name': 'Sandeep Singh Sandha', 'openreview_id': '~Sandeep_Singh_Sandha1', 'affiliation_name': 'Abacus inc', 'affiliation_domain': 'abacus.ai', 'affiliation_country': 'US'}, {'name': 'Siddartha Venkat Naidu', 'openreview_id': '~Siddartha_Venkat_Naidu1', 'affiliation_name': 'Abacus.AI', 'affiliation_domain': 'UNK', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Chinmay_Hegde1', 'affiliation_name': 'New York University', 'affiliation_domain': 'nyu.edu', 'affiliation_country': 'US'}, {'name': 'Yann LeCun', 'openreview_id': '~Yann_LeCun1', 'affiliation_name': 'Facebook', 'affiliation_domain': 'meta.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Tom_Goldstein1', 'affiliation_name': 'University of Maryland, College Park', 'affiliation_domain': 'umd.edu', 'affiliation_country': 'US'}, {'name': 'Willie Neiswanger', 'openreview_id': '~Willie_Neiswanger2', 'affiliation_name': 'University of Southern California', 'affiliation_domain': 'usc.edu', 'affiliation_country': 'US'}, {'name': 'Micah Goldblum', 'openreview_id': '~Micah_Goldblum1', 'affiliation_name': 'Columbia University', 'affiliation_domain': 'columbia.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"LiveBench is a new LLM benchmark designed to address test set contamination issues.  It uses automatically scored, frequently updated questions from recent information sources across various challenging tasks (math, coding, reasoning, etc.).  The benchmark aims for resilience against model overfitting and provides a more reliable evaluation of LLM capabilities.
",sKYHBTAxVa,"LiveBench: A Challenging, Contamination-Limited LLM Benchmark",https://openreview.net/pdf/b0d866d6f88096c375607735dcf000ab2a892567.pdf,False
poster,"[{'name': 'Poojan Chetan Shah', 'openreview_id': '~Poojan_Chetan_Shah1', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Ragesh Jaiswal', 'openreview_id': '~Ragesh_Jaiswal1', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper develops a quantum algorithm for approximating D[2]-sampling, a fundamental component of k-means++ clustering.  The algorithm, along with a dequantized version, achieves a time complexity of O[˜](ζ²k²).  This leads to a quantum-inspired classical implementation of k-means++ with a faster running time than existing methods for large datasets.
",tDIL7UXmSS,Quantum (Inspired)  $D^2$-sampling with Applications,https://openreview.net/pdf/200469483697d3ac66abe0d44a5efe9482fa9101.pdf,True
poster,"[{'name': '', 'openreview_id': '~Bodhisattwa_Prasad_Majumder1', 'affiliation_name': 'Allen Institute for Artificial Intelligence', 'affiliation_domain': 'allenai.org', 'affiliation_country': 'US'}, {'name': 'Harshit Surana', 'openreview_id': '~Harshit_Surana1', 'affiliation_name': 'Allen Institute for Artificial Intelligence', 'affiliation_domain': 'allenai.org', 'affiliation_country': 'US'}, {'name': 'Dhruv Agarwal', 'openreview_id': '~Dhruv_Agarwal2', 'affiliation_name': 'University of Massachusetts Amherst', 'affiliation_domain': 'cs.umass.edu', 'affiliation_country': 'US'}, {'name': 'Bhavana Dalvi Mishra', 'openreview_id': '~Bhavana_Dalvi_Mishra2', 'affiliation_name': 'Allen Institute for Artificial Intelligence', 'affiliation_domain': 'allenai.org', 'affiliation_country': 'US'}, {'name': 'Abhijeetsingh Meena', 'openreview_id': '~Abhijeetsingh_Meena1', 'affiliation_name': 'OpenLocus', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': 'Aryan Prakhar', 'openreview_id': '~Aryan_Prakhar1', 'affiliation_name': 'Indian Institute of Technology (Banaras Hindu University) Varanasi', 'affiliation_domain': 'iitbhu.ac.in', 'affiliation_country': 'IN'}, {'name': 'Tirth Vora', 'openreview_id': '~Tirth_Vora1', 'affiliation_name': 'OpenLocus', 'affiliation_domain': 'openlocus.ai', 'affiliation_country': 'IN'}, {'name': 'Tushar Khot', 'openreview_id': '~Tushar_Khot1', 'affiliation_name': 'Allen Institute for Artificial Intelligence', 'affiliation_domain': 'allenai.org', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Ashish_Sabharwal1', 'affiliation_name': 'Allen Institute for AI', 'affiliation_domain': 'allenai.org', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Peter_Clark1', 'affiliation_name': 'Allen Institute for Artificial Intelligence', 'affiliation_domain': 'allenai.org', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper introduces DISCOVERYBENCH, a comprehensive benchmark to evaluate large language models' (LLMs) abilities in data-driven discovery.  It formalizes this multi-step process using 264 manually derived and 903 synthetic tasks across diverse domains.  The benchmark aims to assess LLM capabilities in automating hypothesis search and verification from datasets alone.
",vyflgpwfJW,DiscoveryBench: Towards Data-Driven Discovery with Large Language Models,https://openreview.net/pdf/86ad04ca338565e2886508ecd9de33292760d63b.pdf,False
poster,"[{'name': 'Kunal Singh', 'openreview_id': '~Kunal_Singh1', 'affiliation_name': 'Fractal Analytics', 'affiliation_domain': 'fractal.ai', 'affiliation_country': 'IN'}, {'name': 'Ankan Biswas', 'openreview_id': '~Ankan_Biswas1', 'affiliation_name': 'Fractal', 'affiliation_domain': 'fractal.ai', 'affiliation_country': 'IN'}, {'name': 'Sayandeep Bhowmick', 'openreview_id': '~Sayandeep_Bhowmick1', 'affiliation_name': 'Indian Institute of Technology Kharagpur', 'affiliation_domain': 'iitkgp.ac.in', 'affiliation_country': 'IN'}, {'name': 'Pradeep Moturi', 'openreview_id': '~Pradeep_Moturi1', 'affiliation_name': 'Fractal AI', 'affiliation_domain': 'fractal.ai', 'affiliation_country': 'IN'}, {'name': 'Siva Kishore Gollapalli', 'openreview_id': '~Siva_Kishore_Gollapalli1', 'affiliation_name': 'Fractal AI Research', 'affiliation_domain': 'fractal.ai', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper introduces SBSC, a multi-turn framework for LLMs to solve mathematical Olympiad problems.  SBSC allows the model to generate a sequence of programs, each addressing a sub-task, ultimately reaching the solution.  Experiments demonstrate significant improvement over existing state-of-the-art methods, especially when evaluated on competition-level datasets.
",wSkvf2WyYz,SBSC: Step-by-Step Coding for Improving Mathematical Olympiad Performance,https://openreview.net/pdf/df1273af2e4a905f17436545415573e192eb813f.pdf,True
spotlight,"[{'name': 'Arnab Bhattacharyya', 'openreview_id': '~Arnab_Bhattacharyya1', 'affiliation_name': 'The University of Warwick', 'affiliation_domain': 'warwick.ac.uk', 'affiliation_country': 'GB'}, {'name': 'Sutanu Gayen', 'openreview_id': '~Sutanu_Gayen1', 'affiliation_name': 'Indian Institute of Technology, Kanpur', 'affiliation_domain': 'iitk.ac.in', 'affiliation_country': 'IN'}, {'name': 'Kuldeep S. Meel', 'openreview_id': '~Kuldeep_S._Meel2', 'affiliation_name': 'Department of Computer Science', 'affiliation_domain': 'cs.toronto.edu', 'affiliation_country': 'CA'}, {'name': 'Dimitrios Myrisiotis', 'openreview_id': '~Dimitrios_Myrisiotis1', 'affiliation_name': 'CNRS@CREATE LTD.', 'affiliation_domain': 'cnrsatcreate.cnrs.fr', 'affiliation_country': 'FR'}, {'name': 'A. Pavan', 'openreview_id': '~A._Pavan1', 'affiliation_name': 'Iowa State University', 'affiliation_domain': 'iastate.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper explores the computational complexity of total variation (TV) distance.  It presents a polynomial-time algorithm for determining the equivalence of mixtures of product distributions.  Conversely, it proves the computational intractability of estimating TV distance for arbitrary Ising models, unless NP is a subset of RP.
",xak8c9l1nu,Computational Explorations of Total Variation Distance,https://openreview.net/pdf/6e8a05bb3916372d453630aead0f422d343d66c3.pdf,False
poster,"[{'name': 'SUBBA REDDY OOTA', 'openreview_id': '~SUBBA_REDDY_OOTA1', 'affiliation_name': 'INRIA', 'affiliation_domain': 'inria.fr', 'affiliation_country': 'FR'}, {'name': 'Akshett Rai Jindal', 'openreview_id': '~Akshett_Rai_Jindal1', 'affiliation_name': 'International Institute of Information Technology, Hyderabad, International Institute of Information Technology Hyderabad', 'affiliation_domain': 'research.iiit.ac.in', 'affiliation_country': 'IN'}, {'name': 'Ishani Mondal', 'openreview_id': '~Ishani_Mondal1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'US'}, {'name': 'Khushbu Pahwa', 'openreview_id': '~Khushbu_Pahwa1', 'affiliation_name': 'Amazon', 'affiliation_domain': 'amazon.com', 'affiliation_country': 'US'}, {'name': 'Satya Sai Srinath Namburi GNVV', 'openreview_id': '~Satya_Sai_Srinath_Namburi_GNVV1', 'affiliation_name': 'GE HealthCare', 'affiliation_domain': 'gehealthcare.com', 'affiliation_country': 'US'}, {'name': 'Manish Shrivastava', 'openreview_id': '~Manish_Shrivastava1', 'affiliation_name': 'International Institute of Information Technology Hyderabad, India', 'affiliation_domain': 'iiit.ac.in', 'affiliation_country': 'IN'}, {'name': 'Maneesh Kumar Singh', 'openreview_id': '~Maneesh_Kumar_Singh1', 'affiliation_name': 'Spector Inc', 'affiliation_domain': 'spector.com', 'affiliation_country': 'US'}, {'name': 'Manish Gupta', 'openreview_id': '~Manish_Gupta1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper investigates how instruction-tuned multimodal large language models (MLLMs) align with brain activity during visual processing.  Specifically, it examines whether MLLMs, prompted with natural instructions, improve brain alignment compared to vision-only models and non-instruction-tuned MLLMs.  The results suggest that MLLMs effectively capture instruction-specific visual concepts, leading to better prediction of neural responses, though not all instructions are equally relevant.
",xkgfLXZ4e0,Correlating instruction-tuning (in multimodal models) with vision-language processing (in the brain),https://openreview.net/pdf/ad1526ba5aa0fcd86c14372acef3466b9e018680.pdf,False
poster,"[{'name': 'Kenneth Enevoldsen', 'openreview_id': '~Kenneth_Enevoldsen1', 'affiliation_name': 'Aarhus University', 'affiliation_domain': 'au.dk', 'affiliation_country': 'DK'}, {'name': 'Isaac Chung', 'openreview_id': '~Isaac_Chung1', 'affiliation_name': 'Zendesk', 'affiliation_domain': 'zendesk.com', 'affiliation_country': 'EE'}, {'name': 'Imene Kerboua', 'openreview_id': '~Imene_Kerboua1', 'affiliation_name': 'INSA Lyon, LIRIS', 'affiliation_domain': 'liris.cnrs.fr', 'affiliation_country': 'FR'}, {'name': 'Márton Kardos', 'openreview_id': '~Márton_Kardos1', 'affiliation_name': 'Aarhus University', 'affiliation_domain': 'au.dk', 'affiliation_country': 'DK'}, {'name': 'Ashwin Mathur', 'openreview_id': '~Ashwin_Mathur1', 'affiliation_name': 'Open Source', 'affiliation_domain': 'github.com', 'affiliation_country': 'IN'}, {'name': 'David Stap', 'openreview_id': '~David_Stap1', 'affiliation_name': 'University of Amsterdam', 'affiliation_domain': 'uva.nl', 'affiliation_country': 'NL'}, {'name': 'Jay Gala', 'openreview_id': '~Jay_Gala1', 'affiliation_name': 'Mohamed bin Zayed University of Artificial Intelligence', 'affiliation_domain': 'mbzuai.ac.ae', 'affiliation_country': 'AE'}, {'name': '', 'openreview_id': '~Wissam_Siblini1', 'affiliation_name': 'Individual Contributor', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': 'Dominik Krzemiński', 'openreview_id': '~Dominik_Krzemiński1', 'affiliation_name': 'Individual Contributor', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': 'Genta Indra Winata', 'openreview_id': '~Genta_Indra_Winata1', 'affiliation_name': 'Capital One', 'affiliation_domain': 'capitalone.com', 'affiliation_country': 'US'}, {'name': 'Saba Sturua', 'openreview_id': '~Saba_Sturua1', 'affiliation_name': 'Jina AI', 'affiliation_domain': 'jina.ai', 'affiliation_country': 'AI'}, {'name': 'Saiteja Utpala', 'openreview_id': '~Saiteja_Utpala1', 'affiliation_name': 'University of California, Santa Barbara', 'affiliation_domain': 'ucsb.edu', 'affiliation_country': 'US'}, {'name': 'Mathieu Ciancone', 'openreview_id': '~Mathieu_Ciancone1', 'affiliation_name': 'Wikit', 'affiliation_domain': 'wiki.ai', 'affiliation_country': 'FR'}, {'name': 'Marion Schaeffer', 'openreview_id': '~Marion_Schaeffer1', 'affiliation_name': 'Institut National des Sciences Appliquées de Rouen', 'affiliation_domain': 'insa-rouen.fr', 'affiliation_country': 'FR'}, {'name': 'Shreeya Dhakal', 'openreview_id': '~Shreeya_Dhakal1', 'affiliation_name': 'icodeformybhasa', 'affiliation_domain': 'icodeformybhasa.com', 'affiliation_country': 'US'}, {'name': 'Jonathan Rystrøm', 'openreview_id': '~Jonathan_Rystrøm1', 'affiliation_name': 'University of Oxford', 'affiliation_domain': 'ox.ac.uk', 'affiliation_country': 'GB'}, {'name': 'Roman Solomatin', 'openreview_id': '~Roman_Solomatin1', 'affiliation_name': 'ITMO University', 'affiliation_domain': 'itmo.ru', 'affiliation_country': 'RU'}, {'name': 'Ömer Veysel Çağatan', 'openreview_id': '~Ömer_Veysel_Çağatan1', 'affiliation_name': 'N/A', 'affiliation_domain': 'github.io', 'affiliation_country': 'TR'}, {'name': 'Akash Kundu', 'openreview_id': '~Akash_Kundu2', 'affiliation_name': 'Heritage Institute of Technology', 'affiliation_domain': 'heritageit.edu', 'affiliation_country': 'IN'}, {'name': 'Martin Bernstorff', 'openreview_id': '~Martin_Bernstorff1', 'affiliation_name': 'Aarhus University', 'affiliation_domain': 'au.dk', 'affiliation_country': 'DK'}, {'name': 'Shitao Xiao', 'openreview_id': '~Shitao_Xiao1', 'affiliation_name': 'Beijing Academy of Artificial Intelligence', 'affiliation_domain': 'baai.ac.cn', 'affiliation_country': 'CN'}, {'name': 'Akshita Sukhlecha', 'openreview_id': '~Akshita_Sukhlecha1', 'affiliation_name': 'Individual Contributor', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': 'Bhavish Pahwa', 'openreview_id': '~Bhavish_Pahwa1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': 'Rafał Poświata', 'openreview_id': '~Rafał_Poświata1', 'affiliation_name': 'National Information Processing Institute', 'affiliation_domain': 'opi.org.pl', 'affiliation_country': 'PL'}, {'name': '', 'openreview_id': '~Kranthi_Kiran_GV1', 'affiliation_name': 'DataChat', 'affiliation_domain': 'datachat.ai', 'affiliation_country': 'AI'}, {'name': 'Shawon Ashraf', 'openreview_id': '~Shawon_Ashraf1', 'affiliation_name': 'ellamind GmbH', 'affiliation_domain': 'ellamind.com', 'affiliation_country': 'DE'}, {'name': 'Daniel Auras', 'openreview_id': '~Daniel_Auras1', 'affiliation_name': 'ellamind GmbH', 'affiliation_domain': 'ellamind.com', 'affiliation_country': 'DE'}, {'name': 'Björn Plüster', 'openreview_id': '~Björn_Plüster1', 'affiliation_name': 'Universität Hamburg', 'affiliation_domain': 'uni-hamburg.de', 'affiliation_country': 'DE'}, {'name': 'Jan Philipp Harries', 'openreview_id': '~Jan_Philipp_Harries1', 'affiliation_name': 'University of Wuppertal', 'affiliation_domain': 'uni-wuppertal.de', 'affiliation_country': 'DE'}, {'name': 'Loïc Magne', 'openreview_id': '~Loïc_Magne1', 'affiliation_name': 'Individual Contributor', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': 'Isabelle Mohr', 'openreview_id': '~Isabelle_Mohr1', 'affiliation_name': 'Jina AI', 'affiliation_domain': 'jina.ai', 'affiliation_country': 'DE'}, {'name': 'Dawei Zhu', 'openreview_id': '~Dawei_Zhu2', 'affiliation_name': 'Peking University', 'affiliation_domain': 'pku.edu.cn', 'affiliation_country': 'CN'}, {'name': 'Hippolyte Gisserot-Boukhlef', 'openreview_id': '~Hippolyte_Gisserot-Boukhlef1', 'affiliation_name': 'CentraleSupelec', 'affiliation_domain': 'centralesupelec.fr', 'affiliation_country': 'FR'}, {'name': 'Tom Aarsen', 'openreview_id': '~Tom_Aarsen1', 'affiliation_name': 'Hugging Face', 'affiliation_domain': 'huggingface.co', 'affiliation_country': 'NL'}, {'name': 'Jan Kostkan', 'openreview_id': '~Jan_Kostkan1', 'affiliation_name': 'Aarhus University', 'affiliation_domain': 'chc.au.dk', 'affiliation_country': 'DK'}, {'name': 'Konrad Wojtasik', 'openreview_id': '~Konrad_Wojtasik1', 'affiliation_name': 'Technical University of Wroclaw', 'affiliation_domain': 'pwr.edu.pl', 'affiliation_country': 'PL'}, {'name': 'Taemin Lee', 'openreview_id': '~Taemin_Lee1', 'affiliation_name': 'Korea University', 'affiliation_domain': 'korea.ac.kr', 'affiliation_country': 'KR'}, {'name': 'Marek Suppa', 'openreview_id': '~Marek_Suppa1', 'affiliation_name': 'Comenius University in Bratislava', 'affiliation_domain': 'uniba.sk', 'affiliation_country': 'SK'}, {'name': 'Roberta Rocca', 'openreview_id': '~Roberta_Rocca1', 'affiliation_name': 'Aarhus University', 'affiliation_domain': 'au.dk', 'affiliation_country': 'DK'}, {'name': 'Mohammed Hamdy', 'openreview_id': '~Mohammed_Hamdy1', 'affiliation_name': 'Independent', 'affiliation_domain': 'gmail.com', 'affiliation_country': 'US'}, {'name': 'Andrianos Michail', 'openreview_id': '~Andrianos_Michail1', 'affiliation_name': 'University of Zurich', 'affiliation_domain': 'uzh.ch', 'affiliation_country': 'CH'}, {'name': 'John Yang', 'openreview_id': '~John_Yang3', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}, {'name': 'Manuel Faysse', 'openreview_id': '~Manuel_Faysse1', 'affiliation_name': 'CentraleSupelec', 'affiliation_domain': 'centralesupelec.fr', 'affiliation_country': 'FR'}, {'name': 'Aleksei Vatolin', 'openreview_id': '~Aleksei_Vatolin1', 'affiliation_name': 'Federal Research Center «Computer Science and Control» of Russian Academy of Sciences', 'affiliation_domain': 'frccsc.ru', 'affiliation_country': 'RU'}, {'name': 'Nandan Thakur', 'openreview_id': '~Nandan_Thakur1', 'affiliation_name': 'University of Waterloo', 'affiliation_domain': 'uwaterloo.ca', 'affiliation_country': 'CA'}, {'name': 'Manan Dey', 'openreview_id': '~Manan_Dey2', 'affiliation_name': 'Salesforce', 'affiliation_domain': 'salesforce.com', 'affiliation_country': 'US'}, {'name': 'Dipam Vasani', 'openreview_id': '~Dipam_Vasani1', 'affiliation_name': 'Individual Contributor', 'affiliation_domain': 'UNK', 'affiliation_country': 'UNK'}, {'name': 'Pranjal A Chitale', 'openreview_id': '~Pranjal_A_Chitale1', 'affiliation_name': 'Microsoft Research', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': 'Simone Tedeschi', 'openreview_id': '~Simone_Tedeschi1', 'affiliation_name': 'University of Roma ""La Sapienza""', 'affiliation_domain': 'uniroma1.it', 'affiliation_country': 'IT'}, {'name': 'Nguyen Tai', 'openreview_id': '~Nguyen_Tai1', 'affiliation_name': 'University of Pennsylvania, University of Pennsylvania', 'affiliation_domain': 'upenn.edu', 'affiliation_country': 'US'}, {'name': 'Artem Snegirev', 'openreview_id': '~Artem_Snegirev1', 'affiliation_name': 'SaluteDevices', 'affiliation_domain': 'salutedevices.org', 'affiliation_country': 'US'}, {'name': 'Mariya Hendriksen', 'openreview_id': '~Mariya_Hendriksen1', 'affiliation_name': 'Research, Microsoft', 'affiliation_domain': 'research.microsoft.com', 'affiliation_country': 'GB'}, {'name': 'Michael Günther', 'openreview_id': '~Michael_Günther1', 'affiliation_name': 'Jina AI', 'affiliation_domain': 'jina.ai', 'affiliation_country': 'DE'}, {'name': '', 'openreview_id': '~Mengzhou_Xia1', 'affiliation_name': 'Princeton University', 'affiliation_domain': 'princeton.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Weijia_Shi1', 'affiliation_name': 'University of Washington, Seattle', 'affiliation_domain': 'uw.edu', 'affiliation_country': 'US'}, {'name': 'Xing Han Lù', 'openreview_id': '~Xing_Han_Lù1', 'affiliation_name': 'McGill University', 'affiliation_domain': 'mcgill.ca', 'affiliation_country': 'CA'}, {'name': 'Jordan Clive', 'openreview_id': '~Jordan_Clive1', 'affiliation_name': 'Chattermill', 'affiliation_domain': 'chattermill.io', 'affiliation_country': 'GB'}, {'name': 'Gayatri K', 'openreview_id': '~Gayatri_K1', 'affiliation_name': 'R V College of Engineering', 'affiliation_domain': 'rvce.edu.in', 'affiliation_country': 'IN'}, {'name': 'Maksimova Anna', 'openreview_id': '~Maksimova_Anna1', 'affiliation_name': 'Higher School of Economics, Higher School of Economics', 'affiliation_domain': 'edu.hse.ru', 'affiliation_country': 'RU'}, {'name': 'Silvan Wehrli', 'openreview_id': '~Silvan_Wehrli1', 'affiliation_name': 'Robert Koch Institute', 'affiliation_domain': 'rki.de', 'affiliation_country': 'DE'}, {'name': 'Maria Tikhonova', 'openreview_id': '~Maria_Tikhonova1', 'affiliation_name': 'Higher School of Economics', 'affiliation_domain': 'hse.ru', 'affiliation_country': 'RU'}, {'name': 'Henil Shalin Panchal', 'openreview_id': '~Henil_Shalin_Panchal1', 'affiliation_name': 'Institute of Technology,Nirma University', 'affiliation_domain': 'nirmauni.ac.in', 'affiliation_country': 'IN'}, {'name': 'Aleksandr Abramov', 'openreview_id': '~Aleksandr_Abramov1', 'affiliation_name': 'SaluteDevices', 'affiliation_domain': 'UNK', 'affiliation_country': 'US'}, {'name': 'Malte Ostendorff', 'openreview_id': '~Malte_Ostendorff1', 'affiliation_name': 'Deutsche Telekom', 'affiliation_domain': 'telekom.de', 'affiliation_country': 'DE'}, {'name': 'Zheng Liu', 'openreview_id': '~Zheng_Liu4', 'affiliation_name': 'Research, Microsoft', 'affiliation_domain': 'research.microsoft.com', 'affiliation_country': 'CN'}, {'name': '', 'openreview_id': '~Simon_Clematide1', 'affiliation_name': 'University of Zurich', 'affiliation_domain': 'uzh.ch', 'affiliation_country': 'CH'}, {'name': 'Lester James Validad Miranda', 'openreview_id': '~Lester_James_Validad_Miranda1', 'affiliation_name': 'Allen Institute for Artificial Intelligence', 'affiliation_domain': 'allenai.org', 'affiliation_country': 'US'}, {'name': 'Alena Fenogenova', 'openreview_id': '~Alena_Fenogenova1', 'affiliation_name': 'SaluteDevices', 'affiliation_domain': 'UNK', 'affiliation_country': 'US'}, {'name': 'Ruqiya Bin Safi', 'openreview_id': '~Ruqiya_Bin_Safi1', 'affiliation_name': 'The London Institute of Banking & Finance', 'affiliation_domain': 'libf.ac.uk', 'affiliation_country': 'GB'}, {'name': 'Wen-Ding Li', 'openreview_id': '~Wen-Ding_Li1', 'affiliation_name': 'Cornell University', 'affiliation_domain': 'cornell.edu', 'affiliation_country': 'US'}, {'name': 'Alessia Borghini', 'openreview_id': '~Alessia_Borghini1', 'affiliation_name': 'Sapienza University of Rome', 'affiliation_domain': 'uniroma1.it', 'affiliation_country': 'IT'}, {'name': 'Federico Cassano', 'openreview_id': '~Federico_Cassano1', 'affiliation_name': 'Cursor AI', 'affiliation_domain': 'cursor.com', 'affiliation_country': 'US'}, {'name': 'Lasse Hansen', 'openreview_id': '~Lasse_Hansen2', 'affiliation_name': 'Aarhus University', 'affiliation_domain': 'au.dk', 'affiliation_country': 'DK'}, {'name': 'Sara Hooker', 'openreview_id': '~Sara_Hooker2', 'affiliation_name': 'Cohere For AI', 'affiliation_domain': 'cohere.com', 'affiliation_country': 'US'}, {'name': 'Chenghao Xiao', 'openreview_id': '~Chenghao_Xiao1', 'affiliation_name': 'Durham University', 'affiliation_domain': 'durham.ac.uk', 'affiliation_country': 'GB'}, {'name': 'Vaibhav Adlakha', 'openreview_id': '~Vaibhav_Adlakha1', 'affiliation_name': 'McGill University', 'affiliation_domain': 'mcgill.ca', 'affiliation_country': 'CA'}, {'name': 'Orion Weller', 'openreview_id': '~Orion_Weller1', 'affiliation_name': 'Johns Hopkins University', 'affiliation_domain': 'jhu.edu', 'affiliation_country': 'US'}, {'name': 'Siva Reddy', 'openreview_id': '~Siva_Reddy1', 'affiliation_name': 'ServiceNow Inc', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'CA'}, {'name': 'Niklas Muennighoff', 'openreview_id': '~Niklas_Muennighoff1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,False,"This paper introduces MMTEB, a massive multilingual text embedding benchmark.  It aims to provide a more comprehensive evaluation of text embeddings by expanding upon the existing MTEB benchmark, expanding its scope to over 500 tasks across multiple languages and introducing challenging, novel tasks.  The authors utilize this expanded benchmark to evaluate various multilingual models.
",zl3pfz4VCV,MMTEB: Massive Multilingual Text Embedding Benchmark,https://openreview.net/pdf/7bf08b41c76111ea7d40d27a3d73670c7eb4c75d.pdf,False
poster,"[{'name': 'Ashish Kumar', 'openreview_id': '~Ashish_Kumar2', 'affiliation_name': 'ScorelabsAI, USA', 'affiliation_domain': 'scorelabsai.com', 'affiliation_country': 'IN'}, {'name': 'Jaesik Park', 'openreview_id': '~Jaesik_Park3', 'affiliation_name': 'Seoul National University', 'affiliation_domain': 'snu.ac.kr', 'affiliation_country': 'KR'}]",ui/indiaml-tracker/public/tracker/iclr-2025.json,True,"This paper introduces CoSNet, a new convolutional neural network (ConvNet) design focused on resource-constrained deployments.  CoSNet aims to improve upon existing concise ConvNets by considering factors beyond runtime optimization, such as computational cost (FLOPs and parameters), in addition to depth reduction.  The proposed design specifically targets efficient resource use through a novel columnar stacking methodology, while maintaining competitive performance with existing state-of-the-art ConvNets.
",zvaiz3FjA9,Designing Concise ConvNets with Columnar Stages,https://openreview.net/pdf/8eb49e491feecae804537675c711f98f57149f2f.pdf,True
poster,"[{'name': 'Arnab Bhattacharyya', 'openreview_id': '~Arnab_Bhattacharyya1', 'affiliation_name': 'The University of Warwick', 'affiliation_domain': 'warwick.ac.uk', 'affiliation_country': 'GB'}, {'name': 'Sutanu Gayen', 'openreview_id': '~Sutanu_Gayen1', 'affiliation_name': 'Indian Institute of Technology, Kanpur', 'affiliation_domain': 'iitk.ac.in', 'affiliation_country': 'IN'}, {'name': 'Kuldeep S. Meel', 'openreview_id': '~Kuldeep_S._Meel2', 'affiliation_name': 'Department of Computer Science', 'affiliation_domain': 'cs.toronto.edu', 'affiliation_country': 'CA'}, {'name': 'Dimitrios Myrisiotis', 'openreview_id': '~Dimitrios_Myrisiotis1', 'affiliation_name': 'CNRS@CREATE LTD.', 'affiliation_domain': 'cnrsatcreate.cnrs.fr', 'affiliation_country': 'FR'}, {'name': 'A. Pavan', 'openreview_id': '~A._Pavan1', 'affiliation_name': 'Iowa State University', 'affiliation_domain': 'iastate.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,False,"This paper establishes a novel link between total variation distance estimation and probabilistic inference in graphical models.  It presents an efficient algorithm for approximating total variation distance between probability distributions defined over Bayes nets with small treewidth.  Prior methods only handled product distributions; this new approach employs partial couplings of high-dimensional distributions.
",6OSLjErBhh,Total Variation Distance Meets Probabilistic Inference,https://openreview.net/pdf/e6ffa80506c26dd3909c142042ed7744ef824792.pdf,False
poster,"[{'name': 'Dheeraj Baby', 'openreview_id': '~Dheeraj_Baby1', 'affiliation_name': 'Amazon', 'affiliation_domain': 'amazon.com', 'affiliation_country': 'US'}, {'name': 'Soumyabrata Pal', 'openreview_id': '~Soumyabrata_Pal1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,True,"This paper investigates online matrix completion for recommendation systems, focusing on the efficient recommendation of items to users.  The authors propose two algorithms, PHASEDCLUSTERELIM and DETERMINANTELIM, that leverage user collaboration to reduce the number of sub-optimal items in phases.  These algorithms aim to minimize regret in the face of noisy reward feedback, achieving near-optimal per-user regret bounds.
",7XZKzQtooN,Online Matrix Completion: A Collaborative Approach with Hott Items,https://openreview.net/pdf/a47b0150343c512aed145c5634271d63eea7b922.pdf,False
poster,"[{'name': '', 'openreview_id': '~Gugan_Thoppe1', 'affiliation_name': 'Indian Institute of Science', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': 'Prashanth L. A.', 'openreview_id': '~Prashanth_L_A1', 'affiliation_name': 'Indian Institute of Technology, Madras', 'affiliation_domain': 'iitm.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Sanjay_P._Bhat1', 'affiliation_name': 'Tata Consultancy Services Limited, India', 'affiliation_domain': 'tcs.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,True,"This paper analyzes the computational cost of estimating risk measures, such as variance, Value-at-Risk (VaR), and Conditional Value-at-Risk (CVaR), for infinite-horizon discounted Markov cost processes.  It derives lower and upper bounds for estimating these risk measures, demonstrating that  Ω(1/ϵ<sup>2</sup>) samples are required for ϵ-accuracy, both in expectation and in high probability scenarios.  The findings extend to other risk measures that meet a specific continuity criterion.
",7xzhKEPfBo,Risk Estimation in a Markov Cost Process: Lower and Upper Bounds,https://openreview.net/pdf/61c68b6da42e9185837b464227ecbcbc75504505.pdf,True
poster,"[{'name': 'Kumar Shubham', 'openreview_id': '~Kumar_Shubham1', 'affiliation_name': 'Indian Institute of Science, Indian institute of science, Bangalore', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': 'Aishwarya Jayagopal', 'openreview_id': '~Aishwarya_Jayagopal1', 'affiliation_name': 'National University of Singapore', 'affiliation_domain': 'u.nus.edu', 'affiliation_country': 'SG'}, {'name': 'Syed Mohammed Danish', 'openreview_id': '~Syed_Mohammed_Danish1', 'affiliation_name': 'Indian Institute of Technology, Patna', 'affiliation_domain': 'iitp.ac.in', 'affiliation_country': 'IN'}, {'name': 'Prathosh AP', 'openreview_id': '~Prathosh_AP1', 'affiliation_name': 'Indian Institute of Science, Indian institute of science, Bangalore', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': 'Vaibhav Rajan', 'openreview_id': '~Vaibhav_Rajan2', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,True,"This paper introduces WISER, a novel method for predicting personalized drug responses in cancer patients.  It leverages weak supervision in conjunction with supervised representation learning to overcome the challenges of limited drug response data and heterogeneous patient responses.  The method aims to improve upon existing techniques by integrating both supervision stages for enhanced drug response prediction accuracy.
",8ySQaphUYH,WISER: Weak Supervision and Supervised Representation Learning to Improve Drug Response Prediction in Cancer,https://openreview.net/pdf/07f74f6818e7261951b0dfd09d5666e670e5e9d0.pdf,True
poster,"[{'name': 'Pratik Bhowal', 'openreview_id': '~Pratik_Bhowal1', 'affiliation_name': 'CMU, Carnegie Mellon University', 'affiliation_domain': 'andrew.cmu.edu', 'affiliation_country': 'IN'}, {'name': 'Achint Soni', 'openreview_id': '~Achint_Soni1', 'affiliation_name': 'University of Waterloo', 'affiliation_domain': 'uwaterloo.ca', 'affiliation_country': 'CA'}, {'name': 'Sirisha Rambhatla', 'openreview_id': '~Sirisha_Rambhatla1', 'affiliation_name': 'University of Waterloo', 'affiliation_domain': 'uwaterloo.ca', 'affiliation_country': 'CA'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,False,"This paper aims to theoretically investigate how the orthogonality properties of variational autoencoder (VAE) decoders contribute to disentanglement in real-world applications.  The authors hypothesize that decoder orthogonality is key to disentanglement, a concept crucial for latent space manipulation in various fields.  Through both theoretical analysis and experimental results, they seek to validate this hypothesis in practical VAE setups.
",Ao9UUaScAU,Why do Variational Autoencoders Really Promote Disentanglement?,https://openreview.net/pdf/71efc1da1d0fe38f66103886bdf9d41d7a430479.pdf,True
poster,"[{'name': 'Shikhar Mohan', 'openreview_id': '~Shikhar_Mohan1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': 'Deepak Saini', 'openreview_id': '~Deepak_Saini2', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'US'}, {'name': 'Anshul Mittal', 'openreview_id': '~Anshul_Mittal2', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': 'Sayak Ray Chowdhury', 'openreview_id': '~Sayak_Ray_Chowdhury1', 'affiliation_name': 'Indian Institute of Technology, Kanpur', 'affiliation_domain': 'iitk.ac.in', 'affiliation_country': 'IN'}, {'name': 'Bhawna Paliwal', 'openreview_id': '~Bhawna_Paliwal1', 'affiliation_name': 'Microsoft Research', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'US'}, {'name': 'Jian Jiao', 'openreview_id': '~Jian_Jiao2', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'US'}, {'name': 'Manish Gupta', 'openreview_id': '~Manish_Gupta4', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Manik_Varma1', 'affiliation_name': 'Research, Microsoft', 'affiliation_domain': 'research.microsoft.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,True,"This paper introduces OAK, a novel framework for eXtreme Classification (XC).  OAK leverages auxiliary knowledge linked to documents to improve classification accuracy by enriching document embeddings with auxiliary knowledge embeddings.  The framework demonstrates superior performance compared to existing state-of-the-art XC methods on various datasets and in sponsored search applications.
",Cbacx90Wkt,OAK: Enriching Document Representations using Auxiliary Knowledge for Extreme Classification,https://openreview.net/pdf/c0530913b6c22d453b2332a2be5cbf1c57e67ff0.pdf,True
poster,"[{'name': 'Zakhar Shumaylov', 'openreview_id': '~Zakhar_Shumaylov1', 'affiliation_name': 'University of Cambridge', 'affiliation_domain': 'cam.ac.uk', 'affiliation_country': 'GB'}, {'name': 'Jeremy Budd', 'openreview_id': '~Jeremy_Budd1', 'affiliation_name': 'California Institute of Technology', 'affiliation_domain': 'caltech.edu', 'affiliation_country': 'US'}, {'name': 'Subhadip Mukherjee', 'openreview_id': '~Subhadip_Mukherjee1', 'affiliation_name': 'Indian Institute of Technology Kharagpur', 'affiliation_domain': 'iitkgp.ernet.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Carola-Bibiane_Schönlieb1', 'affiliation_name': 'University of Cambridge', 'affiliation_domain': 'cam.ac.uk', 'affiliation_country': 'GB'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,False,"This paper investigates the convergence of critical points for variational regularisation in inverse problems, particularly focusing on weakly convex regularisers.  It develops a generalized framework for convergence analysis, proving the convergence of the primal-dual hybrid gradient method for associated variational problems.  Finally, the paper applies these theoretical findings to learned regularisation, demonstrating improved performance in, for example, computed tomography reconstruction.
",E8FpcUyPuS,Weakly Convex Regularisers for Inverse Problems: Convergence of Critical Points and Primal-Dual Optimisation,https://openreview.net/pdf/b0eb7cb8f2998339c2df68fb673e093522aa7257.pdf,False
poster,"[{'name': 'Shashwat Singh', 'openreview_id': '~Shashwat_Singh1', 'affiliation_name': 'International Institute of Information Technology Hyderabad', 'affiliation_domain': 'iiit.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Shauli_Ravfogel1', 'affiliation_name': 'Bar-Ilan University', 'affiliation_domain': 'biu.ac.il', 'affiliation_country': 'IL'}, {'name': 'Jonathan Herzig', 'openreview_id': '~Jonathan_Herzig2', 'affiliation_name': 'Research, Google', 'affiliation_domain': 'research.google.com', 'affiliation_country': 'US'}, {'name': 'Roee Aharoni', 'openreview_id': '~Roee_Aharoni1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': 'Ryan Cotterell', 'openreview_id': '~Ryan_Cotterell1', 'affiliation_name': 'Swiss Federal Institute of Technology', 'affiliation_domain': 'ethz.ch', 'affiliation_country': 'CH'}, {'name': 'Ponnurangam Kumaraguru', 'openreview_id': '~Ponnurangam_Kumaraguru3', 'affiliation_name': 'International Institute of Information Technology Hyderabad ', 'affiliation_domain': 'iiit.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,False,"This paper develops a theoretical framework and practical methods for ""steering"" neural language model representations to reduce undesirable behaviors, such as generating toxic or biased text.  Specifically, it derives optimal affine steering functions to modify model representations, providing justification for existing techniques and proposing an improved approach.  Empirical experiments demonstrate the effectiveness of these methods in mitigating biases and reducing toxic content generation.
",GwA4go0Mw4,Representation Surgery: Theory and Practice of Affine Steering,https://openreview.net/pdf/b913a137f582939ceef4f0e95b210de1e8e9e8cc.pdf,True
poster,"[{'name': 'Kirankumar Shiragur', 'openreview_id': '~Kirankumar_Shiragur1', 'affiliation_name': 'Microsoft Research', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': 'Jiaqi Zhang', 'openreview_id': '~Jiaqi_Zhang2', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Caroline_Uhler1', 'affiliation_name': 'Electrical Engineering & Computer Science, Massachusetts Institute of Technology', 'affiliation_domain': 'eecs.mit.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,False,"This paper addresses the computational limitations of existing causal discovery algorithms, which often require an exponential number of conditional independence tests.  It proposes a new method, the Causal Consistent Partition Graph (CCPG), that learns a coarser representation of the causal graph using a polynomial number of tests.  This approach aims to provide an efficient algorithm for recovering the true causal graph in specific cases, particularly when the graph is fully identifiable.
",HpT19AKddu,Causal Discovery with Fewer Conditional Independence Tests,https://openreview.net/pdf/23331b236f09db1c4293895ed7d92c5d7c76991f.pdf,True
poster,"[{'name': 'Pravendra Singh', 'openreview_id': '~Pravendra_Singh1', 'affiliation_name': 'Indian Institute of Technology, Roorkee', 'affiliation_domain': 'iitr.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,True,"This research paper introduces a novel self-supervised approach, SSWDP, for trajectory prediction.  The goal is to enhance representation learning for improved trajectory prediction accuracy by predicting distortion within observed trajectories.  The authors aim to complement existing methods and demonstrate significant improvements on various benchmark datasets, particularly in environments with distortions.
",OQ7TlOphGX,Enhancing Trajectory Prediction through Self-Supervised Waypoint Distortion Prediction,https://openreview.net/pdf/6f5199a867ae97c4ee3f4303b1afe90f767d9d65.pdf,True
poster,"[{'name': 'Tianjun Zhang', 'openreview_id': '~Tianjun_Zhang1', 'affiliation_name': 'University of California Berkeley', 'affiliation_domain': 'berkeley.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Aman_Madaan1', 'affiliation_name': 'Carnegie Mellon University', 'affiliation_domain': 'cmu.edu', 'affiliation_country': 'US'}, {'name': 'Luyu Gao', 'openreview_id': '~Luyu_Gao1', 'affiliation_name': 'Carnegie Mellon University', 'affiliation_domain': 'cmu.edu', 'affiliation_country': 'US'}, {'name': 'Steven Zheng', 'openreview_id': '~Steven_Zheng1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': 'Swaroop Mishra', 'openreview_id': '~Swaroop_Mishra1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Yiming_Yang1', 'affiliation_name': 'School of Computer Science, Carnegie Mellon University', 'affiliation_domain': 'cs.cmu.edu', 'affiliation_country': 'US'}, {'name': 'Niket Tandon', 'openreview_id': '~Niket_Tandon2', 'affiliation_name': 'Research, Microsoft', 'affiliation_domain': 'research.microsoft.com', 'affiliation_country': 'IN'}, {'name': 'Uri Alon', 'openreview_id': '~Uri_Alon1', 'affiliation_name': 'Google DeepMind', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,False,"This paper introduces LEAP, a method for improving in-context learning (ICL) in large language models (LLMs).  LEAP intentionally induces errors in example input-output pairs, allowing the model to derive task-specific principles for solving similar problems.  These learned principles, combined with the original examples, then enhance the LLM's performance on unseen test data across various benchmarks, including question answering and math problems.
",PAPY0cAB3C,In-Context Principle Learning from Mistakes,https://openreview.net/pdf/2526010313edf53a746ebfa778cf15642b26a62c.pdf,False
poster,"[{'name': 'mohit sharma', 'openreview_id': '~mohit_sharma5', 'affiliation_name': 'Indraprastha Institute of Information Technology, Delhi', 'affiliation_domain': 'iiitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Amit Deshpande', 'openreview_id': '~Amit_Deshpande1', 'affiliation_name': 'Microsoft Research', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,True,"This paper extends previous research on fair classification by demonstrating how fairness constraints can recover accurate and fair classifiers even when the training data is significantly biased.  It generalizes these results to different types of bias, data distributions, and hypothesis classes.  The authors prove that under specific conditions, the optimal fair classifier on biased data equals the optimal classifier on unbiased data, thus suggesting that well-designed fairness constraints can mitigate data bias.
",RfQT6vJt8b,How Far Can Fairness Constraints Help Recover From Biased Data?,https://openreview.net/pdf/409965515edccbc49d377b009df2f47a57479ebd.pdf,True
poster,"[{'name': 'Aishwarya P S', 'openreview_id': '~Aishwarya_P_S1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': 'Yashas Samaga B L', 'openreview_id': '~Yashas_Samaga_B_L2', 'affiliation_name': 'University of Washington', 'affiliation_domain': 'uw.edu', 'affiliation_country': 'US'}, {'name': 'Toby James Boyd', 'openreview_id': '~Toby_James_Boyd1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': '', 'openreview_id': '~Sanjiv_Kumar1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Prateek_Jain1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Praneeth_Netrapalli1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,False,"This paper introduces Tandem Transformers, a novel architecture for large language models (LLMs).  The architecture combines a small, autoregressive model with a larger, block-mode model to accelerate inference.  The goal is to improve inference speed without sacrificing downstream task accuracy by strategically allocating capacity for prompt processing versus response generation.
",TN3fi7dwPo,Tandem Transformers for Inference Efficient LLMs,https://openreview.net/pdf/c14bbb8bb8638326ffae116b81072096457da928.pdf,True
spotlight,"[{'name': 'Aditya Gopalan', 'openreview_id': '~Aditya_Gopalan1', 'affiliation_name': 'Indian Institute of Science', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': 'Venkatesh Saligrama', 'openreview_id': '~Venkatesh_Saligrama1', 'affiliation_name': 'Amazon', 'affiliation_domain': 'amazon.com', 'affiliation_country': 'US'}, {'name': 'Clayton Scott', 'openreview_id': '~Clayton_Scott1', 'affiliation_name': 'University of Michigan', 'affiliation_domain': 'umich.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,False,"This paper investigates the feasibility testing of linear programs with bandit feedback.  It develops a novel test for determining if a linear program has a feasible solution, based on low-regret algorithms and a non-asymptotic law of iterated logarithms, within a linear bandit setting.  The method is shown to be reliable and adaptive to the signal level of the problem, with sample costs scaling efficiently.
",TfwGtfPkhV,Testing the Feasibility of Linear Programs with Bandit Feedback,https://openreview.net/pdf/a89b112bea8fde3d1e91d41d41e6dd7fdf86aff2.pdf,True
poster,"[{'name': 'Shubhada Agrawal', 'openreview_id': '~Shubhada_Agrawal1', 'affiliation_name': 'Carnegie Mellon University', 'affiliation_domain': 'cmu.edu', 'affiliation_country': 'US'}, {'name': 'Prashanth L. A.', 'openreview_id': '~Prashanth_L_A1', 'affiliation_name': 'Indian Institute of Technology, Madras', 'affiliation_domain': 'iitm.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Siva_Theja_Maguluri1', 'affiliation_name': 'Georgia Institute of Technology', 'affiliation_domain': 'gatech.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,False,"This paper develops a temporal-difference (TD) algorithm for evaluating policies in average reward reinforcement learning problems, focusing on asymptotic variance as a risk measure.  The algorithm, applicable to both tabular and linear function approximation settings, achieves a finite-time convergence rate of O(1/k) and provides the first sequential estimator for asymptotic variance with provable finite sample guarantees. This work aims to facilitate the development of variance-constrained reinforcement learning algorithms.
",bID9PiBFpT,Policy Evaluation for Variance in Average Reward Reinforcement Learning,https://openreview.net/pdf/3b877b3be936eb628fd438c4713ff612a784fae7.pdf,False
poster,"[{'name': '', 'openreview_id': '~Piyushi_Manupriya1', 'affiliation_name': 'Indian Institute of Technology Hyderabad', 'affiliation_domain': 'iith.ac.in', 'affiliation_country': 'IN'}, {'name': 'Pratik Jawanpuria', 'openreview_id': '~Pratik_Jawanpuria1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'US'}, {'name': 'Karthik S. Gurumoorthy', 'openreview_id': '~Karthik_S._Gurumoorthy2', 'affiliation_name': 'Walmart Global Tech', 'affiliation_domain': 'walmart.com', 'affiliation_country': 'IN'}, {'name': 'SakethaNath Jagarlapudi', 'openreview_id': '~SakethaNath_Jagarlapudi1', 'affiliation_name': 'Indian Institute of Technology Hyderabad', 'affiliation_domain': 'iith.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Bamdev_Mishra1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,True,"This paper introduces novel sparsity-constrained optimal transport (OT) formulations for unbalanced OT (UOT).  It leverages a submodular framework to efficiently optimize transport plans with a structured sparsity pattern.  The authors develop efficient algorithms with theoretical guarantees, demonstrating practical applicability in various domains.
",bfQCO9Vqhk,Submodular framework for structured-sparse optimal transport,https://openreview.net/pdf/15e9e2ce1a2a6304834b144d8443de2478e30aa7.pdf,True
poster,"[{'name': 'Avishek Ghosh', 'openreview_id': '~Avishek_Ghosh2', 'affiliation_name': 'Indian Institute of Technology, Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Arya_Mazumdar1', 'affiliation_name': 'University of California, San Diego', 'affiliation_domain': 'ucsd.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,True,"This paper investigates the agnostic learning of mixed linear regressions.  It demonstrates that the EM and AM algorithms, under specific conditions, can learn optimal solutions for the problem even without a generative model. The key is finding the set of linear functions that minimize a predefined loss function for a given dataset.
",eo88noTbb5,Agnostic Learning of Mixed Linear Regressions with EM and AM Algorithms,https://openreview.net/pdf/17a75d2d4ceb5ac28e380f4e82e1c0df8d09dbb8.pdf,True
poster,"[{'name': 'VIKAS DEEP', 'openreview_id': '~VIKAS_DEEP1', 'affiliation_name': 'Northwestern University', 'affiliation_domain': 'northwestern.edu', 'affiliation_country': 'US'}, {'name': 'Sandeep Kumar Juneja', 'openreview_id': '~Sandeep_Kumar_Juneja1', 'affiliation_name': 'Ashoka University', 'affiliation_domain': 'ashoka.edu.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,True,"This paper investigates estimating the average treatment effect (ATE) in A/B testing.  It develops asymptotically optimal and computationally efficient adaptive policies for constructing confidence intervals (CIs) for ATE.  The proposed methods minimize the expected sample size while guaranteeing a desired level of precision and confidence.
",eqIGoEoI10,Asymptotically Optimal and Computationally Efficient Average Treatment Effect Estimation in A/B testing,https://openreview.net/pdf/e6a6390164671b94fb6543bf8b3cc2674dbadc9d.pdf,False
poster,"[{'name': 'Utsav Singh', 'openreview_id': '~Utsav_Singh1', 'affiliation_name': 'Indian Institute of Technology, Kanpur', 'affiliation_domain': 'iitk.ac.in', 'affiliation_country': 'IN'}, {'name': 'Wesley A. Suttle', 'openreview_id': '~Wesley_A_Suttle1', 'affiliation_name': 'Army Research Laboratory', 'affiliation_domain': 'army.mil', 'affiliation_country': 'US'}, {'name': 'Brian M. Sadler', 'openreview_id': '~Brian_M._Sadler1', 'affiliation_name': 'University of Texas at Austin', 'affiliation_domain': 'utexas.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Vinay_P_Namboodiri1', 'affiliation_name': 'University of Bath', 'affiliation_domain': 'bath.ac.uk', 'affiliation_country': 'GB'}, {'name': 'Amrit Singh Bedi', 'openreview_id': '~Amrit_Bedi1', 'affiliation_name': 'University of Central Florida', 'affiliation_domain': 'ucf.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,False,"The paper introduces PIPER, a novel hierarchical reinforcement learning approach.  It aims to address the challenges of non-stationarity and infeasible subgoals by leveraging preference-based learning to create a reward model for relabeling replay buffers.  This approach, replacing human feedback with primitive-in-the-loop feedback using sparse rewards, shows improved performance in sparse-reward robotic tasks compared to existing baselines.
",l6Hef6FVd0,PIPER: Primitive-Informed Preference-based Hierarchical Reinforcement Learning via Hindsight Relabeling,https://openreview.net/pdf/486d2e3f8b1d6cd84cc050e257c70fda5c2f6980.pdf,True
poster,"[{'name': '', 'openreview_id': '~Shiv_Shankar2', 'affiliation_name': 'IIT Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Ritwik_Sinha1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Madalina Fiterau', 'openreview_id': '~Madalina_Fiterau3', 'affiliation_name': 'Department of Computer Science, University of Massachusetts, Amherst', 'affiliation_domain': 'cs.umass.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,False,"This paper introduces HIFIVE, a variational method for estimating global average treatment effects in online A/B testing.  The method addresses the challenge of fragmented user data across devices, a problem emerging from the decline of identifying user devices and the rise of multi-device usage.  HIFIVE aims to improve the accuracy and robustness of preference estimation for online experimentation under these conditions.
",merZTLSdC9,On Online Experimentation without Device Identifiers,https://openreview.net/pdf/0615d619c3602e2d636f310e2ddca4c631b9613c.pdf,True
poster,"[{'name': 'Gaurav Pandey', 'openreview_id': '~Gaurav_Pandey2', 'affiliation_name': 'International Business Machines', 'affiliation_domain': 'ibm.com', 'affiliation_country': 'US'}, {'name': 'Yatin Nandwani', 'openreview_id': '~Yatin_Nandwani1', 'affiliation_name': 'International Business Machines', 'affiliation_domain': 'ibm.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Tahira_Naseem1', 'affiliation_name': 'IBM, International Business Machines', 'affiliation_domain': 'us.ibm.com', 'affiliation_country': 'US'}, {'name': 'Mayank Mishra', 'openreview_id': '~Mayank_Mishra1', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}, {'name': 'Guangxuan Xu', 'openreview_id': '~Guangxuan_Xu1', 'affiliation_name': 'Red Hat. Inc', 'affiliation_domain': 'redhat.com', 'affiliation_country': 'US'}, {'name': 'Dinesh Raghu', 'openreview_id': '~Dinesh_Raghu1', 'affiliation_name': 'IBM Research - New Delhi', 'affiliation_domain': 'in.ibm.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Sachindra_Joshi1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Asim Munawar', 'openreview_id': '~Asim_Munawar2', 'affiliation_name': 'International Business Machines', 'affiliation_domain': 'ibm.com', 'affiliation_country': 'US'}, {'name': 'Ramón Fernandez Astudillo', 'openreview_id': '~Ramón_Fernandez_Astudillo1', 'affiliation_name': 'International Business Machines', 'affiliation_domain': 'ibm.com', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,False,"This research paper introduces BRAIN, a new reinforcement learning from human feedback (RLHF) method for natural language generation.  It aims to improve upon existing distribution matching techniques by reducing gradient variance and generalizing the target distribution using Bayesian methods.  The proposed approach, a bridge between distribution matching and Direct Preference Optimization (DPO), demonstrates superior performance on summarization and Antropic HH tasks compared to previous methods.
",nxzXTLByXO,BRAIn: Bayesian Reward-conditioned Amortized Inference for natural language generation from feedback,https://openreview.net/pdf/adec4b8db2c08af7cf38121b2b60680f89348c2c.pdf,False
poster,"[{'name': 'Lokesh Nagalapatti', 'openreview_id': '~Lokesh_Nagalapatti1', 'affiliation_name': 'Indian Institute of Technology, Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Avishek Ghosh', 'openreview_id': '~Avishek_Ghosh2', 'affiliation_name': 'Indian Institute of Technology, Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Sunita Sarawagi', 'openreview_id': '~Sunita_Sarawagi1', 'affiliation_name': 'IIT Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,True,"This paper introduces PairNet, a novel method for estimating individual treatment effects (ITE) from observational data.  PairNet avoids the use of potentially inaccurate pseudo-outcomes, focusing instead on observed outcomes in pairs of examples.  The theoretical analysis and empirical results demonstrate its superior performance compared to existing methods in estimating ITE.
",o5SVr80Rgg,PairNet: Training with Observed Pairs to Estimate Individual Treatment Effect,https://openreview.net/pdf/8542c0b81c30deb10c2d35fd220b4d912812d24a.pdf,True
poster,"[{'name': 'Achintya Nath', 'openreview_id': '~Achintya_Nath1', 'affiliation_name': 'Indian Institute of Technology, Roorkee', 'affiliation_domain': 'iitr.ac.in', 'affiliation_country': 'IO'}, {'name': 'Paritosh Kabra', 'openreview_id': '~Paritosh_Kabra1', 'affiliation_name': 'Indian Institute of Technology, Roorkee', 'affiliation_domain': 'iitr.ac.in', 'affiliation_country': 'IN'}, {'name': 'Ishu Gupta', 'openreview_id': '~Ishu_Gupta1', 'affiliation_name': 'Indian Institute of Technology, Roorkee, Dhirubhai Ambani Institute Of Information and Communication Technology', 'affiliation_domain': 'iitr.ac.in', 'affiliation_country': 'IN'}, {'name': 'Pravendra Singh', 'openreview_id': '~Pravendra_Singh1', 'affiliation_name': 'Indian Institute of Technology, Roorkee', 'affiliation_domain': 'iitr.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,True,"This paper proposes MS-TIP, a novel approach for pedestrian trajectory prediction that addresses missing data in observed sequences.  MS-TIP leverages transformers for imputation and multi-scale hypergraphs for interaction modeling, aiming to improve prediction accuracy by considering context and interactions at different scales.  The method includes a control point and refinement module for enhanced future trajectory inference.
",s4Hy0L4mml,MS-TIP: Imputation Aware Pedestrian Trajectory Prediction,https://openreview.net/pdf/1d8e4c1deb5aa09684e661e39df6dfe8bba15611.pdf,False
poster,"[{'name': 'Rahul Singh', 'openreview_id': '~Rahul_Singh5', 'affiliation_name': 'Indian Institute of Science', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': 'Akshay Mete', 'openreview_id': '~Akshay_Mete1', 'affiliation_name': 'Texas A&M University - College Station', 'affiliation_domain': 'tamu.edu', 'affiliation_country': 'US'}, {'name': 'Avik Kar', 'openreview_id': '~Avik_Kar1', 'affiliation_name': 'Indian Institute of Science, Indian institute of science, Bangalore', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Panganamala_Kumar1', 'affiliation_name': 'Texas A&M', 'affiliation_domain': 'tamu.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,True,"This paper introduces a novel algorithm, PIECE, for the self-tuning regulation problem, which aims to minimize the output variance of a system with an unknown model.  Crucially, the algorithm achieves a logarithmic regret bound for finite time, a significant improvement over existing methods for similar problems.  The proposed PIECE algorithm addresses the often problematic initial transient performance of reinforcement learning algorithms for linear systems by cleverly incorporating techniques for exploration and input clipping.
",tTtSnpH4fc,Finite Time Logarithmic Regret Bounds for Self-Tuning Regulation,https://openreview.net/pdf/a7f969be6c3977786d11395298655bfc29c99967.pdf,True
poster,"[{'name': 'Hiren Madhu', 'openreview_id': '~Hiren_Madhu1', 'affiliation_name': 'Yale University', 'affiliation_domain': 'yale.edu', 'affiliation_country': 'US'}, {'name': 'Sravanthi Gurugubelli', 'openreview_id': '~Sravanthi_Gurugubelli1', 'affiliation_name': 'Indian Institute of Science, Bangalore', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': 'Sundeep Prabhakar Chepuri', 'openreview_id': '~Sundeep_Prabhakar_Chepuri1', 'affiliation_name': 'Indian Institute of Science', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,True,"This paper introduces simplicial scattering networks (SSNs), a parameter-free model for learning task-agnostic features from simplicial complex data.  Unlike existing simplicial neural networks, SSNs avoid the high training complexity and reliance on task-specific labels by employing a scattering transform.  The proposed method uses random walk matrices to extract high-frequency information, demonstrating superior performance on various tasks like node classification and graph classification compared to existing simplicial or graph neural networks.
",wmljUnbjy6,Unsupervised Parameter-free Simplicial Representation Learning with Scattering Transforms,https://openreview.net/pdf/c86519c899c3ac54e7702b9fdcbb438886ce2c8c.pdf,False
poster,"[{'name': 'Nathaniel Li', 'openreview_id': '~Nathaniel_Li1', 'affiliation_name': 'University of California, Berkeley', 'affiliation_domain': 'berkeley.edu', 'affiliation_country': 'US'}, {'name': 'Alexander Pan', 'openreview_id': '~Alexander_Pan1', 'affiliation_name': 'University of California, Berkeley', 'affiliation_domain': 'berkeley.edu', 'affiliation_country': 'US'}, {'name': 'Anjali Gopal', 'openreview_id': '~Anjali_Gopal1', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}, {'name': 'Summer Yue', 'openreview_id': '~Summer_Yue2', 'affiliation_name': 'Scale AI', 'affiliation_domain': 'scale.ai', 'affiliation_country': 'US'}, {'name': 'Daniel Berrios', 'openreview_id': '~Daniel_Berrios1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Alice Gatti', 'openreview_id': '~Alice_Gatti1', 'affiliation_name': 'Center for AI Safety', 'affiliation_domain': 'safe.ai', 'affiliation_country': 'US'}, {'name': 'Justin D. Li', 'openreview_id': '~Justin_D._Li1', 'affiliation_name': 'New York University', 'affiliation_domain': 'nyu.edu', 'affiliation_country': 'US'}, {'name': 'Ann-Kathrin Dombrowski', 'openreview_id': '~Ann-Kathrin_Dombrowski1', 'affiliation_name': 'FAR.AI', 'affiliation_domain': 'far.ai', 'affiliation_country': 'US'}, {'name': 'Shashwat Goel', 'openreview_id': '~Shashwat_Goel1', 'affiliation_name': 'ELLIS, Max Planck Institute', 'affiliation_domain': 'tuebingen.mpg.de', 'affiliation_country': 'DE'}, {'name': 'Gabriel Mukobi', 'openreview_id': '~Gabriel_Mukobi1', 'affiliation_name': 'UC Berkeley, University of California, Berkeley', 'affiliation_domain': 'cs.berkeley.edu', 'affiliation_country': 'US'}, {'name': 'Nathan Helm-Burger', 'openreview_id': '~Nathan_Helm-Burger1', 'affiliation_name': 'SecureBio', 'affiliation_domain': 'securebio.org', 'affiliation_country': 'US'}, {'name': 'Rassin Lababidi', 'openreview_id': '~Rassin_Lababidi1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Lennart Justen', 'openreview_id': '~Lennart_Justen1', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}, {'name': 'Andrew Bo Liu', 'openreview_id': '~Andrew_Bo_Liu1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Michael Chen', 'openreview_id': '~Michael_Chen3', 'affiliation_name': 'Model Evaluation and Threat Research', 'affiliation_domain': 'metr.org', 'affiliation_country': 'US'}, {'name': 'Isabelle Barrass', 'openreview_id': '~Isabelle_Barrass1', 'affiliation_name': 'Center for AI Safety', 'affiliation_domain': 'safe.ai', 'affiliation_country': 'AI'}, {'name': 'Oliver Zhang', 'openreview_id': '~Oliver_Zhang1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}, {'name': 'Xiaoyuan Zhu', 'openreview_id': '~Xiaoyuan_Zhu2', 'affiliation_name': 'University of Southern California', 'affiliation_domain': 'usc.edu', 'affiliation_country': 'US'}, {'name': 'Rishub Tamirisa', 'openreview_id': '~Rishub_Tamirisa1', 'affiliation_name': 'University of Illinois at Urbana-Champaign', 'affiliation_domain': 'cs.illinois.edu', 'affiliation_country': 'US'}, {'name': 'Bhrugu Bharathi', 'openreview_id': '~Bhrugu_Bharathi2', 'affiliation_name': 'University of California, San Diego', 'affiliation_domain': 'ucsd.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Ariel_Herbert-Voss1', 'affiliation_name': 'Harvard University', 'affiliation_domain': 'harvard.edu', 'affiliation_country': 'US'}, {'name': 'Cort B Breuer', 'openreview_id': '~Cort_B_Breuer1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}, {'name': 'Andy Zou', 'openreview_id': '~Andy_Zou1', 'affiliation_name': 'CMU, Carnegie Mellon University', 'affiliation_domain': 'andrew.cmu.edu', 'affiliation_country': 'US'}, {'name': 'Mantas Mazeika', 'openreview_id': '~Mantas_Mazeika3', 'affiliation_name': 'Center for AI Safety', 'affiliation_domain': 'safe.ai', 'affiliation_country': 'US'}, {'name': 'Zifan Wang', 'openreview_id': '~Zifan_Wang1', 'affiliation_name': 'Scale AI', 'affiliation_domain': 'scale.com', 'affiliation_country': 'US'}, {'name': 'Palash Oswal', 'openreview_id': '~Palash_Oswal1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Weiran Lin', 'openreview_id': '~Weiran_Lin1', 'affiliation_name': 'CMU, Carnegie Mellon University', 'affiliation_domain': 'andrew.cmu.edu', 'affiliation_country': 'US'}, {'name': 'Adam Alfred Hunt', 'openreview_id': '~Adam_Alfred_Hunt1', 'affiliation_name': 'Carnegie Mellon University', 'affiliation_domain': 'cmu.edu', 'affiliation_country': 'US'}, {'name': 'Justin Tienken-Harder', 'openreview_id': '~Justin_Tienken-Harder1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Kevin Y. Shih', 'openreview_id': '~Kevin_Y._Shih1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}, {'name': 'Kemper Talley', 'openreview_id': '~Kemper_Talley1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'John Guan', 'openreview_id': '~John_Guan1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Ian Steneker', 'openreview_id': '~Ian_Steneker1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'David Campbell', 'openreview_id': '~David_Campbell2', 'affiliation_name': 'Drake University', 'affiliation_domain': 'drake.edu', 'affiliation_country': 'US'}, {'name': 'Brad Jokubaitis', 'openreview_id': '~Brad_Jokubaitis1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Steven Basart', 'openreview_id': '~Steven_Basart1', 'affiliation_name': 'Center for AI Safety ', 'affiliation_domain': 'safe.ai', 'affiliation_country': 'US'}, {'name': 'Ponnurangam Kumaraguru', 'openreview_id': '~Ponnurangam_Kumaraguru3', 'affiliation_name': 'International Institute of Information Technology Hyderabad ', 'affiliation_domain': 'iiit.ac.in', 'affiliation_country': 'IN'}, {'name': 'Kallol Krishna Karmakar', 'openreview_id': '~Kallol_Krishna_Karmakar1', 'affiliation_name': 'University of Newcastle', 'affiliation_domain': 'newcastle.edu.au', 'affiliation_country': 'AU'}, {'name': 'Uday Tupakula', 'openreview_id': '~Uday_Tupakula1', 'affiliation_name': 'University of New England', 'affiliation_domain': 'une.edu', 'affiliation_country': 'US'}, {'name': 'Vijay Varadharajan', 'openreview_id': '~Vijay_Varadharajan1', 'affiliation_name': 'University of Newcastle', 'affiliation_domain': 'newcastle.edu.au', 'affiliation_country': 'AU'}, {'name': 'Yan Shoshitaishvili', 'openreview_id': '~Yan_Shoshitaishvili1', 'affiliation_name': 'Arizona State University', 'affiliation_domain': 'asu.edu', 'affiliation_country': 'US'}, {'name': 'Jimmy Ba', 'openreview_id': '~Jimmy_Ba1', 'affiliation_name': 'Department of Computer Science, University of Toronto', 'affiliation_domain': 'cs.toronto.edu', 'affiliation_country': 'CA'}, {'name': 'Kevin M. Esvelt', 'openreview_id': '~Kevin_M._Esvelt1', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}, {'name': 'Alexandr Wang', 'openreview_id': '~Alexandr_Wang1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Dan Hendrycks', 'openreview_id': '~Dan_Hendrycks1', 'affiliation_name': 'UC Berkeley', 'affiliation_domain': 'berkeley.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,False,"This paper introduces the WMDP benchmark, a dataset of multiple-choice questions designed to assess hazardous knowledge in large language models (LLMs).  The authors aim to measure and mitigate the potential for malicious use by LLMs related to biosecurity, cybersecurity, and chemical security.  Further, they present a novel unlearning method, RMU, which effectively reduces dangerous knowledge capabilities while preserving general knowledge.
",xlr6AUDuJz,The WMDP Benchmark: Measuring and Reducing Malicious Use with Unlearning,https://openreview.net/pdf/1c3ad9f79f4531bbb0c52de9996b3ff95f17a046.pdf,False
poster,"[{'name': 'Sayak Ray Chowdhury', 'openreview_id': '~Sayak_Ray_Chowdhury1', 'affiliation_name': 'Indian Institute of Technology, Kanpur', 'affiliation_domain': 'iitk.ac.in', 'affiliation_country': 'IN'}, {'name': 'Nagarajan Natarajan', 'openreview_id': '~Nagarajan_Natarajan1', 'affiliation_name': 'Microsoft Research', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/icml-2024.json,True,"This paper introduces a novel, provably robust method for Direct Preference Optimization (DPO) in the context of aligning language models with human preferences, specifically addressing the issue of noisy feedback.  The authors develop a new loss function that mitigates the impact of noisy preference data on the learned policy.  Theoretical analysis demonstrates the improved robustness of the proposed method, achieving a sub-optimality gap that scales favorably with the dataset size and noise level.
",yhpDKSw7yA,Provably Robust DPO: Aligning Language Models with Noisy Feedback,https://openreview.net/pdf/3f1185c2cb457015bf09600ef1508b8737fcf2a4.pdf,True
poster,"[{'name': 'Washim Uddin Mondal', 'openreview_id': '~Washim_Uddin_Mondal1', 'affiliation_name': 'Indian Institute of Technology, Kanpur', 'affiliation_domain': 'iitk.ac.in', 'affiliation_country': 'IN'}, {'name': 'Vaneet Aggarwal', 'openreview_id': '~Vaneet_Aggarwal1', 'affiliation_name': 'Purdue University', 'affiliation_domain': 'purdue.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper introduces a new algorithm, Primal-Dual Accelerated Natural Policy Gradient (PD-ANPG), for constrained Markov Decision Problems (CMDPs) with general policy parameterization.  The algorithm aims to improve sample complexity by achieving an ϵ global optimality gap and constraint violation with a reduced complexity compared to existing methods.  Specifically, the proposed approach outperforms prior state-of-the-art methods by a factor of O((1 − γ) −1 ϵ −2) in sample complexity for general parameterizations.
",1po4j1Tv7O,Sample-Efficient Constrained Reinforcement Learning with General Parameterization,https://openreview.net/pdf/b178b4957c9f40578fc6a3a1e59fd2b08dc2b708.pdf,True
poster,"[{'name': 'Vijay Ekambaram', 'openreview_id': '~Vijay_Ekambaram1', 'affiliation_name': 'International Business Machines', 'affiliation_domain': 'ibm.com', 'affiliation_country': 'US'}, {'name': 'Arindam Jati', 'openreview_id': '~Arindam_Jati1', 'affiliation_name': 'International Business Machines', 'affiliation_domain': 'ibm.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Pankaj_Dayama1', 'affiliation_name': 'International Business Machines', 'affiliation_domain': 'ibm.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Sumanta_Mukherjee1', 'affiliation_name': 'International Business Machines', 'affiliation_domain': 'ibm.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Nam_H_Nguyen1', 'affiliation_name': 'Capital One', 'affiliation_domain': 'capitalone.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Wesley_M._Gifford1', 'affiliation_name': 'IBM Research', 'affiliation_domain': 'ibm.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Chandra_Reddy1', 'affiliation_name': 'IBM Research, International Business Machines', 'affiliation_domain': 'us.ibm.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Jayant_Kalagnanam1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper introduces Tiny Time Mixers (TTMs), a lightweight pre-trained model for fast and accurate zero/few-shot forecasting of multivariate time series.  TTM leverages a compact architecture and transfer learning techniques to improve upon existing models' speed and reduce computational demands while maintaining accuracy.  The model is designed for use in resource-constrained environments and is available for reproducibility and research.
",3O5YCEWETq,Tiny Time Mixers (TTMs): Fast Pre-trained Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series,https://openreview.net/pdf/c1a7cea36450273599d6fedfb15d84e946924570.pdf,False
poster,"[{'name': 'Qinbo Bai', 'openreview_id': '~Qinbo_Bai1', 'affiliation_name': 'Purdue University', 'affiliation_domain': 'purdue.edu', 'affiliation_country': 'US'}, {'name': 'Washim Uddin Mondal', 'openreview_id': '~Washim_Uddin_Mondal1', 'affiliation_name': 'Indian Institute of Technology, Kanpur', 'affiliation_domain': 'iitk.ac.in', 'affiliation_country': 'IN'}, {'name': 'Vaneet Aggarwal', 'openreview_id': '~Vaneet_Aggarwal1', 'affiliation_name': 'Purdue University', 'affiliation_domain': 'purdue.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper introduces a novel policy gradient algorithm for average reward constrained Markov Decision Processes (CMDPs) with general parameterization.  The algorithm aims to achieve a low regret and guarantee constraint satisfaction, offering  sublinear regret and constraint violation bounds.  This represents the first study of this type with a general policy parametrization for infinite horizon average reward CMDPs.
",3lQgEPRxeu,Learning General Parameterized Policies for Infinite Horizon Average Reward Constrained MDPs via Primal-Dual Policy Gradient Algorithm,https://openreview.net/pdf/500b125b905014d27b7d9d90d28918d9cdfe0d33.pdf,False
spotlight,"[{'name': 'Mohammad Sadil Khan', 'openreview_id': '~Mohammad_Sadil_Khan1', 'affiliation_name': 'Rheinland-Pfälzische Technische Universität Kaiserslautern-Landau', 'affiliation_domain': 'rptu.de', 'affiliation_country': 'DE'}, {'name': 'Sankalp Sinha', 'openreview_id': '~Sankalp_Sinha1', 'affiliation_name': 'German Research Center for AI', 'affiliation_domain': 'dfki.de', 'affiliation_country': 'DE'}, {'name': 'Sheikh Talha Uddin', 'openreview_id': '~Sheikh_Talha_Uddin1', 'affiliation_name': 'German Research Center for AI', 'affiliation_domain': 'dfki.de', 'affiliation_country': 'DE'}, {'name': 'Sk Aziz Ali', 'openreview_id': '~Sk_Aziz_Ali2', 'affiliation_name': 'BITS Pilani, Birla Institute of Technology and Science', 'affiliation_domain': 'hyderabad.bits-pilani.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"The paper introduces Text2CAD, a novel AI framework designed to generate parametric CAD models from text prompts.  It aims to bridge the gap in current CAD tools by enabling the creation of 3D models from natural language descriptions, accommodating various skill levels.  The framework utilizes a transformer-based autoregressive network to achieve this, and a new dataset of ~170,000 models and ~660,000 text annotations was developed to facilitate model training.
",5k9XeHIK3L,Text2CAD: Generating Sequential CAD Designs from Beginner-to-Expert Level Text Prompts,https://openreview.net/pdf/9f3142a99be0b0075f8fb4b87e46c8d0b8ed25e0.pdf,False
poster,"[{'name': 'Abhinav Joshi', 'openreview_id': '~Abhinav_Joshi1', 'affiliation_name': 'Indian Institute of Technology, Kanpur', 'affiliation_domain': 'iitk.ac.in', 'affiliation_country': 'IN'}, {'name': 'Areeb Ahmad', 'openreview_id': '~Areeb_Ahmad2', 'affiliation_name': 'Indian Institute of Technology Kanpur (IIT Kanpur)', 'affiliation_domain': 'iitk.ac.in', 'affiliation_country': 'IN'}, {'name': 'Ashutosh Modi', 'openreview_id': '~Ashutosh_Modi1', 'affiliation_name': 'IIT Kanpur', 'affiliation_domain': 'iitk.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper introduces COLD, a framework for evaluating large language models' (LLMs) ability to reason causally about everyday activities.  COLD bridges the gap between real-world grounding and theoretically backed analysis in causal reasoning by creating a large dataset of causal queries derived from human understanding of daily activities.  The authors aim to assess if LLMs can truly understand causal relationships or are merely mimicking patterns in the training data.
",7Mo1NOosNT,COLD: Causal reasOning in cLosed Daily activities,https://openreview.net/pdf/015330ba1dcf5481f996a511f4b038f8acfab65f.pdf,True
poster,"[{'name': 'Aniket Das', 'openreview_id': '~Aniket_Das1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}, {'name': 'Dheeraj Mysore Nagaraj', 'openreview_id': '~Dheeraj_Mysore_Nagaraj1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': 'Soumyabrata Pal', 'openreview_id': '~Soumyabrata_Pal1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': 'Arun Suggala', 'openreview_id': '~Arun_Suggala1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': 'Prateek Varshney', 'openreview_id': '~Prateek_Varshney1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper investigates the efficiency of the ClippedSGD algorithm for heavy-tailed statistical estimation in streaming data environments.  It demonstrates that ClippedSGD achieves near-optimal sub-Gaussian statistical rates under specific conditions, improving upon previous results.  The key contribution is a novel iterative refinement strategy for martingale concentration, leading to tighter error bounds.
",8JauriwDeH,Near-Optimal Streaming Heavy-Tailed Statistical Estimation with Clipped SGD,https://openreview.net/pdf/492b971c4dfd9caecfce61206d2bccbf105635fc.pdf,False
spotlight,"[{'name': 'Ayush Sawarni', 'openreview_id': '~Ayush_Sawarni1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Nirjhar Das', 'openreview_id': '~Nirjhar_Das1', 'affiliation_name': 'Indian Institute of Science, Indian institute of science, Bangalore', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Siddharth_Barman1', 'affiliation_name': 'Indian Institute of Science', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': 'Gaurav Sinha', 'openreview_id': '~Gaurav_Sinha2', 'affiliation_name': 'Research, Microsoft', 'affiliation_domain': 'research.microsoft.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper investigates generalized linear contextual bandits with limited adaptivity.  It presents two algorithms, B-GLinCB and RS-GLinCB, designed for two distinct limited adaptivity settings.  The algorithms aim to minimize regret while adhering to a predefined budget of policy updates, achieving  optimal regret bounds that eliminate dependence on an instance-dependent parameter.
",FTPDBQuT4G,Generalized Linear Bandits with Limited Adaptivity,https://openreview.net/pdf/e2e8732933515749d301bfc2d477bffdf36dc55d.pdf,False
poster,"[{'name': 'Gagan Jain', 'openreview_id': '~Gagan_Jain1', 'affiliation_name': 'Google DeepMind', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': 'Nidhi Hegde', 'openreview_id': '~Nidhi_Hegde2', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': 'Aditya Kusupati', 'openreview_id': '~Aditya_Kusupati1', 'affiliation_name': 'Google DeepMind', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': 'Arsha Nagrani', 'openreview_id': '~Arsha_Nagrani2', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': 'Shyamal Buch', 'openreview_id': '~Shyamal_Buch1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Prateek_Jain1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Sujoy_Paul1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper introduces Mixture of Nested Experts (MoNE), a framework for computationally efficient visual processing.  MoNE leverages a nested expert structure to prioritize token processing based on a learned importance order, reducing inference time by over two-fold while maintaining performance parity with baseline models.  The method adapts to different compute budgets, demonstrating its applicability to real-world deployments requiring real-time processing.
",HbV5vRJMOY,Mixture of Nested Experts: Adaptive Processing of Visual Tokens,https://openreview.net/pdf/34a8b1b90acda923db4408bc2dca4c3d5f6d3531.pdf,True
poster,"[{'name': 'Abhipsa Basu', 'openreview_id': '~Abhipsa_Basu1', 'affiliation_name': 'Indian Institute of Science', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': 'Venkatesh Babu Radhakrishnan', 'openreview_id': '~Venkatesh_Babu_Radhakrishnan2', 'affiliation_name': 'Indian Institute of Science', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper investigates mitigating biases in pre-trained, black-box feature extractors for image classification.  It proposes a novel method, employing a clustering-based adaptive margin loss, to achieve this without requiring access to model weights.  The approach aims to address bias in downstream tasks where the feature extractor cannot be directly modified.
",HwO1mNluoL,Mitigating Biases in Blackbox Feature Extractors for Image Classification Tasks,https://openreview.net/pdf/3ccdc8010ed3b8d63897bedec7328d708c92eaa3.pdf,True
poster,"[{'name': 'Moses Charikar', 'openreview_id': '~Moses_Charikar1', 'affiliation_name': 'Princeton University', 'affiliation_domain': 'princeton.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Chirag_Pabbaraju1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'cs.stanford.edu', 'affiliation_country': 'US'}, {'name': 'Kirankumar Shiragur', 'openreview_id': '~Kirankumar_Shiragur1', 'affiliation_name': 'Microsoft Research', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper develops a theoretical framework to quantify the performance improvement of a strong language model (e.g., GPT-4) when fine-tuned with labels from a weaker model (e.g., GPT-2).  It demonstrates that this ""weak-to-strong generalization"" gain is directly related to the misfit error of the strong model on the weaker model's labels.  The authors aim to provide a method for predicting and optimizing this improvement, enabling the selection of the best weak model for fine-tuning strong models.
",MyVyH5Jo1l,Quantifying the Gain in Weak-to-Strong Generalization,https://openreview.net/pdf/36318fbff6dff7b5a38aa7f1c82e90a342ffee0a.pdf,False
poster,"[{'name': 'Akhil Jalan', 'openreview_id': '~Akhil_Jalan1', 'affiliation_name': 'University of Texas at Austin', 'affiliation_domain': 'utexas.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Arya_Mazumdar1', 'affiliation_name': 'University of California, San Diego', 'affiliation_domain': 'ucsd.edu', 'affiliation_country': 'US'}, {'name': 'Soumendu Sundar Mukherjee', 'openreview_id': '~Soumendu_Sundar_Mukherjee2', 'affiliation_name': 'Indian Statistical Institute', 'affiliation_domain': 'isical.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Purnamrita_Sarkar1', 'affiliation_name': 'University of Texas, Austin', 'affiliation_domain': 'utexas.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper investigates transfer learning for estimating latent variable network models.  It proposes an algorithm to estimate a target network's conditional edge probability matrix using data from a source network, even with only a small subset of target network data.  The method leverages shared latent variables between the source and target networks to achieve efficient estimation.
",PK8xOCBQRO,Transfer Learning for Latent Variable Network Models,https://openreview.net/pdf/4830f6ed817c8346d73ee25f85017b31d6e4996f.pdf,False
poster,"[{'name': 'Abhinav Dutta', 'openreview_id': '~Abhinav_Dutta1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': 'Sanjeev Krishnan', 'openreview_id': '~Sanjeev_Krishnan1', 'affiliation_name': 'Research, Microsoft', 'affiliation_domain': 'research.microsoft.com', 'affiliation_country': 'IN'}, {'name': 'Nipun Kwatra', 'openreview_id': '~Nipun_Kwatra1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'US'}, {'name': 'Ramachandran Ramjee', 'openreview_id': '~Ramachandran_Ramjee1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper argues that simply measuring accuracy is insufficient to evaluate the quality of compressed large language models (LLMs).  It finds that while compressed models often maintain similar accuracy to baseline models, significant changes in answers (flips) can occur, indicating a difference in model behavior.  The authors propose two new metrics, KL-divergence and percentage of flips, as superior methods for evaluating the effectiveness of compression techniques, as these metrics better capture the nuanced changes in behavior.
",QVG7j29Sta,Accuracy is Not All You Need,https://openreview.net/pdf/7ecf82af167db2fa1a4c2972d42f903ce9507ee9.pdf,True
poster,"[{'name': 'Aditya Bommakanti', 'openreview_id': '~Aditya_Bommakanti1', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Harshith Reddy Vonteri', 'openreview_id': '~Harshith_Reddy_Vonteri1', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Konstantinos Skitsas', 'openreview_id': '~Konstantinos_Skitsas1', 'affiliation_name': 'Aarhus University', 'affiliation_domain': 'au.dk', 'affiliation_country': 'DK'}, {'name': '', 'openreview_id': '~Sayan_Ranu2', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Davide_Mottin1', 'affiliation_name': 'Aarhus University', 'affiliation_domain': 'au.dk', 'affiliation_country': 'DK'}, {'name': 'Panagiotis Karras', 'openreview_id': '~Panagiotis_Karras1', 'affiliation_name': 'Copenhagen University', 'affiliation_domain': 'ku.dk', 'affiliation_country': 'DK'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper introduces FUGAL, an unrestricted graph alignment method for finding a permutation matrix mapping one graph to another.  It aims to improve upon existing, ""mediated"" approaches that use intermediate representations, which can lose critical information and potentially miss optimal solutions.  FUGAL directly operates on adjacency matrices, maintaining full graph information while retaining efficiency.
",SdLOs1FR4h,FUGAL: Feature-fortified Unrestricted Graph Alignment,https://openreview.net/pdf/17aef8ff1d289ba15e7ffd178b132deee4f747e3.pdf,True
poster,"[{'name': 'Abbavaram Gowtham Reddy', 'openreview_id': '~Abbavaram_Gowtham_Reddy1', 'affiliation_name': 'CISPA Helmholtz Center for Information Security', 'affiliation_domain': 'cispa.de', 'affiliation_country': 'DE'}, {'name': 'Vineeth N. Balasubramanian', 'openreview_id': '~Vineeth_N._Balasubramanian2', 'affiliation_name': 'Research, Microsoft', 'affiliation_domain': 'research.microsoft.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper aims to develop a comprehensive approach for detecting and measuring confounding in observational data.  It seeks to relax the unrealistic assumptions of causal sufficiency and strong parametric models, and leverage advancements in causal discovery to identify and quantify confounding, both observed and unobserved.  The proposed approach considers different definitions of confounding and introduces measures that satisfy specific properties, aiming to assess the strength of confounding bias between variables.
",SvmJJJS0q1,Detecting and Measuring Confounding Using Causal Mechanism Shifts,https://openreview.net/pdf/f7c0e21c497fe89f9229cc3ade022dcfaaae4e0a.pdf,False
poster,"[{'name': 'Yuanjie Shi', 'openreview_id': '~Yuanjie_Shi1', 'affiliation_name': 'Washington State University', 'affiliation_domain': 'wsu.edu', 'affiliation_country': 'US'}, {'name': 'SUBHANKAR GHOSH', 'openreview_id': '~SUBHANKAR_GHOSH1', 'affiliation_name': 'Washington State University at Pullman', 'affiliation_domain': 'wsu.edu', 'affiliation_country': 'IN'}, {'name': 'Taha Belkhouja', 'openreview_id': '~Taha_Belkhouja1', 'affiliation_name': 'Accenture', 'affiliation_domain': 'accenture.com', 'affiliation_country': 'US'}, {'name': 'Yan Yan', 'openreview_id': '~Yan_Yan3', 'affiliation_name': 'Washington State University, Pullman', 'affiliation_domain': 'wsu.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper introduces RC3P, a conformal prediction algorithm designed to improve prediction set sizes for class-conditional coverage in classification tasks with many or imbalanced classes.  RC3P selectively adjusts class-wise thresholds to achieve valid coverage for each class, and the authors demonstrate that their method reduces prediction set size compared to existing approaches.  Empirical results on various datasets support the claim of improved prediction efficiency with maintained coverage validity.
",T7dS1Ghwwu,Conformal Prediction for Class-wise Coverage via Augmented Label Rank Calibration,https://openreview.net/pdf/7ad03c77e17e962d610bd1999051ca39e4372d0d.pdf,False
poster,"[{'name': '', 'openreview_id': '~Ameya_Prabhu1', 'affiliation_name': 'Eberhard-Karls-Universität Tübingen', 'affiliation_domain': 'uni-tuebingen.de', 'affiliation_country': 'DE'}, {'name': 'Shiven Sinha', 'openreview_id': '~Shiven_Sinha1', 'affiliation_name': 'International Institute of Information Technology, Hyderabad', 'affiliation_domain': 'iiit.ac.in', 'affiliation_country': 'IN'}, {'name': 'Ponnurangam Kumaraguru', 'openreview_id': '~Ponnurangam_Kumaraguru3', 'affiliation_name': 'International Institute of Information Technology Hyderabad ', 'affiliation_domain': 'iiit.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Philip_Torr1', 'affiliation_name': 'University of Oxford', 'affiliation_domain': 'ox.ac.uk', 'affiliation_country': 'GB'}, {'name': '', 'openreview_id': '~Ozan_Sener1', 'affiliation_name': 'Apple', 'affiliation_domain': 'apple.com', 'affiliation_country': 'DE'}, {'name': 'Puneet K. Dokania', 'openreview_id': '~Puneet_K._Dokania1', 'affiliation_name': 'Bosch ', 'affiliation_domain': 'bosch.com', 'affiliation_country': 'GB'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper investigates the effectiveness of representations learned through continual learning in online settings.  It empirically demonstrates that simple, randomly-generated representations outperform continually learned representations in deep networks for online continual learning.  The findings challenge the conventional assumption that representations learned during continual learning are superior to fixed representations.
",TZ5k9IYBBf,RanDumb: Random Representations Outperform Online Continually Learned Representations,https://openreview.net/pdf/c6f95dcde7006c0eddbc1baac2ad61b9f7af445f.pdf,False
spotlight,"[{'name': 'Abhishek Sinha', 'openreview_id': '~Abhishek_Sinha3', 'affiliation_name': 'Tata Institute of Fundamental Research', 'affiliation_domain': 'tifr.res.in', 'affiliation_country': 'IN'}, {'name': 'Rahul Vaze', 'openreview_id': '~Rahul_Vaze1', 'affiliation_name': 'Tata Institute of Fundamental Research, Mumbai', 'affiliation_domain': 'tifr.res.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper addresses the constrained online convex optimization (COCO) problem.  It aims to develop an online learning policy that minimizes regret and cumulative constraint violation (CCV) without restrictive assumptions.  The key contribution is a novel approach that combines existing adaptive online convex optimization techniques with Lyapunov optimization to achieve optimal bounds for regret and CCV.
",TxffvJMnBy,Optimal Algorithms for Online Convex Optimization with Adversarial Constraints,https://openreview.net/pdf/269618651cc4c3886e154ec85079164a62691bdc.pdf,True
poster,"[{'name': 'Sandika Biswas', 'openreview_id': '~Sandika_Biswas2', 'affiliation_name': 'Monash University', 'affiliation_domain': 'monash.edu', 'affiliation_country': 'AU'}, {'name': 'Qianyi Wu', 'openreview_id': '~Qianyi_Wu2', 'affiliation_name': 'Monash University', 'affiliation_domain': 'monash.edu', 'affiliation_country': 'AU'}, {'name': 'Biplab Banerjee', 'openreview_id': '~Biplab_Banerjee1', 'affiliation_name': 'Indian Institute of Technology, Bombay, Dhirubhai Ambani Institute Of Information and Communication Technology', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Hamid Rezatofighi', 'openreview_id': '~Hamid_Rezatofighi1', 'affiliation_name': 'Monash University', 'affiliation_domain': 'monash.edu', 'affiliation_country': 'AU'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper introduces TFS-NeRF, a template-free neural radiance field (NeRF) method for reconstructing dynamic scenes.  It aims to improve upon existing methods by enabling efficient semantic reconstruction of multiple interacting entities, particularly those in complex interactions, and handles dynamic scenes more generally without needing prior knowledge or specific templates for each object.  The approach leverages an invertible neural network (INN) for linear blend skinning (LBS) prediction to improve training efficiency.
",UPxFYvHsyN,TFS-NeRF: Template-Free NeRF for Semantic 3D Reconstruction of Dynamic Scene,https://openreview.net/pdf/b14cb8a20e1c562c42ee0b3c2b1b0305ef13ce98.pdf,False
poster,"[{'name': 'Shashank Reddy Chirra', 'openreview_id': '~Shashank_Reddy_Chirra1', 'affiliation_name': 'Singapore Management University', 'affiliation_domain': 'smu.edu.sg', 'affiliation_country': 'SG'}, {'name': '', 'openreview_id': '~Pradeep_Varakantham1', 'affiliation_name': 'Singapore Management University', 'affiliation_domain': 'smu.edu.sg', 'affiliation_country': 'SG'}, {'name': '', 'openreview_id': '~Praveen_Paruchuri1', 'affiliation_name': 'IIIT Hyderabad', 'affiliation_domain': None, 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper introduces a method for learning cost functions in constrained reinforcement learning, particularly in safety-critical domains like self-driving.  The method leverages trajectory-level feedback from humans or automated systems, addressing the challenges of complex environment scaling and noisy labels.  The approach prioritizes feedback collection through a novelty-based sampling mechanism, allowing for efficient learning while minimizing the need for extensive human evaluation.
",WSsht66fbC,Safety through feedback in Constrained RL,https://openreview.net/pdf/e7f3312fa2dfe2dbb6bbfcd396ae3babb1cddcfa.pdf,False
poster,"[{'name': 'Emre Acartürk', 'openreview_id': '~Emre_Acartürk1', 'affiliation_name': 'Rensselaer Polytechnic Institute', 'affiliation_domain': 'rpi.edu', 'affiliation_country': 'US'}, {'name': 'Burak Varıcı', 'openreview_id': '~Burak_Varıcı1', 'affiliation_name': 'Carnegie Mellon University', 'affiliation_domain': 'cmu.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Karthikeyan_Shanmugam1', 'affiliation_name': 'Google Deepmind', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Ali_Tajer1', 'affiliation_name': 'Rensselaer Polytechnic Institute', 'affiliation_domain': 'rpi.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper analyzes the sample complexity of interventional causal representation learning.  It derives finite-sample guarantees for recovering latent causal variables and the causal structure among them, considering stochastic soft interventions and linear transformations.  The results specify sample size requirements for accurate recovery with high probability.
",XL9aaXl0u6,Sample Complexity of Interventional Causal Representation Learning,https://openreview.net/pdf/3cd848f730138b8b2afd1dcc6c71c80ba6f6a6a1.pdf,False
poster,"[{'name': 'Siddharth Nayak', 'openreview_id': '~Siddharth_Nayak1', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}, {'name': 'Adelmo Morrison Orozco', 'openreview_id': '~Adelmo_Morrison_Orozco1', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}, {'name': 'Marina Ten Have', 'openreview_id': '~Marina_Ten_Have1', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}, {'name': 'Jackson Zhang', 'openreview_id': '~Jackson_Zhang1', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}, {'name': 'Vittal Thirumalai', 'openreview_id': '~Vittal_Thirumalai1', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}, {'name': 'Darren Chen', 'openreview_id': '~Darren_Chen1', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}, {'name': 'Aditya Kapoor', 'openreview_id': '~Aditya_Kapoor1', 'affiliation_name': 'Tata Consultancy Services Limited, India', 'affiliation_domain': 'tcs.com', 'affiliation_country': 'IN'}, {'name': 'Eric Robinson', 'openreview_id': '~Eric_Robinson2', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}, {'name': 'Karthik Gopalakrishnan', 'openreview_id': '~Karthik_Gopalakrishnan3', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}, {'name': 'James Harrison', 'openreview_id': '~James_Harrison1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': 'Anuj Mahajan', 'openreview_id': '~Anuj_Mahajan1', 'affiliation_name': 'Apple', 'affiliation_domain': 'apple.com', 'affiliation_country': 'US'}, {'name': 'brian ichter', 'openreview_id': '~brian_ichter1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Hamsa_Balakrishnan1', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper introduces LLaMAR, an LM-based long-horizon planner for multi-agent robotics.  The goal is to improve upon existing single-agent planning methods by creating a robust planning architecture that effectively addresses the challenges of long-horizon tasks in partially observable, multi-agent environments.  LLaMAR utilizes a plan-act-correct-verify framework to enable adaptive planning and self-correction without relying on external oracles or simulators.
",Y1rOWS2Z4i,Long-Horizon Planning for Multi-Agent Robots in Partially Observable Environments,https://openreview.net/pdf/30511ccbe77a9b3fbd9e34c29efcb47db4044e7c.pdf,False
poster,"[{'name': 'Agniv Bandyopadhyay', 'openreview_id': '~Agniv_Bandyopadhyay1', 'affiliation_name': 'Tata Institute of Fundamental Research', 'affiliation_domain': 'tifr.res.in', 'affiliation_country': 'IN'}, {'name': 'Sandeep Kumar Juneja', 'openreview_id': '~Sandeep_Kumar_Juneja1', 'affiliation_name': 'Ashoka University', 'affiliation_domain': 'ashoka.edu.in', 'affiliation_country': 'IN'}, {'name': 'Shubhada Agrawal', 'openreview_id': '~Shubhada_Agrawal1', 'affiliation_name': 'Carnegie Mellon University', 'affiliation_domain': 'cmu.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper addresses the problem of identifying the best arm among a finite number of arms with a guaranteed probability of an incorrect selection.  It proposes a novel, optimal ""top-2"" algorithm with sample complexity within a constant of the information-theoretic lower bound, contrasting with computationally intensive plug-in methods.  The method utilizes a threshold-based approach to allocate samples, exhibiting optimal performance as the desired probability of incorrect selection approaches zero.
",YXQW4qQe2U,Optimal Top-Two Method for Best Arm Identification and Fluid Analysis,https://openreview.net/pdf/4c086ee463f48a315e6fd957d196e6a78530c83d.pdf,True
poster,"[{'name': 'Abhinav Kumar', 'openreview_id': '~Abhinav_Kumar3', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}, {'name': 'Kirankumar Shiragur', 'openreview_id': '~Kirankumar_Shiragur1', 'affiliation_name': 'Microsoft Research', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Caroline_Uhler1', 'affiliation_name': 'Electrical Engineering & Computer Science, Massachusetts Institute of Technology', 'affiliation_domain': 'eecs.mit.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper addresses the problem of disentangling mixed interventional and observational data in linear structural equation models (SEMs).  It aims to develop an efficient algorithm capable of learning individual components within a mixture of unknown interventional distributions, given i.i.d. samples.  The approach focuses on Linear-SEMs with additive Gaussian noise, a key framework in causal discovery.
",aC9mB1PqYJ,Learning Mixtures of Unknown Causal Interventions,https://openreview.net/pdf/c8ddbf508bab28061e330169ce61ad8000132249.pdf,False
poster,"[{'name': 'Pranjal Aggarwal', 'openreview_id': '~Pranjal_Aggarwal1', 'affiliation_name': 'School of Computer Science, Carnegie Mellon University', 'affiliation_domain': 'cs.cmu.edu', 'affiliation_country': 'US'}, {'name': 'Aman Madaan', 'openreview_id': '~Aman_Madaan1', 'affiliation_name': 'xAI', 'affiliation_domain': 'x.ai', 'affiliation_country': 'US'}, {'name': 'Ankit Anand', 'openreview_id': '~Ankit_Anand4', 'affiliation_name': 'Google DeepMind', 'affiliation_domain': 'deepmind.com', 'affiliation_country': 'GB'}, {'name': 'Swaroop Mishra', 'openreview_id': '~Swaroop_Mishra1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': 'Pei Zhou', 'openreview_id': '~Pei_Zhou1', 'affiliation_name': 'University of Southern California', 'affiliation_domain': 'usc.edu', 'affiliation_country': 'US'}, {'name': 'Aditya Gupta', 'openreview_id': '~Aditya_Gupta2', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': 'Dheeraj Rajagopal', 'openreview_id': '~Dheeraj_Rajagopal1', 'affiliation_name': 'Fastino AI', 'affiliation_domain': 'fastino.ai', 'affiliation_country': 'US'}, {'name': 'Karthik Kappaganthu', 'openreview_id': '~Karthik_Kappaganthu1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Yiming_Yang1', 'affiliation_name': 'School of Computer Science, Carnegie Mellon University', 'affiliation_domain': 'cs.cmu.edu', 'affiliation_country': 'US'}, {'name': 'Shyam Upadhyay', 'openreview_id': '~Shyam_Upadhyay1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': 'Manaal Faruqui', 'openreview_id': '~Manaal_Faruqui2', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': 'Mausam', 'openreview_id': '~Mausam_.1', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper introduces AutoMix, a method for automatically routing language model queries.  AutoMix dynamically selects the optimal model size for a given query based on estimated output accuracy, aiming to minimize computational cost while maintaining performance.  The approach leverages a self-verification mechanism and a probabilistic decision-making process for effective model selection.
",e6WrwIvgzX,AutoMix: Automatically Mixing Language Models,https://openreview.net/pdf/f99d5e58580a4ddb7a4d60eef66db492cfafb4d9.pdf,False
poster,"[{'name': 'Burouj Armgaan', 'openreview_id': '~Burouj_Armgaan1', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Manthan Dalmia', 'openreview_id': '~Manthan_Dalmia1', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Sourav Medya', 'openreview_id': '~Sourav_Medya1', 'affiliation_name': 'University of Illinois at Chicago', 'affiliation_domain': 'uic.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Sayan_Ranu2', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper introduces GRAPHTRAIL, a novel global explainer for graph neural networks (GNNs).  GRAPHTRAIL translates GNN predictions into human-understandable logical rules, unlike existing instance-level explainers.  It leverages Shapley values and symbolic regression to achieve this, demonstrating improved accuracy in generating faithful logical formulae over existing global explanation methods.
",fzlMza6dRZ,GraphTrail: Translating GNN Predictions into Human-Interpretable Logical Rules,https://openreview.net/pdf/476e9d9dcd1fe989b9ed65ef25c804d563cf1340.pdf,True
poster,"[{'name': 'Mohit Kataria', 'openreview_id': '~Mohit_Kataria1', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Sandeep Kumar', 'openreview_id': '~Sandeep_Kumar8', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Jayadeva_Jayadeva1', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper introduces Universal Graph Coarsening (UGC), a novel framework for simplifying large graphs while retaining essential information, specifically targeting both homophilic and heterophilic datasets.  The method leverages node attributes and adjacency information, and it boasts superior performance and speed compared to existing techniques.  The authors aim to improve the efficiency and effectiveness of downstream graph processing tasks by creating a readily applicable framework to diverse graph structures.
",nN6NSd1Qds,UGC: Universal Graph Coarsening,https://openreview.net/pdf/7835e160109c7dd1023e90ff5f2eb18f64b1e6cb.pdf,True
spotlight,"[{'name': 'Yerram Varun', 'openreview_id': '~Yerram_Varun1', 'affiliation_name': 'Research, Google', 'affiliation_domain': 'research.google.com', 'affiliation_country': 'IN'}, {'name': 'Rahul Madhavan', 'openreview_id': '~Rahul_Madhavan1', 'affiliation_name': 'Indian Institute of Management, Ahmedabad', 'affiliation_domain': 'iima.ac.in', 'affiliation_country': 'IN'}, {'name': 'Sravanti Addepalli', 'openreview_id': '~Sravanti_Addepalli1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': 'Arun Suggala', 'openreview_id': '~Arun_Suggala1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Karthikeyan_Shanmugam1', 'affiliation_name': 'Google Deepmind', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Prateek_Jain1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper introduces Time Reversed Language Models (TRLMs) to provide unsupervised feedback to large language models (LLMs).  TRLMs operate in reverse time, scoring and generating queries conditioned on responses, which complements the forward generation processes of typical LLMs.  The authors demonstrate improved performance on tasks like re-ranking, citation generation, and passage retrieval, and reduced false negatives in safety filters, achieving this with minimal impact on false positives.
",nY0BrZdqLt,Time-Reversal Provides Unsupervised Feedback to LLMs,https://openreview.net/pdf/08ee7a3ea3b3fd8e7bf896a4e8fac2fc695aab87.pdf,True
poster,"[{'name': 'Victor Boutin', 'openreview_id': '~Victor_Boutin2', 'affiliation_name': 'CNRS', 'affiliation_domain': 'cnrs.fr', 'affiliation_country': 'FR'}, {'name': 'Rishav Mukherji', 'openreview_id': '~Rishav_Mukherji1', 'affiliation_name': 'School of Computer Science, Carnegie Mellon University', 'affiliation_domain': 'cs.cmu.edu', 'affiliation_country': 'US'}, {'name': 'Aditya Agrawal', 'openreview_id': '~Aditya_Agrawal3', 'affiliation_name': 'Birla Institute of Tchnology and Science - KK Birla Goa Campus', 'affiliation_domain': 'goa.bits-pilani.ac.in', 'affiliation_country': 'IN'}, {'name': 'Thomas Fel', 'openreview_id': '~Thomas_FEL1', 'affiliation_name': 'Harvard University', 'affiliation_domain': 'harvard.edu', 'affiliation_country': 'US'}, {'name': 'Thomas Serre', 'openreview_id': '~Thomas_Serre1', 'affiliation_name': 'Brown University', 'affiliation_domain': 'brown.edu', 'affiliation_country': 'US'}, {'name': 'Rufin VanRullen', 'openreview_id': '~Rufin_VanRullen1', 'affiliation_name': 'CNRS', 'affiliation_domain': 'cnrs.fr', 'affiliation_country': 'FR'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper investigates how different inductive biases influence latent spaces in Latent Diffusion Models (LDMs) for one-shot drawing tasks.  The study explores various regularizations, including standard and supervised methods, to generate human-like drawings.  The primary goal is to identify representational inductive biases within LDMs that improve the likeness and originality of generated drawings, effectively bridging the gap between human and machine drawing capabilities.
",tZRpvLXevU,Latent Representation Matters: Human-like Sketches in One-shot Drawing Tasks,https://openreview.net/pdf/260aead53bf9f89aad29e7ba04bfc14fb441a286.pdf,False
poster,"[{'name': 'Chiranjib Bhattacharyya', 'openreview_id': '~Chiranjib_Bhattacharyya1', 'affiliation_name': 'Indian Institute of Science, Indian institute of science, Bangalore', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper introduces DISCEDIT, a method for model editing by identifying discriminative components within neural networks.  It leverages a discriminative filters hypothesis to find critical subnetworks essential for class-wise predictions, enabling algorithms for structured pruning and selective forgetting.  The approach uses novel lower bounds on the Total Variation distance to avoid restrictive assumptions on feature distributions, showcasing improved performance in model editing tasks.
",tuiqq1G8I5,DisCEdit: Model Editing by Identifying Discriminative Components,https://openreview.net/pdf/c7df4a98dbe1cbf0192e59c5f5fa58b1b3a7693e.pdf,True
poster,"[{'name': 'Eeshaan Jain', 'openreview_id': '~Eeshaan_Jain1', 'affiliation_name': 'EPFL - EPF Lausanne', 'affiliation_domain': 'epfl.ch', 'affiliation_country': 'CH'}, {'name': 'Indradyumna Roy', 'openreview_id': '~Indradyumna_Roy1', 'affiliation_name': 'Indian Institute of Technology Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Saswat Meher', 'openreview_id': '~Saswat_Meher1', 'affiliation_name': 'Indian Institute of Technology Bombay, Indian Institute of Technology, Bombay', 'affiliation_domain': 'cse.iitb.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Soumen_Chakrabarti1', 'affiliation_name': 'Indian Institute of Technology Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Abir De', 'openreview_id': '~Abir_De1', 'affiliation_name': 'Indian Institute of Technology Bombay,', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper introduces GRAPHEDX, a neural estimator for Graph Edit Distance (GED).  It addresses the limitation of existing neural GED methods that do not handle varying edit costs by formulating GED as a quadratic assignment problem (QAP) and employing neural set divergence surrogates.  The model learns optimal node and edge alignments to accurately estimate GED with diverse edit operation costs.
",u7JRmrGutT,Graph Edit Distance with General Costs Using Neural Set Divergence,https://openreview.net/pdf/405e32e6f9667c1d8b6932a8b230ad111ba7d111.pdf,False
poster,"[{'name': 'Ashwin Ramachandran', 'openreview_id': '~Ashwin_Ramachandran1', 'affiliation_name': 'Indian Institute of Technology, Bombay, Dhirubhai Ambani Institute Of Information and Communication Technology', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Vaibhav Raj', 'openreview_id': '~Vaibhav_Raj1', 'affiliation_name': 'Indian Institute of Technology, Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Indradyumna Roy', 'openreview_id': '~Indradyumna_Roy1', 'affiliation_name': 'Indian Institute of Technology Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Soumen_Chakrabarti1', 'affiliation_name': 'Indian Institute of Technology Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Abir De', 'openreview_id': '~Abir_De1', 'affiliation_name': 'Indian Institute of Technology Bombay,', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,True,"This paper introduces IsoNet++, a novel graph neural network (GNN) for subgraph matching in graph retrieval.  It improves upon existing methods by iteratively refining the alignment between query and corpus graphs through early interaction, incorporating node-pair partner interaction, and using a lazy update strategy.  The goal is to achieve significantly better retrieval performance compared to existing techniques.
",udTwwF7tks,Iteratively Refined Early Interaction Alignment for Subgraph Matching based Graph Retrieval,https://openreview.net/pdf/4ae7afbdb746c97e2bfe511705355b40c1bce0e3.pdf,True
poster,"[{'name': 'Fan-Yun Sun', 'openreview_id': '~Fan-Yun_Sun1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}, {'name': 'Harini S I', 'openreview_id': '~Harini_S_I1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': 'Angela Yi', 'openreview_id': '~Angela_Yi2', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}, {'name': 'Yihan Zhou', 'openreview_id': '~Yihan_Zhou4', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}, {'name': 'Alex Zook', 'openreview_id': '~Alex_Zook1', 'affiliation_name': 'NVIDIA', 'affiliation_domain': 'nvidia.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Jonathan_Tremblay1', 'affiliation_name': 'NVIDIA', 'affiliation_domain': 'nvidia.com', 'affiliation_country': 'US'}, {'name': 'Logan Cross', 'openreview_id': '~Logan_Cross1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Jiajun_Wu1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Nick_Haber1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"FACTORSIM is a framework that generates coded simulations from natural language input.  It leverages a factored partially observable Markov decision process representation to improve the accuracy and adherence to input details.  The resulting simulations are evaluated for their ability to facilitate zero-shot transfers in reinforcement learning tasks.
",wBzvYh3PRA,FactorSim: Generative Simulation via Factorized Representation,https://openreview.net/pdf/c3c4eed43ecec8fe574f69437c9137f8c41b7797.pdf,False
poster,"[{'name': 'Burak Varıcı', 'openreview_id': '~Burak_Varıcı1', 'affiliation_name': 'Carnegie Mellon University', 'affiliation_domain': 'cmu.edu', 'affiliation_country': 'US'}, {'name': 'Emre Acartürk', 'openreview_id': '~Emre_Acartürk1', 'affiliation_name': 'Rensselaer Polytechnic Institute', 'affiliation_domain': 'rpi.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Karthikeyan_Shanmugam1', 'affiliation_name': 'Google Deepmind', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Ali_Tajer1', 'affiliation_name': 'Rensselaer Polytechnic Institute', 'affiliation_domain': 'rpi.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper addresses interventional causal representation learning (CRL) with unknown interventions on multiple nodes.  It establishes identifiability results for general latent causal models under various intervention types, matching the best known results for single-node interventions.  Furthermore, the paper provides CRL algorithms achieving these identifiability guarantees.
",weemASPtzg,Linear Causal Representation Learning from Unknown Multi-node Interventions,https://openreview.net/pdf/97134ff9ae5f0c497e5980844484a73aa21a38ba.pdf,False
poster,"[{'name': 'Marc Wanner', 'openreview_id': '~Marc_Wanner1', 'affiliation_name': 'Chalmers University of Technology', 'affiliation_domain': 'chalmers.se', 'affiliation_country': 'SE'}, {'name': 'Laura Lewis', 'openreview_id': '~Laura_Lewis2', 'affiliation_name': 'University of Cambridge', 'affiliation_domain': 'cam.ac.uk', 'affiliation_country': 'GB'}, {'name': 'Chiranjib Bhattacharyya', 'openreview_id': '~Chiranjib_Bhattacharyya1', 'affiliation_name': 'Indian Institute of Science, Indian institute of science, Bangalore', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': 'Devdatt Dubhashi', 'openreview_id': '~Devdatt_Dubhashi1', 'affiliation_name': 'Chalmers University', 'affiliation_domain': 'chalmers.se', 'affiliation_country': 'SE'}, {'name': 'Alexandru Gheorghiu', 'openreview_id': '~Alexandru_Gheorghiu1', 'affiliation_name': 'IBM, International Business Machines', 'affiliation_domain': 'us.ibm.com', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/neurips-2024.json,False,"This paper introduces two machine learning algorithms for predicting ground state properties of quantum systems.  The algorithms achieve constant sample complexity, independent of system size, for learning properties.  The first uses a modified existing model, while the second employs a deep neural network, offering the first rigorous sample complexity bound for neural networks in this context.
",ybLXvqJyQA,Predicting Ground State Properties: Constant Sample Complexity and Deep Learning Algorithms,https://openreview.net/pdf/83a1900fe49a28fcac07aec59f2f276432aaaff2.pdf,False
poster,"[{'name': 'Suresh Bishnoi', 'openreview_id': '~Suresh_Bishnoi1', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Jayadeva_Jayadeva1', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Sayan_Ranu2', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'N M Anoop Krishnan', 'openreview_id': '~N_M_Anoop_Krishnan1', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,True,"This paper introduces BROGNET, a framework utilizing graph neural networks (GNNs) and stochastic differential equations (SDEs) to learn Brownian dynamics from trajectories.  Crucially, the architecture enforces linear momentum conservation, enhancing learning performance and data efficiency.  The authors demonstrate superior performance of BROGNET on various Brownian systems compared to existing baselines, highlighting its zero-shot generalizability to unseen system sizes and different temperatures.
",2iGiSHmeAN,BroGNet: Momentum-Conserving Graph Neural Stochastic Differential Equation for Learning Brownian Dynamics,https://openreview.net/pdf/7068bcb7f8feb34ebb6a585e0060e3135e592aac.pdf,True
poster,"[{'name': '', 'openreview_id': '~Yash_Chandak1', 'affiliation_name': 'Computer Science Department, Stanford University', 'affiliation_domain': 'cs.stanford.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Shiv_Shankar2', 'affiliation_name': 'IIT Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Vasilis_Syrgkanis1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,False,"This paper develops a method for improving the efficiency of indirect experiments, where treatment effects are estimated using instrumental variables rather than direct assignment.  The authors aim to create a practical computational procedure to optimize data collection policies for instrumental variables, specifically minimizing the mean-squared error of treatment effect estimates.  This approach addresses a gap in the existing adaptive experiment design literature by focusing on indirect experimentation scenarios that lack direct intervention control.
",4Zz5UELkIt,Adaptive Instrument Design for Indirect Experiments,https://openreview.net/pdf/841d3f3401e57b98c2c18da54ad64762ad042108.pdf,False
poster,"[{'name': 'Anirudh Buvanesh', 'openreview_id': '~Anirudh_Buvanesh2', 'affiliation_name': 'Mila - Quebec Artificial Intelligence Institute', 'affiliation_domain': 'mila.quebec', 'affiliation_country': 'CA'}, {'name': 'Rahul Chand', 'openreview_id': '~Rahul_Chand1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Jatin Prakash', 'openreview_id': '~Jatin_Prakash2', 'affiliation_name': 'New York University', 'affiliation_domain': 'nyu.edu', 'affiliation_country': 'US'}, {'name': 'Bhawna Paliwal', 'openreview_id': '~Bhawna_Paliwal1', 'affiliation_name': 'Microsoft Research', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'US'}, {'name': 'Mudit Dhawan', 'openreview_id': '~Mudit_Dhawan2', 'affiliation_name': 'Carnegie Mellon University', 'affiliation_domain': 'cmu.edu', 'affiliation_country': 'US'}, {'name': 'Neelabh Madan', 'openreview_id': '~Neelabh_Madan2', 'affiliation_name': 'New York University', 'affiliation_domain': 'nyu.edu', 'affiliation_country': 'US'}, {'name': 'Deepesh Hada', 'openreview_id': '~Deepesh_Hada1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'US'}, {'name': 'Vidit Jain', 'openreview_id': '~Vidit_Jain2', 'affiliation_name': 'Microsoft Research, India', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': 'Sonu Mehta', 'openreview_id': '~SONU_MEHTA1', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'cs.iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Manish Gupta', 'openreview_id': '~Manish_Gupta4', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': 'Ramachandran Ramjee', 'openreview_id': '~Ramachandran_Ramjee1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Manik_Varma1', 'affiliation_name': 'Research, Microsoft', 'affiliation_domain': 'research.microsoft.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,False,"This paper investigates the underperformance of ""tail labels"" (labels with few samples) in extreme classification models.  It proposes a method, LEVER, to reduce label variance by transferring knowledge from a specialized, tail-robust teacher model to the existing One-vs-All classifiers.  Experiments demonstrate improved tail performance on various datasets, achieving a new state-of-the-art in some cases.
",6ARlSgun7J,Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction,https://openreview.net/pdf/a20d3764489727d5956f74f1b28ba95a1d848575.pdf,False
poster,"[{'name': 'Mridul Gupta', 'openreview_id': '~Mridul_Gupta2', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Sahil Manchanda', 'openreview_id': '~Sahil_Manchanda1', 'affiliation_name': 'Pocket FM', 'affiliation_domain': 'pocketfm.com', 'affiliation_country': 'IN'}, {'name': 'HARIPRASAD KODAMANA', 'openreview_id': '~HARIPRASAD_KODAMANA1', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Sayan_Ranu2', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,True,"This paper introduces MIRAGE, a novel graph distillation algorithm for graph classification.  MIRAGE addresses the limitations of existing methods by being model-agnostic, focusing on the inherent computation tree structure of graph neural networks (GNNs).  The method compresses the computation data directly, leading to improved generalization accuracy and distillation efficiency compared to prior approaches.
",78iGZdqxYY,Mirage: Model-agnostic Graph Distillation for Graph Classification,https://openreview.net/pdf/6734ad0e165c7017f3c6c0f400183a1bae684654.pdf,True
poster,"[{'name': 'Ayan Sengupta', 'openreview_id': '~Ayan_Sengupta1', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Md Shad Akhtar', 'openreview_id': '~Md_Shad_Akhtar1', 'affiliation_name': 'Indraprastha Institute of Information Technology, Delhi', 'affiliation_domain': 'iiitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Tanmoy Chakraborty', 'openreview_id': '~Tanmoy_Chakraborty2', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,True,"This paper introduces MPDistil, a meta-policy distillation technique for knowledge distillation.  It aims to improve knowledge transfer from a larger ""teacher"" model to a smaller ""student"" model by fostering collaboration and competition during teacher fine-tuning.  The method also incorporates curriculum learning in the student model to enhance performance and generalizability, achieving significant performance gains compared to existing methods on benchmark datasets like SuperGLUE.
",Ixi4j6LtdX,A Good Learner can Teach Better: Teacher-Student Collaborative Knowledge Distillation,https://openreview.net/pdf/79548908914d91f19b250084cc53384846d7ddbb.pdf,True
poster,"[{'name': 'Shreyas Havaldar', 'openreview_id': '~Shreyas_Havaldar1', 'affiliation_name': 'Columbia University', 'affiliation_domain': 'columbia.edu', 'affiliation_country': 'US'}, {'name': 'Navodita Sharma', 'openreview_id': '~Navodita_Sharma1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': 'Shubhi Sareen', 'openreview_id': '~Shubhi_Sareen1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Karthikeyan_Shanmugam1', 'affiliation_name': 'Google Deepmind', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Aravindan_Raghuveer1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,False,"This paper introduces a novel framework for learning from label proportions (LLP).  The method iteratively refines instance-level pseudo-labels, leveraging both bag-level aggregate labels and covariate similarity, to improve embeddings and ultimately, classification accuracy.  The algorithm demonstrates significant performance gains (up to 15%) compared to state-of-the-art baselines, particularly for large bag sizes, with minimal computational overhead.
",KQe9tHd0k8,Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation,https://openreview.net/pdf/fe1295b607d0d088fa07653fbda2b9c5a57e521f.pdf,False
spotlight,"[{'name': 'Sohan Patnaik', 'openreview_id': '~Sohan_Patnaik1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': 'Milan Aggarwal', 'openreview_id': '~Milan_Aggarwal2', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'US'}, {'name': 'Sumit Bhatia', 'openreview_id': '~Sumit_Bhatia1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': 'Yaman Kumar Singla', 'openreview_id': '~Yaman_Kumar1', 'affiliation_name': 'Adobe ', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Balaji_Krishnamurthy1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,True,"The paper introduces CABINET, a framework designed to improve question answering over tables using large language models (LLMs).  CABINET employs an unsupervised relevance scorer to weigh table content based on question relevance before feeding it to the QA LLM, thereby reducing noise.  The framework also utilizes a weakly supervised module to enhance relevance scoring.
",SQrHpTllXa,CABINET: Content Relevance-based Noise Reduction for Table Question Answering,https://openreview.net/pdf/0a15c1a222a5d423ce19524261f01484f4e7b695.pdf,True
spotlight,"[{'name': '', 'openreview_id': '~Vincent_Roulet1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': 'Krishna Pillutla', 'openreview_id': '~Krishna_Pillutla1', 'affiliation_name': 'Indian Institute of Technology, Madras, Dhirubhai Ambani Institute Of Information and Communication Technology', 'affiliation_domain': 'iitm.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,True,"This paper aims to develop stochastic algorithms for spectral risk minimization, specifically for distributionally robust optimization (DRO) problems.  The authors propose a new algorithm, Prospect, which, unlike previous methods, requires only a single hyperparameter and exhibits linear convergence for smooth regularized losses.  Prospect is designed to be faster than existing methods on various benchmark datasets.
",TTrzgEZt9s,Distributionally Robust Optimization with Bias and Variance Reduction,https://openreview.net/pdf/6c3d461c90f544421c04e52861860e354c20c157.pdf,False
spotlight,"[{'name': 'Ashmit Khandelwal', 'openreview_id': '~Ashmit_Khandelwal1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': 'Aditya Agrawal', 'openreview_id': '~Aditya_Agrawal3', 'affiliation_name': 'Carnegie Mellon University', 'affiliation_domain': 'cmu.edu', 'affiliation_country': 'US'}, {'name': 'Aanisha Bhattacharyya', 'openreview_id': '~Aanisha_Bhattacharyya2', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': 'Yaman Kumar Singla', 'openreview_id': '~Yaman_Kumar1', 'affiliation_name': 'Adobe ', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}, {'name': 'Somesh Singh', 'openreview_id': '~Somesh_Singh1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Uttaran Bhattacharya', 'openreview_id': '~Uttaran_Bhattacharya1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'US'}, {'name': 'Ishita Dasgupta', 'openreview_id': '~Ishita_Dasgupta3', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Rajiv_Ratn_Shah1', 'affiliation_name': 'Indraprastha Institute of Information Technology, Delhi', 'affiliation_domain': 'iiitd.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Changyou_Chen1', 'affiliation_name': 'State University of New York, Buffalo', 'affiliation_domain': 'buffalo.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Balaji_Krishnamurthy1', 'affiliation_name': 'Adobe Systems', 'affiliation_domain': 'adobe.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,True,"This paper introduces Large Content and Behavior Models (LCBMs), which aim to improve upon existing communication models by incorporating receiver behavior into the training data.  The models are designed to predict and optimize communication for desired receiver behaviors, a level of communication not addressed by previous models.  The authors demonstrate the LCBM's capabilities across various tasks and introduce a new corpus (CBC) to stimulate further research.
",TrKq4Wlwcz,"Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior",https://openreview.net/pdf/b2522b24d83cf73195d3d49d25c22b11f9633228.pdf,True
poster,"[{'name': 'Yair Ori Gat', 'openreview_id': '~Yair_Ori_Gat1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Nitay Calderon', 'openreview_id': '~Nitay_Calderon1', 'affiliation_name': 'Technion - Israel Institute of Technology', 'affiliation_domain': 'campus.technion.ac.il', 'affiliation_country': 'IL'}, {'name': '', 'openreview_id': '~Amir_Feder1', 'affiliation_name': 'Columbia University', 'affiliation_domain': 'columbia.edu', 'affiliation_country': 'US'}, {'name': 'Alexander Chapanin', 'openreview_id': '~Alexander_Chapanin1', 'affiliation_name': 'Technion - Israel Institute of Technology, Technion - Israel Institute of Technology', 'affiliation_domain': 'campus.technion.ac.il', 'affiliation_country': 'IL'}, {'name': 'Amit Sharma', 'openreview_id': '~Amit_Sharma3', 'affiliation_name': 'Microsoft Research', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': 'Roi Reichart', 'openreview_id': '~Roi_Reichart1', 'affiliation_name': 'Technion, Israel Institute of Technology', 'affiliation_domain': 'technion.ac.il', 'affiliation_country': 'IL'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,False,"This paper introduces two model-agnostic methods for generating faithful explanations of black-box NLP models.  The first approach utilizes large language models to create counterfactual examples, while the second leverages a learned embedding space guided by an LLM during training.  Both approaches aim to identify causal relationships behind model predictions in NLP tasks.
",UMfcdRIotC,Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals,https://openreview.net/pdf/b005b0a0b705b0f6459282c15ecfdd504dfb1ebd.pdf,False
poster,"[{'name': 'Mert Kosan', 'openreview_id': '~Mert_Kosan1', 'affiliation_name': 'VISA', 'affiliation_domain': 'visa.com', 'affiliation_country': 'US'}, {'name': 'Samidha Verma', 'openreview_id': '~Samidha_Verma1', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Burouj Armgaan', 'openreview_id': '~Burouj_Armgaan1', 'affiliation_name': 'Indian Institute of Technology, Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}, {'name': 'Khushbu Pahwa', 'openreview_id': '~Khushbu_Pahwa1', 'affiliation_name': 'Rice University', 'affiliation_domain': 'rice.edu', 'affiliation_country': 'US'}, {'name': 'Sourav Medya', 'openreview_id': '~Sourav_Medya1', 'affiliation_name': 'University of Illinois at Chicago', 'affiliation_domain': 'uic.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Sayan_Ranu2', 'affiliation_name': 'Indian Institute of Technology Delhi', 'affiliation_domain': 'iitd.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,True,"This research paper presents a benchmarking study evaluating perturbation-based explainability methods for Graph Neural Networks (GNNs).  The study aims to systematically compare various techniques, identifying Pareto-optimal methods and exploring the impact of noise and domain constraints on their stability and feasibility.  The goal is to provide a comprehensive understanding of current explainability methods, highlight areas for improvement, and discuss their real-world applications.
",VJvbOSXRUq,GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking,https://openreview.net/pdf/90e802f6f746c5b317b20806c0d0b7885db4edeb.pdf,False
poster,"[{'name': 'Nishant Jain', 'openreview_id': '~Nishant_Jain2', 'affiliation_name': 'University of Illinois at Urbana-Champaign', 'affiliation_domain': 'illinois.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Karthikeyan_Shanmugam1', 'affiliation_name': 'Google Deepmind', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}, {'name': 'Pradeep Shenoy', 'openreview_id': '~Pradeep_Shenoy1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,True,"This paper introduces a novel approach to learning model uncertainty by reweighting training instances.  It aims to capture diverse sources of uncertainty, such as label noise and distribution shifts, using an auxiliary network trained with a meta-objective that minimizes dropout variance.  This method is shown to improve performance in selective classification and other real-world tasks on various datasets.
",bDWXhzZT40,Learning model uncertainty as variance-minimizing instance weights,https://openreview.net/pdf/ebdd64cc233d279eff550647eb57b1baf57fd9eb.pdf,False
poster,"[{'name': 'Xingyu Zhou', 'openreview_id': '~Xingyu_Zhou2', 'affiliation_name': 'Wayne State University', 'affiliation_domain': 'wayne.edu', 'affiliation_country': 'US'}, {'name': 'Sayak Ray Chowdhury', 'openreview_id': '~Sayak_Ray_Chowdhury1', 'affiliation_name': 'Indian Institute of Technology, Kanpur', 'affiliation_domain': 'iitk.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,True,"This paper addresses the problem of differentially private federated linear contextual bandits.  It proposes an algorithmic framework incorporating privacy protocols to improve upon existing methods' shortcomings in privacy guarantee, regret bounds, and communication cost.  The framework is then analyzed under two differential privacy constraints, demonstrating near-optimal regret performance and offering new theoretical results on privacy amplification via shuffling.
",cuAxSHcsSX,On Differentially Private Federated Linear Contextual Bandits,https://openreview.net/pdf/01e3e3b782a27d1e25f072db1cdadb1ac80b628d.pdf,False
spotlight,"[{'name': 'Sravanthi Gurugubelli', 'openreview_id': '~Sravanthi_Gurugubelli1', 'affiliation_name': 'Indian Institute of Science, Bangalore', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': 'Sundeep Prabhakar Chepuri', 'openreview_id': '~Sundeep_Prabhakar_Chepuri1', 'affiliation_name': 'Indian Institute of Science', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,True,"This paper proposes a scalable simplicial-aware neural network (SaNN) model.  SaNN overcomes the computational limitations of existing simplicial neural networks (SNNs) by pre-aggregating simplicial features.  The model's efficiency and expressive power are theoretically analyzed and validated through experiments, demonstrating its effectiveness in predicting trajectories, simplicial closures, and classifying graphs.
",eUgS9Ig8JG,SaNN: Simple Yet Powerful Simplicial-aware Neural Networks,https://openreview.net/pdf/b5b2e785dec69b9ea0c8b01d6e2eca5896246cce.pdf,True
poster,"[{'name': 'Aleksei Ustimenko', 'openreview_id': '~Aleksei_Ustimenko1', 'affiliation_name': 'ShareChat', 'affiliation_domain': 'sharechat.co', 'affiliation_country': 'IN'}, {'name': 'Aleksandr Beznosikov', 'openreview_id': '~Aleksandr_Beznosikov1', 'affiliation_name': 'Moscow Institute of Physics and Technology', 'affiliation_domain': 'phystech.edu', 'affiliation_country': 'RU'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,True,"This paper analyzes the diffusion approximation of a broad class of Ito chains, a type of Markov chain.  Specifically, it establishes bounds on the error between the discrete-time Ito chain and its continuous-time diffusion counterpart.  The analysis considers chains with potentially non-Gaussian noise, state-dependent diffusion, and inexact drift, covering a wide range of applications.
",fjpfCOV4ru,"Ito Diffusion Approximation of Universal Ito Chains for Sampling, Optimization and Boosting",https://openreview.net/pdf/6096e5c08f636d6144a7e20b80523e0168fe0a4a.pdf,True
poster,"[{'name': 'Karan Mirakhor', 'openreview_id': '~Karan_Mirakhor1', 'affiliation_name': 'CMU, Carnegie Mellon University', 'affiliation_domain': 'andrew.cmu.edu', 'affiliation_country': 'US'}, {'name': 'Sourav Ghosh', 'openreview_id': '~Sourav_Ghosh2', 'affiliation_name': 'Tata Consultancy Services Limited, India', 'affiliation_domain': 'tcs.com', 'affiliation_country': 'IN'}, {'name': 'Dipanjan Das', 'openreview_id': '~Dipanjan_Das4', 'affiliation_name': 'Jadavpur University', 'affiliation_domain': 'jadavpur.edu', 'affiliation_country': 'IN'}, {'name': 'Brojeshwar Bhowmick', 'openreview_id': '~Brojeshwar_Bhowmick3', 'affiliation_name': 'TCS Research & Innovation', 'affiliation_domain': 'tcs.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,True,"This paper introduces a novel task planner for visually guided room rearrangements under partial observability.  The planner leverages a search network incorporating commonsense knowledge, a deep reinforcement learning network, and a graph-based state representation to optimize action sequences.  Experimental results demonstrate superior performance compared to existing state-of-the-art methods.
",jJvXNpvOdM,Task Planning for Visual Room Rearrangement under Partial Observability,https://openreview.net/pdf/12382b91f39a182002d5412bce5637aec72fe8c3.pdf,False
spotlight,"[{'name': 'Niklas Muennighoff', 'openreview_id': '~Niklas_Muennighoff1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}, {'name': 'Qian Liu', 'openreview_id': '~Qian_Liu2', 'affiliation_name': 'Tiktok', 'affiliation_domain': 'bytedance.com', 'affiliation_country': 'SG'}, {'name': 'Armel Randy Zebaze', 'openreview_id': '~Armel_Randy_Zebaze1', 'affiliation_name': 'INRIA', 'affiliation_domain': 'inria.fr', 'affiliation_country': 'FR'}, {'name': 'Qinkai Zheng', 'openreview_id': '~Qinkai_Zheng2', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Binyuan Hui', 'openreview_id': '~Binyuan_Hui1', 'affiliation_name': 'Alibaba Group', 'affiliation_domain': 'alibaba-inc.com', 'affiliation_country': 'CN'}, {'name': 'Terry Yue Zhuo', 'openreview_id': '~Terry_Yue_Zhuo1', 'affiliation_name': 'Commonwealth Scientific and Industrial Research Organisation, CSIRO', 'affiliation_domain': 'data61.csiro.au', 'affiliation_country': 'AU'}, {'name': 'Swayam Singh', 'openreview_id': '~Swayam_Singh1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': 'Xiangru Tang', 'openreview_id': '~Xiangru_Tang2', 'affiliation_name': 'Yale University', 'affiliation_domain': 'yale.edu', 'affiliation_country': 'US'}, {'name': 'Leandro Von Werra', 'openreview_id': '~Leandro_Von_Werra1', 'affiliation_name': 'Hugging Face', 'affiliation_domain': 'hf.co', 'affiliation_country': 'CH'}, {'name': 'Shayne Longpre', 'openreview_id': '~Shayne_Longpre1', 'affiliation_name': 'Massachusetts Institute of Technology', 'affiliation_domain': 'mit.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,False,"This paper aims to improve the performance of large language models (LLMs) on code-related tasks by fine-tuning them on a massive dataset of Git commits (COMMITPACK).  It also introduces a new benchmark (HUMANEVALPACK) to evaluate the models' performance on various coding tasks across multiple programming languages.  The goal is to surpass the performance of existing code LLMs, particularly those not trained on OpenAI outputs, and demonstrate the advantages of using natural code instructions for LLM tuning.
",mw1PWNSWZP,OctoPack: Instruction Tuning Code Large Language Models,https://openreview.net/pdf/2b332f4f4e9406870d019ed23d22f771fefbe70f.pdf,False
poster,"[{'name': '', 'openreview_id': '~Gundeep_Arora1', 'affiliation_name': 'Amazon', 'affiliation_domain': 'amazon.com', 'affiliation_country': 'US'}, {'name': 'Anoop Saladi', 'openreview_id': '~Anoop_Saladi1', 'affiliation_name': 'Amazon', 'affiliation_domain': 'amazon.com', 'affiliation_country': 'IN'}, {'name': 'Rajeev Rastogi', 'openreview_id': '~Rajeev_Rastogi2', 'affiliation_name': 'Amazon', 'affiliation_domain': 'amazon.com', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,False,"This paper investigates how incorporating uncertainty estimates into binary classifiers can improve performance, especially in scenarios with class imbalance.  The authors analyze the impact of uncertainty and model scores on decision boundary selection, developing algorithms incorporating both for better precision-recall trade-offs.  Empirical results on real-world datasets demonstrate improvements of 25-40% in recall at high precision bounds compared to traditional methods.
",nsNyDvNQTc,Leveraging Uncertainty Estimates To Improve Classifier Performance,https://openreview.net/pdf/3bb77982d318ab68d64c9400ec10f25c4cd5ac82.pdf,False
spotlight,"[{'name': 'Shrinivas Ramasubramanian', 'openreview_id': '~Shrinivas_Ramasubramanian1', 'affiliation_name': 'CMU, Carnegie Mellon University', 'affiliation_domain': 'andrew.cmu.edu', 'affiliation_country': 'US'}, {'name': 'Harsh Rangwani', 'openreview_id': '~Harsh_Rangwani1', 'affiliation_name': 'Indian Institute of Science', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': 'Sho Takemori', 'openreview_id': '~Sho_Takemori1', 'affiliation_name': 'Fujitsu Research and Development Center Co. Ltm.', 'affiliation_domain': 'fujitsu.com', 'affiliation_country': 'JP'}, {'name': 'Kunal Samanta', 'openreview_id': '~Kunal_Samanta1', 'affiliation_name': 'Indian Institute of Science, Dhirubhai Ambani Institute Of Information and Communication Technology', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}, {'name': 'Yuhei Umeda', 'openreview_id': '~Yuhei_Umeda1', 'affiliation_name': 'Fujitsu LIMITED', 'affiliation_domain': 'fujitsu.com', 'affiliation_country': 'JP'}, {'name': 'Venkatesh Babu Radhakrishnan', 'openreview_id': '~Venkatesh_Babu_Radhakrishnan2', 'affiliation_name': 'Indian Institute of Science', 'affiliation_domain': 'iisc.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,True,"This paper introduces SelMix, a novel fine-tuning technique for pre-trained models.  SelMix aims to optimize non-decomposable objectives—such as worst-case recall—for deep networks, a problem where existing methods either perform poorly or require complete model retraining.  The method leverages mixup to improve performance on imbalanced classification benchmarks.
",rxVBKhyfSo,Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives,https://openreview.net/pdf/42154f6a78eb07727368d3e4f20969606728ec4b.pdf,False
poster,"[{'name': 'Sina Baharlouei', 'openreview_id': '~Sina_Baharlouei1', 'affiliation_name': 'eBay Inc.', 'affiliation_domain': 'ebay.com', 'affiliation_country': 'US'}, {'name': 'Shivam Patel', 'openreview_id': '~Shivam_Patel1', 'affiliation_name': 'Indian Institute of Technology Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Meisam_Razaviyayn1', 'affiliation_name': 'University of Southern California', 'affiliation_domain': 'usc.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,False,"This paper introduces f-FERM, a novel, scalable framework for fair empirical risk minimization.  It addresses the limitations of existing approaches by utilizing stochastic optimization techniques to achieve theoretical convergence guarantees.  The framework is designed to handle distribution shifts and offers superior fairness-accuracy tradeoffs compared to existing methods.
",s90VIdza2K,f-FERM: A  Scalable Framework for  Robust Fair Empirical Risk Minimization,https://openreview.net/pdf/1d2b7d920918fe102d32b04476b29c2c607925bd.pdf,False
spotlight,"[{'name': 'Omar Khattab', 'openreview_id': '~Omar_Khattab1', 'affiliation_name': 'Databricks, Databricks', 'affiliation_domain': 'databricks.com', 'affiliation_country': 'US'}, {'name': 'Arnav Singhvi', 'openreview_id': '~Arnav_Singhvi1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Paridhi Maheshwari', 'openreview_id': '~Paridhi_Maheshwari1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Zhiyuan Zhang', 'openreview_id': '~Zhiyuan_Zhang4', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}, {'name': 'Keshav Santhanam', 'openreview_id': '~Keshav_Santhanam1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}, {'name': 'Sri Vardhamanan A', 'openreview_id': '~Sri_Vardhamanan_A1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': 'Saiful Haq', 'openreview_id': '~Saiful_Haq1', 'affiliation_name': 'Indian Institute of Technology Bombay, Indian Institute of Technology, Bombay', 'affiliation_domain': 'cse.iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Ashutosh Sharma', 'openreview_id': '~Ashutosh_Sharma1', 'affiliation_name': 'Department of Computer Science, UIUC', 'affiliation_domain': 'cs.illinois.edu', 'affiliation_country': 'US'}, {'name': 'Thomas T. Joshi', 'openreview_id': '~Thomas_T._Joshi1', 'affiliation_name': 'Computer Science Department, Stanford University', 'affiliation_domain': 'cs.stanford.edu', 'affiliation_country': 'US'}, {'name': 'Hanna Moazam', 'openreview_id': '~Hanna_Moazam1', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': '', 'openreview_id': '~Heather_Miller1', 'affiliation_name': 'Carnegie Mellon University', 'affiliation_domain': 'cmu.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Matei_Zaharia1', 'affiliation_name': 'University of California, Berkeley', 'affiliation_domain': 'berkeley.edu', 'affiliation_country': 'US'}, {'name': 'Christopher Potts', 'openreview_id': '~Christopher_Potts1', 'affiliation_name': 'Stanford University', 'affiliation_domain': 'stanford.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,False,"DSPy is a programming model that allows for the creation and optimization of language model (LM) pipelines.  It abstracts LM pipelines as text transformation graphs, enabling parameterized modules that learn prompting, finetuning, augmentation, and reasoning techniques.  The model features a compiler that automates pipeline optimization, leading to performance improvements over traditional prompting methods.
",sY5N0zY5Od,DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines,https://openreview.net/pdf/41028bc2988c119c4fb5c213ab3919ceae696846.pdf,False
poster,"[{'name': 'Anson Bastos', 'openreview_id': '~Anson_Bastos1', 'affiliation_name': 'Microsoft', 'affiliation_domain': 'microsoft.com', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Kuldeep_Singh1', 'affiliation_name': 'Cerence GmbH', 'affiliation_domain': 'cerence.com', 'affiliation_country': 'DE'}, {'name': 'Abhishek Nadgeri', 'openreview_id': '~Abhishek_Nadgeri1', 'affiliation_name': 'RWTH Aachen University', 'affiliation_domain': 'rwth-aachen.de', 'affiliation_country': 'DE'}, {'name': 'Manish Singh', 'openreview_id': '~Manish_Singh4', 'affiliation_name': 'Unknown', 'affiliation_domain': 'unknown.edu', 'affiliation_country': 'UNK'}, {'name': '', 'openreview_id': '~Toyotaro_Suzumura1', 'affiliation_name': 'The University of Tokyo', 'affiliation_domain': 'u-tokyo.ac.jp', 'affiliation_country': 'JP'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,False,"This paper introduces the Evolving Graph Fourier Transform (EFT), a novel spectral transform for temporal graphs with dynamic structures.  The transform aims to efficiently capture evolving graph spectra, overcoming the limitations of existing methods by focusing on the Laplacian of the continuous-time dynamic graph.  This approach outperforms existing techniques by offering a more efficient and effective way to analyze the evolution of temporal graphs.
",uvFhCUPjtI,Beyond Spatio-Temporal Representations: Evolving Fourier Transform for Temporal Graphs,https://openreview.net/pdf/5386623c7dfc54fe602556b341b906eb0ec58d06.pdf,True
poster,"[{'name': 'Prateek Chanda', 'openreview_id': '~Prateek_Chanda2', 'affiliation_name': 'Indian Institute of Technology, Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'Shrey Modi', 'openreview_id': '~Shrey_Modi1', 'affiliation_name': 'Indian Institute of Technology, Bombay', 'affiliation_domain': 'iitb.ac.in', 'affiliation_country': 'IN'}, {'name': '', 'openreview_id': '~Ganesh_Ramakrishnan1', 'affiliation_name': 'Indian Institute of Technology Bombay, Indian Institute of Technology Bombay', 'affiliation_domain': 'cse.iitb.ac.in', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,True,"This paper proposes CORESET-PFEDBAYES, a personalized federated learning method.  It leverages coresets—representative data subsets—to reduce computational burden on clients, while theoretically achieving minimax-optimal generalization error.  Experiments demonstrate improved performance over random sampling for various datasets and architectures.
",uz7d2N2zul,Bayesian Coreset Optimization for Personalized Federated Learning,https://openreview.net/pdf/cd650d7bda1c2da0c78084f2b993c15c2ec0925f.pdf,True
poster,"[{'name': 'Hansheng Xue', 'openreview_id': '~Hansheng_Xue2', 'affiliation_name': 'National University of Singapore', 'affiliation_domain': 'nus.edu.sg', 'affiliation_country': 'SG'}, {'name': 'Vijini Mallawaarachchi', 'openreview_id': '~Vijini_Mallawaarachchi1', 'affiliation_name': 'Flinders University of South Australia', 'affiliation_domain': 'flinders.edu.au', 'affiliation_country': 'AU'}, {'name': 'Lexing Xie', 'openreview_id': '~Lexing_Xie1', 'affiliation_name': 'Australian National University', 'affiliation_domain': 'anu.edu.au', 'affiliation_country': 'AU'}, {'name': 'Vaibhav Rajan', 'openreview_id': '~Vaibhav_Rajan2', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'IN'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,False,"This paper introduces UNITIGBIN, a new metagenomic binning tool.  It leverages unitig-level assembly graphs and heterophilous constraints from marker genes to improve binning accuracy, particularly for shorter sequences.  The authors aim to surpass existing binning methods through this novel approach.
",vBw8JGBJWj,Encoding Unitig-level Assembly Graphs with Heterophilous Constraints for Metagenomic Contigs Binning,https://openreview.net/pdf/5e09b5e2a56f96a1275298d6160aaeaac721aa8d.pdf,False
poster,"[{'name': 'Zhirui Chen', 'openreview_id': '~Zhirui_Chen1', 'affiliation_name': 'National University of Singapore', 'affiliation_domain': 'u.nus.edu', 'affiliation_country': 'SG'}, {'name': 'P. N. Karthik', 'openreview_id': '~P._N._Karthik1', 'affiliation_name': 'Indian Institute of Technology, Hyderabad', 'affiliation_domain': 'iith.ac.in', 'affiliation_country': 'IN'}, {'name': 'Yeow Meng Chee', 'openreview_id': '~Yeow_Meng_Chee2', 'affiliation_name': 'National University of Singapore', 'affiliation_domain': 'nus.edu.sg', 'affiliation_country': 'SG'}, {'name': '', 'openreview_id': '~Vincent_Tan1', 'affiliation_name': 'National University of Singapore', 'affiliation_domain': 'nus.edu.sg', 'affiliation_country': 'SG'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,False,"This paper investigates best arm identification (BAI) in linear bandits under fixed budget constraints and differential privacy.  Specifically, it aims to minimize the error probability of identifying the best arm while adhering to ε-differential privacy constraints, and derives upper and lower bounds on this error probability.  The work fills a gap in the literature by providing results for fixed-budget BAI with differential privacy.
",vrE2fqAInO,Fixed-Budget Differentially Private Best Arm Identification,https://openreview.net/pdf/dd40a8239bbbebb74ac3c42f364deef2026392fb.pdf,False
spotlight,"[{'name': 'Ruqi Bai', 'openreview_id': '~Ruqi_Bai1', 'affiliation_name': 'Purdue University', 'affiliation_domain': 'purdue.edu', 'affiliation_country': 'US'}, {'name': '', 'openreview_id': '~Saurabh_Bagchi1', 'affiliation_name': 'Indian Institute of Technology Bombay, Indian Institute of Technology, Bombay', 'affiliation_domain': 'cse.iitb.ac.in', 'affiliation_country': 'IN'}, {'name': 'David I. Inouye', 'openreview_id': '~David_I._Inouye1', 'affiliation_name': 'Purdue University', 'affiliation_domain': 'purdue.edu', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,False,"This paper introduces a benchmark for Federated Domain Generalization (FDG), addressing the limitations of existing evaluations in terms of client and dataset diversity.  The benchmark evaluates 14 DG methods on 7 datasets, using a novel data partitioning method to control client heterogeneity.  The authors aim to highlight the performance gaps in FDG, especially with large client numbers and heterogeneous datasets, and provide publicly available benchmark code.
",wprSv7ichW,Benchmarking Algorithms for Federated Domain Generalization,https://openreview.net/pdf/216358074a4ed3ebfdc3beb60b624a2b6647445d.pdf,False
poster,"[{'name': 'Christopher A. Choquette-Choo', 'openreview_id': '~Christopher_A._Choquette-Choo1', 'affiliation_name': 'Google DeepMind', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': 'Krishnamurthy Dj Dvijotham', 'openreview_id': '~Krishnamurthy_Dj_Dvijotham1', 'affiliation_name': 'ServiceNow', 'affiliation_domain': 'servicenow.com', 'affiliation_country': 'US'}, {'name': 'Krishna Pillutla', 'openreview_id': '~Krishna_Pillutla1', 'affiliation_name': 'Indian Institute of Technology, Madras, Dhirubhai Ambani Institute Of Information and Communication Technology', 'affiliation_domain': 'iitm.ac.in', 'affiliation_country': 'IN'}, {'name': 'Arun Ganesh', 'openreview_id': '~Arun_Ganesh1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}, {'name': 'Thomas Steinke', 'openreview_id': '~Thomas_Steinke2', 'affiliation_name': 'Google DeepMind', 'affiliation_domain': 'deepmind.com', 'affiliation_country': 'GB'}, {'name': 'Abhradeep Guha Thakurta', 'openreview_id': '~Abhradeep_Guha_Thakurta1', 'affiliation_name': 'Google', 'affiliation_domain': 'google.com', 'affiliation_country': 'US'}]",ui/indiaml-tracker/public/tracker/iclr-2024.json,False,"This paper analyzes differentially private learning algorithms, focusing on the use of correlated noise.  It aims to demonstrate that correlated noise provably improves learning utility compared to existing independent noise methods like DP-SGD.  The authors provide analytical bounds for linear regression and convex problems to quantify this improvement, proposing a more efficient method for finding optimal noise correlations.
",xHmCdSArUC,Correlated Noise Provably Beats Independent Noise for Differentially Private Learning,https://openreview.net/pdf/07874a562caa579a83a03bac6b2e1b60b3da81e6.pdf,False
