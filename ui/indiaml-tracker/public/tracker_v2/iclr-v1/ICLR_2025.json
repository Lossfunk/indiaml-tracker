{
  "conference": "ICLR 2025",
  "focus_country": "India",
  "total_papers": 492,
  "generated_at": "2025-07-06T10:37:20.807637",
  "config": {
    "first_author_weight": 3.0,
    "last_author_weight": 2.0,
    "middle_author_weight": 1.0,
    "status_weights": {
      "oral": 10.0,
      "spotlight": 7.5,
      "poster": 5.0,
      "unknown": 1.0
    },
    "output_format": "json",
    "include_review_details": true,
    "include_citation_data": true
  },
  "papers": [
    {
      "paper_id": "bnINPG5A32",
      "title": "RB-Modulation: Training-Free Stylization using Reference-Based Modulation",
      "status": "Oral",
      "normalized_status": "oral",
      "abstract": "We propose Reference-Based Modulation (RB-Modulation), a new plug-and-play solution for training-free personalization of diffusion models.\nExisting training-free approaches exhibit difficulties in (a) style extraction from reference images in the absence of additional style or content text descriptions, (b) unwanted content leakage from reference style images, and (c) effective composition of style and content. \nRB-Modulation is built on a novel stochastic optimal controller where a style descriptor encodes the desired attributes through a terminal cost. \nThe resulting drift not only overcomes the difficulties above, but also ensures high fidelity to the reference style and adheres to the given text prompt. \nWe also introduce a cross-attention-based feature aggregation scheme that allows RB-Modulation to decouple content and style from the reference image.\nWith theoretical justification and empirical evidence, our test-time optimization framework demonstrates precise extraction and control of *content* and *style* in a training-free manner. \nFurther, our method allows a seamless composition of content and style, which marks a departure from the dependency on external adapters or ControlNets. See project page:  https://rb-modulation.github.io/ for code and further details.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=bnINPG5A32",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Litu_Rout1",
        "name": "Litu Rout",
        "name_site": "Litu Rout, Alexander Korotin, Evgeny Burnaev",
        "openreview_id": "~Litu_Rout1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://liturout.github.io/",
        "dblp_id": "206/6445",
        "google_scholar_url": "https://scholar.google.co.in/citations?hl=en",
        "orcid": null,
        "linkedin_url": "litu-rout-sac-isro/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Texas at Austin (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 30.0,
      "reviews": {
        "rating_mean": 8.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "odjMSBSWRt",
      "title": "DarkBench: Benchmarking Dark Patterns in Large Language Models",
      "status": "Oral",
      "normalized_status": "oral",
      "abstract": "We introduce DarkBench, a comprehensive benchmark for detecting dark design patterns—manipulative techniques that influence user behavior—in interactions with large language models (LLMs). Our benchmark comprises 660 prompts across six categories: brand bias, user retention, sycophancy, anthropomorphism, harmful generation, and sneaking. We evaluate models from five leading companies (OpenAI, Anthropic, Meta, Mistral, Google) and find that some LLMs are explicitly designed to favor their developers' products and exhibit untruthful communication, among other manipulative behaviors. Companies developing LLMs should recognize and mitigate the impact of dark design patterns to promote more ethical Al.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28346",
      "pdf_url": "https://openreview.net/pdf?id=odjMSBSWRt",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Esben_Kran1",
        "name": "Esben Kran",
        "name_site": null,
        "openreview_id": "~Esben_Kran1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://apartresearch.com",
        "dblp_id": null,
        "google_scholar_url": "SH5diRUAAAAJ",
        "orcid": "0000-0003-0710-2635",
        "linkedin_url": "esbenkc/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Apart Research (Unknown)",
        "countries": [
          "Unknown"
        ],
        "country_codes": [
          "UN"
        ]
      },
      "sort_score": 30.0,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "bW9fGYo44s",
      "title": "MotionAura: Generating High-Quality and Motion Consistent Videos using Discrete Diffusion",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "The spatio-temporal complexity of video data presents significant challenges in tasks such as compression, generation, and inpainting. We present four key contributions to address the challenges of spatiotemporal video processing. First, we introduce the 3D Mobile Inverted Vector-Quantization Variational Autoencoder (3D-MBQ-VAE), which combines Variational Autoencoders (VAEs) with masked modeling to enhance spatiotemporal video compression. The model achieves superior temporal consistency and state-of-the-art (SOTA) reconstruction quality by employing a novel training strategy with full frame masking. Second, we present MotionAura, a text-to-video generation framework that utilizes vector-quantized diffusion models to discretize the latent space and capture complex motion dynamics, producing temporally coherent videos aligned with text prompts. Third, we propose a spectral transformer-based denoising network that processes video data in the frequency domain using the Fourier Transform. This method effectively captures global context and long-range dependencies for high-quality video generation and denoising. Lastly, we introduce a downstream task of Sketch Guided Video Inpainting. This task leverages Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning. Our models achieve SOTA performance on a range of benchmarks.  Our work offers robust frameworks for spatiotemporal modeling and user-driven video content manipulation.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29105",
      "pdf_url": "https://openreview.net/pdf?id=bW9fGYo44s",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Onkar_Kishor_Susladkar1",
        "name": "Onkar Kishor Susladkar",
        "name_site": "Onkar Susladkar, Jishu Sen Gupta, Chirag Sehgal, Sparsh Mittal, Rekha Singhal",
        "openreview_id": "~Onkar_Kishor_Susladkar1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "321/1077",
        "google_scholar_url": "pxBOqNkAAAAJ",
        "orcid": "0000-0003-4511-1858",
        "linkedin_url": "onkar-susladkar-248752169/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 22.5,
      "reviews": {
        "rating_mean": 7.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "0nJEgNpb4l",
      "title": "PEAR: Primitive Enabled Adaptive Relabeling for Boosting Hierarchical Reinforcement Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Hierarchical reinforcement learning (HRL) has the potential to solve complex long horizon tasks using temporal abstraction and increased exploration. However, hierarchical agents are difficult to train due to inherent non-stationarity. We present primitive enabled adaptive relabeling (PEAR), a two-phase approach where we first perform adaptive relabeling on a few expert demonstrations to generate efficient subgoal supervision, and then jointly optimize HRL agents by employing reinforcement learning (RL) and imitation learning (IL). We perform theoretical analysis to bound the sub-optimality of our approach and derive a joint optimization framework using RL and IL. Since PEAR utilizes only a few expert demonstrations and considers minimal limiting assumptions on the task structure, it can be easily integrated with typical off-policy \\RL algorithms to produce a practical HRL approach. We perform extensive experiments on challenging environments and show that PEAR is able to outperform various hierarchical and non-hierarchical baselines and achieve upto 80% success rates in complex sparse robotic control tasks where other baselines typically fail to show significant progress. We also perform ablations to thoroughly analyze the importance of our various design choices. Finally, we perform real world robotic experiments on complex tasks and demonstrate that PEAR consistently outperforms the baselines.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/31238",
      "pdf_url": "https://openreview.net/pdf?id=0nJEgNpb4l",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Utsav_Singh1",
        "name": "Utsav Singh",
        "name_site": null,
        "openreview_id": "~Utsav_Singh1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://www.cse.iitk.ac.in/users/utsavz/",
        "dblp_id": "241/9336",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "52UtL8uA35",
      "title": "Deep Networks Learn Features From Local Discontinuities in the Label Function",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Deep neural networks outperform kernel machines on several datasets due to feature learning that happens during gradient descent training. In this paper, we analyze the mechanism through which feature learning happens and use a notion of features that corresponds to discontinuities in the true label function. We hypothesize that the core feature learning mechanism is label function discontinuities attracting model function discontinuities during training. To test this hypothesis, we perform experiments on classification data where the true label function is given by an oblique decision tree. This setup allows easy enumeration of label function discontinuities, while still remaining intractable for static kernel/linear methods. We then design/construct a novel deep architecture called a Deep Linearly Gated Network (DLGN), whose discontinuities in the input space can be easily enumerated.  In this setup, we provide supporting evidence demonstrating the movement of model function discontinuities towards the label function discontinuities during training. The easy enumerability of discontinuities in the DLGN also enables greater mechanistic interpretability. We demonstrate this by extracting the parameters of a high-accuracy decision tree from the parameters of a DLGN. We also show that the DLGN is competitive with ReLU networks and other tree-learning algorithms on several real-world tabular datasets.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30974",
      "pdf_url": "https://openreview.net/pdf?id=52UtL8uA35",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Prithaj_Banerjee1",
        "name": "Prithaj Banerjee",
        "name_site": null,
        "openreview_id": "~Prithaj_Banerjee1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://www.cse.iitm.ac.in/profile.php?arg=Mjc4Mg==",
        "dblp_id": "206/7099.html",
        "google_scholar_url": "rlr99eAAAAAJ",
        "orcid": null,
        "linkedin_url": "prithaj-banerjee-946a3a104/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5RZoYIT3u6",
      "title": "You Only Prune Once: Designing Calibration-Free Model Compression With Policy Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The ever-increasing size of large language models (LLMs) presents significant challenges for deployment due to their heavy computational and memory requirements. Current model pruning techniques attempt to alleviate these issues by relying heavily on external calibration datasets to determine which parameters to prune or compress, thus limiting their flexibility and scalability across different compression ratios. Moreover, these methods often cause severe performance degradation, particularly in downstream tasks, when subjected to higher compression rates. In this paper, we propose *PruneNet*, a novel model compression method that addresses these limitations by reformulating model pruning as a policy learning process. PruneNet decouples the pruning process from the model architecture, eliminating the need for calibration datasets. It learns a stochastic pruning policy to assess parameter importance solely based on intrinsic model properties while preserving the spectral structure to minimize information loss. PruneNet can compress the LLaMA-2-7B model in just 15 minutes, achieving over 80\\% retention of its zero-shot performance with a 30\\% compression ratio, outperforming existing methods that retain only 75\\% performance. Furthermore, on complex multitask language understanding tasks, PruneNet demonstrates its robustness by preserving up to 80\\% performance of the original model, proving itself a superior alternative to conventional structured compression techniques.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30946",
      "pdf_url": "https://openreview.net/pdf?id=5RZoYIT3u6",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ayan_Sengupta1",
        "name": "Ayan Sengupta",
        "name_site": null,
        "openreview_id": "~Ayan_Sengupta1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://victor7246.github.io/",
        "dblp_id": null,
        "google_scholar_url": "90EGfboAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5pd78GmXC6",
      "title": "Charting the Design Space of Neural Graph Representations for Subgraph Matching",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Subgraph matching is vital in knowledge graph (KG) question answering, molecule design, scene graph, code and circuit search, etc.\nNeural methods have shown promising results for subgraph matching.\nOur study of recent systems suggests refactoring them into a unified design space for graph matching networks.\nExisting methods occupy only a few isolated patches in this space, which remains largely uncharted.\nWe undertake the first comprehensive exploration of this space, featuring such axes as attention-based vs. soft permutation-based interaction between query and corpus graphs, aligning nodes vs. edges, and the form of the final scoring network that integrates neural representations of the graphs.\nOur extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.\nBeyond better performance, our study uncovers valuable insights and establishes general design principles for neural graph representation and interaction, which may be of wider interest.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30929",
      "pdf_url": "https://openreview.net/pdf?id=5pd78GmXC6",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vaibhav_Raj1",
        "name": "Vaibhav Raj",
        "name_site": "Vaibhav Raj, Indradyumna Roy, Ashwin Ramachandran, Soumen Chakrabarti, Abir De",
        "openreview_id": "~Vaibhav_Raj1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "vaibhav-raj-8446421b9/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5x88lQ2MsH",
      "title": "Bonsai: Gradient-free Graph Condensation for Node Classification",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph condensation has emerged as a promising avenue to enable scalable training of GNNs by compressing the training dataset while preserving essential graph characteristics. Our study uncovers significant shortcomings in current graph condensation techniques. First, the majority of the algorithms paradoxically require training on the full dataset to perform condensation. Second, due to their gradient-emulating approach, these methods require fresh condensation for any change in hyperparameters or GNN architecture, limiting their flexibility and reusability. To address these challenges, we present Bonsai, a novel graph condensation method empowered by the observation that *computation trees* form the fundamental processing units of message-passing GNNs. Bonsai condenses datasets by encoding a careful selection of *exemplar* trees that maximize the representation of all computation trees in the training set. This unique approach imparts Bonsai as the first linear-time, model-agnostic graph condensation algorithm for node classification that outperforms existing baselines across $7$ real-world datasets on accuracy, while being $22$ times faster on average. Bonsai is grounded in rigorous mathematical guarantees on the adopted approximation strategies, making it robust to GNN architectures, datasets, and parameters.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30924",
      "pdf_url": "https://openreview.net/pdf?id=5x88lQ2MsH",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mridul_Gupta2",
        "name": "Mridul Gupta",
        "name_site": "Mridul Gupta, Sahil Manchanda, HARIPRASAD KODAMANA, Sayan Ranu",
        "openreview_id": "~Mridul_Gupta2",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://web.iitd.ac.in/~aiz218322",
        "dblp_id": null,
        "google_scholar_url": "g_cTs3YAAAAJ",
        "orcid": "0009-0003-4343-4263",
        "linkedin_url": "mridul1618/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "AkBrb7yQ0G",
      "title": "Periodic Materials Generation using Text-Guided Joint Diffusion Model",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Equivariant diffusion models have emerged as the prevailing approach for generat-\ning novel crystal materials due to their ability to leverage the physical symmetries\nof periodic material structures. However, current models do not effectively learn the\njoint distribution of atom types, fractional coordinates, and lattice structure of the\ncrystal material in a cohesive end-to-end diffusion framework. Also, none of these\nmodels work under realistic setups, where users specify the desired characteristics\nthat the generated structures must match. In this work, we introduce TGDMat, a\nnovel text-guided diffusion model designed for 3D periodic material generation.\nOur approach integrates global structural knowledge through textual descriptions\nat each denoising step while jointly generating atom coordinates, types, and lattice\nstructure using a periodic-E(3)-equivariant graph neural network (GNN). Extensive\nexperiments using popular datasets on benchmark tasks reveal that TGDMat out-\nperforms existing baseline methods by a good margin. Notably, for the structure\nprediction task, with just one generated sample, TGDMat outperforms all baseline\nmodels, highlighting the importance of text-guided diffusion. Further, in the genera-\ntion task, TGDMat surpasses all baselines and their text-fusion variants, showcasing\nthe effectiveness of the joint diffusion paradigm. Additionally, incorporating textual\nknowledge reduces overall training and sampling computational overhead while\nenhancing generative performance when utilizing real-world textual prompts from\nexperts. Code is available at https://github.com/kdmsit/TGDMat",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30619",
      "pdf_url": "https://openreview.net/pdf?id=AkBrb7yQ0G",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~KISHALAY_DAS1",
        "name": "KISHALAY DAS",
        "name_site": "KISHALAY DAS, Subhojyoti Khastagir, Pawan Goyal, Seung-Cheol Lee, Satadeep Bhattacharjee, Niloy Ganguly",
        "openreview_id": "~KISHALAY_DAS1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://kdmsit.github.io/index.html",
        "dblp_id": "258/3218",
        "google_scholar_url": "AMP0uJsAAAAJ",
        "orcid": null,
        "linkedin_url": "kishalay-das-kd-309850143/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "DFSb67ksVr",
      "title": "Clique Number Estimation via Differentiable Functions of Adjacency Matrix Permutations",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Estimating the clique number in a graph is central to various applications, e.g., community detection, graph retrieval, etc. \nExisting estimators often rely on non-differentiable combinatorial components. Here, we propose a full differentiable estimator for clique number estimation, which can be trained from distant supervision of clique numbers, rather than demonstrating actual cliques.\nOur key insight is a formulation of the maximum clique problem (MCP) as a maximization of the size of fully dense square submatrix, within a suitably row-column-permuted adjacency matrix.\nWe design a differentiable mechanism to search for permutations that lead to the discovery of such dense blocks.\nHowever, the optimal permutation is not unique, which leads to the learning of spurious permutations. To tackle this problem, we view the MCP problem as a sequence of subgraph matching tasks, each detecting progressively larger cliques in a nested manner. This allows effective navigation through suitable node permutations.\nThese steps result in MxNet, an end-to-end differentiable model, which learns to predict clique number without explicit clique demonstrations, with the added benefit of interpretability.  Experiments on eight datasets show the superior accuracy of our approach.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30469",
      "pdf_url": "https://openreview.net/pdf?id=DFSb67ksVr",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Indradyumna_Roy1",
        "name": "Indradyumna Roy",
        "name_site": null,
        "openreview_id": "~Indradyumna_Roy1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://indradyumna.github.io/",
        "dblp_id": "124/9185.html",
        "google_scholar_url": "qb70i84AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "EzrZX9bd4G",
      "title": "BEEM: Boosting Performance of Early Exit DNNs using Multi-Exit Classifiers as Experts",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Early Exit (EE) techniques have emerged as a means to reduce inference latency in Deep Neural Networks (DNNs). The latency improvement and accuracy in these techniques crucially depend on the criteria used to make exit decisions. We propose a new decision criterion BEEM where exit classifiers are treated as experts and aggregate their confidence scores. The confidence scores are aggregated only if neighbouring experts are consistent in prediction as the samples pass through them, thus capturing their ensemble effect. A sample exits when the aggregated confidence value exceeds a threshold. The threshold is set using the error rates of the intermediate exits aiming to surpass the performance of conventional DNN inference. Experimental results on the COCO dataset for Image captioning and GLUE datasets for various language tasks demonstrate that our method enhances the performance of state-of-the-art EE methods, achieving improvements in speed-up by a factor $1.5\\times$ to $2.1\\times$. When compared to the final layer, its accuracy is comparable in harder Image Captioning and improves in the easier language tasks. The source code is available at https://github.com/Div290/BEEM1/tree/main.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30371",
      "pdf_url": "https://openreview.net/pdf?id=EzrZX9bd4G",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Divya_Jyoti_Bajpai1",
        "name": "Divya Jyoti Bajpai",
        "name_site": null,
        "openreview_id": "~Divya_Jyoti_Bajpai1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://www.ieor.iitb.ac.in/node/2823",
        "dblp_id": "357/1369",
        "google_scholar_url": "J-z9diIAAAAJ",
        "orcid": null,
        "linkedin_url": "divya-jyoti-bajpai-139128209",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Hu0FSOSEyS",
      "title": "Semantic Image Inversion and Editing using Rectified Stochastic Differential Equations",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Generative models transform random noise into images, while their inversion aims to reconstruct structured noise for recovery and editing.\nThis paper addresses two key tasks: (i) *inversion* and (ii) *editing* of real images using stochastic equivalents of rectified flow models (e.g., Flux).\nWhile Diffusion Models (DMs) dominate the field of generative modeling for images, their inversion suffers from faithfulness and editability challenges due to nonlinear drift and diffusion.\nExisting DM inversion methods require costly training of additional parameters or test-time optimization of latent variables.\nRectified Flows (RFs) offer a promising alternative to DMs, yet their inversion remains underexplored. \nWe propose RF inversion using dynamic optimal control derived via a linear quadratic regulator, and prove that the resulting vector field is equivalent to a rectified stochastic differential equation. \nWe further extend our framework to design a stochastic sampler for Flux.\nOur method achieves state-of-the-art performance in zero-shot inversion and editing, surpassing prior works in stroke-to-image synthesis and semantic image editing, with large-scale human evaluations confirming user preference.\nSee our project page https://rf-inversion.github.io/ for code and demo.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30203",
      "pdf_url": "https://openreview.net/pdf?id=Hu0FSOSEyS",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Litu_Rout1",
        "name": "Litu Rout",
        "name_site": "Litu Rout, Alexander Korotin, Evgeny Burnaev",
        "openreview_id": "~Litu_Rout1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://liturout.github.io/",
        "dblp_id": "206/6445",
        "google_scholar_url": "https://scholar.google.co.in/citations?hl=en",
        "orcid": null,
        "linkedin_url": "litu-rout-sac-isro/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Texas at Austin (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 19,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "LO4MEPoqrG",
      "title": "Does Safety Training of LLMs Generalize to Semantically Related Natural Prompts?",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Large Language Models (LLMs) are known to be susceptible to crafted adversarial attacks or jailbreaks that lead to the generation of objectionable content despite being aligned to human preferences using safety fine-tuning methods. While the large dimensionality of input token space makes it inevitable to find *adversarial* prompts that can jailbreak these models, we aim to evaluate whether safety fine-tuned LLMs are safe against *natural* prompts which are semantically related to toxic seed prompts that elicit safe responses after alignment. We surprisingly find that popular aligned LLMs such as GPT-4 can be compromised using naive prompts that are NOT even crafted with an objective of jailbreaking the model. Furthermore, we empirically show that given a seed prompt that elicits a toxic response from an unaligned model, one can systematically generate several semantically related *natural* prompts that can jailbreak aligned LLMs. Towards this, we propose a method of *Response Guided Question Augmentation (ReG-QA)* to evaluate the generalization of safety aligned LLMs to natural prompts, that first generates several toxic answers given a seed question using an unaligned LLM (Q to A), and further leverages an LLM to generate questions that are likely to produce these answers (A to Q). We interestingly find that safety fine-tuned LLMs such as GPT-4o are vulnerable to producing natural jailbreak *questions* from unsafe content (without denial) and can thus be used for the latter (A to Q) step. We obtain attack success rates that are comparable to/ better than leading adversarial attack methods on the JailbreakBench leaderboard, while being significantly more stable against defenses such as Smooth-LLM and Synonym Substitution, which are effective against existing all attacks on the leaderboard.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30001",
      "pdf_url": "https://openreview.net/pdf?id=LO4MEPoqrG",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sravanti_Addepalli1",
        "name": "Sravanti Addepalli",
        "name_site": null,
        "openreview_id": "~Sravanti_Addepalli1",
        "position": 1,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "127/7715",
        "google_scholar_url": "MOO12i0AAAAJ",
        "orcid": null,
        "linkedin_url": "sravanti-addepalli/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (United Kingdom)",
        "countries": [
          "United Kingdom"
        ],
        "country_codes": [
          "GB"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "MyVC4X5B2X",
      "title": "SEBRA : Debiasing through Self-Guided Bias Ranking",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Ranking samples by fine-grained estimates of spuriosity (the degree to which spurious cues are present) has recently been shown to significantly benefit bias mitigation, over the traditional binary biased-vs-unbiased partitioning of train sets. However, this spuriousity ranking comes with the requirement of human supervision. In this paper, we propose a debiasing framework based on our novel Self-Guided Bias Ranking (Sebra), that mitigates biases via an automatic ranking of data points by spuriosity within their respective classes. Sebra leverages a key local symmetry in Empirical Risk Minimization (ERM) training -- the ease of learning a sample via ERM inversely correlates with its spuriousity; the fewer spurious correlations a sample exhibits, the harder it is to learn, and vice versa. However, globally across iterations, ERM tends to deviate from this symmetry. Sebra dynamically steers ERM to correct this deviation, facilitating the sequential learning of attributes in increasing order of difficulty, ie, decreasing order of spuriosity. As a result, the sequence in which Sebra learns samples naturally provides spuriousity rankings. We use the resulting fine-grained bias characterization in a contrastive learning framework to mitigate biases from multiple sources. Extensive experiments show that Sebra consistently outperforms previous state-of-the-art unsupervised debiasing techniques across multiple standard benchmarks, including UrbanCars, BAR, and CelebA.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29907",
      "pdf_url": "https://openreview.net/pdf?id=MyVC4X5B2X",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Adarsh_Kappiyath1",
        "name": "Adarsh Kappiyath",
        "name_site": null,
        "openreview_id": "~Adarsh_Kappiyath1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Fujitsu (United Kingdom)",
        "countries": [
          "United Kingdom"
        ],
        "country_codes": [
          "GB"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 2.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "NHxwxc3ql6",
      "title": "It Helps to Take a Second Opinion: Teaching Smaller LLMs To Deliberate Mutually via Selective Rationale Optimisation",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Very large language models (LLMs) such as GPT-4 have shown the ability to handle complex tasks by generating and self-refining step-by-step rationales. Smaller language models (SLMs), typically with < 13B parameters, have been improved by using the data generated from very-large LMs through knowledge distillation. However, various practical constraints such as API costs, copyright, legal and ethical policies restrict using large (often opaque) models to train smaller models for commercial use. Limited success has been achieved at improving the ability of an SLM to explore the space of possible rationales and evaluate them by itself through self-deliberation. To address this, we propose COALITION, a trainable framework that facilitates interaction between two variants of the same SLM and trains them to generate and refine rationales optimized for the end-task. The variants exhibit different behaviors to produce a set of diverse candidate rationales during the generation and refinement steps. The model is then trained via Selective Rationale Optimization (SRO) to prefer generating rationale candidates that maximize the likelihood of producing the ground-truth answer. During inference, COALITION employs a controller to select the suitable variant for generating and refining the rationales. On five different datasets covering mathematical problems, commonsense reasoning, and natural language inference, COALITION outperforms several baselines by up to 5%. Our ablation studies reveal that cross-communication between the two variants performs better than using the single model to self-refine the rationales. We also demonstrate the applicability of COALITION for LMs of varying scales (4B to 14B parameters) and model families (Mistral, Llama, Qwen, Phi). We release the code for this work here.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29886",
      "pdf_url": "https://openreview.net/pdf?id=NHxwxc3ql6",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sohan_Patnaik1",
        "name": "Sohan Patnaik",
        "name_site": "Sohan Patnaik, Heril Changwal, Milan Aggarwal, Sumit Bhatia, Yaman Singla, Balaji Krishnamurthy",
        "openreview_id": "~Sohan_Patnaik1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": "sohan-patnaik-29061a1a4/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Adobe (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "NtwFghsJne",
      "title": "From Search to Sampling: Generative Models for Robust Algorithmic Recourse",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Algorithmic Recourse provides recommendations to individuals who are adversely impacted by automated model decisions, on how to alter their profiles to achieve a favorable outcome. Effective recourse methods must balance three conflicting goals: proximity to the original profile to minimize cost, plausibility for realistic recourse, and validity to ensure the desired outcome. We show that existing methods train for these objectives separately and then search for recourse through a joint optimization over the recourse goals during inference, leading to poor recourse recommendations. We introduce GenRe, a generative recourse model designed to train the three recourse objectives jointly. Training such generative models is non-trivial due to lack of direct recourse supervision. We propose efficient ways to synthesize such supervision and further show that GenRe's training leads to a consistent estimator. Unlike most prior methods, that employ non-robust gradient descent based search during inference, GenRe simply performs a forward sampling over the generative model to produce minimum cost recourse, leading to superior performance across multiple metrics. We also demonstrate GenRe provides the best trade-off between cost, plausibility and validity, compared to state-of-art baselines. Our code is available at: https://github.com/prateekgargX/genre",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29854",
      "pdf_url": "https://openreview.net/pdf?id=NtwFghsJne",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Prateek_Garg3",
        "name": "Prateek Garg",
        "name_site": "Prateek Garg, Lokesh Nagalapatti, Sunita Sarawagi",
        "openreview_id": "~Prateek_Garg3",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "meuyHdkAAAAJ",
        "orcid": "0009-0005-5348-8905",
        "linkedin_url": "prateekgg/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "bSq0XGS3kW",
      "title": "On the Transfer of Object-Centric Representation Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The goal of object-centric representation learning is to decompose visual scenes into a structured representation that isolates the entities into individual vectors. Recent successes have shown that object-centric representation learning can be scaled to real-world scenes by utilizing features from pre-trained foundation models like DINO. However, so far, these object-centric methods have mostly been applied in-distribution, with models trained and evaluated on the same dataset. This is in contrast to the underlying foundation models, which have been shown to be applicable to a wide range of data and tasks. Thus, in this work, we answer the question of whether current real-world capable object-centric methods exhibit similar levels of transferability by introducing a benchmark comprising seven different synthetic and real-world datasets. We analyze the factors influencing performance under transfer and find that training on diverse real-world images improves generalization to unseen scenarios. Furthermore, inspired by the success of task-specific fine-tuning in foundation models, we introduce a novel fine-tuning strategy to adapt pre-trained vision encoders for the task of object discovery. We find that the proposed approach results in state-of-the-art performance for unsupervised object discovery, exhibiting strong zero-shot transfer to unseen datasets.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29108",
      "pdf_url": "https://openreview.net/pdf?id=bSq0XGS3kW",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aniket_Rajiv_Didolkar1",
        "name": "Aniket Rajiv Didolkar",
        "name_site": null,
        "openreview_id": "~Aniket_Rajiv_Didolkar1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://github.com/dido1998/",
        "dblp_id": "245/8589",
        "google_scholar_url": "https://scholar.google.ca/citations?user=ekvl5o0AAAAJ",
        "orcid": null,
        "linkedin_url": "aniket-didolkar-7a9b8912a",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Manipal Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "bW9fGYo44s",
      "title": "MotionAura: Generating High-Quality and Motion Consistent Videos using Discrete Diffusion",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "The spatio-temporal complexity of video data presents significant challenges in tasks such as compression, generation, and inpainting. We present four key contributions to address the challenges of spatiotemporal video processing. First, we introduce the 3D Mobile Inverted Vector-Quantization Variational Autoencoder (3D-MBQ-VAE), which combines Variational Autoencoders (VAEs) with masked modeling to enhance spatiotemporal video compression. The model achieves superior temporal consistency and state-of-the-art (SOTA) reconstruction quality by employing a novel training strategy with full frame masking. Second, we present MotionAura, a text-to-video generation framework that utilizes vector-quantized diffusion models to discretize the latent space and capture complex motion dynamics, producing temporally coherent videos aligned with text prompts. Third, we propose a spectral transformer-based denoising network that processes video data in the frequency domain using the Fourier Transform. This method effectively captures global context and long-range dependencies for high-quality video generation and denoising. Lastly, we introduce a downstream task of Sketch Guided Video Inpainting. This task leverages Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning. Our models achieve SOTA performance on a range of benchmarks.  Our work offers robust frameworks for spatiotemporal modeling and user-driven video content manipulation.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29105",
      "pdf_url": "https://openreview.net/pdf?id=bW9fGYo44s",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rekha_Singhal1",
        "name": "Rekha Singhal",
        "name_site": null,
        "openreview_id": "~Rekha_Singhal1",
        "position": 5,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "rekha-singhal-7122635/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tata Consultancy Services Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 7.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "c6zI3Cp8c6",
      "title": "A New Perspective on Shampoo's Preconditioner",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Shampoo, a second-order optimization algorithm that uses a Kronecker product preconditioner, has recently received increasing attention from the machine learning community. Despite the increasing popularity of Shampoo, the theoretical foundations of its effectiveness are not well understood. The preconditioner used by Shampoo can be viewed as either an approximation of the Gauss--Newton component of the Hessian or the covariance matrix of the gradients maintained by Adagrad. Our key contribution is providing an explicit and novel connection between the optimal Kronecker product approximation of these matrices and the approximation\nmade by Shampoo. Our connection highlights a subtle but common misconception about Shampoo’s approximation. In particular, the square of the approximation used by the Shampoo optimizer is equivalent to a single step of the power\niteration algorithm for computing the aforementioned optimal Kronecker product approximation. Across a variety of datasets and architectures we empirically\ndemonstrate that this is close to the optimal Kronecker product approximation. We also study the impact of batch gradients and empirical Fisher on the quality of Hessian approximation. Our findings not only advance the theoretical understanding of Shampoo but also illuminate potential pathways for enhancing its practical performance.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29069",
      "pdf_url": "https://openreview.net/pdf?id=c6zI3Cp8c6",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Depen_Morwani1",
        "name": "Depen Morwani",
        "name_site": null,
        "openreview_id": "~Depen_Morwani1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "277/5200",
        "google_scholar_url": "vOngxFUAAAAJ",
        "orcid": null,
        "linkedin_url": "depen-morwani-070298122/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Harvard University (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 2.0463381929681126,
        "confidence_mean": 2.75,
        "confidence_std": 1.0897247358851685,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 11,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "chanJGoa7f",
      "title": "Towards Interpreting Visual Information Processing in Vision-Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Vision-Language Models (VLMs) are powerful tools for processing and understanding text and images. We study the processing of visual tokens in the language model component of LLaVA, a prominent VLM. Our approach focuses on analyzing the localization of object information, the evolution of visual token representations across layers, and the mechanism of integrating visual information for predictions. Through ablation studies, we demonstrated that object identification accuracy drops by over 70\\% when object-specific tokens are removed. We observed that visual token representations become increasingly interpretable in the vocabulary space across layers, suggesting an alignment with textual tokens corresponding to image content. Finally, we found that the model extracts object information from these refined representations at the last token position for prediction, mirroring the process in text-only language models for factual association tasks. These findings provide crucial insights into how VLMs process and integrate visual information, bridging the gap between our understanding of language and vision models, and paving the way for more interpretable and controllable multimodal systems.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29034",
      "pdf_url": "https://openreview.net/pdf?id=chanJGoa7f",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Clement_Neo1",
        "name": "Clement Neo",
        "name_site": null,
        "openreview_id": "~Clement_Neo1",
        "position": 1,
        "gender": null,
        "homepage_url": "https://clementneo.com",
        "dblp_id": "367/9292",
        "google_scholar_url": "Y2-g_2cAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Apart Research (Singapore)",
        "countries": [
          "Singapore"
        ],
        "country_codes": [
          "SG"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 12,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "dOAkHmsjRX",
      "title": "Budgeted Online Continual Learning by Adaptive Layer Freezing and Frequency-based Sampling",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "The majority of online continual learning (CL) advocates single-epoch training and imposes restrictions on the size of replay memory. However, single-epoch training would incur a different amount of computations per CL algorithm, and the additional storage cost to store logit or model in addition to replay memory is largely ignored in calculating the storage budget. Arguing different computational and storage budgets hinder fair comparison among CL algorithms in practice, we propose to use floating point operations (FLOPs) and total memory size in Byte as a metric for computational and memory budgets, respectively, to compare and develop CL algorithms in the same ‘total resource budget.’ To improve a CL method in a limited total budget, we propose adaptive layer freezing that does not update the layers for less informative batches to reduce computational costs with a negligible loss of accuracy. In addition, we propose a memory retrieval method that allows the model to learn the same amount of knowledge as using random retrieval in fewer iterations. Empirical validations on the CIFAR-10/100, CLEAR-10/100, and ImageNet-1K datasets demonstrate that the proposed approach outperforms the state-of-the-art methods within the same total budget. Furthermore, we validate its effectiveness in the Multi-modal Concept incremental Learning setup with multimodal large language models, such as LLaVA-1.5-7B. Code is available at https://github.com/snumprlab/budgeted-cl.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28988",
      "pdf_url": "https://openreview.net/pdf?id=dOAkHmsjRX",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jonghyun_Choi1",
        "name": "Jonghyun Choi",
        "name_site": null,
        "openreview_id": "~Jonghyun_Choi1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://ppolon.github.io/",
        "dblp_id": "21/11103",
        "google_scholar_url": "uiGWnm4AAAAJ",
        "orcid": "0000-0002-7934-8434",
        "linkedin_url": "jonghyun-choi-459bb615/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Seoul National University (South Korea)",
        "countries": [
          "South Korea"
        ],
        "country_codes": [
          "KR"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 7.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "h0vC0fm1q7",
      "title": "Sensitivity Verification for Additive Decision Tree Ensembles",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Tree ensemble models, such as Gradient Boosted Decision Trees (GBDTs) and random forests, are widely popular models for a variety of machine learning tasks. The power of these models comes from the ensemble of decision trees, which makes analysis of such models significantly harder than for single trees. As a result, recent work has focused on developing exact and approximate techniques for questions such as robustness verification, fairness and explainability for such models of tree ensembles.\n\nIn this paper, we focus on a specific problem of feature sensitivity for additive decision tree ensembles and build a formal verification framework for a parametrized variant of it, where we also take into account the confidence of the tree ensemble in its output. We start by showing theoretical (NP-)hardness of the problem and explain how it relates to other verification problems. Next, we provide a novel encoding of the problem using pseudo-Boolean constraints. Based on this encoding, we develop a tunable algorithm to perform sensitivity analysis, which can trade off precision for running time. We implement our algorithm and study its performance on a suite of GBDT benchmarks from the literature. Our experiments show the practical utility of our approach and its improved performance compared to existing approaches.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28785",
      "pdf_url": "https://openreview.net/pdf?id=h0vC0fm1q7",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arhaan_Ahmad1",
        "name": "Arhaan Ahmad",
        "name_site": "Arhaan Ahmad, Tanay Tayal, Ashutosh Gupta, S. Akshay",
        "openreview_id": "~Arhaan_Ahmad1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "arhaan-ahmad-418191182/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.4,
        "rating_std": 0.7999999999999999,
        "confidence_mean": 3.4,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "kbeX97jExm",
      "title": "Neural Wave Equation for Irregularly Sampled Sequence Data",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Sequence labeling problems arise in several real-world applications such as healthcare and robotics. In many such applications, sequence data are irregularly sampled and are of varying complexities. Recently, efforts have been made to develop neural ODE-based architectures to model the evolution of hidden states continuously in time, to address irregularly sampled sequence data. However, they assume a fixed architectural depth and limit their flexibility to adapt to data sets with varying complexities. We propose the neural wave equation, a novel deep learning method inspired by the wave equation, to address this through continuous modeling of depth. Neural Wave Equation models the evolution of hidden states continuously across time as well as depth by using a non-homogeneous wave equation parameterized by a neural network.  Through d'Alembert's analytical solution of the wave equation, we also show that the neural wave equation provides denser connections across the hidden states, allowing for better modeling capability.  We conduct experiments on several sequence labeling problems involving irregularly sampled sequence data and demonstrate the superior performance of the proposed neural wave equation model.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28570",
      "pdf_url": "https://openreview.net/pdf?id=kbeX97jExm",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arkaprava_Majumdar1",
        "name": "Arkaprava Majumdar",
        "name_site": "Arkaprava Majumdar, M Krishna, P. K. Srijith",
        "openreview_id": "~Arkaprava_Majumdar1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "arkaprava-majumdar-b61003179/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "l11DZY5Nxu",
      "title": "Robust Root Cause Diagnosis using In-Distribution Interventions",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Diagnosing the root cause of an anomaly in a complex interconnected system is\na pressing problem in today’s cloud services and industrial operations. We propose In-Distribution Interventions (IDI), a novel algorithm that predicts root cause\nas nodes that meet two criteria: 1) Anomaly: root cause nodes should take on\nanomalous values; 2) Fix: had the root cause nodes assumed usual values, the\ntarget node would not have been anomalous. Prior methods of assessing the fix\ncondition rely on counterfactuals inferred from a Structural Causal Model (SCM)\ntrained on historical data. But since anomalies are rare and fall outside the training distribution, the fitted SCMs yield unreliable counterfactual estimates. IDI\novercomes this by relying on interventional estimates obtained by solely probing the fitted SCM at in-distribution inputs. We present a theoretical analysis\ncomparing and bounding the errors in assessing the fix condition using interventional and counterfactual estimates. We then conduct experiments by systematically varying the SCM’s complexity to demonstrate the cases where IDI’s interventional approach outperforms the counterfactual approach and vice versa.\nExperiments on both synthetic and PetShop RCD benchmark datasets demonstrate that IDI consistently identifies true root causes more accurately and robustly than nine existing state-of-the-art RCD baselines. Code will be released\nat https://github.com/nlokeshiisc/IDI_release.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28541",
      "pdf_url": "https://openreview.net/pdf?id=l11DZY5Nxu",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Lokesh_Nagalapatti1",
        "name": "Lokesh Nagalapatti",
        "name_site": null,
        "openreview_id": "~Lokesh_Nagalapatti1",
        "position": 1,
        "gender": null,
        "homepage_url": "https://nlokesh.netlify.app/",
        "dblp_id": "259/2681.html",
        "google_scholar_url": "BkkZbo0AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 2.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nNiWRRj6r9",
      "title": "ONLINE EPSILON NET & PIERCING SET FOR GEOMETRIC CONCEPTS",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "VC-dimension (Vapnik & Chervonenkis (1971)) and $\\varepsilon$-nets  (Haussler & Welzl (1987)) are key concepts in Statistical Learning Theory. Intuitively, VC-dimension is a measure of the size of a class of sets. The famous $\\varepsilon$-net theorem, a fundamental result in Discrete Geometry, asserts that if the VC-dimension of a set system is bounded, then a small sample exists that intersects all sufficiently large sets.\n    \n    In online learning scenarios where data arrives sequentially, the VC-dimension helps to bound the complexity of the set system, and $\\varepsilon$-nets ensure the selection of a small representative set. This sampling framework is crucial in various domains, including spatial data analysis, motion planning in dynamic environments, optimization of sensor networks, and feature extraction in computer vision, among others. Motivated by these applications, we study the online $\\varepsilon$-net problem for geometric concepts with bounded VC-dimension. While the offline version of this problem has been extensively studied, surprisingly, there are no known theoretical results for the online version to date. We present the first deterministic online algorithm with an optimal competitive ratio for intervals in $\\mathbb{R}$. Next, we give a randomized online algorithm with a near-optimal competitive ratio for axis-aligned boxes in $\\mathbb{R}^d$, for $d\\le 3$. Furthermore, we introduce a novel technique to analyze similar-sized objects of constant description complexity in $\\mathbb{R}^d$, which may be of independent interest. \n    \n    Next, we focus on the continuous version of this problem (called online piercing set), where ranges of the set system are geometric concepts in $\\mathbb{R}^d$ arriving in an online manner, but the universe is the entire ambient space, and the objective is to choose a small sample that intersects all the ranges. Although online piercing set is a very well-studied problem in the literature, to our surprise, very few works have addressed generic geometric concepts without any assumption about the sizes. We advance this field by proposing asymptotically optimal competitive deterministic algorithms for boxes and ellipsoids in $\\mathbb{R}^d$, for any $d\\in\\mathbb{N}$.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28409",
      "pdf_url": "https://openreview.net/pdf?id=nNiWRRj6r9",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sujoy_Bhore1",
        "name": "Sujoy Bhore",
        "name_site": "Sujoy Bhore, Devdan Dey, Satyam Singh",
        "openreview_id": "~Sujoy_Bhore1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 2.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qnlG3zPQUy",
      "title": "ILLUSION: Unveiling Truth with a Comprehensive Multi-Modal, Multi-Lingual Deepfake Dataset",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The proliferation of deepfakes and AI-generated content has led to a surge in media forgeries and misinformation, necessitating robust detection systems. However, current datasets lack diversity across modalities, languages, and real-world scenarios. To address this gap, we present ILLUSION (Integration of Life-Like Unique Synthetic Identities and Objects from Neural Networks), a large-scale, multi-modal\ndeepfake dataset comprising 1.3 million samples spanning audio-visual forgeries, 26 languages, challenging noisy environments, and various manipulation protocols. Generated using 28 state-of-the-art generative techniques, ILLUSION includes\nfaceswaps, audio spoofing, synchronized audio-video manipulations, and synthetic media while ensuring a balanced representation of gender and skin tone for unbiased evaluation. Using Jaccard Index and UpSet plot analysis, we demonstrate ILLUSION’s distinctiveness and minimal overlap with existing datasets, emphasizing its novel generative coverage. We benchmarked image, audio, video, and multi-modal detection models, revealing key challenges such as performance degradation in multilingual and multi-modal contexts, vulnerability to real-world distortions, and limited generalization to zero-day attacks. By bridging synthetic and real-world complexities, ILLUSION provides a challenging yet essential platform for advancing deepfake detection research. The dataset is publicly available at https://www.iab-rubric.org/illusion-database.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28235",
      "pdf_url": "https://openreview.net/pdf?id=qnlG3zPQUy",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Kartik_Thakral1",
        "name": "Kartik Thakral",
        "name_site": "Kartik Thakral, Rishabh Ranjan, Akanksha Singh, Akshat Jain, Richa Singh, Mayank Vatsa",
        "openreview_id": "~Kartik_Thakral1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://sites.google.com/iitj.ac.in/thakralkartik",
        "dblp_id": "256/4230",
        "google_scholar_url": "dSqzxC4AAAAJ",
        "orcid": "0000-0002-2528-9950",
        "linkedin_url": "thakral-kartik?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_contact_details%3BGLN%2FUjpdSz2kzFL0fm6ROg%3D%3D",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Jodhpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.0954451150103321,
        "confidence_mean": 4.0,
        "confidence_std": 0.6324555320336759,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "rnJxelIZrq",
      "title": "Beyond Mere Token Analysis: A Hypergraph Metric Space Framework for Defending Against Socially Engineered LLM Attacks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent jailbreak attempts on Large Language Models (LLMs) have shifted from algorithm-focused to human-like social engineering attacks, with persuasion-based techniques emerging as a particularly effective subset. These attacks evolve rapidly, demonstrate high creativity, and boast superior attack success rates. To combat such threats, we propose a promising approach to enhancing LLM safety by leveraging the underlying geometry of input prompt token embeddings using hypergraphs. This approach allows us to model the differences in information flow between benign and malicious LLM prompts.\n\nIn our approach, each LLM prompt is represented as a metric hypergraph, forming a compact metric space. We then construct a higher-order metric space over these compact metric hypergraphs using the Gromov-Hausdorff distance as a generalized metric. Within this space of metric hypergraph spaces, our safety filter learns to classify between harmful and benign prompts. Our study presents theoretical guarantees on the classifier's generalization error for novel and unseen LLM input prompts. Extensive empirical evaluations demonstrate that our method significantly outperforms both existing state-of-the-art generic defense mechanisms and naive baselines. Notably, our approach also achieves comparable performance to specialized defenses against algorithm-focused attacks.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28172",
      "pdf_url": "https://openreview.net/pdf?id=rnJxelIZrq",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manohar_Kaul1",
        "name": "Manohar Kaul",
        "name_site": null,
        "openreview_id": "~Manohar_Kaul1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://manukaul.github.io/",
        "dblp_id": "29/10735",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=jNroyK4AAAAJ",
        "orcid": null,
        "linkedin_url": "manu-k-72b936287/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Fujitsu Research and Development Center (Japan)",
        "countries": [
          "Japan"
        ],
        "country_codes": [
          "JP"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 1.0897247358851685,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "tDIL7UXmSS",
      "title": "Quantum (Inspired) $D^2$-sampling with Applications",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "$D^2$-sampling is a fundamental component of sampling-based clustering algorithms such as $k$-means++. \nGiven a dataset  $V \\subset \\mathbb{R}^d$ with $N$ points and a center set $C \\subset \\mathbb{R}^d$, $D^2$-sampling refers to picking a point from $V$ where the sampling probability of a point is proportional to its squared distance from the nearest center in $C$.\nThe popular $k$-means++ algorithm is simply a $k$-round $D^2$-sampling process, which runs in $O(Nkd)$ time and gives $O(\\log{k})$-approximation in expectation for the $k$-means problem.\nIn this work, we give a quantum algorithm for (approximate) $D^2$-sampling in the QRAM model that results in a quantum implementation of $k$-means++ with a running time $\\tilde{O}(\\zeta^2 k^2)$. \nHere $\\zeta$ is the aspect ratio ( i.e., largest to smallest interpoint distance) and $\\tilde{O}$ hides polylogarithmic factors in $N, d, k$.\nIt can be shown through a robust approximation analysis of $k$-means++ that the quantum version preserves its $O(\\log{k})$ approximation guarantee.\nFurther, we show that our quantum algorithm for $D^2$-sampling can be  dequantized using the  sample-query access model of Tang (PhD Thesis, Ewin Tang, University of Washington, 2023). This results in a fast quantum-inspired classical implementation of $k$-means++, which we call  QI-$k$-means++, with a running time $O(Nd) + \\tilde{O}(\\zeta^2k^2d)$, where the $O(Nd)$ term is for setting up the sample-query access data structure.\nExperimental investigations show promising results for QI-$k$-means++ on large datasets with bounded aspect ratio.\nFinally, we use our quantum $D^2$-sampling with the known $ D^2$-sampling-based classical approximation scheme \nto obtain the first quantum approximation scheme for the $k$-means problem with polylogarithmic running time dependence on $N$.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28068",
      "pdf_url": "https://openreview.net/pdf?id=tDIL7UXmSS",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Poojan_Chetan_Shah1",
        "name": "Poojan Chetan Shah",
        "name_site": "Poojan Shah, Ragesh Jaiswal",
        "openreview_id": "~Poojan_Chetan_Shah1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "poojan-shah-b077ab25b",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 2.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "zvaiz3FjA9",
      "title": "Designing Concise ConvNets with Columnar Stages",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In the era of vision Transformers, the recent success of VanillaNet shows the huge\npotential of simple and concise convolutional neural networks (ConvNets). Where\nsuch models mainly focus on runtime, it is also crucial to simultaneously focus\non other aspects, e.g., FLOPs, parameters, etc, to strengthen their utility further.\nTo this end, we introduce a refreshing ConvNet macro design called Columnar\nStage Network (CoSNet). CoSNet has a systematically developed simple and\nconcise structure, smaller depth, low parameter count, low FLOPs, and attention-\nless operations, well suited for resource-constrained deployment. The key novelty\nof CoSNet is deploying parallel convolutions with fewer kernels fed by input\nreplication, using columnar stacking of these convolutions, and minimizing the use\nof 1×1 convolution layers. Our comprehensive evaluations show that CoSNet rivals\nmany renowned ConvNets and Transformer designs under resource-constrained\nscenarios. Pretrained models shall be open-sourced.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/27642",
      "pdf_url": "https://openreview.net/pdf?id=zvaiz3FjA9",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ashish_Kumar2",
        "name": "Ashish Kumar",
        "name_site": null,
        "openreview_id": "~Ashish_Kumar2",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://ashishkumar822.github.io",
        "dblp_id": "34/5378-6",
        "google_scholar_url": "n-oRDEYAAAAJ",
        "orcid": null,
        "linkedin_url": "ashishkumar822/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "ScorelabsAI (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "52UtL8uA35",
      "title": "Deep Networks Learn Features From Local Discontinuities in the Label Function",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Deep neural networks outperform kernel machines on several datasets due to feature learning that happens during gradient descent training. In this paper, we analyze the mechanism through which feature learning happens and use a notion of features that corresponds to discontinuities in the true label function. We hypothesize that the core feature learning mechanism is label function discontinuities attracting model function discontinuities during training. To test this hypothesis, we perform experiments on classification data where the true label function is given by an oblique decision tree. This setup allows easy enumeration of label function discontinuities, while still remaining intractable for static kernel/linear methods. We then design/construct a novel deep architecture called a Deep Linearly Gated Network (DLGN), whose discontinuities in the input space can be easily enumerated.  In this setup, we provide supporting evidence demonstrating the movement of model function discontinuities towards the label function discontinuities during training. The easy enumerability of discontinuities in the DLGN also enables greater mechanistic interpretability. We demonstrate this by extracting the parameters of a high-accuracy decision tree from the parameters of a DLGN. We also show that the DLGN is competitive with ReLU networks and other tree-learning algorithms on several real-world tabular datasets.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30974",
      "pdf_url": "https://openreview.net/pdf?id=52UtL8uA35",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Chandra_Shekar_Lakshminarayanan2",
        "name": "Chandra Shekar Lakshminarayanan",
        "name_site": null,
        "openreview_id": "~Chandra_Shekar_Lakshminarayanan2",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://iitpkd.ac.in/people/cnarayanan",
        "dblp_id": "143/7535",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5pd78GmXC6",
      "title": "Charting the Design Space of Neural Graph Representations for Subgraph Matching",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Subgraph matching is vital in knowledge graph (KG) question answering, molecule design, scene graph, code and circuit search, etc.\nNeural methods have shown promising results for subgraph matching.\nOur study of recent systems suggests refactoring them into a unified design space for graph matching networks.\nExisting methods occupy only a few isolated patches in this space, which remains largely uncharted.\nWe undertake the first comprehensive exploration of this space, featuring such axes as attention-based vs. soft permutation-based interaction between query and corpus graphs, aligning nodes vs. edges, and the form of the final scoring network that integrates neural representations of the graphs.\nOur extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.\nBeyond better performance, our study uncovers valuable insights and establishes general design principles for neural graph representation and interaction, which may be of wider interest.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30929",
      "pdf_url": "https://openreview.net/pdf?id=5pd78GmXC6",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abir_De1",
        "name": "Abir De",
        "name_site": null,
        "openreview_id": "~Abir_De1",
        "position": 5,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "118/7174",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=_9ZKKbIAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5x88lQ2MsH",
      "title": "Bonsai: Gradient-free Graph Condensation for Node Classification",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph condensation has emerged as a promising avenue to enable scalable training of GNNs by compressing the training dataset while preserving essential graph characteristics. Our study uncovers significant shortcomings in current graph condensation techniques. First, the majority of the algorithms paradoxically require training on the full dataset to perform condensation. Second, due to their gradient-emulating approach, these methods require fresh condensation for any change in hyperparameters or GNN architecture, limiting their flexibility and reusability. To address these challenges, we present Bonsai, a novel graph condensation method empowered by the observation that *computation trees* form the fundamental processing units of message-passing GNNs. Bonsai condenses datasets by encoding a careful selection of *exemplar* trees that maximize the representation of all computation trees in the training set. This unique approach imparts Bonsai as the first linear-time, model-agnostic graph condensation algorithm for node classification that outperforms existing baselines across $7$ real-world datasets on accuracy, while being $22$ times faster on average. Bonsai is grounded in rigorous mathematical guarantees on the adopted approximation strategies, making it robust to GNN architectures, datasets, and parameters.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30924",
      "pdf_url": "https://openreview.net/pdf?id=5x88lQ2MsH",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sayan_Ranu2",
        "name": "Sayan Ranu",
        "name_site": null,
        "openreview_id": "~Sayan_Ranu2",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://www.cse.iitd.ac.in/~sayan/index.html",
        "dblp_id": "38/768",
        "google_scholar_url": "K4w5qYUAAAAJ",
        "orcid": "0000-0003-4147-9372",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "9juyeCqL0u",
      "title": "Causal Order: The Key to Leveraging Imperfect Experts in Causal Inference",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Large Language Models (LLMs) have recently been used as experts to infer causal graphs, often by repeatedly applying a pairwise prompt that asks about the causal relationship of each variable pair. However, such experts, including human domain experts, cannot distinguish between direct and indirect effects given a pairwise prompt. Therefore, instead of the graph, we propose that causal order be used as a more stable output interface for utilizing expert knowledge. When querying a perfect expert with a pairwise prompt, we show that the inferred graph can have significant errors whereas the causal order is always correct. In practice, however, LLMs are imperfect experts and we find that pairwise prompts lead to multiple cycles and do not yield a valid order. Hence, we propose a prompting strategy that introduces an auxiliary variable for every variable pair and instructs the LLM to avoid cycles within this triplet. We show, both theoretically and empirically, that such a triplet prompt leads to fewer cycles than the pairwise prompt. Across multiple real-world graphs, the triplet prompt yields a more accurate order using both LLMs and human annotators as experts. By querying the expert with different auxiliary variables for the same variable pair, it also increases robustness---triplet method with much smaller models such as Phi-3 and Llama-3 8B outperforms a pairwise prompt with GPT-4. For practical usage, we show how the estimated causal order from the triplet method  can be used to reduce error in downstream discovery and effect inference tasks.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30671",
      "pdf_url": "https://openreview.net/pdf?id=9juyeCqL0u",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Balaji_Krishnamurthy1_1",
        "name": "Balaji Krishnamurthy",
        "name_site": null,
        "openreview_id": "~Vineeth_Balasubramanian1",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://people.iith.ac.in/vineethnb/",
        "dblp_id": "88/4691",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=7soDcboAAAAJ",
        "orcid": "0000-0003-2656-0375",
        "linkedin_url": "vineethnb?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 3.4,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "AkBrb7yQ0G",
      "title": "Periodic Materials Generation using Text-Guided Joint Diffusion Model",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Equivariant diffusion models have emerged as the prevailing approach for generat-\ning novel crystal materials due to their ability to leverage the physical symmetries\nof periodic material structures. However, current models do not effectively learn the\njoint distribution of atom types, fractional coordinates, and lattice structure of the\ncrystal material in a cohesive end-to-end diffusion framework. Also, none of these\nmodels work under realistic setups, where users specify the desired characteristics\nthat the generated structures must match. In this work, we introduce TGDMat, a\nnovel text-guided diffusion model designed for 3D periodic material generation.\nOur approach integrates global structural knowledge through textual descriptions\nat each denoising step while jointly generating atom coordinates, types, and lattice\nstructure using a periodic-E(3)-equivariant graph neural network (GNN). Extensive\nexperiments using popular datasets on benchmark tasks reveal that TGDMat out-\nperforms existing baseline methods by a good margin. Notably, for the structure\nprediction task, with just one generated sample, TGDMat outperforms all baseline\nmodels, highlighting the importance of text-guided diffusion. Further, in the genera-\ntion task, TGDMat surpasses all baselines and their text-fusion variants, showcasing\nthe effectiveness of the joint diffusion paradigm. Additionally, incorporating textual\nknowledge reduces overall training and sampling computational overhead while\nenhancing generative performance when utilizing real-world textual prompts from\nexperts. Code is available at https://github.com/kdmsit/TGDMat",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30619",
      "pdf_url": "https://openreview.net/pdf?id=AkBrb7yQ0G",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Niloy_Ganguly1",
        "name": "Niloy Ganguly",
        "name_site": null,
        "openreview_id": "~Niloy_Ganguly1",
        "position": 6,
        "gender": "M",
        "homepage_url": "http://www.facweb.iitkgp.ac.in/~niloy/",
        "dblp_id": "https://dblp.org/pers/hd/g/Ganguly:Niloy",
        "google_scholar_url": "hCbFmUUAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "DFSb67ksVr",
      "title": "Clique Number Estimation via Differentiable Functions of Adjacency Matrix Permutations",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Estimating the clique number in a graph is central to various applications, e.g., community detection, graph retrieval, etc. \nExisting estimators often rely on non-differentiable combinatorial components. Here, we propose a full differentiable estimator for clique number estimation, which can be trained from distant supervision of clique numbers, rather than demonstrating actual cliques.\nOur key insight is a formulation of the maximum clique problem (MCP) as a maximization of the size of fully dense square submatrix, within a suitably row-column-permuted adjacency matrix.\nWe design a differentiable mechanism to search for permutations that lead to the discovery of such dense blocks.\nHowever, the optimal permutation is not unique, which leads to the learning of spurious permutations. To tackle this problem, we view the MCP problem as a sequence of subgraph matching tasks, each detecting progressively larger cliques in a nested manner. This allows effective navigation through suitable node permutations.\nThese steps result in MxNet, an end-to-end differentiable model, which learns to predict clique number without explicit clique demonstrations, with the added benefit of interpretability.  Experiments on eight datasets show the superior accuracy of our approach.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30469",
      "pdf_url": "https://openreview.net/pdf?id=DFSb67ksVr",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abir_De1",
        "name": "Abir De",
        "name_site": null,
        "openreview_id": "~Abir_De1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "118/7174",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=_9ZKKbIAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "EzrZX9bd4G",
      "title": "BEEM: Boosting Performance of Early Exit DNNs using Multi-Exit Classifiers as Experts",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Early Exit (EE) techniques have emerged as a means to reduce inference latency in Deep Neural Networks (DNNs). The latency improvement and accuracy in these techniques crucially depend on the criteria used to make exit decisions. We propose a new decision criterion BEEM where exit classifiers are treated as experts and aggregate their confidence scores. The confidence scores are aggregated only if neighbouring experts are consistent in prediction as the samples pass through them, thus capturing their ensemble effect. A sample exits when the aggregated confidence value exceeds a threshold. The threshold is set using the error rates of the intermediate exits aiming to surpass the performance of conventional DNN inference. Experimental results on the COCO dataset for Image captioning and GLUE datasets for various language tasks demonstrate that our method enhances the performance of state-of-the-art EE methods, achieving improvements in speed-up by a factor $1.5\\times$ to $2.1\\times$. When compared to the final layer, its accuracy is comparable in harder Image Captioning and improves in the easier language tasks. The source code is available at https://github.com/Div290/BEEM1/tree/main.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30371",
      "pdf_url": "https://openreview.net/pdf?id=EzrZX9bd4G",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manjesh_Kumar_Hanawal1",
        "name": "Manjesh Kumar Hanawal",
        "name_site": null,
        "openreview_id": "~Manjesh_Kumar_Hanawal1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.ieor.iitb.ac.in/mlions",
        "dblp_id": "01/8397",
        "google_scholar_url": "vtVK3KUAAAAJ",
        "orcid": "0000-0002-1807-5487",
        "linkedin_url": "manjesh-kumar-hanawal-a260055/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "NfCEVihkdC",
      "title": "Measuring And Improving Persuasiveness Of Large Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Large Language Models (LLMs) are increasingly being used in workflows involving generating content to be consumed by humans (*e.g.,* marketing) and also in directly interacting with humans (*e.g.,* through chatbots). The development of such systems that are capable of generating verifiably persuasive messages presents both opportunities and challenges for society. On the one hand, such systems could positively impact domains like advertising and social good, such as addressing drug addiction, and on the other, they could be misused for spreading misinformation and shaping political opinions. To channel LLMs' impact on society, we need to develop systems to measure and benchmark their persuasiveness. With this motivation, we introduce **PersuasionBench** and **PersuasionArena**, the first large-scale benchmark and arena containing a battery of tasks to automatically measure the simulative and generative persuasion abilities of large language models. We introduce **transsuasion** (trans = carrying across, suasion = the act of persuading), a novel task of transforming non-persuasive language into persuasive content while preserving other factors determining persuasiveness (sender, receiver, time, and channel). Our findings indicate that the simulative persuasion capabilities of LLMs are barely above random; however, their generative persuasion capabilities are much better. For instance, GPT-4o loses only 36% of the time when playing against the best human persuader. Further, we find that LLMs' persuasiveness correlates positively with model size, but smaller models can also be made to have a higher persuasiveness than much larger models. Notably, targeted training using synthetic and natural datasets significantly enhances smaller models' persuasive capabilities, challenging scale-dependent assumptions. Our findings carry key implications for both model developers and policymakers. For instance, while the EU AI Act and California's SB-1047 aim to regulate AI models based on the number of floating point operations, we demonstrate that simple metrics like this alone fail to capture the full scope of AI's societal impact. We invite the community to explore and contribute to PersuasionArena and PersuasionBench, available at [behavior-in-the-wild.github.io/measure-persuasion](https://behavior-in-the-wild.github.io/measure-persuasion), to advance our understanding of AI-driven persuasion and its societal implications.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29866",
      "pdf_url": "https://openreview.net/pdf?id=NfCEVihkdC",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yaman_Kumar1",
        "name": "Yaman Kumar",
        "name_site": null,
        "openreview_id": "~Yaman_Kumar1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/yaman-kumar/",
        "dblp_id": "239/5601",
        "google_scholar_url": "https://scholar.google.co.in/citations?hl=en",
        "orcid": "0000-0001-7880-8219",
        "linkedin_url": "yaman-kumar/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Adobe (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 5.666666666666667,
        "rating_std": 2.0548046676563256,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 7,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "NtwFghsJne",
      "title": "From Search to Sampling: Generative Models for Robust Algorithmic Recourse",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Algorithmic Recourse provides recommendations to individuals who are adversely impacted by automated model decisions, on how to alter their profiles to achieve a favorable outcome. Effective recourse methods must balance three conflicting goals: proximity to the original profile to minimize cost, plausibility for realistic recourse, and validity to ensure the desired outcome. We show that existing methods train for these objectives separately and then search for recourse through a joint optimization over the recourse goals during inference, leading to poor recourse recommendations. We introduce GenRe, a generative recourse model designed to train the three recourse objectives jointly. Training such generative models is non-trivial due to lack of direct recourse supervision. We propose efficient ways to synthesize such supervision and further show that GenRe's training leads to a consistent estimator. Unlike most prior methods, that employ non-robust gradient descent based search during inference, GenRe simply performs a forward sampling over the generative model to produce minimum cost recourse, leading to superior performance across multiple metrics. We also demonstrate GenRe provides the best trade-off between cost, plausibility and validity, compared to state-of-art baselines. Our code is available at: https://github.com/prateekgargX/genre",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29854",
      "pdf_url": "https://openreview.net/pdf?id=NtwFghsJne",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sunita_Sarawagi1",
        "name": "Sunita Sarawagi",
        "name_site": null,
        "openreview_id": "~Sunita_Sarawagi1",
        "position": 3,
        "gender": "F",
        "homepage_url": "https://www.cse.iitb.ac.in/~sunita/",
        "dblp_id": "s/SunitaSarawagi",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=Hg4HmTAAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "TmCcNuo03f",
      "title": "Measuring And Improving Engagement of Text-to-Image Generation Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent advances in text-to-image generation have achieved impressive aesthetic quality, making these models usable for both personal and commercial purposes. However, in the fields of marketing and advertising, images are often created to be more engaging, as reflected in user behaviors such as increasing clicks, likes, and purchases, in addition to being aesthetically pleasing. To this end, we introduce the challenge of optimizing the image generation process for improved viewer engagement. In order to study image engagement and utility in real-world marketing scenarios, we collect *EngagingImageNet*, the first large-scale dataset of images, along with associated user engagement metrics. Further, we find that existing image evaluation metrics like aesthetics, CLIPScore, PickScore, ImageReward, *etc.* are unable to capture viewer engagement. To address the lack of reliable metrics for assessing image utility, we use the *EngagingImageNet* dataset to train *EngageNet*, an engagement-aware Vision Language Model (VLM) that predicts viewer engagement of images by leveraging contextual information about the tweet content, enterprise details, and posting time. We then explore methods to enhance the engagement of text-to-image models, making initial strides in this direction. These include conditioning image generation on improved prompts, supervised fine-tuning of stable diffusion on high-performing images, and reinforcement learning to align stable diffusion with *EngageNet*-based reward signals, all of which lead to the generation of images with higher viewer engagement. Finally, we propose the *Engagement Arena*, to benchmark text-to-image models based on their ability to generate engaging images, using *EngageNet* as the evaluator, thereby encouraging the research community to measure further advances in the engagement of text-to-image modeling. These contributions provide a new pathway for advancing utility-driven image generation, with significant implications for the commercial application of image generation. We have released our code and dataset on [behavior-in-the-wild.github.io/image-engagement](https://behavior-in-the-wild.github.io/image-engagement).",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=TmCcNuo03f",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yaman_Kumar1",
        "name": "Yaman Kumar",
        "name_site": null,
        "openreview_id": "~Yaman_Kumar1",
        "position": 7,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/yaman-kumar/",
        "dblp_id": "239/5601",
        "google_scholar_url": "https://scholar.google.co.in/citations?hl=en",
        "orcid": "0000-0001-7880-8219",
        "linkedin_url": "yaman-kumar/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Adobe (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Upoxh7wvmJ",
      "title": "Strong Preferences Affect the Robustness of Preference Models and Value Alignment",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Value alignment, which aims to ensure that large language models (LLMs) and other AI agents behave in accordance with human values, is critical for ensuring safety and trustworthiness of these systems. A key component of value alignment is the modeling of human preferences as a representation of human values. In this paper, we investigate the robustness of value alignment by examining the sensitivity of preference models. Specifically, we ask: how do changes in the probabilities of some preferences affect the predictions of these models for other preferences? To answer this question, we theoretically analyze the robustness of widely used preference models by examining their sensitivities to minor changes in preferences they model. Our findings reveal that, in the Bradley-Terry and the Placket-Luce model, the probability of a preference can change significantly as other preferences change, especially when these preferences are dominant (i.e., with probabilities near zero or one). We identify specific conditions where this sensitivity becomes significant for these models and discuss the practical implications for the robustness and safety of value alignment in AI systems.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29453",
      "pdf_url": "https://openreview.net/pdf?id=Upoxh7wvmJ",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mohan_Kankanhalli1",
        "name": "Mohan Kankanhalli",
        "name_site": null,
        "openreview_id": "~Mohan_Kankanhalli1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.comp.nus.edu.sg/~mohan",
        "dblp_id": "09/3613.html",
        "google_scholar_url": "6Lx_eowAAAAJ",
        "orcid": "0000-0002-4846-2015",
        "linkedin_url": "mohan-kankanhalli-583417221",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "National University of Singapore (Singapore)",
        "countries": [
          "Singapore"
        ],
        "country_codes": [
          "SG"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 2.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ff2V3UR9sC",
      "title": "Teaching Human Behavior Improves Content Understanding Abilities Of VLMs",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Communication is defined as \"*Who* says *what* to *whom* with *what* effect.\" A message from a communicator generates downstream receiver effects, also known as behavior. Receiver behavior, being a downstream effect of the message, carries rich signals about it. Even after carrying signals about the message, the behavior signal is often ignored while training vision-language models. We show that training VLMs on receiver behavior can actually help improve their content-understanding abilities. We demonstrate that training VLMs to predict receiver behaviors, such as likes, comments, and replay graphs, which are available at scale, enhances the VLM's performance across a broad range of downstream content understanding tasks. We show this performance increase over 6 types of behavior, 46 different tasks covering image, video, text, and audio over 26 benchmark datasets across both zero-shot and fine-tuning settings, outperforming many supervised baselines on diverse tasks ranging from emotion recognition to captioning by up to 150%. We note that since receiver behavior, such as likes, comments, and replay graphs, is collected by default on the internet and does not need any human annotations to be useful, the performance improvement we get after training on this data is essentially free lunch.  We also release **BLIFT**, our **Behaviour-LLaVA IFT** dataset comprising 730k images and videos with their receiver behavior collected from multiple platforms on which we train our models to achieve this. The dataset and code are available at [behavior-in-the-wild.github.io/behavior-llava](https://behavior-in-the-wild.github.io/behavior-llava).",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28866",
      "pdf_url": "https://openreview.net/pdf?id=ff2V3UR9sC",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yaman_Kumar1",
        "name": "Yaman Kumar",
        "name_site": null,
        "openreview_id": "~Yaman_Kumar1",
        "position": 7,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/yaman-kumar/",
        "dblp_id": "239/5601",
        "google_scholar_url": "https://scholar.google.co.in/citations?hl=en",
        "orcid": "0000-0001-7880-8219",
        "linkedin_url": "yaman-kumar/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "jCDF7G3LpF",
      "title": "EFFICIENT JAILBREAK ATTACK SEQUENCES ON LARGE LANGUAGE MODELS VIA MULTI-ARMED BANDIT-BASED CONTEXT SWITCHING",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Content warning: This paper contains examples of harmful language and content.\nRecent advances in large language models (LLMs) have made them increasingly vulnerable to jailbreaking attempts, where malicious users manipulate models into generating harmful content. While existing approaches rely on either single-step attacks that trigger immediate safety responses or multi-step methods that inefficiently iterate prompts using other LLMs, we introduce ``Sequence of Context\" (SoC) attacks that systematically alter conversational context through strategically crafted context-switching queries (CSQs). We formulate this as a multi-armed bandit (MAB) optimization problem, automatically learning optimal sequences of CSQs that gradually weaken the model's safety boundaries. Our theoretical analysis provides tight bounds on both the expected sequence length until successful jailbreak and the convergence of cumulative rewards. Empirically, our method achieves a 95\\% attack success rate, surpassing PAIR by 63.15\\%, AutoDAN by 60\\%, and ReNeLLM by 50\\%. We evaluate our attack across multiple open-source LLMs including Llama and Mistral variants. Our findings highlight critical vulnerabilities in current LLM safeguards and emphasize the need for defenses that consider sequential attack patterns rather than relying solely on static prompt filtering or iterative refinement.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28647",
      "pdf_url": "https://openreview.net/pdf?id=jCDF7G3LpF",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manohar_Kaul1",
        "name": "Manohar Kaul",
        "name_site": null,
        "openreview_id": "~Manohar_Kaul1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://manukaul.github.io/",
        "dblp_id": "29/10735",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=jNroyK4AAAAJ",
        "orcid": null,
        "linkedin_url": "manu-k-72b936287/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Fujitsu Research and Development Center (Japan)",
        "countries": [
          "Japan"
        ],
        "country_codes": [
          "JP"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "kbeX97jExm",
      "title": "Neural Wave Equation for Irregularly Sampled Sequence Data",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Sequence labeling problems arise in several real-world applications such as healthcare and robotics. In many such applications, sequence data are irregularly sampled and are of varying complexities. Recently, efforts have been made to develop neural ODE-based architectures to model the evolution of hidden states continuously in time, to address irregularly sampled sequence data. However, they assume a fixed architectural depth and limit their flexibility to adapt to data sets with varying complexities. We propose the neural wave equation, a novel deep learning method inspired by the wave equation, to address this through continuous modeling of depth. Neural Wave Equation models the evolution of hidden states continuously across time as well as depth by using a non-homogeneous wave equation parameterized by a neural network.  Through d'Alembert's analytical solution of the wave equation, we also show that the neural wave equation provides denser connections across the hidden states, allowing for better modeling capability.  We conduct experiments on several sequence labeling problems involving irregularly sampled sequence data and demonstrate the superior performance of the proposed neural wave equation model.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28570",
      "pdf_url": "https://openreview.net/pdf?id=kbeX97jExm",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~P._K._Srijith1",
        "name": "P. K. Srijith",
        "name_site": null,
        "openreview_id": "~Srijith_P_K1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://sites.google.com/site/pksrijith/home",
        "dblp_id": "120/8712",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=C1YpEWsAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "l11DZY5Nxu",
      "title": "Robust Root Cause Diagnosis using In-Distribution Interventions",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Diagnosing the root cause of an anomaly in a complex interconnected system is\na pressing problem in today’s cloud services and industrial operations. We propose In-Distribution Interventions (IDI), a novel algorithm that predicts root cause\nas nodes that meet two criteria: 1) Anomaly: root cause nodes should take on\nanomalous values; 2) Fix: had the root cause nodes assumed usual values, the\ntarget node would not have been anomalous. Prior methods of assessing the fix\ncondition rely on counterfactuals inferred from a Structural Causal Model (SCM)\ntrained on historical data. But since anomalies are rare and fall outside the training distribution, the fitted SCMs yield unreliable counterfactual estimates. IDI\novercomes this by relying on interventional estimates obtained by solely probing the fitted SCM at in-distribution inputs. We present a theoretical analysis\ncomparing and bounding the errors in assessing the fix condition using interventional and counterfactual estimates. We then conduct experiments by systematically varying the SCM’s complexity to demonstrate the cases where IDI’s interventional approach outperforms the counterfactual approach and vice versa.\nExperiments on both synthetic and PetShop RCD benchmark datasets demonstrate that IDI consistently identifies true root causes more accurately and robustly than nine existing state-of-the-art RCD baselines. Code will be released\nat https://github.com/nlokeshiisc/IDI_release.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28541",
      "pdf_url": "https://openreview.net/pdf?id=l11DZY5Nxu",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Amit_Sharma3",
        "name": "Amit Sharma",
        "name_site": null,
        "openreview_id": "~Amit_Sharma3",
        "position": 4,
        "gender": "M",
        "homepage_url": "http://amitsharma.in/",
        "dblp_id": "72/2540-7",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=CXgQufgAAAAJ",
        "orcid": "0000-0002-2086-3191",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 2.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xiQNfYl33p",
      "title": "A Generic Framework for Conformal Fairness",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Conformal Prediction (CP) is a popular method for uncertainty quantification with machine learning models. While conformal prediction provides probabilistic guarantees regarding the coverage of the true label, these guarantees are agnostic to the presence of sensitive attributes within the dataset. In this work, we formalize \\textit{Conformal Fairness}, a notion of fairness using conformal predictors, and provide a theoretically well-founded algorithm and associated framework to control for the gaps in coverage between different sensitive groups. Our framework leverages the exchangeability assumption (implicit to CP) rather than the typical IID assumption, allowing us to apply the notion of Conformal Fairness to data types and tasks that are not IID, such as graph data. Experiments were conducted on graph and tabular datasets to demonstrate that the algorithm can control fairness-related gaps in addition to coverage aligned with theoretical expectations.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/27770",
      "pdf_url": "https://openreview.net/pdf?id=xiQNfYl33p",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~srinivasan_parthasarathy1",
        "name": "srinivasan parthasarathy",
        "name_site": null,
        "openreview_id": "~srinivasan_parthasarathy1",
        "position": 5,
        "gender": null,
        "homepage_url": "https://web.cse.ohio-state.edu/~parthasarathy.2/",
        "dblp_id": "p/SParathasarathy.html",
        "google_scholar_url": "2mjUsP8AAAAJ",
        "orcid": "0000-0002-6062-6449",
        "linkedin_url": "srinivasan-parthasarathy-5703761/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Ohio State University (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 2.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xkgfLXZ4e0",
      "title": "Correlating instruction-tuning (in multimodal models) with vision-language processing (in the brain)",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Transformer-based language models, though not explicitly trained to mimic brain recordings, have demonstrated surprising alignment with brain activity. Progress in these models—through increased size, instruction-tuning, and multimodality—has led to better representational alignment with neural data. Recently, a new class of instruction-tuned multimodal LLMs (MLLMs) have emerged, showing remarkable zero-shot capabilities in open-ended multimodal vision tasks. However, it is unknown whether MLLMs, when prompted with natural instructions, lead to better brain alignment and effectively capture instruction-specific representations. To address this, we first investigate the brain alignment, i.e., measuring the degree of predictivity of neural visual activity using text output response embeddings from MLLMs as participants engage in watching natural scenes. Experiments with 10 different instructions (like image captioning, visual question answering, etc.) show that  MLLMs exhibit significantly better brain alignment than vision-only models and perform comparably to non-instruction-tuned multimodal models like CLIP. We also find that while these MLLMs are effective at generating high-quality responses suitable to the task-specific instructions, not all instructions are relevant for brain alignment. Further, by varying instructions, we make the MLLMs encode instruction-specific visual concepts related to the input image. This analysis shows that MLLMs effectively capture count-related and recognition-related concepts, demonstrating strong alignment with brain activity. Notably, the majority of the explained variance of the brain encoding models is shared between MLLM embeddings of image captioning and other instructions. These results indicate that enhancing MLLMs' ability to capture more task-specific information could allow for better differentiation between various types of instructions, and hence improve their precision in predicting brain responses.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/27766",
      "pdf_url": "https://openreview.net/pdf?id=xkgfLXZ4e0",
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manish_Gupta1",
        "name": "Manish Gupta",
        "name_site": null,
        "openreview_id": "~Manish_Gupta1",
        "position": 9,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/manishg/",
        "dblp_id": "g/ManishGupta1.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=eX9PSu0AAAAJ",
        "orcid": "0000-0002-2843-3110",
        "linkedin_url": "manishsgupta/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.0,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "r5IXBlTCGc",
      "title": "Consistency Checks for Language Model Forecasters",
      "status": "Oral",
      "normalized_status": "oral",
      "abstract": "Forecasting is a task that is difficult to evaluate: the ground truth can only be known in the future. Recent work showing LLM forecasters rapidly approaching human-level performance begs the question: how can we benchmark and evaluate these forecasters *instantaneously*? Following the consistency check framework, we measure the performance of forecasters in terms of the consistency of their predictions on different logically-related questions. We propose a new, general consistency metric based on *arbitrage*: for example, if a forecasting AI illogically predicts that both the Democratic and Republican parties have 60\\% probability of winning the 2024 US presidential election, an arbitrageur could trade against the forecaster's predictions and make a profit. We build an automated evaluation system that generates a set of base questions, instantiates consistency checks from these questions, elicits the predictions of the forecaster, and measures the consistency of the predictions. We then build a standard, proper-scoring-rule forecasting benchmark, and show that our (instantaneous) consistency metrics correlate strongly with LLM forecasters' ground truth Brier scores (which are only known in the future). We also release a consistency benchmark that resolves in 2028, providing a long-term evaluation tool for forecasting.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28220",
      "pdf_url": "https://openreview.net/pdf?id=r5IXBlTCGc",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Alejandro_Alvarez1",
        "name": "Alejandro Alvarez",
        "name_site": null,
        "openreview_id": "~Alejandro_Alvarez1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "alejandro-alvarez-balanya/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Independent (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 6.666666666666668,
      "reviews": {
        "rating_mean": 7.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "k3gCieTXeY",
      "title": "INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "The performance differential of large language models (LLM) between languages hinders their effective deployment in many regions, inhibiting the potential economic and societal value of generative AI tools in many communities. However, the development of functional LLMs in many languages (i.e., multilingual LLMs) is bottlenecked by the lack of high-quality evaluation resources in languages other than English. Moreover, current practices in multilingual benchmark construction often translate English resources, ignoring the regional and cultural knowledge of the environments in which multilingual systems would be used. In this work, we construct an evaluation suite of 197,243 QA pairs from local exam sources to measure the capabilities of multilingual LLMs in a variety of regional contexts.\nOur novel resource, INCLUDE, is a comprehensive knowledge- and reasoning-centric benchmark across 44 written languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28601",
      "pdf_url": "https://openreview.net/pdf?id=k3gCieTXeY",
      "github_url": "",
      "total_authors": 57,
      "track_name": "Main Conference",
      "author": {
        "id": "~Alfonso_Amayuelas2",
        "name": "Alfonso Amayuelas",
        "name_site": "Alfonso Amayuelas, Shuai Zhang, Xi Rao, Ce Zhang",
        "openreview_id": "~Alfonso_Amayuelas2",
        "position": 11,
        "gender": "M",
        "homepage_url": "https://www.amayuelas.me/",
        "dblp_id": "281/7669",
        "google_scholar_url": "https://scholar.google.dk/citations?user=QGQ2G28AAAAJ",
        "orcid": null,
        "linkedin_url": "alfonsoamayuelas/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of the People (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 6.160714285714286,
      "reviews": {
        "rating_mean": 7.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 9,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "FBkpCyujtS",
      "title": "Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs",
      "status": "Oral",
      "normalized_status": "oral",
      "abstract": "Large Language Models (LLMs) generate text by sampling the next token from a probability distribution over the vocabulary at each decoding step. Popular sampling methods like top-p (nucleus sampling) often struggle to balance quality and diversity, especially at higher temperatures which lead to incoherent or repetitive outputs. We propose min-p sampling, a dynamic truncation method that adjusts the sampling threshold based on the model's confidence by using the top token's probability as a scaling factor. Our experiments on benchmarks including GPQA, GSM8K, and AlpacaEval Creative Writing show that min-p sampling improves both the quality and diversity of generated text across different model families (Mistral and Llama 3) and model sizes (1B to 123B parameters), especially at higher temperatures. Human evaluations further show a clear preference for min-p sampling, in both text quality and creativity. Min-p sampling has been adopted by popular open-source LLM frameworks, including Hugging Face Transformers, VLLM, and many others, highlighting its considerable impact on improving text generation quality.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30358",
      "pdf_url": "https://openreview.net/pdf?id=FBkpCyujtS",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Clement_Neo1",
        "name": "Clement Neo",
        "name_site": null,
        "openreview_id": "~Clement_Neo1",
        "position": 3,
        "gender": null,
        "homepage_url": "https://clementneo.com",
        "dblp_id": "367/9292",
        "google_scholar_url": "Y2-g_2cAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Oracle Corporation (United Kingdom)",
        "countries": [
          "United Kingdom"
        ],
        "country_codes": [
          "GB"
        ]
      },
      "sort_score": 6.0,
      "reviews": {
        "rating_mean": 8.5,
        "rating_std": 1.6583123951777,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 8,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xak8c9l1nu",
      "title": "Computational Explorations of Total Variation Distance",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "We investigate some previously unexplored (or underexplored) computational aspects of total variation (TV) distance.\nFirst, we give a simple deterministic polynomial-time algorithm for checking equivalence between mixtures of product distributions, over arbitrary alphabets.\nThis corresponds to a special case, whereby the TV distance between the two distributions is zero.\nSecond, we prove that unless $\\mathsf{NP} \\subseteq \\mathsf{RP}$ it is impossible to efficiently estimate the TV distance between arbitrary Ising models, even in a bounded-error randomized setting.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/27775",
      "pdf_url": "https://openreview.net/pdf?id=xak8c9l1nu",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sutanu_Gayen1",
        "name": "Sutanu Gayen",
        "name_site": null,
        "openreview_id": "~Sutanu_Gayen1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "183/2766",
        "google_scholar_url": "aqd7jKoAAAAJ",
        "orcid": "0000-0003-3300-1627",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 6.0,
      "reviews": {
        "rating_mean": 7.2,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 3.4,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "bW9fGYo44s",
      "title": "MotionAura: Generating High-Quality and Motion Consistent Videos using Discrete Diffusion",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "The spatio-temporal complexity of video data presents significant challenges in tasks such as compression, generation, and inpainting. We present four key contributions to address the challenges of spatiotemporal video processing. First, we introduce the 3D Mobile Inverted Vector-Quantization Variational Autoencoder (3D-MBQ-VAE), which combines Variational Autoencoders (VAEs) with masked modeling to enhance spatiotemporal video compression. The model achieves superior temporal consistency and state-of-the-art (SOTA) reconstruction quality by employing a novel training strategy with full frame masking. Second, we present MotionAura, a text-to-video generation framework that utilizes vector-quantized diffusion models to discretize the latent space and capture complex motion dynamics, producing temporally coherent videos aligned with text prompts. Third, we propose a spectral transformer-based denoising network that processes video data in the frequency domain using the Fourier Transform. This method effectively captures global context and long-range dependencies for high-quality video generation and denoising. Lastly, we introduce a downstream task of Sketch Guided Video Inpainting. This task leverages Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning. Our models achieve SOTA performance on a range of benchmarks.  Our work offers robust frameworks for spatiotemporal modeling and user-driven video content manipulation.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29105",
      "pdf_url": "https://openreview.net/pdf?id=bW9fGYo44s",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jishu_Sen_Gupta1",
        "name": "Jishu Sen Gupta",
        "name_site": null,
        "openreview_id": "~Jishu_Sen_Gupta1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "jishu-sengupta-949444258/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 5.625,
      "reviews": {
        "rating_mean": 7.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "71pur4y8gs",
      "title": "TabWak: A Watermark for Tabular Diffusion Models",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "Synthetic data offers alternatives for data augmentation and sharing. Till date, it remains unknown how to use watermarking techniques to trace and audit synthetic tables generated by tabular diffusion models to mitigate potential misuses. In this paper, we design TabWak, the first watermarking method to embed invisible signatures that control the sampling of Gaussian latent codes used to synthesize table rows via the diffusion backbone. TabWak has two key features. Different from existing image watermarking techniques, TabWak uses self-cloning and shuffling to embed the secret key in positional information of random seeds that control the Gaussian latents, allowing to use different seeds at each row for high inter-row diversity and enabling row-wise detectability. To further boost the robustness of watermark detection against post-editing attacks, TabWak uses a valid-bit mechanism that focuses on the tail of the latent code distribution for superior noise resilience. We provide theoretical guarantees on the row diversity and effectiveness of detectability. We evaluate TabWak on five datasets against baselines to show that the quality of watermarked tables remains nearly indistinguishable from non-watermarked tables while achieving high detectability in the presence of strong post-editing attacks, with a 100% true positive rate at a 0.1% false positive rate on synthetic tables with fewer than 300 rows. Our code is available at the following anonymized repository https://github.com/chaoyitud/TabWak.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30853",
      "pdf_url": "https://openreview.net/pdf?id=71pur4y8gs",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jeroen_M._Galjaard1",
        "name": "Jeroen M. Galjaard",
        "name_site": null,
        "openreview_id": "~Jeroen_M._Galjaard1",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tata Steel (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 5.000000000000001,
      "reviews": {
        "rating_mean": 7.2,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 3.4,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "k3gCieTXeY",
      "title": "INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "The performance differential of large language models (LLM) between languages hinders their effective deployment in many regions, inhibiting the potential economic and societal value of generative AI tools in many communities. However, the development of functional LLMs in many languages (i.e., multilingual LLMs) is bottlenecked by the lack of high-quality evaluation resources in languages other than English. Moreover, current practices in multilingual benchmark construction often translate English resources, ignoring the regional and cultural knowledge of the environments in which multilingual systems would be used. In this work, we construct an evaluation suite of 197,243 QA pairs from local exam sources to measure the capabilities of multilingual LLMs in a variety of regional contexts.\nOur novel resource, INCLUDE, is a comprehensive knowledge- and reasoning-centric benchmark across 44 written languages that evaluates multilingual LLMs for performance in the actual language environments where they would be deployed.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28601",
      "pdf_url": "https://openreview.net/pdf?id=k3gCieTXeY",
      "github_url": "",
      "total_authors": 57,
      "track_name": "Main Conference",
      "author": {
        "id": "~Daniel_Fernando_Erazo_Florez1",
        "name": "Daniel Fernando Erazo Florez",
        "name_site": null,
        "openreview_id": "~Daniel_Fernando_Erazo_Florez1",
        "position": 21,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0009-0009-7499-710X",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Bath (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 4.821428571428571,
      "reviews": {
        "rating_mean": 7.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 9,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "TJo6aQb7mK",
      "title": "Surprising Effectiveness of pretraining Ternary Language Model at Scale",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "Rapid advancements in GPU computational power has outpaced memory capacity and bandwidth growth, creating bottlenecks in Large Language Model (LLM) inference. Post-training quantization is the leading method for addressing memory-related bottlenecks in LLM inference, but it suffers from significant performance degradation below 4-bit precision. This paper addresses these challenges by investigating the pretraining of low-bitwidth models specifically Ternary Language Models (TriLMs) as an alternative to traditional floating-point models (FloatLMs) and their post-training quantized versions (QuantLMs). We present Spectra LLM suite, the first open suite of LLMs spanning multiple bit-widths, including FloatLMs, QuantLMs, and TriLMs, ranging from 99M to 3.9B parameters trained on 300B tokens. Our comprehensive evaluation demonstrates that TriLMs offer superior scaling behavior in terms of model size (in bits). Surprisingly, at scales exceeding one billion parameters, TriLMs consistently outperform their QuantLM and FloatLM counterparts for a given bit size across various benchmarks. Notably, the 3.9B parameter TriLM matches the performance of the FloatLM 3.9B across all benchmarks, despite having fewer bits than FloatLM 830M. Overall, this research provides valuable insights into the feasibility and scalability of low-bitwidth language models, paving the way for the development of more efficient LLMs.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29550",
      "pdf_url": "https://openreview.net/pdf?id=TJo6aQb7mK",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arnab_Kumar_Mondal1",
        "name": "Arnab Kumar Mondal",
        "name_site": null,
        "openreview_id": "~Arnab_Kumar_Mondal1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://arnab39.github.io",
        "dblp_id": null,
        "google_scholar_url": "NhWR4yIAAAAJ",
        "orcid": null,
        "linkedin_url": "arnab-mondal-01b522a9/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 4.5,
      "reviews": {
        "rating_mean": 7.6,
        "rating_std": 2.244994432064365,
        "confidence_mean": 3.8,
        "confidence_std": 0.7483314773547882,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xkgfLXZ4e0",
      "title": "Correlating instruction-tuning (in multimodal models) with vision-language processing (in the brain)",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Transformer-based language models, though not explicitly trained to mimic brain recordings, have demonstrated surprising alignment with brain activity. Progress in these models—through increased size, instruction-tuning, and multimodality—has led to better representational alignment with neural data. Recently, a new class of instruction-tuned multimodal LLMs (MLLMs) have emerged, showing remarkable zero-shot capabilities in open-ended multimodal vision tasks. However, it is unknown whether MLLMs, when prompted with natural instructions, lead to better brain alignment and effectively capture instruction-specific representations. To address this, we first investigate the brain alignment, i.e., measuring the degree of predictivity of neural visual activity using text output response embeddings from MLLMs as participants engage in watching natural scenes. Experiments with 10 different instructions (like image captioning, visual question answering, etc.) show that  MLLMs exhibit significantly better brain alignment than vision-only models and perform comparably to non-instruction-tuned multimodal models like CLIP. We also find that while these MLLMs are effective at generating high-quality responses suitable to the task-specific instructions, not all instructions are relevant for brain alignment. Further, by varying instructions, we make the MLLMs encode instruction-specific visual concepts related to the input image. This analysis shows that MLLMs effectively capture count-related and recognition-related concepts, demonstrating strong alignment with brain activity. Notably, the majority of the explained variance of the brain encoding models is shared between MLLM embeddings of image captioning and other instructions. These results indicate that enhancing MLLMs' ability to capture more task-specific information could allow for better differentiation between various types of instructions, and hence improve their precision in predicting brain responses.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/27766",
      "pdf_url": "https://openreview.net/pdf?id=xkgfLXZ4e0",
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Akshett_Rai_Jindal1",
        "name": "Akshett Rai Jindal",
        "name_site": null,
        "openreview_id": "~Akshett_Rai_Jindal1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "lV4mq6QAAAAJ",
        "orcid": null,
        "linkedin_url": "https://linkedin.com/in/akshettrj",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology, Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 4.375,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.0,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "zl3pfz4VCV",
      "title": "MMTEB: Massive Multilingual Text Embedding Benchmark",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Text embeddings are typically evaluated on a narrow set of tasks, limited in terms of languages, domains, and task types. To circumvent this limitation and to provide a more comprehensive evaluation, we introduce the Massive Multilingual Text Embedding Benchmark (MMTEB) -- a large-scale community-driven initiative expanding MTEB to over 500 quality-controlled evaluation tasks across 1,000+ languages. MMTEB includes a wide range of challenging novel tasks such as instruction following, long-document retrieval, and code retrieval, and represents the largest multilingual collection of evaluation tasks for embedding models to date. We use this collection to construct multiple highly multilingual benchmarks. We evaluate a representative set of models on these benchmarks.\nOur findings indicate that, while LLM-based models can achieve state-of-the-art performance on a subset of languages, the best-performing publicly available model across languages is the notably smaller, multilingual-e5-large-instruct.\n\nMassive benchmarks often impose high computational demands, limiting accessibility, particularly for low-resource communities. To address this, we downsample tasks based on inter-task correlation (i.e., selecting only a diverse set of tasks) while preserving relative rankings.\nWe further optimize tasks such as retrieval by sampling hard negatives, creating smaller but effective splits. These optimizations allow us to introduce benchmarks at a significantly lower computational cost. For instance, we introduce a new zero-shot English benchmark that maintains a similar ordering at a fraction of the cost.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/27651",
      "pdf_url": "https://openreview.net/pdf?id=zl3pfz4VCV",
      "github_url": "",
      "total_authors": 82,
      "track_name": "Main Conference",
      "author": {
        "id": "~Saiteja_Utpala1",
        "name": "Saiteja Utpala",
        "name_site": null,
        "openreview_id": "~Saiteja_Utpala1",
        "position": 12,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "saiteja-utpala/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "ITMO University (Denmark)",
        "countries": [
          "Denmark"
        ],
        "country_codes": [
          "DK"
        ]
      },
      "sort_score": 4.320987654320988,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "JCiF03qnmi",
      "title": "How Does Critical Batch Size Scale in Pre-training?",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Training large-scale models under given resources requires careful design of parallelism strategies. In particular, the efficiency notion of critical batch size (CBS), concerning the compromise between time and compute, marks the threshold beyond which greater data parallelism leads to diminishing returns. To operationalize it, we propose a measure of CBS and pre-train a series of auto-regressive language models, ranging from 85 million to 1.2 billion parameters, on the C4 dataset. Through extensive hyper-parameter sweeps and careful control of factors such as batch size, momentum, and learning rate along with its scheduling, we systematically investigate the impact of scale on CBS. Then we fit scaling laws with respect to model and data sizes to decouple their effects. Overall, our results demonstrate that CBS scales primarily with data size rather than model size, a finding we justify theoretically through the analysis of infinite-width limits of neural networks and infinite-dimensional least squares regression. Of independent interest, we highlight the importance of common hyper-parameter choices and strategies for studying large-scale pre-training beyond fixed training durations.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30121",
      "pdf_url": "https://openreview.net/pdf?id=JCiF03qnmi",
      "github_url": "",
      "total_authors": 8,
      "track_name": "Main Conference",
      "author": {
        "id": "~Depen_Morwani1",
        "name": "Depen Morwani",
        "name_site": null,
        "openreview_id": "~Depen_Morwani1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "277/5200",
        "google_scholar_url": "vOngxFUAAAAJ",
        "orcid": null,
        "linkedin_url": "depen-morwani-070298122/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Harvard University (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 4.2857142857142865,
      "reviews": {
        "rating_mean": 6.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 3.6,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 5,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "9QPH1YQCMn",
      "title": "Infilling Score: A Pretraining Data Detection Algorithm for Large Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In pretraining data detection, the goal is to detect whether a given sentence is in the dataset used for training a Large Language Model LLM). Recent methods (such as Min-K % and Min-K%++) reveal that most training corpora are likely contaminated with both sensitive content and evaluation benchmarks, leading to inflated test set performance. These methods sometimes fail to detect samples from the pretraining data, primarily because they depend on statistics composed of causal token likelihoods. We introduce Infilling Score, a new test-statistic based on non-causal token likelihoods. Infilling Score can be computed for autoregressive models without re-training using Bayes rule. A naive application of Bayes rule scales linearly with the vocabulary size. However, we propose a ratio test-statistic whose computation is invariant to vocabulary size. Empirically, our method achieves a significant accuracy gain over state-of-the-art methods including Min-K%, and Min-K%++ on the WikiMIA benchmark across seven models with different parameter sizes. Further, we achieve higher AUC compared to reference-free methods on the challenging MIMIR benchmark. Finally, we create a benchmark dataset consisting of recent data sources published after the release of Llama-3; this benchmark provides a statistical baseline to indicate potential corpora used for Llama-3 training.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30693",
      "pdf_url": "https://openreview.net/pdf?id=9QPH1YQCMn",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Litu_Rout1",
        "name": "Litu Rout",
        "name_site": "Litu Rout, Alexander Korotin, Evgeny Burnaev",
        "openreview_id": "~Litu_Rout1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://liturout.github.io/",
        "dblp_id": "206/6445",
        "google_scholar_url": "https://scholar.google.co.in/citations?hl=en",
        "orcid": null,
        "linkedin_url": "litu-rout-sac-isro/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Texas at Austin (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 4.166666666666667,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 2.0463381929681126,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "IDxZhXrpNf",
      "title": "SOAP: Improving and Stabilizing Shampoo using Adam for Language Modeling",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "There is growing evidence of the effectiveness of Shampoo, a higher-order preconditioning method, over Adam in deep learning optimization tasks. However, Shampoo's drawbacks include additional hyperparameters and computational overhead when compared to Adam, which only updates running averages of first- and second-moment quantities. This work establishes a formal connection between Shampoo (implemented with the 1/2 power) and Adafactor --- a memory-efficient approximation of Adam --- showing that Shampoo is equivalent to running Adafactor in the eigenbasis of Shampoo's preconditioner. This insight leads to the design of a simpler and computationally efficient algorithm: **S**hampo**O** with **A**dam in the **P**reconditioner's eigenbasis (SOAP).\nWith regards to improving Shampoo's computational efficiency, the most straightforward approach would be to simply compute Shampoo's eigendecomposition less frequently. Unfortunately, as our empirical results show, this leads to performance degradation that worsens with this frequency. SOAP mitigates this degradation by continually updating the running average of the second moment, just as Adam does, but in the current (slowly changing) coordinate basis. Furthermore, since SOAP is equivalent to running Adam in a rotated space, it introduces only one additional hyperparameter (the preconditioning frequency) compared to Adam. We empirically evaluate SOAP on language model pre-training with 360m and 660m sized models. In the large batch regime, SOAP reduces the number of iterations by over 40\\% and wall clock time by over 35\\% compared to AdamW, with approximately 20\\% improvements in both metrics compared to Shampoo. An implementation of SOAP is available at https://github.com/nikhilvyas/SOAP.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30183",
      "pdf_url": "https://openreview.net/pdf?id=IDxZhXrpNf",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Depen_Morwani1",
        "name": "Depen Morwani",
        "name_site": null,
        "openreview_id": "~Depen_Morwani1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "277/5200",
        "google_scholar_url": "vOngxFUAAAAJ",
        "orcid": null,
        "linkedin_url": "depen-morwani-070298122/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Harvard University (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 4.166666666666667,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.25,
        "confidence_std": 1.0897247358851685,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "0dELcFHig2",
      "title": "Multi-modal brain encoding models for multi-modal stimuli",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Despite participants engaging in unimodal stimuli, such as watching images or silent videos, recent work has demonstrated that multi-modal Transformer models can predict visual brain activity impressively well, even with incongruent modality representations. This raises the question of how accurately these multi-modal models can predict brain activity when participants are engaged in multi-modal stimuli. As these models grow increasingly popular, their use in studying neural activity provides insights into how our brains respond to such multi-modal naturalistic stimuli, i.e., where it separates and integrates information across modalities through a hierarchy of early sensory regions to higher cognition (language regions). We investigate this question by using multiple unimodal and two types of multi-modal models—cross-modal and jointly pretrained—to determine which type of models is more relevant to fMRI brain activity when participants are engaged in watching movies (videos with audio). We observe that both types of multi-modal models show improved alignment in several language and visual regions. This study also helps in identifying which brain regions process unimodal versus multi-modal information. We further investigate the contribution of each modality to multi-modal alignment by carefully removing unimodal features one by one from multi-modal representations, and find that there is additional information beyond the unimodal embeddings that is processed in the visual and language regions. Based on this investigation, we find that while for cross-modal models, their brain alignment is partially attributed to the video modality; for jointly pretrained models, it is partially attributed to both the video and audio modalities. These findings serve as strong motivation for the neuro-science community to investigate the interpretability of these models for deepening our understanding of multi-modal information processing in brain.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/31247",
      "pdf_url": "https://openreview.net/pdf?id=0dELcFHig2",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Khushbu_Pahwa1",
        "name": "Khushbu Pahwa",
        "name_site": null,
        "openreview_id": "~Khushbu_Pahwa1",
        "position": 2,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "299/8490",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": "khushbupahwa",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Amazon (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 4.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "9juyeCqL0u",
      "title": "Causal Order: The Key to Leveraging Imperfect Experts in Causal Inference",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Large Language Models (LLMs) have recently been used as experts to infer causal graphs, often by repeatedly applying a pairwise prompt that asks about the causal relationship of each variable pair. However, such experts, including human domain experts, cannot distinguish between direct and indirect effects given a pairwise prompt. Therefore, instead of the graph, we propose that causal order be used as a more stable output interface for utilizing expert knowledge. When querying a perfect expert with a pairwise prompt, we show that the inferred graph can have significant errors whereas the causal order is always correct. In practice, however, LLMs are imperfect experts and we find that pairwise prompts lead to multiple cycles and do not yield a valid order. Hence, we propose a prompting strategy that introduces an auxiliary variable for every variable pair and instructs the LLM to avoid cycles within this triplet. We show, both theoretically and empirically, that such a triplet prompt leads to fewer cycles than the pairwise prompt. Across multiple real-world graphs, the triplet prompt yields a more accurate order using both LLMs and human annotators as experts. By querying the expert with different auxiliary variables for the same variable pair, it also increases robustness---triplet method with much smaller models such as Phi-3 and Llama-3 8B outperforms a pairwise prompt with GPT-4. For practical usage, we show how the estimated causal order from the triplet method  can be used to reduce error in downstream discovery and effect inference tasks.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30671",
      "pdf_url": "https://openreview.net/pdf?id=9juyeCqL0u",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abbavaram_Gowtham_Reddy1",
        "name": "Abbavaram Gowtham Reddy",
        "name_site": null,
        "openreview_id": "~Abbavaram_Gowtham_Reddy1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://gautam0707.github.io",
        "dblp_id": "294/8798",
        "google_scholar_url": "Iewg-GAAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "CISPA Helmholtz Center for Information Security (Germany)",
        "countries": [
          "Germany"
        ],
        "country_codes": [
          "DE"
        ]
      },
      "sort_score": 4.0,
      "reviews": {
        "rating_mean": 6.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 3.4,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "AkBrb7yQ0G",
      "title": "Periodic Materials Generation using Text-Guided Joint Diffusion Model",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Equivariant diffusion models have emerged as the prevailing approach for generat-\ning novel crystal materials due to their ability to leverage the physical symmetries\nof periodic material structures. However, current models do not effectively learn the\njoint distribution of atom types, fractional coordinates, and lattice structure of the\ncrystal material in a cohesive end-to-end diffusion framework. Also, none of these\nmodels work under realistic setups, where users specify the desired characteristics\nthat the generated structures must match. In this work, we introduce TGDMat, a\nnovel text-guided diffusion model designed for 3D periodic material generation.\nOur approach integrates global structural knowledge through textual descriptions\nat each denoising step while jointly generating atom coordinates, types, and lattice\nstructure using a periodic-E(3)-equivariant graph neural network (GNN). Extensive\nexperiments using popular datasets on benchmark tasks reveal that TGDMat out-\nperforms existing baseline methods by a good margin. Notably, for the structure\nprediction task, with just one generated sample, TGDMat outperforms all baseline\nmodels, highlighting the importance of text-guided diffusion. Further, in the genera-\ntion task, TGDMat surpasses all baselines and their text-fusion variants, showcasing\nthe effectiveness of the joint diffusion paradigm. Additionally, incorporating textual\nknowledge reduces overall training and sampling computational overhead while\nenhancing generative performance when utilizing real-world textual prompts from\nexperts. Code is available at https://github.com/kdmsit/TGDMat",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30619",
      "pdf_url": "https://openreview.net/pdf?id=AkBrb7yQ0G",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Subhojyoti_Khastagir1",
        "name": "Subhojyoti Khastagir",
        "name_site": null,
        "openreview_id": "~Subhojyoti_Khastagir1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "271/3391",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "subhojyoti-khastagir-2a4716152/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 4.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qnlG3zPQUy",
      "title": "ILLUSION: Unveiling Truth with a Comprehensive Multi-Modal, Multi-Lingual Deepfake Dataset",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The proliferation of deepfakes and AI-generated content has led to a surge in media forgeries and misinformation, necessitating robust detection systems. However, current datasets lack diversity across modalities, languages, and real-world scenarios. To address this gap, we present ILLUSION (Integration of Life-Like Unique Synthetic Identities and Objects from Neural Networks), a large-scale, multi-modal\ndeepfake dataset comprising 1.3 million samples spanning audio-visual forgeries, 26 languages, challenging noisy environments, and various manipulation protocols. Generated using 28 state-of-the-art generative techniques, ILLUSION includes\nfaceswaps, audio spoofing, synchronized audio-video manipulations, and synthetic media while ensuring a balanced representation of gender and skin tone for unbiased evaluation. Using Jaccard Index and UpSet plot analysis, we demonstrate ILLUSION’s distinctiveness and minimal overlap with existing datasets, emphasizing its novel generative coverage. We benchmarked image, audio, video, and multi-modal detection models, revealing key challenges such as performance degradation in multilingual and multi-modal contexts, vulnerability to real-world distortions, and limited generalization to zero-day attacks. By bridging synthetic and real-world complexities, ILLUSION provides a challenging yet essential platform for advancing deepfake detection research. The dataset is publicly available at https://www.iab-rubric.org/illusion-database.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28235",
      "pdf_url": "https://openreview.net/pdf?id=qnlG3zPQUy",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rishabh_Ranjan4",
        "name": "Rishabh Ranjan",
        "name_site": null,
        "openreview_id": "~Akanksha_Singh1",
        "position": 2,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0009-0004-3264-8829",
        "linkedin_url": "-singh-akanksha/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 4.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.0954451150103321,
        "confidence_mean": 4.0,
        "confidence_std": 0.6324555320336759,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5pd78GmXC6",
      "title": "Charting the Design Space of Neural Graph Representations for Subgraph Matching",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Subgraph matching is vital in knowledge graph (KG) question answering, molecule design, scene graph, code and circuit search, etc.\nNeural methods have shown promising results for subgraph matching.\nOur study of recent systems suggests refactoring them into a unified design space for graph matching networks.\nExisting methods occupy only a few isolated patches in this space, which remains largely uncharted.\nWe undertake the first comprehensive exploration of this space, featuring such axes as attention-based vs. soft permutation-based interaction between query and corpus graphs, aligning nodes vs. edges, and the form of the final scoring network that integrates neural representations of the graphs.\nOur extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.\nBeyond better performance, our study uncovers valuable insights and establishes general design principles for neural graph representation and interaction, which may be of wider interest.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30929",
      "pdf_url": "https://openreview.net/pdf?id=5pd78GmXC6",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Indradyumna_Roy1",
        "name": "Indradyumna Roy",
        "name_site": null,
        "openreview_id": "~Indradyumna_Roy1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://indradyumna.github.io/",
        "dblp_id": "124/9185.html",
        "google_scholar_url": "qb70i84AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of California, San Diego (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 3.75,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5x88lQ2MsH",
      "title": "Bonsai: Gradient-free Graph Condensation for Node Classification",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph condensation has emerged as a promising avenue to enable scalable training of GNNs by compressing the training dataset while preserving essential graph characteristics. Our study uncovers significant shortcomings in current graph condensation techniques. First, the majority of the algorithms paradoxically require training on the full dataset to perform condensation. Second, due to their gradient-emulating approach, these methods require fresh condensation for any change in hyperparameters or GNN architecture, limiting their flexibility and reusability. To address these challenges, we present Bonsai, a novel graph condensation method empowered by the observation that *computation trees* form the fundamental processing units of message-passing GNNs. Bonsai condenses datasets by encoding a careful selection of *exemplar* trees that maximize the representation of all computation trees in the training set. This unique approach imparts Bonsai as the first linear-time, model-agnostic graph condensation algorithm for node classification that outperforms existing baselines across $7$ real-world datasets on accuracy, while being $22$ times faster on average. Bonsai is grounded in rigorous mathematical guarantees on the adopted approximation strategies, making it robust to GNN architectures, datasets, and parameters.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30924",
      "pdf_url": "https://openreview.net/pdf?id=5x88lQ2MsH",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Samyak_Jain5",
        "name": "Samyak Jain",
        "name_site": null,
        "openreview_id": "~Samyak_Jain5",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "samyak-jain1729/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.75,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "FrFQpAgnGE",
      "title": "The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Modern language models can process inputs across diverse languages and modalities. We hypothesize that models acquire this capability through learning a _shared representation space_ across heterogeneous data types (e.g., different languages and modalities), which places semantically similar inputs near one another, even if they are from different modalities/languages. We term this the _semantic hub hypothesis_, following the hub-and-spoke model from neuroscience (Patterson et al., 2007) which posits that semantic knowledge in the human brain is organized through a transmodal semantic \"hub\" which integrates information from various modality-specific ``spokes'' regions. We first show that model representations for semantically equivalent inputs in different languages are similar in the intermediate layers,  and that this space can be interpreted using the model's dominant pretraining language via the logit lens. This tendency extends to other data types, including arithmetic expressions, code, and visual/audio inputs. Interventions in the shared representation space in one data type also predictably affect model outputs in other data types, suggesting that this shared representations space is not simply a vestigial byproduct of large-scale training on broad data, but something that is actively utilized by the model during input processing.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30324",
      "pdf_url": "https://openreview.net/pdf?id=FrFQpAgnGE",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yoon_Kim1",
        "name": "Yoon Kim",
        "name_site": null,
        "openreview_id": "~Yoon_Kim1",
        "position": 2,
        "gender": null,
        "homepage_url": "https://people.csail.mit.edu/yoonkim/",
        "dblp_id": null,
        "google_scholar_url": "n_ts4eYAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Massachusetts Institute of Technology (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 3.75,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "bW9fGYo44s",
      "title": "MotionAura: Generating High-Quality and Motion Consistent Videos using Discrete Diffusion",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "The spatio-temporal complexity of video data presents significant challenges in tasks such as compression, generation, and inpainting. We present four key contributions to address the challenges of spatiotemporal video processing. First, we introduce the 3D Mobile Inverted Vector-Quantization Variational Autoencoder (3D-MBQ-VAE), which combines Variational Autoencoders (VAEs) with masked modeling to enhance spatiotemporal video compression. The model achieves superior temporal consistency and state-of-the-art (SOTA) reconstruction quality by employing a novel training strategy with full frame masking. Second, we present MotionAura, a text-to-video generation framework that utilizes vector-quantized diffusion models to discretize the latent space and capture complex motion dynamics, producing temporally coherent videos aligned with text prompts. Third, we propose a spectral transformer-based denoising network that processes video data in the frequency domain using the Fourier Transform. This method effectively captures global context and long-range dependencies for high-quality video generation and denoising. Lastly, we introduce a downstream task of Sketch Guided Video Inpainting. This task leverages Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning. Our models achieve SOTA performance on a range of benchmarks.  Our work offers robust frameworks for spatiotemporal modeling and user-driven video content manipulation.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29105",
      "pdf_url": "https://openreview.net/pdf?id=bW9fGYo44s",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Chirag_Sehgal1",
        "name": "Chirag Sehgal",
        "name_site": null,
        "openreview_id": "~Chirag_Sehgal1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "chiragsehgal224/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Delhi Technological University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.75,
      "reviews": {
        "rating_mean": 7.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "kpq3IIjUD3",
      "title": "Learning local equivariant representations for quantum operators",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "Predicting quantum operator matrices such as Hamiltonian, overlap, and density matrices in the density functional theory (DFT) framework is crucial for material science. Current methods often focus on individual operators and struggle with efficiency and scalability for large systems. Here we introduce a novel deep learning model, SLEM (strictly localized equivariant message-passing), for predicting multiple quantum operators that achieves state-of-the-art accuracy while dramatically improving computational efficiency. SLEM's key innovation is its strict locality-based design for equivariant representations of quantum tensors while preserving physical symmetries. This enables complex many-body dependency without expanding the effective receptive field, leading to superior data efficiency and transferability. Using an innovative SO(2) convolution and invariant overlap parameterization, SLEM reduces the computational complexity of high-order tensor products and is, therefore, capable of handling systems requiring the $f$ and $g$ orbitals in their basis sets. We demonstrate SLEM's capabilities across diverse 2D and 3D materials, achieving high accuracy even with limited training data. SLEM's design facilitates efficient parallelization, potentially extending DFT simulations to systems with device-level sizes, opening new possibilities for large-scale quantum simulations and high-throughput materials discovery.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28559",
      "pdf_url": "https://openreview.net/pdf?id=kpq3IIjUD3",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Shishir_Kumar_Pandey1",
        "name": "Shishir Kumar Pandey",
        "name_site": null,
        "openreview_id": "~Shishir_Kumar_Pandey1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "tkjLHxoAAAAJ",
        "orcid": "0000-0003-0204-5205",
        "linkedin_url": "shishirkpandey/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.75,
      "reviews": {
        "rating_mean": 7.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.9428090415820634,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "wSkvf2WyYz",
      "title": "SBSC: Step-by-Step Coding for Improving Mathematical Olympiad Performance",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We propose Step-by-Step Coding (SBSC): a multi-turn math reasoning framework that enables Large Language Models (LLMs) to generate sequence of programs for solving Olympiad level math problems. After each turn/step, by leveraging the code execution outputs and programs of previous steps, the model generates the next sub-task and the corresponding program to complete it. This way, SBSC, sequentially navigates to reach the final answer. SBSC allows more granular, flexible and precise approach to problem-solving compared to existing methods. Extensive experiments highlight the effectiveness of SBSC in tackling competition and Olympiad-level math problems. For Claude-3.5-Sonnet, we observe SBSC (greedy decoding) surpasses existing state-of-the-art (SOTA) program generation based reasoning strategies by absolute 10.7% on AMC12, 8% on AIME and 12.6% on MathOdyssey. Given SBSC is multi-turn in nature, we also benchmark SBSC’s greedy decoding against self- consistency decoding results of existing SOTA math reasoning strategies and observe performance gain by absolute 6.2% on AMC, 6.7% on AIME and 7.4% on MathOdyssey.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/27845",
      "pdf_url": "https://openreview.net/pdf?id=wSkvf2WyYz",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ankan_Biswas1",
        "name": "Ankan Biswas",
        "name_site": null,
        "openreview_id": "~Ankan_Biswas1",
        "position": 2,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "ankanbiswas7/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Fractal (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.75,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "zfeso8ceqr",
      "title": "Deconstructing What Makes a Good Optimizer for Autoregressive Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Training language models becomes increasingly expensive with scale, prompting numerous attempts to improve optimization efficiency. Despite these efforts, the Adam optimizer remains the most widely used, due to a prevailing view that it is the most effective approach. We aim to compare several optimization algorithms, including SGD, Adafactor, Adam, Lion, and Sophia in the context of autoregressive language modeling across a range of model sizes, hyperparameters, and architecture variants. Our findings indicate that, except for SGD, these algorithms all perform comparably both in their optimal performance and also in terms of how they fare across a wide range of hyperparameter choices. Our results suggest to practitioners that the choice of optimizer can be guided by practical considerations like memory constraints and ease of implementation, as no single algorithm emerged as a clear winner in terms of performance or stability to hyperparameter misspecification. Given our findings, we further dissect these approaches, examining two simplified versions of Adam: a) signed momentum (Signum)  which we see recovers both the performance and hyperparameter stability of Adam and b) Adalayer, a layerwise variant of Adam which we introduce to study the impact on Adam's preconditioning for different layers of the network. Examining Adalayer leads us to the conclusion that, perhaps surprisingly, adaptivity on *both* the last layer and LayerNorm parameters in particular are necessary for retaining performance and stability to learning rate.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/27658",
      "pdf_url": "https://openreview.net/pdf?id=zfeso8ceqr",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Depen_Morwani1",
        "name": "Depen Morwani",
        "name_site": null,
        "openreview_id": "~Depen_Morwani1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "277/5200",
        "google_scholar_url": "vOngxFUAAAAJ",
        "orcid": null,
        "linkedin_url": "depen-morwani-070298122/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Harvard University (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 3.75,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "52UtL8uA35",
      "title": "Deep Networks Learn Features From Local Discontinuities in the Label Function",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Deep neural networks outperform kernel machines on several datasets due to feature learning that happens during gradient descent training. In this paper, we analyze the mechanism through which feature learning happens and use a notion of features that corresponds to discontinuities in the true label function. We hypothesize that the core feature learning mechanism is label function discontinuities attracting model function discontinuities during training. To test this hypothesis, we perform experiments on classification data where the true label function is given by an oblique decision tree. This setup allows easy enumeration of label function discontinuities, while still remaining intractable for static kernel/linear methods. We then design/construct a novel deep architecture called a Deep Linearly Gated Network (DLGN), whose discontinuities in the input space can be easily enumerated.  In this setup, we provide supporting evidence demonstrating the movement of model function discontinuities towards the label function discontinuities during training. The easy enumerability of discontinuities in the DLGN also enables greater mechanistic interpretability. We demonstrate this by extracting the parameters of a high-accuracy decision tree from the parameters of a DLGN. We also show that the DLGN is competitive with ReLU networks and other tree-learning algorithms on several real-world tabular datasets.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30974",
      "pdf_url": "https://openreview.net/pdf?id=52UtL8uA35",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Harish_Guruprasad_Ramaswamy1",
        "name": "Harish Guruprasad Ramaswamy",
        "name_site": null,
        "openreview_id": "~Harish_Guruprasad_Ramaswamy1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "126/1729",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "90DC0IvlSs",
      "title": "LevAttention: Time, Space and Streaming Efficient Algorithm for Heavy Attentions",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "A central problem related to transformers can be stated as follows: given two $n \\times d$ matrices $Q$ and $K$, and a non-negative function $f$, define the matrix $A$ as follows: (1) apply the function $f$ to each entry of the $n \\times n$ matrix $Q K^T$, and then (2) normalize each of the row sums of $A$ to be equal to $1$. The matrix $A$ can be computed in $O(n^2 d)$ time assuming $f$ can be applied to a number in constant time, but the quadratic dependence on $n$ is prohibitive in applications where it corresponds to long context lengths. For a large class of functions $f$, we show how to find all the \"large attention scores\", i.e., entries of $A$ which are at least a positive value $\\varepsilon$, in time with linear dependence on $n$ (i.e., $n \\cdot \\textrm{poly}(d/\\varepsilon)$) for a positive parameter $\\varepsilon > 0$. Our class of functions include all functions $f$ of the form $f(x) = |x|^p$, as explored recently in transformer models. Using recently developed tools from randomized numerical linear algebra, we prove that for any $K$, there is a \"universal set\" $U \\subset [n]$ of size independent of $n$, such that for any $Q$ and any row $i$, the large attention scores $A_{i,j}$ in row $i$ of $A$ all have $j \\in U$. We also find $U$ in $n \\cdot \\textrm{poly}(d/\\varepsilon)$ time. Notably, we \n(1) make no assumptions on the data, (2) our workspace does not grow with $n$, and (3) our algorithms can be computed in streaming and parallel settings. We empirically show the benefits of our scheme for vision transformers, showing how to train new models that use our universal set while training as well, showing that our model is able to consistently select \"important keys'\" during training. We also provide theoretical motivation by formulating a planted model in which our efficient algorithms provably identify relevant keys for \neach query.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30728",
      "pdf_url": "https://openreview.net/pdf?id=90DC0IvlSs",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Chiranjib_Bhattacharyya1",
        "name": "Chiranjib Bhattacharyya",
        "name_site": null,
        "openreview_id": "~Chiranjib_Bhattacharyya1",
        "position": 2,
        "gender": "M",
        "homepage_url": "http://www.csa.iisc.ac.in/~chiru/",
        "dblp_id": "b/CBhattacharyya",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "AsFxRSLtqR",
      "title": "LR0.FM: Low-Res Benchmark and Improving robustness for Zero-Shot Classification in Foundation Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Visual-language foundation Models (FMs) exhibit remarkable zero-shot generalization across diverse tasks, largely attributed to extensive pre-training on largescale datasets. However, their robustness on low-resolution/pixelated (LR) images, a common challenge in real-world scenarios, remains underexplored. We introduce LR0.FM, a comprehensive benchmark evaluating the impact of low resolution on the zero-shot classification performance of 10 FM(s) across 66 backbones and 15 datasets. We propose a novel metric, Weighted Aggregated Robustness, to address the limitations of existing metrics and better evaluate model performance across resolutions and datasets. Our key findings show that: (i) model size positively correlates with robustness to resolution degradation, (ii) pre-training dataset quality is more important than its size, and (iii) fine-tuned and higher resolution models are less robust against LR. Our analysis further reveals that the model makes semantically reasonable predictions at LR, and the lack of fine-grained details in input adversely impacts the model’s initial layers more than the deeper layers. We use these insights and introduce a simple strategy, LR-TK0, to enhance the robustness of models without compromising their pre-trained weights. We demonstrate the effectiveness of LR-TK0 for robustness against low-resolution across several datasets and its generalization capability across backbones and other approaches. Code is available at this : https://github.com/shyammarjit/LR0.FM",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=AsFxRSLtqR",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Shyam_Marjit1",
        "name": "Shyam Marjit",
        "name_site": null,
        "openreview_id": "~Shyam_Marjit1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "347/1029",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": "0000-0002-7385-4432",
        "linkedin_url": "shyam-marjit/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "DFSb67ksVr",
      "title": "Clique Number Estimation via Differentiable Functions of Adjacency Matrix Permutations",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Estimating the clique number in a graph is central to various applications, e.g., community detection, graph retrieval, etc. \nExisting estimators often rely on non-differentiable combinatorial components. Here, we propose a full differentiable estimator for clique number estimation, which can be trained from distant supervision of clique numbers, rather than demonstrating actual cliques.\nOur key insight is a formulation of the maximum clique problem (MCP) as a maximization of the size of fully dense square submatrix, within a suitably row-column-permuted adjacency matrix.\nWe design a differentiable mechanism to search for permutations that lead to the discovery of such dense blocks.\nHowever, the optimal permutation is not unique, which leads to the learning of spurious permutations. To tackle this problem, we view the MCP problem as a sequence of subgraph matching tasks, each detecting progressively larger cliques in a nested manner. This allows effective navigation through suitable node permutations.\nThese steps result in MxNet, an end-to-end differentiable model, which learns to predict clique number without explicit clique demonstrations, with the added benefit of interpretability.  Experiments on eight datasets show the superior accuracy of our approach.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30469",
      "pdf_url": "https://openreview.net/pdf?id=DFSb67ksVr",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Eeshaan_Jain1",
        "name": "Eeshaan Jain",
        "name_site": null,
        "openreview_id": "~Eeshaan_Jain1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://eeshaanjain.github.io",
        "dblp_id": null,
        "google_scholar_url": "r5rqqJEAAAAJ",
        "orcid": null,
        "linkedin_url": "eeshaanjain/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "EPFL (Switzerland)",
        "countries": [
          "Switzerland"
        ],
        "country_codes": [
          "CH"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Q1kPHLUbhi",
      "title": "Towards Self-Supervised Covariance Estimation in Deep Heteroscedastic Regression",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Deep heteroscedastic regression models the mean and covariance of the target distribution through neural networks. The challenge arises from heteroscedasticity, which implies that the covariance is sample dependent and is often unknown. Consequently, recent methods learn the covariance through unsupervised frameworks, which unfortunately yield a trade-off between computational complexity and accuracy. While this trade-off could be alleviated through supervision, obtaining labels for the covariance is non-trivial.\nHere, we study self-supervised covariance estimation in deep heteroscedastic regression. We address two questions: (1) How should we supervise the covariance assuming ground truth is available? (2) How can we obtain pseudo labels in the absence of the ground-truth? We address (1) by analysing two popular measures: the KL Divergence and the 2-Wasserstein distance. Subsequently, we derive an upper bound on the 2-Wasserstein distance between normal distributions with non-commutative covariances that is stable to optimize. We address (2) through a simple neighborhood based heuristic algorithm which results in surprisingly effective pseudo labels for the covariance. Our experiments over a wide range of synthetic and real datasets demonstrate that the proposed 2-Wasserstein bound coupled with pseudo label annotations results in a computationally cheaper yet accurate deep heteroscedastic regression.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29712",
      "pdf_url": "https://openreview.net/pdf?id=Q1kPHLUbhi",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aziz_Shameem1",
        "name": "Aziz Shameem",
        "name_site": null,
        "openreview_id": "~Aziz_Shameem1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://azizshameem.github.io/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "aziz-shameem-9676bb209/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "XrsOu4KgDE",
      "title": "Attributing Culture-Conditioned Generations to Pretraining Corpora",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In open-ended generative tasks like narrative writing or dialogue, large language models often exhibit cultural biases, showing limited knowledge and generating templated outputs for less prevalent cultures. Recent works show that these biases may stem from uneven cultural representation in pretraining corpora. This work investigates how pretraining leads to biased culture-conditioned generations\nby analyzing how models associate entities with cultures based on pretraining data patterns. We propose the MEMOED framework (MEMOrization from prEtraining Document) to determine whether a generation for a culture arises from memorization. Using MEMOED on culture-conditioned generations about food and clothing for 110 cultures, we find that high-frequency cultures in pretraining data yield more generations with memorized symbols, while some low-frequency cultures produce none. Additionally, the model favors generating entities with extraordinarily high frequency regardless of the conditioned culture, reflecting biases toward frequent pretraining terms irrespective of relevance. We hope that the MEMOED framework and our insights will inspire more works on attributing model performance on pretraining data.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29287",
      "pdf_url": "https://openreview.net/pdf?id=XrsOu4KgDE",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arnav_Goel1",
        "name": "Arnav Goel",
        "name_site": null,
        "openreview_id": "~Arnav_Goel1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://github.com/arnav10goel",
        "dblp_id": "161/3392",
        "google_scholar_url": "PPozs9sAAAAJ",
        "orcid": "0009-0005-8508-0517",
        "linkedin_url": "arnavg10/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.2649110640673518,
        "confidence_mean": 3.0,
        "confidence_std": 0.6324555320336759,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "bSq0XGS3kW",
      "title": "On the Transfer of Object-Centric Representation Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The goal of object-centric representation learning is to decompose visual scenes into a structured representation that isolates the entities into individual vectors. Recent successes have shown that object-centric representation learning can be scaled to real-world scenes by utilizing features from pre-trained foundation models like DINO. However, so far, these object-centric methods have mostly been applied in-distribution, with models trained and evaluated on the same dataset. This is in contrast to the underlying foundation models, which have been shown to be applicable to a wide range of data and tasks. Thus, in this work, we answer the question of whether current real-world capable object-centric methods exhibit similar levels of transferability by introducing a benchmark comprising seven different synthetic and real-world datasets. We analyze the factors influencing performance under transfer and find that training on diverse real-world images improves generalization to unseen scenarios. Furthermore, inspired by the success of task-specific fine-tuning in foundation models, we introduce a novel fine-tuning strategy to adapt pre-trained vision encoders for the task of object discovery. We find that the proposed approach results in state-of-the-art performance for unsupervised object discovery, exhibiting strong zero-shot transfer to unseen datasets.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29108",
      "pdf_url": "https://openreview.net/pdf?id=bSq0XGS3kW",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Di_He1_1",
        "name": "Di He",
        "name_site": null,
        "openreview_id": "~Anirudh_Goyal1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://anirudh9119.github.io/",
        "dblp_id": "172/1039",
        "google_scholar_url": "krrh6OUAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (United Kingdom)",
        "countries": [
          "United Kingdom"
        ],
        "country_codes": [
          "GB"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "h0vC0fm1q7",
      "title": "Sensitivity Verification for Additive Decision Tree Ensembles",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Tree ensemble models, such as Gradient Boosted Decision Trees (GBDTs) and random forests, are widely popular models for a variety of machine learning tasks. The power of these models comes from the ensemble of decision trees, which makes analysis of such models significantly harder than for single trees. As a result, recent work has focused on developing exact and approximate techniques for questions such as robustness verification, fairness and explainability for such models of tree ensembles.\n\nIn this paper, we focus on a specific problem of feature sensitivity for additive decision tree ensembles and build a formal verification framework for a parametrized variant of it, where we also take into account the confidence of the tree ensemble in its output. We start by showing theoretical (NP-)hardness of the problem and explain how it relates to other verification problems. Next, we provide a novel encoding of the problem using pseudo-Boolean constraints. Based on this encoding, we develop a tunable algorithm to perform sensitivity analysis, which can trade off precision for running time. We implement our algorithm and study its performance on a suite of GBDT benchmarks from the literature. Our experiments show the practical utility of our approach and its improved performance compared to existing approaches.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28785",
      "pdf_url": "https://openreview.net/pdf?id=h0vC0fm1q7",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Tanay_Vineet_Tayal1",
        "name": "Tanay Vineet Tayal",
        "name_site": null,
        "openreview_id": "~Tanay_Vineet_Tayal1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "tanay-tayal-340541105/?trk=opento_sprofile_topcard",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 6.4,
        "rating_std": 0.7999999999999999,
        "confidence_mean": 3.4,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "l11DZY5Nxu",
      "title": "Robust Root Cause Diagnosis using In-Distribution Interventions",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Diagnosing the root cause of an anomaly in a complex interconnected system is\na pressing problem in today’s cloud services and industrial operations. We propose In-Distribution Interventions (IDI), a novel algorithm that predicts root cause\nas nodes that meet two criteria: 1) Anomaly: root cause nodes should take on\nanomalous values; 2) Fix: had the root cause nodes assumed usual values, the\ntarget node would not have been anomalous. Prior methods of assessing the fix\ncondition rely on counterfactuals inferred from a Structural Causal Model (SCM)\ntrained on historical data. But since anomalies are rare and fall outside the training distribution, the fitted SCMs yield unreliable counterfactual estimates. IDI\novercomes this by relying on interventional estimates obtained by solely probing the fitted SCM at in-distribution inputs. We present a theoretical analysis\ncomparing and bounding the errors in assessing the fix condition using interventional and counterfactual estimates. We then conduct experiments by systematically varying the SCM’s complexity to demonstrate the cases where IDI’s interventional approach outperforms the counterfactual approach and vice versa.\nExperiments on both synthetic and PetShop RCD benchmark datasets demonstrate that IDI consistently identifies true root causes more accurately and robustly than nine existing state-of-the-art RCD baselines. Code will be released\nat https://github.com/nlokeshiisc/IDI_release.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28541",
      "pdf_url": "https://openreview.net/pdf?id=l11DZY5Nxu",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ashutosh_Srivastava2",
        "name": "Ashutosh Srivastava",
        "name_site": null,
        "openreview_id": "~Ashutosh_Srivastava2",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "https://linkedin.com/in/srivhash",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology, Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 2.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "pxclAomHat",
      "title": "On the Optimization Landscape of Low Rank Adaptation Methods for Large Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Training Large Language Models (LLMs) poses significant memory challenges, making low-rank adaptation methods an attractive solution. Previously, Low-Rank Adaptation (LoRA) addressed this by adding a trainable low-rank matrix to the frozen pre-trained weights in each layer, reducing the number of trainable parameters and optimizer states. GaLore, which compresses the gradient matrix instead of the weight matrix, has demonstrated superior performance to LoRA with faster convergence and reduced memory consumption. Despite their empirical success, the performance of these methods has not been fully understood or explained theoretically. In this paper, we analyze the optimization landscapes of LoRA, GaLore, and full-rank methods, revealing that GaLore benefits from fewer spurious local minima and a larger region that satisfies the \\pl, a variant of Polyak-Łojasiewicz (PL) condition, leading to faster convergence. Our analysis leads to a novel method, GaRare, which further improves GaLore by using gradient random projection to reduce computational overhead. Practically, GaRare achieves strong performance in both pre-training and fine-tuning tasks, offering a more efficient approach to large-scale model adaptation.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28273",
      "pdf_url": "https://openreview.net/pdf?id=pxclAomHat",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yali_Du1",
        "name": "Yali Du",
        "name_site": null,
        "openreview_id": "~Yali_Du1",
        "position": 2,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University College London (United Kingdom)",
        "countries": [
          "United Kingdom"
        ],
        "country_codes": [
          "GB"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.7453559924999299,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "iuxaCU3DI7",
      "title": "Recognize Any Surgical Object: Unleashing the Power of Weakly-Supervised Data",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "We present RASO, a foundation model designed to Recognize Any Surgical Object, offering robust open-set recognition capabilities across a broad range of surgical procedures and object classes, in both surgical images and videos. RASO leverages a novel weakly-supervised learning framework that generates tag-image-text pairs automatically from large-scale unannotated surgical lecture videos, significantly reducing the need for manual annotations. Our scalable data generation pipeline gathers 2,200 surgical procedures and produces 3.6 million tag annotations across 2,066 unique surgical tags. Our experiments show that RASO achieves improvements of 2.9 mAP, 4.5 mAP, 10.6 mAP, and 7.2 mAP on four standard surgical benchmarks respectively in zero-shot settings, and surpasses state-of-the-art models in supervised surgical action recognition tasks. We will open-source our code, model, and dataset to facilitate further research.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28666",
      "pdf_url": "https://openreview.net/pdf?id=iuxaCU3DI7",
      "github_url": "",
      "total_authors": 8,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ruiyang_Qin1",
        "name": "Ruiyang Qin",
        "name_site": null,
        "openreview_id": "~Ruiyang_Qin1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://ruiyangqin2016.github.io/",
        "dblp_id": "280/1019",
        "google_scholar_url": "https://scholar.google.ca/citations?user=c26FtWIAAAAJ",
        "orcid": "0000-0003-0827-2257",
        "linkedin_url": "ruiyang-qin-gatech/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Notre Dame (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.2142857142857144,
      "reviews": {
        "rating_mean": 7.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xkgfLXZ4e0",
      "title": "Correlating instruction-tuning (in multimodal models) with vision-language processing (in the brain)",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Transformer-based language models, though not explicitly trained to mimic brain recordings, have demonstrated surprising alignment with brain activity. Progress in these models—through increased size, instruction-tuning, and multimodality—has led to better representational alignment with neural data. Recently, a new class of instruction-tuned multimodal LLMs (MLLMs) have emerged, showing remarkable zero-shot capabilities in open-ended multimodal vision tasks. However, it is unknown whether MLLMs, when prompted with natural instructions, lead to better brain alignment and effectively capture instruction-specific representations. To address this, we first investigate the brain alignment, i.e., measuring the degree of predictivity of neural visual activity using text output response embeddings from MLLMs as participants engage in watching natural scenes. Experiments with 10 different instructions (like image captioning, visual question answering, etc.) show that  MLLMs exhibit significantly better brain alignment than vision-only models and perform comparably to non-instruction-tuned multimodal models like CLIP. We also find that while these MLLMs are effective at generating high-quality responses suitable to the task-specific instructions, not all instructions are relevant for brain alignment. Further, by varying instructions, we make the MLLMs encode instruction-specific visual concepts related to the input image. This analysis shows that MLLMs effectively capture count-related and recognition-related concepts, demonstrating strong alignment with brain activity. Notably, the majority of the explained variance of the brain encoding models is shared between MLLM embeddings of image captioning and other instructions. These results indicate that enhancing MLLMs' ability to capture more task-specific information could allow for better differentiation between various types of instructions, and hence improve their precision in predicting brain responses.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/27766",
      "pdf_url": "https://openreview.net/pdf?id=xkgfLXZ4e0",
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Khushbu_Pahwa1",
        "name": "Khushbu Pahwa",
        "name_site": null,
        "openreview_id": "~Khushbu_Pahwa1",
        "position": 4,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "299/8490",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": "khushbupahwa",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Amazon (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 3.125,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.0,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "BpIbnXWfhL",
      "title": "RuAG: Learned-rule-augmented Generation for Large Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In-context learning (ICL) and Retrieval-Augmented Generation (RAG) have gained attention for their ability to enhance LLMs' reasoning by incorporating external knowledge but suffer from limited contextual window size, leading to insufficient information injection. To this end, we propose a novel framework to automatically distill large volumes of offline data into interpretable first-order logic rules, which are injected into LLMs to boost their reasoning capabilities. Our method begins by formulating the search process relying on LLMs' commonsense, where LLMs automatically define head and body predicates. Then, we apply Monte Carlo Tree Search (MCTS)  to address the combinational searching space and efficiently discover logic rules from data. The resulting logic rules are translated into natural language, allowing targeted knowledge injection and seamless integration into LLM prompts for LLM's downstream task reasoning. We evaluate our framework on public and private industrial tasks, including Natural Language Processing (NLP), time-series, decision-making, and industrial tasks, demonstrating its effectiveness in enhancing LLM's capability over diverse tasks.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30545",
      "pdf_url": "https://openreview.net/pdf?id=BpIbnXWfhL",
      "github_url": "",
      "total_authors": 14,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yali_Du1",
        "name": "Yali Du",
        "name_site": null,
        "openreview_id": "~Yali_Du1",
        "position": 6,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 3.076923076923077,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "0dELcFHig2",
      "title": "Multi-modal brain encoding models for multi-modal stimuli",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Despite participants engaging in unimodal stimuli, such as watching images or silent videos, recent work has demonstrated that multi-modal Transformer models can predict visual brain activity impressively well, even with incongruent modality representations. This raises the question of how accurately these multi-modal models can predict brain activity when participants are engaged in multi-modal stimuli. As these models grow increasingly popular, their use in studying neural activity provides insights into how our brains respond to such multi-modal naturalistic stimuli, i.e., where it separates and integrates information across modalities through a hierarchy of early sensory regions to higher cognition (language regions). We investigate this question by using multiple unimodal and two types of multi-modal models—cross-modal and jointly pretrained—to determine which type of models is more relevant to fMRI brain activity when participants are engaged in watching movies (videos with audio). We observe that both types of multi-modal models show improved alignment in several language and visual regions. This study also helps in identifying which brain regions process unimodal versus multi-modal information. We further investigate the contribution of each modality to multi-modal alignment by carefully removing unimodal features one by one from multi-modal representations, and find that there is additional information beyond the unimodal embeddings that is processed in the visual and language regions. Based on this investigation, we find that while for cross-modal models, their brain alignment is partially attributed to the video modality; for jointly pretrained models, it is partially attributed to both the video and audio modalities. These findings serve as strong motivation for the neuro-science community to investigate the interpretability of these models for deepening our understanding of multi-modal information processing in brain.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/31247",
      "pdf_url": "https://openreview.net/pdf?id=0dELcFHig2",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~mounika_marreddy1",
        "name": "mounika marreddy",
        "name_site": null,
        "openreview_id": "~mounika_marreddy1",
        "position": 3,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "206/3366",
        "google_scholar_url": "Ikqyo5sAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology, Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "AkBrb7yQ0G",
      "title": "Periodic Materials Generation using Text-Guided Joint Diffusion Model",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Equivariant diffusion models have emerged as the prevailing approach for generat-\ning novel crystal materials due to their ability to leverage the physical symmetries\nof periodic material structures. However, current models do not effectively learn the\njoint distribution of atom types, fractional coordinates, and lattice structure of the\ncrystal material in a cohesive end-to-end diffusion framework. Also, none of these\nmodels work under realistic setups, where users specify the desired characteristics\nthat the generated structures must match. In this work, we introduce TGDMat, a\nnovel text-guided diffusion model designed for 3D periodic material generation.\nOur approach integrates global structural knowledge through textual descriptions\nat each denoising step while jointly generating atom coordinates, types, and lattice\nstructure using a periodic-E(3)-equivariant graph neural network (GNN). Extensive\nexperiments using popular datasets on benchmark tasks reveal that TGDMat out-\nperforms existing baseline methods by a good margin. Notably, for the structure\nprediction task, with just one generated sample, TGDMat outperforms all baseline\nmodels, highlighting the importance of text-guided diffusion. Further, in the genera-\ntion task, TGDMat surpasses all baselines and their text-fusion variants, showcasing\nthe effectiveness of the joint diffusion paradigm. Additionally, incorporating textual\nknowledge reduces overall training and sampling computational overhead while\nenhancing generative performance when utilizing real-world textual prompts from\nexperts. Code is available at https://github.com/kdmsit/TGDMat",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30619",
      "pdf_url": "https://openreview.net/pdf?id=AkBrb7yQ0G",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Pawan_Goyal1",
        "name": "Pawan Goyal",
        "name_site": null,
        "openreview_id": "~Pawan_Goyal1",
        "position": 3,
        "gender": "M",
        "homepage_url": "http://cse.iitkgp.ac.in/~pawang/",
        "dblp_id": "77/2307-2",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=F14FHsIAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qnlG3zPQUy",
      "title": "ILLUSION: Unveiling Truth with a Comprehensive Multi-Modal, Multi-Lingual Deepfake Dataset",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The proliferation of deepfakes and AI-generated content has led to a surge in media forgeries and misinformation, necessitating robust detection systems. However, current datasets lack diversity across modalities, languages, and real-world scenarios. To address this gap, we present ILLUSION (Integration of Life-Like Unique Synthetic Identities and Objects from Neural Networks), a large-scale, multi-modal\ndeepfake dataset comprising 1.3 million samples spanning audio-visual forgeries, 26 languages, challenging noisy environments, and various manipulation protocols. Generated using 28 state-of-the-art generative techniques, ILLUSION includes\nfaceswaps, audio spoofing, synchronized audio-video manipulations, and synthetic media while ensuring a balanced representation of gender and skin tone for unbiased evaluation. Using Jaccard Index and UpSet plot analysis, we demonstrate ILLUSION’s distinctiveness and minimal overlap with existing datasets, emphasizing its novel generative coverage. We benchmarked image, audio, video, and multi-modal detection models, revealing key challenges such as performance degradation in multilingual and multi-modal contexts, vulnerability to real-world distortions, and limited generalization to zero-day attacks. By bridging synthetic and real-world complexities, ILLUSION provides a challenging yet essential platform for advancing deepfake detection research. The dataset is publicly available at https://www.iab-rubric.org/illusion-database.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28235",
      "pdf_url": "https://openreview.net/pdf?id=qnlG3zPQUy",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Akanksha_Singh1",
        "name": "Akanksha Singh",
        "name_site": null,
        "openreview_id": "~Akshat_Jain2",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "akshat-jain-103550201/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Jodhpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.0954451150103321,
        "confidence_mean": 4.0,
        "confidence_std": 0.6324555320336759,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "vyflgpwfJW",
      "title": "DiscoveryBench: Towards Data-Driven Discovery with Large Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Can the rapid advances in code generation, function calling, and data analysis using large language models (LLMs) help automate the search and verification of hypotheses purely from a set of provided datasets? To evaluate this question, we present DiscoveryBench, the first comprehensive benchmark that formalizes the multi-step process of data-driven discovery. The benchmark is designed to systematically assess current model capabilities in discovery tasks and provide a useful resource for improving them. Our benchmark contains 264 tasks collected across 6 diverse domains, such as sociology and engineering, by manually deriving discovery workflows from published papers to approximate the real-world challenges faced by researchers, where each task is defined by a dataset, its metadata, and a discovery goal in natural language. We additionally provide 903 synthetic tasks to conduct controlled evaluations on data-driven workflows that are not covered in the manually collected split. Furthermore, our structured formalism of data-driven discovery enables a facet-based evaluation that provides useful insights into different failure modes. We evaluate several popular LLM-based reasoning frameworks using both open and closed LLMs as baselines on DiscoveryBench and find that even the best system scores only 25%. Our benchmark, thus, illustrates the challenges in autonomous data-driven discovery and serves as a valuable resource for the community to make progress.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=vyflgpwfJW",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 10,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abhijeetsingh_Meena1",
        "name": "Abhijeetsingh Meena",
        "name_site": null,
        "openreview_id": "~Aryan_Prakhar1",
        "position": 5,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "aryan-prakhar/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Dwarkadas J. Sanghvi College of Engineering (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.7777777777777777,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 21,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5RZoYIT3u6",
      "title": "You Only Prune Once: Designing Calibration-Free Model Compression With Policy Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The ever-increasing size of large language models (LLMs) presents significant challenges for deployment due to their heavy computational and memory requirements. Current model pruning techniques attempt to alleviate these issues by relying heavily on external calibration datasets to determine which parameters to prune or compress, thus limiting their flexibility and scalability across different compression ratios. Moreover, these methods often cause severe performance degradation, particularly in downstream tasks, when subjected to higher compression rates. In this paper, we propose *PruneNet*, a novel model compression method that addresses these limitations by reformulating model pruning as a policy learning process. PruneNet decouples the pruning process from the model architecture, eliminating the need for calibration datasets. It learns a stochastic pruning policy to assess parameter importance solely based on intrinsic model properties while preserving the spectral structure to minimize information loss. PruneNet can compress the LLaMA-2-7B model in just 15 minutes, achieving over 80\\% retention of its zero-shot performance with a 30\\% compression ratio, outperforming existing methods that retain only 75\\% performance. Furthermore, on complex multitask language understanding tasks, PruneNet demonstrates its robustness by preserving up to 80\\% performance of the original model, proving itself a superior alternative to conventional structured compression techniques.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30946",
      "pdf_url": "https://openreview.net/pdf?id=5RZoYIT3u6",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Tanmoy_Chakraborty2",
        "name": "Tanmoy Chakraborty",
        "name_site": null,
        "openreview_id": "~Tanmoy_Chakraborty2",
        "position": 2,
        "gender": "M",
        "homepage_url": "http://tanmoychak.com",
        "dblp_id": "65/2136-2.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=C5S9JnIAAAAJ",
        "orcid": "0000-0002-0210-0369",
        "linkedin_url": "tanmoy-chakraborty-89553324/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5pd78GmXC6",
      "title": "Charting the Design Space of Neural Graph Representations for Subgraph Matching",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Subgraph matching is vital in knowledge graph (KG) question answering, molecule design, scene graph, code and circuit search, etc.\nNeural methods have shown promising results for subgraph matching.\nOur study of recent systems suggests refactoring them into a unified design space for graph matching networks.\nExisting methods occupy only a few isolated patches in this space, which remains largely uncharted.\nWe undertake the first comprehensive exploration of this space, featuring such axes as attention-based vs. soft permutation-based interaction between query and corpus graphs, aligning nodes vs. edges, and the form of the final scoring network that integrates neural representations of the graphs.\nOur extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.\nBeyond better performance, our study uncovers valuable insights and establishes general design principles for neural graph representation and interaction, which may be of wider interest.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30929",
      "pdf_url": "https://openreview.net/pdf?id=5pd78GmXC6",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ashwin_Ramachandran1",
        "name": "Ashwin Ramachandran",
        "name_site": null,
        "openreview_id": "~Ashwin_Ramachandran1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://ashwinramachandran2002.github.io/",
        "dblp_id": "07/1826",
        "google_scholar_url": "y7H-6IgAAAAJ",
        "orcid": null,
        "linkedin_url": "ashwin-ramachandran-042152204/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5x88lQ2MsH",
      "title": "Bonsai: Gradient-free Graph Condensation for Node Classification",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph condensation has emerged as a promising avenue to enable scalable training of GNNs by compressing the training dataset while preserving essential graph characteristics. Our study uncovers significant shortcomings in current graph condensation techniques. First, the majority of the algorithms paradoxically require training on the full dataset to perform condensation. Second, due to their gradient-emulating approach, these methods require fresh condensation for any change in hyperparameters or GNN architecture, limiting their flexibility and reusability. To address these challenges, we present Bonsai, a novel graph condensation method empowered by the observation that *computation trees* form the fundamental processing units of message-passing GNNs. Bonsai condenses datasets by encoding a careful selection of *exemplar* trees that maximize the representation of all computation trees in the training set. This unique approach imparts Bonsai as the first linear-time, model-agnostic graph condensation algorithm for node classification that outperforms existing baselines across $7$ real-world datasets on accuracy, while being $22$ times faster on average. Bonsai is grounded in rigorous mathematical guarantees on the adopted approximation strategies, making it robust to GNN architectures, datasets, and parameters.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30924",
      "pdf_url": "https://openreview.net/pdf?id=5x88lQ2MsH",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vansh_Ramani1",
        "name": "Vansh Ramani",
        "name_site": null,
        "openreview_id": "~Vansh_Ramani1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://vanshramani.framer.website/",
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.ch/citations?user=hKH8NPoAAAAJ",
        "orcid": null,
        "linkedin_url": "https://linkedin.com/in/ramanivansh/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "AUBvo4sxVL",
      "title": "MatExpert: Decomposing Materials Discovery By Mimicking Human Experts",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Material discovery is a critical research area with profound implications for various industries. In this work, we introduce MatExpert, a novel framework that leverages Large Language Models (LLMs) and contrastive learning to accelerate the discovery and design of new solid-state materials. Inspired by the workflow of human materials design experts, our approach integrates three key stages: retrieval, transition, and generation. First, in the retrieval stage, MatExpert identifies an existing material that closely matches the desired criteria. Second, in the transition stage, MatExpert outlines the necessary modifications to transform this material formulation to meet specific requirements outlined by the initial user query. Third, in the generation state, MatExpert performs detailed computations and structural generation to create a new material based on the provided information. Our experimental results demonstrate that MatExpert outperforms state-of-the-art methods in material generation tasks, achieving superior performance across various metrics including validity, distribution, and stability. As such, MatExpert represents a meaningful advancement in computational material discovery using langauge-based generative models.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30631",
      "pdf_url": "https://openreview.net/pdf?id=AUBvo4sxVL",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Santiago_Miret1",
        "name": "Santiago Miret",
        "name_site": null,
        "openreview_id": "~Santiago_Miret1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.intel.ai/bio/santiago-miret/",
        "dblp_id": "241/5030",
        "google_scholar_url": "HLQ_te4AAAAJ",
        "orcid": "0000-0002-5121-3853",
        "linkedin_url": "santiago-miret/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Intel (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "IQxBDLmVpT",
      "title": "Generalization v.s. Memorization: Tracing Language Models’ Capabilities Back to Pretraining Data",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The impressive capabilities of large language models (LLMs) have sparked debate over whether these models genuinely generalize to unseen tasks or predominantly rely on memorizing vast amounts of pretraining data. To explore this issue, we introduce an extended concept of memorization, distributional memorization, which measures the correlation between the LLM output probabilities and the pretraining data frequency. To effectively capture task-specific pretraining data frequency, we propose a novel task-gram language model, which is built by counting the co-occurrence of semantically related $n$-gram pairs from task inputs and outputs in the pretraining corpus. Using the Pythia models trained on the Pile dataset, we evaluate four distinct tasks: machine translation, factual question answering, world knowledge understanding, and math reasoning. Our findings reveal varying levels of memorization, with the strongest effect observed in factual question answering. Furthermore, while model performance improves across all tasks as LLM size increases, only factual question answering shows an increase in memorization, whereas machine translation and reasoning tasks exhibit greater generalization, producing more novel outputs. This study demonstrates that memorization plays a larger role in simpler, knowledge-intensive tasks, while generalization is the key for harder, reasoning-based tasks, providing a scalable method for analyzing large pretraining corpora in greater depth.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30169",
      "pdf_url": "https://openreview.net/pdf?id=IQxBDLmVpT",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Alfonso_Amayuelas2",
        "name": "Alfonso Amayuelas",
        "name_site": "Alfonso Amayuelas, Shuai Zhang, Xi Rao, Ce Zhang",
        "openreview_id": "~Alfonso_Amayuelas2",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://www.amayuelas.me/",
        "dblp_id": "281/7669",
        "google_scholar_url": "https://scholar.google.dk/citations?user=QGQ2G28AAAAJ",
        "orcid": null,
        "linkedin_url": "alfonsoamayuelas/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of California, Santa Barbara (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 2.1213203435596424,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "NtwFghsJne",
      "title": "From Search to Sampling: Generative Models for Robust Algorithmic Recourse",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Algorithmic Recourse provides recommendations to individuals who are adversely impacted by automated model decisions, on how to alter their profiles to achieve a favorable outcome. Effective recourse methods must balance three conflicting goals: proximity to the original profile to minimize cost, plausibility for realistic recourse, and validity to ensure the desired outcome. We show that existing methods train for these objectives separately and then search for recourse through a joint optimization over the recourse goals during inference, leading to poor recourse recommendations. We introduce GenRe, a generative recourse model designed to train the three recourse objectives jointly. Training such generative models is non-trivial due to lack of direct recourse supervision. We propose efficient ways to synthesize such supervision and further show that GenRe's training leads to a consistent estimator. Unlike most prior methods, that employ non-robust gradient descent based search during inference, GenRe simply performs a forward sampling over the generative model to produce minimum cost recourse, leading to superior performance across multiple metrics. We also demonstrate GenRe provides the best trade-off between cost, plausibility and validity, compared to state-of-art baselines. Our code is available at: https://github.com/prateekgargX/genre",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29854",
      "pdf_url": "https://openreview.net/pdf?id=NtwFghsJne",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Lokesh_Nagalapatti1",
        "name": "Lokesh Nagalapatti",
        "name_site": null,
        "openreview_id": "~Lokesh_Nagalapatti1",
        "position": 2,
        "gender": null,
        "homepage_url": "https://nlokesh.netlify.app/",
        "dblp_id": "259/2681.html",
        "google_scholar_url": "BkkZbo0AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "TmCcNuo03f",
      "title": "Measuring And Improving Engagement of Text-to-Image Generation Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent advances in text-to-image generation have achieved impressive aesthetic quality, making these models usable for both personal and commercial purposes. However, in the fields of marketing and advertising, images are often created to be more engaging, as reflected in user behaviors such as increasing clicks, likes, and purchases, in addition to being aesthetically pleasing. To this end, we introduce the challenge of optimizing the image generation process for improved viewer engagement. In order to study image engagement and utility in real-world marketing scenarios, we collect *EngagingImageNet*, the first large-scale dataset of images, along with associated user engagement metrics. Further, we find that existing image evaluation metrics like aesthetics, CLIPScore, PickScore, ImageReward, *etc.* are unable to capture viewer engagement. To address the lack of reliable metrics for assessing image utility, we use the *EngagingImageNet* dataset to train *EngageNet*, an engagement-aware Vision Language Model (VLM) that predicts viewer engagement of images by leveraging contextual information about the tweet content, enterprise details, and posting time. We then explore methods to enhance the engagement of text-to-image models, making initial strides in this direction. These include conditioning image generation on improved prompts, supervised fine-tuning of stable diffusion on high-performing images, and reinforcement learning to align stable diffusion with *EngageNet*-based reward signals, all of which lead to the generation of images with higher viewer engagement. Finally, we propose the *Engagement Arena*, to benchmark text-to-image models based on their ability to generate engaging images, using *EngageNet* as the evaluator, thereby encouraging the research community to measure further advances in the engagement of text-to-image modeling. These contributions provide a new pathway for advancing utility-driven image generation, with significant implications for the commercial application of image generation. We have released our code and dataset on [behavior-in-the-wild.github.io/image-engagement](https://behavior-in-the-wild.github.io/image-engagement).",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=TmCcNuo03f",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rajiv_Ratn_Shah1",
        "name": "Rajiv Ratn Shah",
        "name_site": null,
        "openreview_id": "~Rajiv_Ratn_Shah1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://iiitd.ac.in/rajivratn",
        "dblp_id": "134/3502",
        "google_scholar_url": "https://scholar.google.com.sg/citations?hl=en",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ff2V3UR9sC",
      "title": "Teaching Human Behavior Improves Content Understanding Abilities Of VLMs",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Communication is defined as \"*Who* says *what* to *whom* with *what* effect.\" A message from a communicator generates downstream receiver effects, also known as behavior. Receiver behavior, being a downstream effect of the message, carries rich signals about it. Even after carrying signals about the message, the behavior signal is often ignored while training vision-language models. We show that training VLMs on receiver behavior can actually help improve their content-understanding abilities. We demonstrate that training VLMs to predict receiver behaviors, such as likes, comments, and replay graphs, which are available at scale, enhances the VLM's performance across a broad range of downstream content understanding tasks. We show this performance increase over 6 types of behavior, 46 different tasks covering image, video, text, and audio over 26 benchmark datasets across both zero-shot and fine-tuning settings, outperforming many supervised baselines on diverse tasks ranging from emotion recognition to captioning by up to 150%. We note that since receiver behavior, such as likes, comments, and replay graphs, is collected by default on the internet and does not need any human annotations to be useful, the performance improvement we get after training on this data is essentially free lunch.  We also release **BLIFT**, our **Behaviour-LLaVA IFT** dataset comprising 730k images and videos with their receiver behavior collected from multiple platforms on which we train our models to achieve this. The dataset and code are available at [behavior-in-the-wild.github.io/behavior-llava](https://behavior-in-the-wild.github.io/behavior-llava).",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28866",
      "pdf_url": "https://openreview.net/pdf?id=ff2V3UR9sC",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rajiv_Ratn_Shah1",
        "name": "Rajiv Ratn Shah",
        "name_site": null,
        "openreview_id": "~Rajiv_Ratn_Shah1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://iiitd.ac.in/rajivratn",
        "dblp_id": "134/3502",
        "google_scholar_url": "https://scholar.google.com.sg/citations?hl=en",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "kbeX97jExm",
      "title": "Neural Wave Equation for Irregularly Sampled Sequence Data",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Sequence labeling problems arise in several real-world applications such as healthcare and robotics. In many such applications, sequence data are irregularly sampled and are of varying complexities. Recently, efforts have been made to develop neural ODE-based architectures to model the evolution of hidden states continuously in time, to address irregularly sampled sequence data. However, they assume a fixed architectural depth and limit their flexibility to adapt to data sets with varying complexities. We propose the neural wave equation, a novel deep learning method inspired by the wave equation, to address this through continuous modeling of depth. Neural Wave Equation models the evolution of hidden states continuously across time as well as depth by using a non-homogeneous wave equation parameterized by a neural network.  Through d'Alembert's analytical solution of the wave equation, we also show that the neural wave equation provides denser connections across the hidden states, allowing for better modeling capability.  We conduct experiments on several sequence labeling problems involving irregularly sampled sequence data and demonstrate the superior performance of the proposed neural wave equation model.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28570",
      "pdf_url": "https://openreview.net/pdf?id=kbeX97jExm",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~M_Anand_Krishna1",
        "name": "M Anand Krishna",
        "name_site": null,
        "openreview_id": "~M_Anand_Krishna1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "anand-krishna-4aa30315a/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nNiWRRj6r9",
      "title": "ONLINE EPSILON NET & PIERCING SET FOR GEOMETRIC CONCEPTS",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "VC-dimension (Vapnik & Chervonenkis (1971)) and $\\varepsilon$-nets  (Haussler & Welzl (1987)) are key concepts in Statistical Learning Theory. Intuitively, VC-dimension is a measure of the size of a class of sets. The famous $\\varepsilon$-net theorem, a fundamental result in Discrete Geometry, asserts that if the VC-dimension of a set system is bounded, then a small sample exists that intersects all sufficiently large sets.\n    \n    In online learning scenarios where data arrives sequentially, the VC-dimension helps to bound the complexity of the set system, and $\\varepsilon$-nets ensure the selection of a small representative set. This sampling framework is crucial in various domains, including spatial data analysis, motion planning in dynamic environments, optimization of sensor networks, and feature extraction in computer vision, among others. Motivated by these applications, we study the online $\\varepsilon$-net problem for geometric concepts with bounded VC-dimension. While the offline version of this problem has been extensively studied, surprisingly, there are no known theoretical results for the online version to date. We present the first deterministic online algorithm with an optimal competitive ratio for intervals in $\\mathbb{R}$. Next, we give a randomized online algorithm with a near-optimal competitive ratio for axis-aligned boxes in $\\mathbb{R}^d$, for $d\\le 3$. Furthermore, we introduce a novel technique to analyze similar-sized objects of constant description complexity in $\\mathbb{R}^d$, which may be of independent interest. \n    \n    Next, we focus on the continuous version of this problem (called online piercing set), where ranges of the set system are geometric concepts in $\\mathbb{R}^d$ arriving in an online manner, but the universe is the entire ambient space, and the objective is to choose a small sample that intersects all the ranges. Although online piercing set is a very well-studied problem in the literature, to our surprise, very few works have addressed generic geometric concepts without any assumption about the sizes. We advance this field by proposing asymptotically optimal competitive deterministic algorithms for boxes and ellipsoids in $\\mathbb{R}^d$, for any $d\\in\\mathbb{N}$.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28409",
      "pdf_url": "https://openreview.net/pdf?id=nNiWRRj6r9",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Devdan_Dey1",
        "name": "Devdan Dey",
        "name_site": null,
        "openreview_id": "~Devdan_Dey1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0009-0009-4898-4161",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 2.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "AkBrb7yQ0G",
      "title": "Periodic Materials Generation using Text-Guided Joint Diffusion Model",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Equivariant diffusion models have emerged as the prevailing approach for generat-\ning novel crystal materials due to their ability to leverage the physical symmetries\nof periodic material structures. However, current models do not effectively learn the\njoint distribution of atom types, fractional coordinates, and lattice structure of the\ncrystal material in a cohesive end-to-end diffusion framework. Also, none of these\nmodels work under realistic setups, where users specify the desired characteristics\nthat the generated structures must match. In this work, we introduce TGDMat, a\nnovel text-guided diffusion model designed for 3D periodic material generation.\nOur approach integrates global structural knowledge through textual descriptions\nat each denoising step while jointly generating atom coordinates, types, and lattice\nstructure using a periodic-E(3)-equivariant graph neural network (GNN). Extensive\nexperiments using popular datasets on benchmark tasks reveal that TGDMat out-\nperforms existing baseline methods by a good margin. Notably, for the structure\nprediction task, with just one generated sample, TGDMat outperforms all baseline\nmodels, highlighting the importance of text-guided diffusion. Further, in the genera-\ntion task, TGDMat surpasses all baselines and their text-fusion variants, showcasing\nthe effectiveness of the joint diffusion paradigm. Additionally, incorporating textual\nknowledge reduces overall training and sampling computational overhead while\nenhancing generative performance when utilizing real-world textual prompts from\nexperts. Code is available at https://github.com/kdmsit/TGDMat",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30619",
      "pdf_url": "https://openreview.net/pdf?id=AkBrb7yQ0G",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Seung-Cheol_Lee1",
        "name": "Seung-Cheol Lee",
        "name_site": null,
        "openreview_id": "~Seung-Cheol_Lee1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://www.ikst.res.in",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0000-0002-9741-6955",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Korea Institute of Science and Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qnlG3zPQUy",
      "title": "ILLUSION: Unveiling Truth with a Comprehensive Multi-Modal, Multi-Lingual Deepfake Dataset",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The proliferation of deepfakes and AI-generated content has led to a surge in media forgeries and misinformation, necessitating robust detection systems. However, current datasets lack diversity across modalities, languages, and real-world scenarios. To address this gap, we present ILLUSION (Integration of Life-Like Unique Synthetic Identities and Objects from Neural Networks), a large-scale, multi-modal\ndeepfake dataset comprising 1.3 million samples spanning audio-visual forgeries, 26 languages, challenging noisy environments, and various manipulation protocols. Generated using 28 state-of-the-art generative techniques, ILLUSION includes\nfaceswaps, audio spoofing, synchronized audio-video manipulations, and synthetic media while ensuring a balanced representation of gender and skin tone for unbiased evaluation. Using Jaccard Index and UpSet plot analysis, we demonstrate ILLUSION’s distinctiveness and minimal overlap with existing datasets, emphasizing its novel generative coverage. We benchmarked image, audio, video, and multi-modal detection models, revealing key challenges such as performance degradation in multilingual and multi-modal contexts, vulnerability to real-world distortions, and limited generalization to zero-day attacks. By bridging synthetic and real-world complexities, ILLUSION provides a challenging yet essential platform for advancing deepfake detection research. The dataset is publicly available at https://www.iab-rubric.org/illusion-database.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28235",
      "pdf_url": "https://openreview.net/pdf?id=qnlG3zPQUy",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mayank_Vatsa1",
        "name": "Mayank Vatsa",
        "name_site": null,
        "openreview_id": "~Mayank_Vatsa1",
        "position": 4,
        "gender": "M",
        "homepage_url": "http://home.iitj.ac.in/~mvatsa/",
        "dblp_id": "58/323",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=-DAxp-cAAAAJ",
        "orcid": "0000-0001-5952-2274",
        "linkedin_url": "mayankvatsa/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Jodhpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.0954451150103321,
        "confidence_mean": 4.0,
        "confidence_std": 0.6324555320336759,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "yR47RmND1m",
      "title": "Understanding and Enhancing Safety Mechanisms of LLMs via Safety-Specific Neuron",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Safety alignment for large language models (LLMs) has become a critical issue due to their rapid progress. However, our understanding of effective safety mechanisms in LLMs remains limited, leading to safety alignment training that mainly focuses on improving optimization, data-level enhancement, or adding extra structures to intentionally block harmful outputs. To address this gap, we develop a neuron detection method to identify safety neurons—those consistently crucial for handling and defending against harmful queries. Our findings reveal that these safety neurons constitute less than $1\\%$ of all parameters, are language-specific and are predominantly located in self-attention layers. Moreover, safety is collectively managed by these neurons in the first several layers. Based on these observations, we introduce a $\\underline{S}$afety $\\underline{N}$euron $\\underline{Tun}$ing method, named $\\texttt{SN-Tune}$, that exclusively tune safety neurons without compromising models' general capabilities. $\\texttt{SN-Tune}$ significantly enhances the safety of instruction-tuned models, notably reducing the harmful scores of Llama3-8B-Instruction from $65.5$ to $2.0$, Mistral-7B-Instruct-v0.2 from $70.8$ to $4.5$, and Vicuna-13B-1.5 from $93.5$ to $3.0$. Moreover, $\\texttt{SN-Tune}$ can be applied to base models on efficiently establishing LLMs' safety mechanism. In addition, we propose $\\underline{R}$obust $\\underline{S}$afety $\\underline{N}$euron $\\underline{Tun}$ing method ($\\texttt{RSN-Tune}$), which preserves the integrity of LLMs' safety mechanisms during downstream task fine-tuning by separating the safety neurons from models' foundation neurons.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=yR47RmND1m",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Di_He1_1",
        "name": "Di He",
        "name_site": null,
        "openreview_id": "~Anirudh_Goyal1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://anirudh9119.github.io/",
        "dblp_id": "172/1039",
        "google_scholar_url": "krrh6OUAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (Singapore)",
        "countries": [
          "Singapore"
        ],
        "country_codes": [
          "SG"
        ]
      },
      "sort_score": 2.0,
      "reviews": {
        "rating_mean": 6.2,
        "rating_std": 1.8330302779823362,
        "confidence_mean": 3.6,
        "confidence_std": 1.019803902718557,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "bW9fGYo44s",
      "title": "MotionAura: Generating High-Quality and Motion Consistent Videos using Discrete Diffusion",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "The spatio-temporal complexity of video data presents significant challenges in tasks such as compression, generation, and inpainting. We present four key contributions to address the challenges of spatiotemporal video processing. First, we introduce the 3D Mobile Inverted Vector-Quantization Variational Autoencoder (3D-MBQ-VAE), which combines Variational Autoencoders (VAEs) with masked modeling to enhance spatiotemporal video compression. The model achieves superior temporal consistency and state-of-the-art (SOTA) reconstruction quality by employing a novel training strategy with full frame masking. Second, we present MotionAura, a text-to-video generation framework that utilizes vector-quantized diffusion models to discretize the latent space and capture complex motion dynamics, producing temporally coherent videos aligned with text prompts. Third, we propose a spectral transformer-based denoising network that processes video data in the frequency domain using the Fourier Transform. This method effectively captures global context and long-range dependencies for high-quality video generation and denoising. Lastly, we introduce a downstream task of Sketch Guided Video Inpainting. This task leverages Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning. Our models achieve SOTA performance on a range of benchmarks.  Our work offers robust frameworks for spatiotemporal modeling and user-driven video content manipulation.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29105",
      "pdf_url": "https://openreview.net/pdf?id=bW9fGYo44s",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sparsh_Mittal1",
        "name": "Sparsh Mittal",
        "name_site": null,
        "openreview_id": "~Sparsh_Mittal1",
        "position": 4,
        "gender": "M",
        "homepage_url": "http://faculty.iitr.ac.in/~sparshfec/",
        "dblp_id": "97/9523",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=Hz44YrEAAAAJ",
        "orcid": "0000-0002-2908-993X",
        "linkedin_url": "sparsh-mittal-b77aa715/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Roorkee (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.875,
      "reviews": {
        "rating_mean": 7.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xkgfLXZ4e0",
      "title": "Correlating instruction-tuning (in multimodal models) with vision-language processing (in the brain)",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Transformer-based language models, though not explicitly trained to mimic brain recordings, have demonstrated surprising alignment with brain activity. Progress in these models—through increased size, instruction-tuning, and multimodality—has led to better representational alignment with neural data. Recently, a new class of instruction-tuned multimodal LLMs (MLLMs) have emerged, showing remarkable zero-shot capabilities in open-ended multimodal vision tasks. However, it is unknown whether MLLMs, when prompted with natural instructions, lead to better brain alignment and effectively capture instruction-specific representations. To address this, we first investigate the brain alignment, i.e., measuring the degree of predictivity of neural visual activity using text output response embeddings from MLLMs as participants engage in watching natural scenes. Experiments with 10 different instructions (like image captioning, visual question answering, etc.) show that  MLLMs exhibit significantly better brain alignment than vision-only models and perform comparably to non-instruction-tuned multimodal models like CLIP. We also find that while these MLLMs are effective at generating high-quality responses suitable to the task-specific instructions, not all instructions are relevant for brain alignment. Further, by varying instructions, we make the MLLMs encode instruction-specific visual concepts related to the input image. This analysis shows that MLLMs effectively capture count-related and recognition-related concepts, demonstrating strong alignment with brain activity. Notably, the majority of the explained variance of the brain encoding models is shared between MLLM embeddings of image captioning and other instructions. These results indicate that enhancing MLLMs' ability to capture more task-specific information could allow for better differentiation between various types of instructions, and hence improve their precision in predicting brain responses.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/27766",
      "pdf_url": "https://openreview.net/pdf?id=xkgfLXZ4e0",
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manish_Shrivastava1",
        "name": "Manish Shrivastava",
        "name_site": null,
        "openreview_id": "~Manish_Shrivastava1",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://www.iiit.ac.in/people/faculty/m.shrivastava/",
        "dblp_id": "65/3881",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=sIvMnGQAAAAJ",
        "orcid": "0000-0001-8705-6637",
        "linkedin_url": "manishrivastava/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.875,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.0,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "zl3pfz4VCV",
      "title": "MMTEB: Massive Multilingual Text Embedding Benchmark",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Text embeddings are typically evaluated on a narrow set of tasks, limited in terms of languages, domains, and task types. To circumvent this limitation and to provide a more comprehensive evaluation, we introduce the Massive Multilingual Text Embedding Benchmark (MMTEB) -- a large-scale community-driven initiative expanding MTEB to over 500 quality-controlled evaluation tasks across 1,000+ languages. MMTEB includes a wide range of challenging novel tasks such as instruction following, long-document retrieval, and code retrieval, and represents the largest multilingual collection of evaluation tasks for embedding models to date. We use this collection to construct multiple highly multilingual benchmarks. We evaluate a representative set of models on these benchmarks.\nOur findings indicate that, while LLM-based models can achieve state-of-the-art performance on a subset of languages, the best-performing publicly available model across languages is the notably smaller, multilingual-e5-large-instruct.\n\nMassive benchmarks often impose high computational demands, limiting accessibility, particularly for low-resource communities. To address this, we downsample tasks based on inter-task correlation (i.e., selecting only a diverse set of tasks) while preserving relative rankings.\nWe further optimize tasks such as retrieval by sampling hard negatives, creating smaller but effective splits. These optimizations allow us to introduce benchmarks at a significantly lower computational cost. For instance, we introduce a new zero-shot English benchmark that maintains a similar ordering at a fraction of the cost.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/27651",
      "pdf_url": "https://openreview.net/pdf?id=zl3pfz4VCV",
      "github_url": "",
      "total_authors": 82,
      "track_name": "Main Conference",
      "author": {
        "id": "~Nguyen_Tai1",
        "name": "Nguyen Tai",
        "name_site": null,
        "openreview_id": "~Nguyen_Tai1",
        "position": 52,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Nirma University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.8518518518518516,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "2uPZ4aX1VV",
      "title": "Null Counterfactual Factor Interactions for Goal-Conditioned Reinforcement Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Hindsight relabeling is a powerful tool for overcoming sparsity in goal-conditioned reinforcement learning (GCRL), especially in certain domains such as navigation and locomotion. However, hindsight relabeling can struggle in object-centric domains. For example, suppose that the goal space consists of a robotic arm pushing a particular target block to a goal location. In this case, hindsight relabeling will give high rewards to any trajectory that does not interact with the block. However, these behaviors are only useful when the object is already at the goal---an extremely rare case in practice. A dataset dominated by these kinds of trajectories can complicate learning and lead to failures. In object-centric domains, one key intuition is that meaningful trajectories are often characterized by object-object interactions such as pushing the block with the gripper. To leverage this intuition, we introduce Hindsight Relabeling using Interactions (HInt), which combines interactions with hindsight relabeling to improve the sample efficiency of downstream RL. However, interactions do not have a consensus statistical definition that is tractable for downstream GCRL. Therefore, we propose a definition of interactions based on the concept of _null counterfactual_: a cause object is interacting with a target object if, in a world where the cause object did not exist, the target object would have different transition dynamics. We leverage this definition to infer interactions in Null Counterfactual Interaction Inference (NCII), which uses a ``nulling'' operation with a learned model to simulate absences and infer interactions. We demonstrate that NCII is able to achieve significantly improved interaction inference accuracy in both simple linear dynamics domains and dynamic robotic domains in Robosuite, Robot Air Hockey, and Franka Kitchen. Furthermore, we demonstrate that HInt improves sample efficiency by up to $4\\times$ in these domains as goal-conditioned tasks.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/31106",
      "pdf_url": "https://openreview.net/pdf?id=2uPZ4aX1VV",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Siddhant_Agarwal1",
        "name": "Siddhant Agarwal",
        "name_site": null,
        "openreview_id": "~Siddhant_Agarwal1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://agarwalsiddhant10.github.io/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "siddhant-agarwal-688a31156/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "44z7HL4mfX",
      "title": "Instruct-SkillMix: A Powerful Pipeline for LLM Instruction Tuning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We introduce INSTRUCT-SKILLMIX, an automated approach for creating diverse, high quality SFT data for instruction-following. The pipeline involves two stages, each leveraging an existing powerful LLM: (1) Skill extraction: uses the LLM to extract core “skills” for instruction-following by directly prompting the model. This is inspired by “LLM metacognition” of (Didolkar et al., 2024); (2) Data generation: uses the powerful LLM to generate (instruction, response) data that\nexhibit a randomly chosen pair of these skills. Here, the use of random skill combinations promotes diversity and difficulty. The estimated cost of creating the dataset is under $600. \n\nVanilla SFT (i.e., no PPO, DPO, or RL methods) on data generated from INSTRUCT-SKILLMIX leads to strong gains on instruction following benchmarks such as AlpacaEval 2.0, MT-Bench, and WildBench. With just 4K examples, LLaMA-3-8B-Base achieves 42.76% length-controlled win rate on AlpacaEval 2.0, a level similar to frontier models like Claude 3 Opus and LLaMA-3.1-405B-Instruct. Ablation studies also suggest plausible reasons for why creating open instruction-tuning datasets via naive crowd-sourcing has proved difficult. In our dataset,adding 20% low quality answers (“shirkers”) causes a noticeable degradation in performance.\n\nThe INSTRUCT-SKILLMIX pipeline seems flexible and adaptable to other settings.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/31037",
      "pdf_url": "https://openreview.net/pdf?id=44z7HL4mfX",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Di_He1_1",
        "name": "Di He",
        "name_site": null,
        "openreview_id": "~Anirudh_Goyal1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://anirudh9119.github.io/",
        "dblp_id": "172/1039",
        "google_scholar_url": "krrh6OUAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 4.666666666666667,
        "rating_std": 1.247219128924647,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 8,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "52UtL8uA35",
      "title": "Deep Networks Learn Features From Local Discontinuities in the Label Function",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Deep neural networks outperform kernel machines on several datasets due to feature learning that happens during gradient descent training. In this paper, we analyze the mechanism through which feature learning happens and use a notion of features that corresponds to discontinuities in the true label function. We hypothesize that the core feature learning mechanism is label function discontinuities attracting model function discontinuities during training. To test this hypothesis, we perform experiments on classification data where the true label function is given by an oblique decision tree. This setup allows easy enumeration of label function discontinuities, while still remaining intractable for static kernel/linear methods. We then design/construct a novel deep architecture called a Deep Linearly Gated Network (DLGN), whose discontinuities in the input space can be easily enumerated.  In this setup, we provide supporting evidence demonstrating the movement of model function discontinuities towards the label function discontinuities during training. The easy enumerability of discontinuities in the DLGN also enables greater mechanistic interpretability. We demonstrate this by extracting the parameters of a high-accuracy decision tree from the parameters of a DLGN. We also show that the DLGN is competitive with ReLU networks and other tree-learning algorithms on several real-world tabular datasets.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30974",
      "pdf_url": "https://openreview.net/pdf?id=52UtL8uA35",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mahesh_Lorik_Yadav1",
        "name": "Mahesh Lorik Yadav",
        "name_site": null,
        "openreview_id": "~Mahesh_Lorik_Yadav1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "mahesh-yadav-25779716a/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "DFSb67ksVr",
      "title": "Clique Number Estimation via Differentiable Functions of Adjacency Matrix Permutations",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Estimating the clique number in a graph is central to various applications, e.g., community detection, graph retrieval, etc. \nExisting estimators often rely on non-differentiable combinatorial components. Here, we propose a full differentiable estimator for clique number estimation, which can be trained from distant supervision of clique numbers, rather than demonstrating actual cliques.\nOur key insight is a formulation of the maximum clique problem (MCP) as a maximization of the size of fully dense square submatrix, within a suitably row-column-permuted adjacency matrix.\nWe design a differentiable mechanism to search for permutations that lead to the discovery of such dense blocks.\nHowever, the optimal permutation is not unique, which leads to the learning of spurious permutations. To tackle this problem, we view the MCP problem as a sequence of subgraph matching tasks, each detecting progressively larger cliques in a nested manner. This allows effective navigation through suitable node permutations.\nThese steps result in MxNet, an end-to-end differentiable model, which learns to predict clique number without explicit clique demonstrations, with the added benefit of interpretability.  Experiments on eight datasets show the superior accuracy of our approach.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30469",
      "pdf_url": "https://openreview.net/pdf?id=DFSb67ksVr",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Soumen_Chakrabarti1",
        "name": "Soumen Chakrabarti",
        "name_site": null,
        "openreview_id": "~Soumen_Chakrabarti1",
        "position": 3,
        "gender": "Not Specified",
        "homepage_url": "https://www.cse.iitb.ac.in/~soumen/",
        "dblp_id": "c/SChakrabarti",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=LfF2zfQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "MKvQH1ekeY",
      "title": "Zigzag Diffusion Sampling: Diffusion Models Can Self-Improve via Self-Reflection",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Diffusion models, the most popular generative paradigm so far, can inject conditional information into the generation path to guide the latent towards desired directions. However, existing text-to-image diffusion models often fail to maintain high image quality and high prompt-image alignment for those challenging prompts. To mitigate this issue and enhance existing pretrained diffusion models, we mainly made three contributions in this paper. First, we propose **diffusion self-reflection** that alternately performs denoising and inversion and demonstrate that such diffusion self-reflection can leverage the guidance gap between denoising and inversion to capture prompt-related semantic information with theoretical and empirical evidence. Second, motivated by theoretical analysis, we derive Zigzag Diffusion Sampling (Z-Sampling), a novel self-reflection-based diffusion sampling method that leverages the guidance gap between denosing and inversion to accumulate semantic information step by step along the sampling path, leading to improved sampling results. Moreover, as a plug-and-play method, Z-Sampling can be generally applied to various diffusion models (e.g., accelerated ones and Transformer-based ones) with very limited coding and computational costs. Third, our extensive experiments demonstrate that Z-Sampling can generally and significantly enhance generation quality across various benchmark datasets, diffusion models, and performance evaluation metrics. For example, DreamShaper with Z-Sampling can self-improve with the HPSv2 winning rate up to **94%** over the original results. Moreover, Z-Sampling can further enhance existing diffusion models combined with other orthogonal methods, including Diffusion-DPO. The code is publicly available at\n[github.com/xie-lab-ml/Zigzag-Diffusion-Sampling](https://github.com/xie-lab-ml/Zigzag-Diffusion-Sampling).",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/29938",
      "pdf_url": "https://openreview.net/pdf?id=MKvQH1ekeY",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~zhiqiang_xu1",
        "name": "zhiqiang xu",
        "name_site": null,
        "openreview_id": "~zhiqiang_xu1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://scholar.google.com/citations?user=0R20iBMAAAAJ&hl=en",
        "dblp_id": "72/51-3.html",
        "google_scholar_url": null,
        "orcid": "0000-0002-5693-8933",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United Arab Emirates)",
        "countries": [
          "United Arab Emirates"
        ],
        "country_codes": [
          "AE"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "TmCcNuo03f",
      "title": "Measuring And Improving Engagement of Text-to-Image Generation Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent advances in text-to-image generation have achieved impressive aesthetic quality, making these models usable for both personal and commercial purposes. However, in the fields of marketing and advertising, images are often created to be more engaging, as reflected in user behaviors such as increasing clicks, likes, and purchases, in addition to being aesthetically pleasing. To this end, we introduce the challenge of optimizing the image generation process for improved viewer engagement. In order to study image engagement and utility in real-world marketing scenarios, we collect *EngagingImageNet*, the first large-scale dataset of images, along with associated user engagement metrics. Further, we find that existing image evaluation metrics like aesthetics, CLIPScore, PickScore, ImageReward, *etc.* are unable to capture viewer engagement. To address the lack of reliable metrics for assessing image utility, we use the *EngagingImageNet* dataset to train *EngageNet*, an engagement-aware Vision Language Model (VLM) that predicts viewer engagement of images by leveraging contextual information about the tweet content, enterprise details, and posting time. We then explore methods to enhance the engagement of text-to-image models, making initial strides in this direction. These include conditioning image generation on improved prompts, supervised fine-tuning of stable diffusion on high-performing images, and reinforcement learning to align stable diffusion with *EngageNet*-based reward signals, all of which lead to the generation of images with higher viewer engagement. Finally, we propose the *Engagement Arena*, to benchmark text-to-image models based on their ability to generate engaging images, using *EngageNet* as the evaluator, thereby encouraging the research community to measure further advances in the engagement of text-to-image modeling. These contributions provide a new pathway for advancing utility-driven image generation, with significant implications for the commercial application of image generation. We have released our code and dataset on [behavior-in-the-wild.github.io/image-engagement](https://behavior-in-the-wild.github.io/image-engagement).",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=TmCcNuo03f",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~zhiqiang_xu1",
        "name": "zhiqiang xu",
        "name_site": null,
        "openreview_id": "~zhiqiang_xu1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://scholar.google.com/citations?user=0R20iBMAAAAJ&hl=en",
        "dblp_id": "72/51-3.html",
        "google_scholar_url": null,
        "orcid": "0000-0002-5693-8933",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Mohamed bin Zayed University of Artificial Intelligence (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "h0vC0fm1q7",
      "title": "Sensitivity Verification for Additive Decision Tree Ensembles",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Tree ensemble models, such as Gradient Boosted Decision Trees (GBDTs) and random forests, are widely popular models for a variety of machine learning tasks. The power of these models comes from the ensemble of decision trees, which makes analysis of such models significantly harder than for single trees. As a result, recent work has focused on developing exact and approximate techniques for questions such as robustness verification, fairness and explainability for such models of tree ensembles.\n\nIn this paper, we focus on a specific problem of feature sensitivity for additive decision tree ensembles and build a formal verification framework for a parametrized variant of it, where we also take into account the confidence of the tree ensemble in its output. We start by showing theoretical (NP-)hardness of the problem and explain how it relates to other verification problems. Next, we provide a novel encoding of the problem using pseudo-Boolean constraints. Based on this encoding, we develop a tunable algorithm to perform sensitivity analysis, which can trade off precision for running time. We implement our algorithm and study its performance on a suite of GBDT benchmarks from the literature. Our experiments show the practical utility of our approach and its improved performance compared to existing approaches.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28785",
      "pdf_url": "https://openreview.net/pdf?id=h0vC0fm1q7",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ashutosh_Gupta2",
        "name": "Ashutosh Gupta",
        "name_site": null,
        "openreview_id": "~Ashutosh_Gupta2",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 6.4,
        "rating_std": 0.7999999999999999,
        "confidence_mean": 3.4,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "h51mpl8Tyx",
      "title": "BANGS: Game-theoretic Node Selection for Graph Self-Training",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph self-training is a semi-supervised learning method that iteratively selects a set of unlabeled data to retrain the underlying graph neural network (GNN) model and improve its prediction performance. While selecting highly confident nodes has proven effective for self-training, this pseudo-labeling strategy ignores the combinatorial dependencies between nodes and suffers from a local view of the distribution.\nTo overcome these issues, we propose BANGS, a novel framework that unifies the labeling strategy with conditional mutual information as the objective of node selection. Our approach---grounded in game theory---selects nodes in a combinatorial fashion and provides theoretical guarantees for robustness under noisy objective. More specifically, unlike traditional methods that rank and select nodes independently, BANGS considers nodes as a collective set in the self-training process. Our method demonstrates superior performance and robustness across various datasets, base models, and hyperparameter settings, outperforming existing techniques. The codebase is available on https://github.com/fangxin-wang/BANGS.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28782",
      "pdf_url": "https://openreview.net/pdf?id=h51mpl8Tyx",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sourav_Medya1",
        "name": "Sourav Medya",
        "name_site": null,
        "openreview_id": "~Sourav_Medya1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://souravmedya.github.io/",
        "dblp_id": "178/3021",
        "google_scholar_url": "RCFhOM4AAAAJ",
        "orcid": "0000-0003-0996-2807",
        "linkedin_url": "sourav-medya-35987a49/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Illinois at Chicago (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 6.2,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 3.4,
        "confidence_std": 0.8,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "l11DZY5Nxu",
      "title": "Robust Root Cause Diagnosis using In-Distribution Interventions",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Diagnosing the root cause of an anomaly in a complex interconnected system is\na pressing problem in today’s cloud services and industrial operations. We propose In-Distribution Interventions (IDI), a novel algorithm that predicts root cause\nas nodes that meet two criteria: 1) Anomaly: root cause nodes should take on\nanomalous values; 2) Fix: had the root cause nodes assumed usual values, the\ntarget node would not have been anomalous. Prior methods of assessing the fix\ncondition rely on counterfactuals inferred from a Structural Causal Model (SCM)\ntrained on historical data. But since anomalies are rare and fall outside the training distribution, the fitted SCMs yield unreliable counterfactual estimates. IDI\novercomes this by relying on interventional estimates obtained by solely probing the fitted SCM at in-distribution inputs. We present a theoretical analysis\ncomparing and bounding the errors in assessing the fix condition using interventional and counterfactual estimates. We then conduct experiments by systematically varying the SCM’s complexity to demonstrate the cases where IDI’s interventional approach outperforms the counterfactual approach and vice versa.\nExperiments on both synthetic and PetShop RCD benchmark datasets demonstrate that IDI consistently identifies true root causes more accurately and robustly than nine existing state-of-the-art RCD baselines. Code will be released\nat https://github.com/nlokeshiisc/IDI_release.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28541",
      "pdf_url": "https://openreview.net/pdf?id=l11DZY5Nxu",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sunita_Sarawagi1",
        "name": "Sunita Sarawagi",
        "name_site": null,
        "openreview_id": "~Sunita_Sarawagi1",
        "position": 3,
        "gender": "F",
        "homepage_url": "https://www.cse.iitb.ac.in/~sunita/",
        "dblp_id": "s/SunitaSarawagi",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=Hg4HmTAAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 2.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "vyflgpwfJW",
      "title": "DiscoveryBench: Towards Data-Driven Discovery with Large Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Can the rapid advances in code generation, function calling, and data analysis using large language models (LLMs) help automate the search and verification of hypotheses purely from a set of provided datasets? To evaluate this question, we present DiscoveryBench, the first comprehensive benchmark that formalizes the multi-step process of data-driven discovery. The benchmark is designed to systematically assess current model capabilities in discovery tasks and provide a useful resource for improving them. Our benchmark contains 264 tasks collected across 6 diverse domains, such as sociology and engineering, by manually deriving discovery workflows from published papers to approximate the real-world challenges faced by researchers, where each task is defined by a dataset, its metadata, and a discovery goal in natural language. We additionally provide 903 synthetic tasks to conduct controlled evaluations on data-driven workflows that are not covered in the manually collected split. Furthermore, our structured formalism of data-driven discovery enables a facet-based evaluation that provides useful insights into different failure modes. We evaluate several popular LLM-based reasoning frameworks using both open and closed LLMs as baselines on DiscoveryBench and find that even the best system scores only 25%. Our benchmark, thus, illustrates the challenges in autonomous data-driven discovery and serves as a valuable resource for the community to make progress.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=vyflgpwfJW",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 10,
      "track_name": "Main Conference",
      "author": {
        "id": "~Tushar_Khot1",
        "name": "Tushar Khot",
        "name_site": "Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, Ashish Sabharwal",
        "openreview_id": "~Tushar_Khot1",
        "position": 7,
        "gender": "M",
        "homepage_url": "https://allenai.org/team/tushark/",
        "dblp_id": "83/8117",
        "google_scholar_url": "_8mkIjgAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Allen Institute for AI (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 21,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "dGVZwyq5tV",
      "title": "Training-Free Activation Sparsity in Large Language Models",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "Activation sparsity can enable practical inference speedups in large language models (LLMs) by reducing the compute and memory-movement required for  matrix multiplications during the forward pass. \nHowever, existing methods face limitations that inhibit widespread adoption. Some approaches are tailored towards older models with ReLU-based sparsity, while others require extensive continued pre-training on up to hundreds of billions of tokens. \nThis paper describes TEAL (**T**raining-Fre**e** **A**ctivation Sparsity in **L**LMs), a simple training-free method that applies magnitude-based activation sparsity to hidden states throughout the entire model. TEAL achieves 40-50\\% model-wide sparsity with minimal performance degradation across Llama-2, Llama-3, and Mistral families, with sizes varying from 7B to 70B. We improve existing sparse kernels and demonstrate wall-clock decoding speed-ups of up to 1.53× and 1.8× at 40\\% and 50\\% model-wide sparsity. TEAL is compatible with weight quantization, enabling further efficiency gains.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28994",
      "pdf_url": "https://openreview.net/pdf?id=dGVZwyq5tV",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yoon_Kim1",
        "name": "Yoon Kim",
        "name_site": null,
        "openreview_id": "~Yoon_Kim1",
        "position": 5,
        "gender": null,
        "homepage_url": "https://people.csail.mit.edu/yoonkim/",
        "dblp_id": null,
        "google_scholar_url": "n_ts4eYAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Together AI (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 1.4999999999999996,
      "reviews": {
        "rating_mean": 7.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 11,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "zl3pfz4VCV",
      "title": "MMTEB: Massive Multilingual Text Embedding Benchmark",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Text embeddings are typically evaluated on a narrow set of tasks, limited in terms of languages, domains, and task types. To circumvent this limitation and to provide a more comprehensive evaluation, we introduce the Massive Multilingual Text Embedding Benchmark (MMTEB) -- a large-scale community-driven initiative expanding MTEB to over 500 quality-controlled evaluation tasks across 1,000+ languages. MMTEB includes a wide range of challenging novel tasks such as instruction following, long-document retrieval, and code retrieval, and represents the largest multilingual collection of evaluation tasks for embedding models to date. We use this collection to construct multiple highly multilingual benchmarks. We evaluate a representative set of models on these benchmarks.\nOur findings indicate that, while LLM-based models can achieve state-of-the-art performance on a subset of languages, the best-performing publicly available model across languages is the notably smaller, multilingual-e5-large-instruct.\n\nMassive benchmarks often impose high computational demands, limiting accessibility, particularly for low-resource communities. To address this, we downsample tasks based on inter-task correlation (i.e., selecting only a diverse set of tasks) while preserving relative rankings.\nWe further optimize tasks such as retrieval by sampling hard negatives, creating smaller but effective splits. These optimizations allow us to introduce benchmarks at a significantly lower computational cost. For instance, we introduce a new zero-shot English benchmark that maintains a similar ordering at a fraction of the cost.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/27651",
      "pdf_url": "https://openreview.net/pdf?id=zl3pfz4VCV",
      "github_url": "",
      "total_authors": 82,
      "track_name": "Main Conference",
      "author": {
        "id": "~Xing_Han_Lù1",
        "name": "Xing Han Lù",
        "name_site": null,
        "openreview_id": "~Xing_Han_Lù1",
        "position": 58,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "London Institute of Banking & Finance (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.4814814814814814,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5pd78GmXC6",
      "title": "Charting the Design Space of Neural Graph Representations for Subgraph Matching",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Subgraph matching is vital in knowledge graph (KG) question answering, molecule design, scene graph, code and circuit search, etc.\nNeural methods have shown promising results for subgraph matching.\nOur study of recent systems suggests refactoring them into a unified design space for graph matching networks.\nExisting methods occupy only a few isolated patches in this space, which remains largely uncharted.\nWe undertake the first comprehensive exploration of this space, featuring such axes as attention-based vs. soft permutation-based interaction between query and corpus graphs, aligning nodes vs. edges, and the form of the final scoring network that integrates neural representations of the graphs.\nOur extensive experiments reveal that judicious and hitherto-unexplored combinations of choices in this space lead to large performance benefits.\nBeyond better performance, our study uncovers valuable insights and establishes general design principles for neural graph representation and interaction, which may be of wider interest.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30929",
      "pdf_url": "https://openreview.net/pdf?id=5pd78GmXC6",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Soumen_Chakrabarti1",
        "name": "Soumen Chakrabarti",
        "name_site": null,
        "openreview_id": "~Soumen_Chakrabarti1",
        "position": 4,
        "gender": "Not Specified",
        "homepage_url": "https://www.cse.iitb.ac.in/~soumen/",
        "dblp_id": "c/SChakrabarti",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=LfF2zfQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.25,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5x88lQ2MsH",
      "title": "Bonsai: Gradient-free Graph Condensation for Node Classification",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph condensation has emerged as a promising avenue to enable scalable training of GNNs by compressing the training dataset while preserving essential graph characteristics. Our study uncovers significant shortcomings in current graph condensation techniques. First, the majority of the algorithms paradoxically require training on the full dataset to perform condensation. Second, due to their gradient-emulating approach, these methods require fresh condensation for any change in hyperparameters or GNN architecture, limiting their flexibility and reusability. To address these challenges, we present Bonsai, a novel graph condensation method empowered by the observation that *computation trees* form the fundamental processing units of message-passing GNNs. Bonsai condenses datasets by encoding a careful selection of *exemplar* trees that maximize the representation of all computation trees in the training set. This unique approach imparts Bonsai as the first linear-time, model-agnostic graph condensation algorithm for node classification that outperforms existing baselines across $7$ real-world datasets on accuracy, while being $22$ times faster on average. Bonsai is grounded in rigorous mathematical guarantees on the adopted approximation strategies, making it robust to GNN architectures, datasets, and parameters.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30924",
      "pdf_url": "https://openreview.net/pdf?id=5x88lQ2MsH",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~HARIPRASAD_KODAMANA1",
        "name": "HARIPRASAD KODAMANA",
        "name_site": null,
        "openreview_id": "~HARIPRASAD_KODAMANA1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://web.iitd.ac.in/~kodamana/",
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.co.in/citations?user=YBcs36wAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.25,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "84WmbzikPP",
      "title": "Stiefel Flow Matching for Moment-Constrained Structure Elucidation",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Molecular structure elucidation is a fundamental step in understanding chemical phenomena, with applications in identifying molecules in natural products, lab syntheses, forensic samples, and the interstellar medium.\nWe consider the task of predicting a molecule's all-atom 3D structure given only its molecular formula and moments of inertia, motivated by the ability of rotational spectroscopy to measure these moments.\nWhile existing generative models can conditionally sample 3D structures with approximately correct moments, this soft conditioning fails to leverage the many digits of precision afforded by experimental rotational spectroscopy.\nTo address this, we first show that the space of $n$-atom point clouds with a fixed set of moments of inertia is embedded in the Stiefel manifold $\\mathrm{St}(n, 4)$.\nWe then propose Stiefel Flow Matching as a generative model for elucidating 3D structure under exact moment constraints.\nAdditionally, we learn simpler and shorter flows by finding approximate solutions for equivariant optimal transport on the Stiefel manifold.\nEmpirically, enforcing exact moment constraints allows Stiefel Flow Matching to achieve higher success rates and faster sampling than Euclidean diffusion models, even on high-dimensional manifolds corresponding to large molecules in the GEOM dataset.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30787",
      "pdf_url": "https://openreview.net/pdf?id=84WmbzikPP",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Santiago_Miret1",
        "name": "Santiago Miret",
        "name_site": null,
        "openreview_id": "~Santiago_Miret1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://www.intel.ai/bio/santiago-miret/",
        "dblp_id": "241/5030",
        "google_scholar_url": "HLQ_te4AAAAJ",
        "orcid": "0000-0002-5121-3853",
        "linkedin_url": "santiago-miret/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Intel (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 1.25,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.0,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "0dELcFHig2",
      "title": "Multi-modal brain encoding models for multi-modal stimuli",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Despite participants engaging in unimodal stimuli, such as watching images or silent videos, recent work has demonstrated that multi-modal Transformer models can predict visual brain activity impressively well, even with incongruent modality representations. This raises the question of how accurately these multi-modal models can predict brain activity when participants are engaged in multi-modal stimuli. As these models grow increasingly popular, their use in studying neural activity provides insights into how our brains respond to such multi-modal naturalistic stimuli, i.e., where it separates and integrates information across modalities through a hierarchy of early sensory regions to higher cognition (language regions). We investigate this question by using multiple unimodal and two types of multi-modal models—cross-modal and jointly pretrained—to determine which type of models is more relevant to fMRI brain activity when participants are engaged in watching movies (videos with audio). We observe that both types of multi-modal models show improved alignment in several language and visual regions. This study also helps in identifying which brain regions process unimodal versus multi-modal information. We further investigate the contribution of each modality to multi-modal alignment by carefully removing unimodal features one by one from multi-modal representations, and find that there is additional information beyond the unimodal embeddings that is processed in the visual and language regions. Based on this investigation, we find that while for cross-modal models, their brain alignment is partially attributed to the video modality; for jointly pretrained models, it is partially attributed to both the video and audio modalities. These findings serve as strong motivation for the neuro-science community to investigate the interpretability of these models for deepening our understanding of multi-modal information processing in brain.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/31247",
      "pdf_url": "https://openreview.net/pdf?id=0dELcFHig2",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manish_Gupta1",
        "name": "Manish Gupta",
        "name_site": null,
        "openreview_id": "~Manish_Gupta1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/manishg/",
        "dblp_id": "g/ManishGupta1.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=eX9PSu0AAAAJ",
        "orcid": "0000-0002-2843-3110",
        "linkedin_url": "manishsgupta/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.9999999999999998,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "9juyeCqL0u",
      "title": "Causal Order: The Key to Leveraging Imperfect Experts in Causal Inference",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Large Language Models (LLMs) have recently been used as experts to infer causal graphs, often by repeatedly applying a pairwise prompt that asks about the causal relationship of each variable pair. However, such experts, including human domain experts, cannot distinguish between direct and indirect effects given a pairwise prompt. Therefore, instead of the graph, we propose that causal order be used as a more stable output interface for utilizing expert knowledge. When querying a perfect expert with a pairwise prompt, we show that the inferred graph can have significant errors whereas the causal order is always correct. In practice, however, LLMs are imperfect experts and we find that pairwise prompts lead to multiple cycles and do not yield a valid order. Hence, we propose a prompting strategy that introduces an auxiliary variable for every variable pair and instructs the LLM to avoid cycles within this triplet. We show, both theoretically and empirically, that such a triplet prompt leads to fewer cycles than the pairwise prompt. Across multiple real-world graphs, the triplet prompt yields a more accurate order using both LLMs and human annotators as experts. By querying the expert with different auxiliary variables for the same variable pair, it also increases robustness---triplet method with much smaller models such as Phi-3 and Llama-3 8B outperforms a pairwise prompt with GPT-4. For practical usage, we show how the estimated causal order from the triplet method  can be used to reduce error in downstream discovery and effect inference tasks.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30671",
      "pdf_url": "https://openreview.net/pdf?id=9juyeCqL0u",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Amit_Sharma3",
        "name": "Amit Sharma",
        "name_site": null,
        "openreview_id": "~Amit_Sharma3",
        "position": 5,
        "gender": "M",
        "homepage_url": "http://amitsharma.in/",
        "dblp_id": "72/2540-7",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=CXgQufgAAAAJ",
        "orcid": "0000-0002-2086-3191",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.9999999999999998,
      "reviews": {
        "rating_mean": 6.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 3.4,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "AkBrb7yQ0G",
      "title": "Periodic Materials Generation using Text-Guided Joint Diffusion Model",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Equivariant diffusion models have emerged as the prevailing approach for generat-\ning novel crystal materials due to their ability to leverage the physical symmetries\nof periodic material structures. However, current models do not effectively learn the\njoint distribution of atom types, fractional coordinates, and lattice structure of the\ncrystal material in a cohesive end-to-end diffusion framework. Also, none of these\nmodels work under realistic setups, where users specify the desired characteristics\nthat the generated structures must match. In this work, we introduce TGDMat, a\nnovel text-guided diffusion model designed for 3D periodic material generation.\nOur approach integrates global structural knowledge through textual descriptions\nat each denoising step while jointly generating atom coordinates, types, and lattice\nstructure using a periodic-E(3)-equivariant graph neural network (GNN). Extensive\nexperiments using popular datasets on benchmark tasks reveal that TGDMat out-\nperforms existing baseline methods by a good margin. Notably, for the structure\nprediction task, with just one generated sample, TGDMat outperforms all baseline\nmodels, highlighting the importance of text-guided diffusion. Further, in the genera-\ntion task, TGDMat surpasses all baselines and their text-fusion variants, showcasing\nthe effectiveness of the joint diffusion paradigm. Additionally, incorporating textual\nknowledge reduces overall training and sampling computational overhead while\nenhancing generative performance when utilizing real-world textual prompts from\nexperts. Code is available at https://github.com/kdmsit/TGDMat",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30619",
      "pdf_url": "https://openreview.net/pdf?id=AkBrb7yQ0G",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Satadeep_Bhattacharjee1",
        "name": "Satadeep Bhattacharjee",
        "name_site": null,
        "openreview_id": "~Satadeep_Bhattacharjee1",
        "position": 5,
        "gender": null,
        "homepage_url": "https://ikst.res.in/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.9999999999999998,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "G7sIFXugTX",
      "title": "SWE-Search: Enhancing Software Agents with Monte Carlo Tree Search and Iterative Refinement",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Software engineers operating in complex and dynamic environments must continuously adapt to evolving requirements, learn iteratively from experience, and reconsider their approaches based on new insights. However, current large language model (LLM)-based software agents often follow linear, sequential processes that prevent backtracking and exploration of alternative solutions, limiting their ability to rethink their strategies when initial approaches prove ineffective. To address these challenges, we propose SWE-Search, a multi-agent framework that integrates Monte Carlo Tree Search (MCTS) with a self-improvement mechanism to enhance software agents' performance on repository-level software tasks. SWE-Search extends traditional MCTS by incorporating a hybrid value function that leverages LLMs for both numerical value estimation and qualitative evaluation. This enables self-feedback loops where agents iteratively refine their strategies based on both quantitative numerical evaluations and qualitative natural language assessments of pursued trajectories. The framework includes a SWE-Agent for adaptive exploration, a Value Agent for iterative feedback, and a Discriminator Agent that facilitates multi-agent debate for collaborative decision-making. Applied to the SWE-bench benchmark, our approach demonstrates a 23% relative improvement in performance across five models compared to standard open-source agents without MCTS. Our analysis reveals how performance scales with increased inference-time compute through deeper search, providing a pathway to improve software agents without requiring larger models or additional training data. This highlights the potential of self-evaluation driven search techniques in complex software engineering environments.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/30299",
      "pdf_url": "https://openreview.net/pdf?id=G7sIFXugTX",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Di_He1_1",
        "name": "Di He",
        "name_site": null,
        "openreview_id": "~Anirudh_Goyal1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://anirudh9119.github.io/",
        "dblp_id": "172/1039",
        "google_scholar_url": "krrh6OUAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (United Kingdom)",
        "countries": [
          "United Kingdom"
        ],
        "country_codes": [
          "GB"
        ]
      },
      "sort_score": 0.9999999999999998,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 14,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qnlG3zPQUy",
      "title": "ILLUSION: Unveiling Truth with a Comprehensive Multi-Modal, Multi-Lingual Deepfake Dataset",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The proliferation of deepfakes and AI-generated content has led to a surge in media forgeries and misinformation, necessitating robust detection systems. However, current datasets lack diversity across modalities, languages, and real-world scenarios. To address this gap, we present ILLUSION (Integration of Life-Like Unique Synthetic Identities and Objects from Neural Networks), a large-scale, multi-modal\ndeepfake dataset comprising 1.3 million samples spanning audio-visual forgeries, 26 languages, challenging noisy environments, and various manipulation protocols. Generated using 28 state-of-the-art generative techniques, ILLUSION includes\nfaceswaps, audio spoofing, synchronized audio-video manipulations, and synthetic media while ensuring a balanced representation of gender and skin tone for unbiased evaluation. Using Jaccard Index and UpSet plot analysis, we demonstrate ILLUSION’s distinctiveness and minimal overlap with existing datasets, emphasizing its novel generative coverage. We benchmarked image, audio, video, and multi-modal detection models, revealing key challenges such as performance degradation in multilingual and multi-modal contexts, vulnerability to real-world distortions, and limited generalization to zero-day attacks. By bridging synthetic and real-world complexities, ILLUSION provides a challenging yet essential platform for advancing deepfake detection research. The dataset is publicly available at https://www.iab-rubric.org/illusion-database.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/28235",
      "pdf_url": "https://openreview.net/pdf?id=qnlG3zPQUy",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Richa_Singh1",
        "name": "Richa Singh",
        "name_site": null,
        "openreview_id": "~Richa_Singh1",
        "position": 5,
        "gender": "F",
        "homepage_url": "http://home.iitj.ac.in/~richa/",
        "dblp_id": "75/3512",
        "google_scholar_url": "okqK5UAAAAAJ",
        "orcid": "0000-0003-4060-4573",
        "linkedin_url": "richa-singh-40ba237/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Jodhpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.9999999999999998,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.0954451150103321,
        "confidence_mean": 4.0,
        "confidence_std": 0.6324555320336759,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xnssGv9rpW",
      "title": "SymmCD: Symmetry-Preserving Crystal Generation with Diffusion Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Generating novel crystalline materials has potential to lead to advancements in fields such as electronics, energy storage, and catalysis. The defining characteristic of crystals is their symmetry, which plays a central role in determining their physical properties. However, existing crystal generation methods either fail to generate materials that display the symmetries of real-world crystals, or simply replicate the symmetry information from examples in a database.  To address this limitation, we propose SymmCD, a novel diffusion-based generative model that explicitly incorporates crystallographic symmetry into the generative process. We decompose crystals into two components and learn their joint distribution through diffusion: 1) the asymmetric unit, the smallest subset of the crystal  which can generate the whole crystal through symmetry transformations, and; 2) the symmetry transformations needed to be applied to each atom in the asymmetric unit. We also use a novel and interpretable representation for these transformations, enabling generalization across different crystallographic symmetry groups. We showcase the competitive performance of SymmCD on a subset of the Materials Project, obtaining diverse and valid crystals with realistic symmetries and predicted properties.",
      "tldr": "",
      "site_url": "https://iclr.cc/virtual/2025/poster/27763",
      "pdf_url": "https://openreview.net/pdf?id=xnssGv9rpW",
      "github_url": "",
      "total_authors": 8,
      "track_name": "Main Conference",
      "author": {
        "id": "~Santiago_Miret1",
        "name": "Santiago Miret",
        "name_site": null,
        "openreview_id": "~Santiago_Miret1",
        "position": 7,
        "gender": "M",
        "homepage_url": "https://www.intel.ai/bio/santiago-miret/",
        "dblp_id": "241/5030",
        "google_scholar_url": "HLQ_te4AAAAJ",
        "orcid": "0000-0002-5121-3853",
        "linkedin_url": "santiago-miret/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.7142857142857145,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 10,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "04RGjODVj3",
      "title": "From Rest to Action: Adaptive Weight Generation for Motor Imagery Classification from Resting-State EEG Using Hypernetworks",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Existing EEG-based brain-computer interface (BCI) systems require long calibration sessions from the intended users to train the models, limiting their use in real-world applications. Additionally, despite containing user-specific information and features correlating with BCI performance of a user, resting-state EEG data is underutilized, especially in motor imagery decoding tasks. To address the challenge of within and across-user generalisation, we propose a novel architecture, HyperEEGNet, which integrates HyperNetworks (HNs) with the EEGNet architecture to adaptively generate weights for motor imagery classification based on resting-state data. Our approach performs similarly in a Leave-Subject-Out scenario using a dataset with 9 participants, compared to the baseline EEGNet. When the dataset size is scaled, with 33 participants' datasets, the model demonstrates its generalisation capabilities using the information from resting state EEG data, particularly when faced with unseen subjects. Our model can learn robust representations in both cross-session and cross-user scenarios, opening a novel premise to leverage the resting state data for downstream tasks like motor imagery classification. The findings also demonstrate that such models with smaller footprints reduce memory and storage requirements for edge computing. The approach opens up avenues for faster user calibration and better feasibility of edge computing, a favourable combination to push forward the efforts to bring BCIs to real-world applications.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=04RGjODVj3",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Param_Rajpura1",
        "name": "Param Rajpura",
        "name_site": null,
        "openreview_id": "~Param_Rajpura1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "365/5245",
        "google_scholar_url": "vZ18sUUAAAAJ",
        "orcid": "0000-0003-3021-9313",
        "linkedin_url": "param-rajpura",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Gandhinagar (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 4.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "04RGjODVj3",
      "title": "From Rest to Action: Adaptive Weight Generation for Motor Imagery Classification from Resting-State EEG Using Hypernetworks",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Existing EEG-based brain-computer interface (BCI) systems require long calibration sessions from the intended users to train the models, limiting their use in real-world applications. Additionally, despite containing user-specific information and features correlating with BCI performance of a user, resting-state EEG data is underutilized, especially in motor imagery decoding tasks. To address the challenge of within and across-user generalisation, we propose a novel architecture, HyperEEGNet, which integrates HyperNetworks (HNs) with the EEGNet architecture to adaptively generate weights for motor imagery classification based on resting-state data. Our approach performs similarly in a Leave-Subject-Out scenario using a dataset with 9 participants, compared to the baseline EEGNet. When the dataset size is scaled, with 33 participants' datasets, the model demonstrates its generalisation capabilities using the information from resting state EEG data, particularly when faced with unseen subjects. Our model can learn robust representations in both cross-session and cross-user scenarios, opening a novel premise to leverage the resting state data for downstream tasks like motor imagery classification. The findings also demonstrate that such models with smaller footprints reduce memory and storage requirements for edge computing. The approach opens up avenues for faster user calibration and better feasibility of edge computing, a favourable combination to push forward the efforts to bring BCIs to real-world applications.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=04RGjODVj3",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yogesh_Kumar_Meena1",
        "name": "Yogesh Kumar Meena",
        "name_site": null,
        "openreview_id": "~Yogesh_Kumar_Meena1",
        "position": 2,
        "gender": "M",
        "homepage_url": "http://yogeshmeena.com/",
        "dblp_id": "66/10604.html",
        "google_scholar_url": "https://scholar.google.it/citations?hl=en",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Gandhinagar (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 4.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "0ASCZrVzSX",
      "title": "Blessing of Dimensionality for Approximating Sobolev Classes on Manifolds",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The manifold hypothesis says that natural high-dimensional data lie on or around a low-dimensional manifold. The recent success of statistical and learning-based methods in very high dimensions empirically supports this hypothesis, suggesting that typical worst-case analysis does not provide practical guarantees. A natural step for analysis is thus to assume the manifold hypothesis and derive bounds that are independent of any ambient dimensions that the data may be embedded in. Theoretical implications in this direction have recently been explored in terms of generalization of ReLU networks and convergence of Langevin methods. In this work, we consider optimal uniform approximations with functions of finite statistical complexity. While upper bounds on uniform approximation exist in the literature in terms of ReLU network approximation, we consider the opposite: lower bounds to quantify the fundamental difficulty of approximation on manifolds. In particular, we demonstrate that the statistical complexity required to approximate a class of bounded Sobolev functions on a compact manifold is bounded from below, and moreover that this bound is dependent only on the intrinsic properties of the manifold, such as curvature, volume, and injectivity radius.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=0ASCZrVzSX",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Subhadip_Mukherjee1",
        "name": "Subhadip Mukherjee",
        "name_site": null,
        "openreview_id": "~Subhadip_Mukherjee1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/subhadip-mukherjee/home",
        "dblp_id": "120/7054",
        "google_scholar_url": "https://scholar.google.se/citations?user=a4UlE_MAAAAJ",
        "orcid": "0000-0002-7957-8758",
        "linkedin_url": "subhadip-mukherjee-11b925101/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "0IqriWHWYy",
      "title": "Watch Out!! Your Confidence Might be a Reason for Vulnerability",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The tremendous success of deep neural networks (DNNs) in solving `any' complex computer vision task leaves no stone unturned for their deployment in the physical world. However, the concerns arise when natural adversarial corruptions might perturb the physical world in unconstrained images. It is widely known that these corruptions are inherently present in the environment and can fool DNNs. While the literature aims to provide safety to DNNs against these natural corruptions they have developed two forms of defenses: (i) detection of corrupted images and (ii) mitigation of corruptions. So far, very little work has been done to understand the reason behind the vulnerabilities of DNNs against such corruption. We assert that network confidence is an essential component and ask whether the higher it is, the better the decision of a network is or not. Moreover, we ask the question of whether this confidence itself is a reason for their vulnerability against corruption. We extensively study the correlation between the confidence of a model and its robustness in handling corruption. Through extensive experimental evaluation using multiple datasets and models, we found a significant connection between the confidence and robustness of a network.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=0IqriWHWYy",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ayush_Pandey3",
        "name": "Ayush Pandey",
        "name_site": null,
        "openreview_id": "~Ayush_Pandey3",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "ayush-pandey-85810a202/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science Education and Research, Bhopal (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "0IqriWHWYy",
      "title": "Watch Out!! Your Confidence Might be a Reason for Vulnerability",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The tremendous success of deep neural networks (DNNs) in solving `any' complex computer vision task leaves no stone unturned for their deployment in the physical world. However, the concerns arise when natural adversarial corruptions might perturb the physical world in unconstrained images. It is widely known that these corruptions are inherently present in the environment and can fool DNNs. While the literature aims to provide safety to DNNs against these natural corruptions they have developed two forms of defenses: (i) detection of corrupted images and (ii) mitigation of corruptions. So far, very little work has been done to understand the reason behind the vulnerabilities of DNNs against such corruption. We assert that network confidence is an essential component and ask whether the higher it is, the better the decision of a network is or not. Moreover, we ask the question of whether this confidence itself is a reason for their vulnerability against corruption. We extensively study the correlation between the confidence of a model and its robustness in handling corruption. Through extensive experimental evaluation using multiple datasets and models, we found a significant connection between the confidence and robustness of a network.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=0IqriWHWYy",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Akshay_Agarwal1",
        "name": "Akshay Agarwal",
        "name_site": null,
        "openreview_id": "~Akshay_Agarwal1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://sites.google.com/iiitd.ac.in/agarwalakshay/home",
        "dblp_id": "152/3672-1",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=LrW6Hb4AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science Education and Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "0JjsZC0w8x",
      "title": "COrAL: Order-Agnostic Language Modeling for Efficient Iterative Refinement",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Iterative refinement has emerged as an effective paradigm for enhancing the capabilities of large language models (LLMs) on complex tasks. However, existing approaches typically implement iterative refinement at the application or prompting level, relying on autoregressive (AR) modeling. The sequential token generation in AR models can lead to high inference latency. \nTo overcome these challenges, we propose **C**ontext-Wise **Or**der-**A**gnostic **L**anguage Modeling (COrAL), which incorporates iterative refinement directly into the LLM architecture while maintaining computational efficiency. Our approach models multiple token dependencies within manageable context windows, enabling the model to perform iterative refinement internally during the generation process. Leveraging the order-agnostic nature of COrAL, we introduce sliding blockwise order-agnostic decoding, which performs multi-token forward prediction and backward reconstruction within context windows. This allows the model to iteratively refine its outputs in parallel in the sliding block, effectively capturing diverse dependencies without the high inference cost of sequential generation.\nEmpirical evaluations on reasoning tasks demonstrate that COrAL improves performance and inference speed, respectively, achieving absolute accuracy gains of $4.6$\\% on GSM8K and $4.0$\\% on LogiQA, along with inference speedups of up to $3.9\\times$ over next-token baselines. Preliminary results on code generation indicate a drop in pass rates due to inconsistencies in order-agnostic outputs, highlighting the inherent quality--speed trade-off.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=0JjsZC0w8x",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 8,
      "track_name": "Main Conference",
      "author": {
        "id": "~Di_He1_1",
        "name": "Di He",
        "name_site": null,
        "openreview_id": "~Anirudh_Goyal1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://anirudh9119.github.io/",
        "dblp_id": "172/1039",
        "google_scholar_url": "krrh6OUAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (United Kingdom)",
        "countries": [
          "United Kingdom"
        ],
        "country_codes": [
          "GB"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.7853571071357126,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "0iXfS9Smqf",
      "title": "Learning through experience:Episodic memory representation for cognitive agents",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "As the demand for intelligent robots and cognitive agents rises, the ability to retain and utilize past experiences through episodic memory has become crucial, especially for social companion robots that rely on previous interactions for task execution. To address this, we introduce Episodic Memory for Cognitive Agents (EMCA), a novel framework that advances knowledge representation by integrating real-world interactions. EMCA enables agents to adapt to complex environments by learning from tasks, interacting with humans, and processing multimodal data—such as speech, vision, and non-verbal cues—without pre-training on specific scenarios.\nEMCA models episodic memory through a graph-based structure , allowing for incremental storage and retrieval of experiences. Each interaction or event enriches the memory graph, supporting continuous learning and adaptation without extensive retraining. This human-like memory formation optimizes the agent’s ability to retrieve relevant information for tasks like localization, planning, and reasoning based on prior experiences.Unlike conventional models relying on temporal markers or recurrent patterns, EMCA encodes data like human memory, allowing reasoning across diverse scenarios regardless of temporal patterns. The framework dynamically builds a memory graph with semantic and temporal connections based on the agent’s experiences, promoting flexible temporal reasoning. It also introduces mechanisms for clustering new memories and a dynamic retrieval policy that adjusts based on context or query type, ensuring robustness even in unpredictable scenarios. Empirical tests show EMCA adapts effectively to real-world data, offering reliability and flexibility in dynamic environments.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=0iXfS9Smqf",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Shweta_Singh3",
        "name": "Shweta Singh",
        "name_site": null,
        "openreview_id": "~Shweta_Singh3",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0009-0003-7055-0251",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology, Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "0iXfS9Smqf",
      "title": "Learning through experience:Episodic memory representation for cognitive agents",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "As the demand for intelligent robots and cognitive agents rises, the ability to retain and utilize past experiences through episodic memory has become crucial, especially for social companion robots that rely on previous interactions for task execution. To address this, we introduce Episodic Memory for Cognitive Agents (EMCA), a novel framework that advances knowledge representation by integrating real-world interactions. EMCA enables agents to adapt to complex environments by learning from tasks, interacting with humans, and processing multimodal data—such as speech, vision, and non-verbal cues—without pre-training on specific scenarios.\nEMCA models episodic memory through a graph-based structure , allowing for incremental storage and retrieval of experiences. Each interaction or event enriches the memory graph, supporting continuous learning and adaptation without extensive retraining. This human-like memory formation optimizes the agent’s ability to retrieve relevant information for tasks like localization, planning, and reasoning based on prior experiences.Unlike conventional models relying on temporal markers or recurrent patterns, EMCA encodes data like human memory, allowing reasoning across diverse scenarios regardless of temporal patterns. The framework dynamically builds a memory graph with semantic and temporal connections based on the agent’s experiences, promoting flexible temporal reasoning. It also introduces mechanisms for clustering new memories and a dynamic retrieval policy that adjusts based on context or query type, ensuring robustness even in unpredictable scenarios. Empirical tests show EMCA adapts effectively to real-world data, offering reliability and flexibility in dynamic environments.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=0iXfS9Smqf",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Shraddha_Seshadri1",
        "name": "Shraddha Seshadri",
        "name_site": null,
        "openreview_id": "~Shraddha_Seshadri1",
        "position": 2,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "AACYsN4AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "SIES GST (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "0rS9o1uKqu",
      "title": "Training-Like Data Reconstruction",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Machine Learning models are often trained on proprietary and private data that cannot be shared, though the trained models themselves are distributed openly assuming that sharing model weights is privacy preserving, as training data is not expected to be inferred from the model weights. In this paper, we present Training-Like Data Reconstruction (TLDR), a network inversion-based approach to reconstruct training-like data from trained models. To begin with, we introduce a comprehensive network inversion technique that learns the input space corresponding to different classes in the classifier using a single conditioned generator. While inversion may typically return random and arbitrary input images for a given output label, we modify the inversion process to incentivize the generator to reconstruct training-like data by exploiting key properties of the classifier with respect to the training data. Specifically, the classifier is expected to be relatively more confident and robust in classifying training samples, and the gradient of the classifiers output with respect to the classifier’s weights is also expected to be lower for training data than for random inverted samples. Using these insights, along with some prior knowledge about the images, we guide the generator to produce data closely resembling the original training data. To validate our approach, we conduct empirical evaluations on multiple standard vision classification datasets, demonstrating that leveraging these robustness and gradient properties enables the reconstruction of data semantically similar to the original training data, thereby highlighting the potential privacy risks involved in sharing machine learning models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=0rS9o1uKqu",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Pirzada_Suhail1",
        "name": "Pirzada Suhail",
        "name_site": null,
        "openreview_id": "~Pirzada_Suhail1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "12nMVncAAAAJ",
        "orcid": null,
        "linkedin_url": "pirzadasuhail/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "1D3TjFidCS",
      "title": "Logarithmic Linear Units (LogLUs): A Novel Activation Function for Improved Convergence in Deep Neural Networks",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The Logarithmic Linear Unit (LogLU) presents a novel activation function for deep neural networks by incorporating logarithmic elements into its design, introducing non-linearity that significantly enhances both training efficiency and accuracy. LogLU effectively addresses common limitations associated with widely used activation functions include ReLU, Leaky ReLU, and ELU, which suffer from issues like the dead neuron problem and vanishing gradients. By enabling neurons to remain active with negative inputs and ensuring effective gradient flow during backpropagation, LogLU promotes more efficient convergence in gradient descent. Its capability to solve fundamental yet complex non-linear tasks, such as the XOR problem, with fewer neurons demonstrates its efficiency in capturing non-linear patterns. Extensive evaluations on benchmark datasets like Caltech 101 and Imagenette, using the InceptionV3 architecture, reveal that LogLU not only accelerates convergence but also enhances model performance compared to existing activation functions. These findings underscore LogLU's potential as an effective activation function that improves both model performance and faster convergence.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=1D3TjFidCS",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rishi_Chaitanya_Sri_Prasad_Nalluri1",
        "name": "Rishi Chaitanya Sri Prasad Nalluri",
        "name_site": null,
        "openreview_id": "~Rishi_Chaitanya_Sri_Prasad_Nalluri1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "rishichaitanya/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "SRM University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 1.6583123951777,
        "confidence_mean": 3.75,
        "confidence_std": 1.299038105676658,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "1D3TjFidCS",
      "title": "Logarithmic Linear Units (LogLUs): A Novel Activation Function for Improved Convergence in Deep Neural Networks",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The Logarithmic Linear Unit (LogLU) presents a novel activation function for deep neural networks by incorporating logarithmic elements into its design, introducing non-linearity that significantly enhances both training efficiency and accuracy. LogLU effectively addresses common limitations associated with widely used activation functions include ReLU, Leaky ReLU, and ELU, which suffer from issues like the dead neuron problem and vanishing gradients. By enabling neurons to remain active with negative inputs and ensuring effective gradient flow during backpropagation, LogLU promotes more efficient convergence in gradient descent. Its capability to solve fundamental yet complex non-linear tasks, such as the XOR problem, with fewer neurons demonstrates its efficiency in capturing non-linear patterns. Extensive evaluations on benchmark datasets like Caltech 101 and Imagenette, using the InceptionV3 architecture, reveal that LogLU not only accelerates convergence but also enhances model performance compared to existing activation functions. These findings underscore LogLU's potential as an effective activation function that improves both model performance and faster convergence.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=1D3TjFidCS",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Prabakaran_Ganeshan1",
        "name": "Prabakaran Ganeshan",
        "name_site": null,
        "openreview_id": "~Prabakaran_Ganeshan1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.pt/citations?hl=en",
        "orcid": "0000-0002-1754-4704",
        "linkedin_url": "https://www.linkedin.com/search/results/all/?fetchDeterministicClustersOnly=true&heroEntityKey=urn%3Ali%3Afsd_profile%3AACoAAAc0vjYBJmK8fX2o-dGgJs-YCzWuHwg5q-0&keywords=karthik%20rajendran&origin=RICH_QUERY_SUGGESTION&position=0&searchId=ca26032f-f8a5-4240-8dc7-b9cbe112ccd6&sid=Yl0&spellCorrectionEnabled=false",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "SRM University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 1.6583123951777,
        "confidence_mean": 3.75,
        "confidence_std": 1.299038105676658,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "1D3TjFidCS",
      "title": "Logarithmic Linear Units (LogLUs): A Novel Activation Function for Improved Convergence in Deep Neural Networks",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The Logarithmic Linear Unit (LogLU) presents a novel activation function for deep neural networks by incorporating logarithmic elements into its design, introducing non-linearity that significantly enhances both training efficiency and accuracy. LogLU effectively addresses common limitations associated with widely used activation functions include ReLU, Leaky ReLU, and ELU, which suffer from issues like the dead neuron problem and vanishing gradients. By enabling neurons to remain active with negative inputs and ensuring effective gradient flow during backpropagation, LogLU promotes more efficient convergence in gradient descent. Its capability to solve fundamental yet complex non-linear tasks, such as the XOR problem, with fewer neurons demonstrates its efficiency in capturing non-linear patterns. Extensive evaluations on benchmark datasets like Caltech 101 and Imagenette, using the InceptionV3 architecture, reveal that LogLU not only accelerates convergence but also enhances model performance compared to existing activation functions. These findings underscore LogLU's potential as an effective activation function that improves both model performance and faster convergence.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=1D3TjFidCS",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Karthik_Rajendran1",
        "name": "Karthik Rajendran",
        "name_site": null,
        "openreview_id": "~Karthik_Rajendran1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.pt/citations?hl=en",
        "orcid": "0000-0002-3638-4347",
        "linkedin_url": "dr-krajendran/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "SRM University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 1.6583123951777,
        "confidence_mean": 3.75,
        "confidence_std": 1.299038105676658,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "2D0uXQbntW",
      "title": "InfiniBench: A Comprehensive Benchmark for Large Multimodal Models in Very Long Video Understanding",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Understanding long videos, ranging from tens of minutes to several hours, presents unique challenges in video comprehension. Despite the increasing importance of long-form video content, existing benchmarks primarily focus on shorter clips. To address this gap, we introduce InfiniBench a comprehensive benchmark for very long video understanding which presents 1)very long video duration, averaging 52.59 minutes per video 2)The largest number of question-answer pairs, 108.2K 3) Diversity in questions that examine nine different skills and include both multiple-choice questions and open-ended questions 4) Memory questions, such as Global Appearance that require remembering and tracking the visual aspects through the video. Using InfiniBench, we comprehensively evaluate existing Large Multi-Modality Models (LMMs) on each skill, including the commercial models such as GPT-4o and Gemini 1.5 Flash and the recent open-source models. \nThe evaluation shows significant challenges in our benchmark.\nOur findings reveal that even leading AI models like GPT-4o and Gemini 1.5 Flash face challenges in achieving high performance in long video understanding, with average accuracies of just 56.01 % and 43.32 %, and average scores of 3.25 and 2.79 out of 5, respectively.\nQwen2-VL matches Gemini's performance in the MCQ skills but lags significantly in open-ended question tasks.\nWe hope this benchmark will stimulate the LMMs community towards long video and human-level understanding.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=2D0uXQbntW",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Khushbu_Pahwa1",
        "name": "Khushbu Pahwa",
        "name_site": null,
        "openreview_id": "~Khushbu_Pahwa1",
        "position": 4,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "299/8490",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": "khushbupahwa",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Amazon (Saudi Arabia)",
        "countries": [
          "Saudi Arabia"
        ],
        "country_codes": [
          "SA"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.8973665961010275,
        "confidence_mean": 4.4,
        "confidence_std": 0.48989794855663565,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "2L7KQ4qbHi",
      "title": "Concept forgetting via label annealing",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "The effectiveness of current machine learning models relies on their ability to grasp diverse concepts present in datasets. However, biased and noisy data can inadvertently cause these models to be biased toward certain concepts, undermining their ability to generalize and provide utility. Consequently, modifying a trained model to forget these concepts becomes imperative for their responsible deployment. We refer to this problem as *concept forgetting*. Our goal is to develop techniques for forgetting specific undesired concepts from a pre-trained classification model's prediction. To achieve this goal, we present an algorithm called **L**abel **AN**nealing (**LAN**). This iterative algorithm employs a two-stage method for each iteration. In the first stage, pseudo-labels are assigned to the samples by annealing or redistributing the original labels based on the current iteration's model predictions of all samples in the dataset. During the second stage, the model is fine-tuned on the dataset with pseudo-labels. We illustrate the effectiveness of the proposed algorithms across various models and datasets. Our method reduces *concept violation*, a metric that measures how much the model forgets specific concepts, by about 85.35\\% on the MNIST dataset, 73.25\\% on the CIFAR-10 dataset, and 69.46\\% on the CelebA dataset while maintaining high model accuracy. Our  implementation can be found at this following link: \\url{https://anonymous.4open.science/r/LAN-141B/}",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=2L7KQ4qbHi",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Subhodip_Panda2",
        "name": "Subhodip Panda",
        "name_site": null,
        "openreview_id": "~Subhodip_Panda2",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://subhodip123.github.io/",
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.co.in/citations?hl=en",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "2L7KQ4qbHi",
      "title": "Concept forgetting via label annealing",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "The effectiveness of current machine learning models relies on their ability to grasp diverse concepts present in datasets. However, biased and noisy data can inadvertently cause these models to be biased toward certain concepts, undermining their ability to generalize and provide utility. Consequently, modifying a trained model to forget these concepts becomes imperative for their responsible deployment. We refer to this problem as *concept forgetting*. Our goal is to develop techniques for forgetting specific undesired concepts from a pre-trained classification model's prediction. To achieve this goal, we present an algorithm called **L**abel **AN**nealing (**LAN**). This iterative algorithm employs a two-stage method for each iteration. In the first stage, pseudo-labels are assigned to the samples by annealing or redistributing the original labels based on the current iteration's model predictions of all samples in the dataset. During the second stage, the model is fine-tuned on the dataset with pseudo-labels. We illustrate the effectiveness of the proposed algorithms across various models and datasets. Our method reduces *concept violation*, a metric that measures how much the model forgets specific concepts, by about 85.35\\% on the MNIST dataset, 73.25\\% on the CIFAR-10 dataset, and 69.46\\% on the CelebA dataset while maintaining high model accuracy. Our  implementation can be found at this following link: \\url{https://anonymous.4open.science/r/LAN-141B/}",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=2L7KQ4qbHi",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Atri_Guha2",
        "name": "Atri Guha",
        "name_site": null,
        "openreview_id": "~Atri_Guha2",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "atri-guha-949100210/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "2L7KQ4qbHi",
      "title": "Concept forgetting via label annealing",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "The effectiveness of current machine learning models relies on their ability to grasp diverse concepts present in datasets. However, biased and noisy data can inadvertently cause these models to be biased toward certain concepts, undermining their ability to generalize and provide utility. Consequently, modifying a trained model to forget these concepts becomes imperative for their responsible deployment. We refer to this problem as *concept forgetting*. Our goal is to develop techniques for forgetting specific undesired concepts from a pre-trained classification model's prediction. To achieve this goal, we present an algorithm called **L**abel **AN**nealing (**LAN**). This iterative algorithm employs a two-stage method for each iteration. In the first stage, pseudo-labels are assigned to the samples by annealing or redistributing the original labels based on the current iteration's model predictions of all samples in the dataset. During the second stage, the model is fine-tuned on the dataset with pseudo-labels. We illustrate the effectiveness of the proposed algorithms across various models and datasets. Our method reduces *concept violation*, a metric that measures how much the model forgets specific concepts, by about 85.35\\% on the MNIST dataset, 73.25\\% on the CIFAR-10 dataset, and 69.46\\% on the CelebA dataset while maintaining high model accuracy. Our  implementation can be found at this following link: \\url{https://anonymous.4open.science/r/LAN-141B/}",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=2L7KQ4qbHi",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Prathosh_AP1",
        "name": "Prathosh AP",
        "name_site": null,
        "openreview_id": "~Prathosh_AP1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/prathosh",
        "dblp_id": "218/5887",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=OEwV4bsAAAAJ",
        "orcid": null,
        "linkedin_url": "prathosh-ap-phd-50ab9511/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "2d734s2WDb",
      "title": "VIBEID: A STRUCTURAL VIBRATION-BASED SOFT BIOMETRIC DATASET FOR HUMAN GAIT RECOGNITION",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We present VIBeID, a dataset and benchmark designed for advancing non-invasive human gait recognition using structural vibration. Structural vibrations, produced by the rhythmic impact of the toe and heel on the ground, are distinct and can be used as a privacy-preserving and non-cooperative soft-biometric modality. We curated the largest dataset VIBeID consists of footfall generated structural vibrations of 100 subjects. Existing datasets in this field typically include around ten subjects and lack comprehensive exploration of domain adaptation. To thoroughly explore the domain adaptation aspect of this biometric approach, we recorded vibration data on three distinct floor types (wooden, carpet, and cement) and at three distances from the geophone sensor (1.5 m, 2.5 m, and 4.0 m), involving 40\nand 30 subjects, respectively. Additionally, we benchmarked our dataset against video recordings from 15 individuals in an outdoor setting. Beyond providing 88 hours of raw vibration data, VIBeID establishes a comprehensive benchmark for a) person identification: where the aim is to recognize individuals through their unique structural vibrations, b) domain adaptation: assessing model performance across different walking surfaces and sensor positions, and c) multi-modal comparison: comparing vibration-based and vision-based identification methods. Our experiments, using both machine learning and deep learning approaches, establish a baseline for future research in this field, and introduce a large-scale dataset for the broader machine learning community.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=2d734s2WDb",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mainak_Chakraborty1",
        "name": "Mainak Chakraborty",
        "name_site": null,
        "openreview_id": "~Mainak_Chakraborty1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://mainakchakraborty.com/",
        "dblp_id": null,
        "google_scholar_url": "FzzgK7wAAAAJ",
        "orcid": null,
        "linkedin_url": "https://www.linkedin.com/feed/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.25,
        "confidence_std": 1.479019945774904,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "2d734s2WDb",
      "title": "VIBEID: A STRUCTURAL VIBRATION-BASED SOFT BIOMETRIC DATASET FOR HUMAN GAIT RECOGNITION",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We present VIBeID, a dataset and benchmark designed for advancing non-invasive human gait recognition using structural vibration. Structural vibrations, produced by the rhythmic impact of the toe and heel on the ground, are distinct and can be used as a privacy-preserving and non-cooperative soft-biometric modality. We curated the largest dataset VIBeID consists of footfall generated structural vibrations of 100 subjects. Existing datasets in this field typically include around ten subjects and lack comprehensive exploration of domain adaptation. To thoroughly explore the domain adaptation aspect of this biometric approach, we recorded vibration data on three distinct floor types (wooden, carpet, and cement) and at three distances from the geophone sensor (1.5 m, 2.5 m, and 4.0 m), involving 40\nand 30 subjects, respectively. Additionally, we benchmarked our dataset against video recordings from 15 individuals in an outdoor setting. Beyond providing 88 hours of raw vibration data, VIBeID establishes a comprehensive benchmark for a) person identification: where the aim is to recognize individuals through their unique structural vibrations, b) domain adaptation: assessing model performance across different walking surfaces and sensor positions, and c) multi-modal comparison: comparing vibration-based and vision-based identification methods. Our experiments, using both machine learning and deep learning approaches, establish a baseline for future research in this field, and introduce a large-scale dataset for the broader machine learning community.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=2d734s2WDb",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Chandan1",
        "name": "Chandan",
        "name_site": null,
        "openreview_id": "~Chandan1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://web.iitd.ac.in/~eez218527/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0009-0002-7503-0602",
        "linkedin_url": "chandan-kumar-516665150/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.25,
        "confidence_std": 1.479019945774904,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "2d734s2WDb",
      "title": "VIBEID: A STRUCTURAL VIBRATION-BASED SOFT BIOMETRIC DATASET FOR HUMAN GAIT RECOGNITION",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We present VIBeID, a dataset and benchmark designed for advancing non-invasive human gait recognition using structural vibration. Structural vibrations, produced by the rhythmic impact of the toe and heel on the ground, are distinct and can be used as a privacy-preserving and non-cooperative soft-biometric modality. We curated the largest dataset VIBeID consists of footfall generated structural vibrations of 100 subjects. Existing datasets in this field typically include around ten subjects and lack comprehensive exploration of domain adaptation. To thoroughly explore the domain adaptation aspect of this biometric approach, we recorded vibration data on three distinct floor types (wooden, carpet, and cement) and at three distances from the geophone sensor (1.5 m, 2.5 m, and 4.0 m), involving 40\nand 30 subjects, respectively. Additionally, we benchmarked our dataset against video recordings from 15 individuals in an outdoor setting. Beyond providing 88 hours of raw vibration data, VIBeID establishes a comprehensive benchmark for a) person identification: where the aim is to recognize individuals through their unique structural vibrations, b) domain adaptation: assessing model performance across different walking surfaces and sensor positions, and c) multi-modal comparison: comparing vibration-based and vision-based identification methods. Our experiments, using both machine learning and deep learning approaches, establish a baseline for future research in this field, and introduce a large-scale dataset for the broader machine learning community.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=2d734s2WDb",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sahil_Anchal1",
        "name": "Sahil Anchal",
        "name_site": null,
        "openreview_id": "~Sahil_Anchal1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/sahilanchal/home",
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.co.in/citations?user=ARNuGNIAAAAJ",
        "orcid": null,
        "linkedin_url": "sahilanchal/?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Roorkee (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.25,
        "confidence_std": 1.479019945774904,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "2gTEW29qsM",
      "title": "Masked Generative Priors Improve World Models Sequence Modelling Capabilities",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Deep Reinforcement Learning (RL) has become the leading approach for creating artificial agents in complex environments. Model-based approaches, which are RL methods with world models that predict environment dynamics, are among the most promising directions for improving data efficiency, forming a critical step toward bridging the gap between research and real-world deployment. In particular, world models enhance sample efficiency by learning in imagination, which involves training a generative sequence model of the environment in a self-supervised manner.\nRecently, Masked Generative Modelling has emerged as a more efficient and superior inductive bias for modelling and generating token sequences. Building on the Efficient Stochastic Transformer-based World Models (STORM) architecture, we replace the traditional MLP prior with a Masked Generative Prior (e.g., MaskGIT Prior) and introduce GIT-STORM.\nWe evaluate our model on two downstream tasks: reinforcement learning and video prediction. GIT-STORM demonstrates substantial performance gains in RL tasks on the Atari 100k benchmark.\nMoreover, we apply Transformer-based World Models to continuous action environments for the first time, addressing a significant gap in prior research. To achieve this, we employ a state mixer function that integrates latent state representations with actions, enabling our model to handle continuous control tasks. We validate this approach through qualitative and quantitative analyses on the DeepMind Control Suite, showcasing the effectiveness of Transformer-based World Models in this new domain.\nOur results highlight the versatility and efficacy of the MaskGIT dynamics prior, paving the way for more accurate world models and effective RL policies.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=2gTEW29qsM",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aniket_Rajiv_Didolkar1",
        "name": "Aniket Rajiv Didolkar",
        "name_site": null,
        "openreview_id": "~Aniket_Rajiv_Didolkar1",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://github.com/dido1998/",
        "dblp_id": "245/8589",
        "google_scholar_url": "https://scholar.google.ca/citations?user=ekvl5o0AAAAJ",
        "orcid": null,
        "linkedin_url": "aniket-didolkar-7a9b8912a",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Manipal Institute of Technology (Canada)",
        "countries": [
          "Canada"
        ],
        "country_codes": [
          "CA"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.5,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "2gTEW29qsM",
      "title": "Masked Generative Priors Improve World Models Sequence Modelling Capabilities",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Deep Reinforcement Learning (RL) has become the leading approach for creating artificial agents in complex environments. Model-based approaches, which are RL methods with world models that predict environment dynamics, are among the most promising directions for improving data efficiency, forming a critical step toward bridging the gap between research and real-world deployment. In particular, world models enhance sample efficiency by learning in imagination, which involves training a generative sequence model of the environment in a self-supervised manner.\nRecently, Masked Generative Modelling has emerged as a more efficient and superior inductive bias for modelling and generating token sequences. Building on the Efficient Stochastic Transformer-based World Models (STORM) architecture, we replace the traditional MLP prior with a Masked Generative Prior (e.g., MaskGIT Prior) and introduce GIT-STORM.\nWe evaluate our model on two downstream tasks: reinforcement learning and video prediction. GIT-STORM demonstrates substantial performance gains in RL tasks on the Atari 100k benchmark.\nMoreover, we apply Transformer-based World Models to continuous action environments for the first time, addressing a significant gap in prior research. To achieve this, we employ a state mixer function that integrates latent state representations with actions, enabling our model to handle continuous control tasks. We validate this approach through qualitative and quantitative analyses on the DeepMind Control Suite, showcasing the effectiveness of Transformer-based World Models in this new domain.\nOur results highlight the versatility and efficacy of the MaskGIT dynamics prior, paving the way for more accurate world models and effective RL policies.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=2gTEW29qsM",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Di_He1_1",
        "name": "Di He",
        "name_site": null,
        "openreview_id": "~Anirudh_Goyal1",
        "position": 7,
        "gender": "M",
        "homepage_url": "https://anirudh9119.github.io/",
        "dblp_id": "172/1039",
        "google_scholar_url": "krrh6OUAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.5,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "3xjc9PhEPd",
      "title": "Empirical Guidelines for Deploying LLMs onto Resource-constrained Edge Devices",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "The scaling laws have become the de facto guidelines for designing large language models (LLMs), but they were studied under the assumption of unlimited computing resources for both training and inference. As LLMs are increasingly used as personalized intelligent assistants, their customization (i.e., learning through fine-tuning) and deployment onto resource-constrained edge devices will become more and more prevalent. An urgent but open question is how a resource-constrained computing environment would affect the design choices for a personalized LLM. We study this problem empirically in this work. In particular, we consider the tradeoffs among a number of key design factors and their intertwined impacts on learning efficiency and accuracy. The factors include the learning methods for LLM customization, the amount of personalized data used for learning customization, the types and sizes of LLMs, the compression methods of LLMs, the amount of time afforded to learn, and the difficulty levels of the target use cases. Through extensive experimentation and benchmarking, we draw a number of surprisingly insightful guidelines for deploying LLMs onto resource-constrained devices. For example, an optimal choice between parameter learning and RAG may vary depending on the difficulty of the downstream task, the longer fine-tuning time does not necessarily help the model, and a compressed LLM may be a better choice than an uncompressed LLM to learn from limited personalized data.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=3xjc9PhEPd",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 12,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ruiyang_Qin1",
        "name": "Ruiyang Qin",
        "name_site": null,
        "openreview_id": "~Ruiyang_Qin1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://ruiyangqin2016.github.io/",
        "dblp_id": "280/1019",
        "google_scholar_url": "https://scholar.google.ca/citations?user=c26FtWIAAAAJ",
        "orcid": "0000-0003-0827-2257",
        "linkedin_url": "ruiyang-qin-gatech/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Notre Dame (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 16,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "44IKUSdbUD",
      "title": "Weighted Diversified Sampling for Efficient Data-Driven Single-Cell Gene-Gene Interaction Discovery",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Gene-gene interactions play a crucial role in the manifestation of complex human diseases. Uncovering significant gene-gene interactions is a challenging task. Here, we present an innovative approach utilizing data-driven computational tools, leveraging an advanced Transformer model, to unearth noteworthy gene-gene interactions. Despite the efficacy of Transformer models, their parameter intensity presents a bottleneck in data ingestion, hindering data efficiency.  To mitigate this, we introduce a novel weighted diversified sampling algorithm. This algorithm computes the diversity score of each data sample in just two passes of the dataset, facilitating efficient subset generation for interaction discovery. Our extensive experimentation demonstrates that by sampling a mere 1% of the single-cell dataset, we achieve performance comparable to that of utilizing the entire dataset.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=44IKUSdbUD",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Khushbu_Pahwa1",
        "name": "Khushbu Pahwa",
        "name_site": null,
        "openreview_id": "~Khushbu_Pahwa1",
        "position": 5,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "299/8490",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": "khushbupahwa",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Texas Health Science Center (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.632993161855452,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.9428090415820634,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "49ti6LOUw5",
      "title": "UnoLoRA: Single Low-Rank Adaptation for Efficient Multitask Fine-tuning",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Recent advances in Parameter-Efficient Fine-Tuning (PEFT) have shown Low- Rank Adaptation (LoRA) to be an effective implicit regularizer for large language models. Building on these findings, we propose UnoLoRA, a novel approach that leverages a single shared LoRA module for efficient multi-task learning. While existing methods typically use separate LoRA adaptations for each task, our approach demonstrates that a single shared adapter can effectively capture both task-specific and task-agnostic knowledge. We further introduce UnoLoRA*, an enhanced variant that employs a shared hypernetwork to generate task-specific embeddings, improving convergence and task adaptation. Our method significantly reduces trainable parameters to just 0.05% per task while maintaining competitive performance on the GLUE benchmark. Our analysis reveals that the A and B matrices in our shared LoRA adapter naturally develop complementary roles: A matrices capture generalizable features across tasks, while B matrices specialize in task-specific representations. Our results show that sharing a single LoRA adapter can achieve efficient multi-task learning while significantly reducing memory requirements, making it particularly valuable for resource-constrained applications.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=49ti6LOUw5",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anirudh_Lakhotia1",
        "name": "Anirudh Lakhotia",
        "name_site": null,
        "openreview_id": "~Anirudh_Lakhotia1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "anirudhlakhotia",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "PES University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "49ti6LOUw5",
      "title": "UnoLoRA: Single Low-Rank Adaptation for Efficient Multitask Fine-tuning",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Recent advances in Parameter-Efficient Fine-Tuning (PEFT) have shown Low- Rank Adaptation (LoRA) to be an effective implicit regularizer for large language models. Building on these findings, we propose UnoLoRA, a novel approach that leverages a single shared LoRA module for efficient multi-task learning. While existing methods typically use separate LoRA adaptations for each task, our approach demonstrates that a single shared adapter can effectively capture both task-specific and task-agnostic knowledge. We further introduce UnoLoRA*, an enhanced variant that employs a shared hypernetwork to generate task-specific embeddings, improving convergence and task adaptation. Our method significantly reduces trainable parameters to just 0.05% per task while maintaining competitive performance on the GLUE benchmark. Our analysis reveals that the A and B matrices in our shared LoRA adapter naturally develop complementary roles: A matrices capture generalizable features across tasks, while B matrices specialize in task-specific representations. Our results show that sharing a single LoRA adapter can achieve efficient multi-task learning while significantly reducing memory requirements, making it particularly valuable for resource-constrained applications.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=49ti6LOUw5",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Akash_Kamalesh1",
        "name": "Akash Kamalesh",
        "name_site": null,
        "openreview_id": "~Akash_Kamalesh1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "akash-kamalesh/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "PES University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "49ti6LOUw5",
      "title": "UnoLoRA: Single Low-Rank Adaptation for Efficient Multitask Fine-tuning",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Recent advances in Parameter-Efficient Fine-Tuning (PEFT) have shown Low- Rank Adaptation (LoRA) to be an effective implicit regularizer for large language models. Building on these findings, we propose UnoLoRA, a novel approach that leverages a single shared LoRA module for efficient multi-task learning. While existing methods typically use separate LoRA adaptations for each task, our approach demonstrates that a single shared adapter can effectively capture both task-specific and task-agnostic knowledge. We further introduce UnoLoRA*, an enhanced variant that employs a shared hypernetwork to generate task-specific embeddings, improving convergence and task adaptation. Our method significantly reduces trainable parameters to just 0.05% per task while maintaining competitive performance on the GLUE benchmark. Our analysis reveals that the A and B matrices in our shared LoRA adapter naturally develop complementary roles: A matrices capture generalizable features across tasks, while B matrices specialize in task-specific representations. Our results show that sharing a single LoRA adapter can achieve efficient multi-task learning while significantly reducing memory requirements, making it particularly valuable for resource-constrained applications.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=49ti6LOUw5",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Prerana_Sanjay_Kulkarni1",
        "name": "Prerana Sanjay Kulkarni",
        "name_site": null,
        "openreview_id": "~Prerana_Sanjay_Kulkarni1",
        "position": 3,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "preranakulkarni5/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "PES University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "49ti6LOUw5",
      "title": "UnoLoRA: Single Low-Rank Adaptation for Efficient Multitask Fine-tuning",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Recent advances in Parameter-Efficient Fine-Tuning (PEFT) have shown Low- Rank Adaptation (LoRA) to be an effective implicit regularizer for large language models. Building on these findings, we propose UnoLoRA, a novel approach that leverages a single shared LoRA module for efficient multi-task learning. While existing methods typically use separate LoRA adaptations for each task, our approach demonstrates that a single shared adapter can effectively capture both task-specific and task-agnostic knowledge. We further introduce UnoLoRA*, an enhanced variant that employs a shared hypernetwork to generate task-specific embeddings, improving convergence and task adaptation. Our method significantly reduces trainable parameters to just 0.05% per task while maintaining competitive performance on the GLUE benchmark. Our analysis reveals that the A and B matrices in our shared LoRA adapter naturally develop complementary roles: A matrices capture generalizable features across tasks, while B matrices specialize in task-specific representations. Our results show that sharing a single LoRA adapter can achieve efficient multi-task learning while significantly reducing memory requirements, making it particularly valuable for resource-constrained applications.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=49ti6LOUw5",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Nischal_H_S1",
        "name": "Nischal H S",
        "name_site": null,
        "openreview_id": "~Nischal_H_S1",
        "position": 4,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "nischal-h-s/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "PES University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "49ti6LOUw5",
      "title": "UnoLoRA: Single Low-Rank Adaptation for Efficient Multitask Fine-tuning",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Recent advances in Parameter-Efficient Fine-Tuning (PEFT) have shown Low- Rank Adaptation (LoRA) to be an effective implicit regularizer for large language models. Building on these findings, we propose UnoLoRA, a novel approach that leverages a single shared LoRA module for efficient multi-task learning. While existing methods typically use separate LoRA adaptations for each task, our approach demonstrates that a single shared adapter can effectively capture both task-specific and task-agnostic knowledge. We further introduce UnoLoRA*, an enhanced variant that employs a shared hypernetwork to generate task-specific embeddings, improving convergence and task adaptation. Our method significantly reduces trainable parameters to just 0.05% per task while maintaining competitive performance on the GLUE benchmark. Our analysis reveals that the A and B matrices in our shared LoRA adapter naturally develop complementary roles: A matrices capture generalizable features across tasks, while B matrices specialize in task-specific representations. Our results show that sharing a single LoRA adapter can achieve efficient multi-task learning while significantly reducing memory requirements, making it particularly valuable for resource-constrained applications.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=49ti6LOUw5",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Gowri_Srinivasa1",
        "name": "Gowri Srinivasa",
        "name_site": null,
        "openreview_id": "~Gowri_Srinivasa1",
        "position": 5,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "77/1585",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=xmJ1KmsAAAAJ",
        "orcid": "0000-0002-3568-6749",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "PES University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "4F1a8nNFGK",
      "title": "Context is Key: A Benchmark for Forecasting with Essential Textual Information",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Forecasting is a critical task in decision making across various domains. While numerical data provides a foundation, it often lacks crucial context necessary for accurate predictions. Human forecasters frequently rely on additional information, such as background knowledge or constraints, which can be efficiently communicated through natural language. However, the ability of existing forecasting models to effectively integrate this textual information remains an open question. To address this, we introduce \"Context is Key\" (CiK), a time series forecasting benchmark that pairs numerical data with diverse types of carefully crafted textual context, requiring models to integrate both modalities. We evaluate a range of approaches, including statistical models, time series foundation models and LLM-based forecasters, and propose a simple yet effective LLM prompting method that outperforms all other tested methods on our benchmark. Our experiments highlight the importance of incorporating contextual information, demonstrate surprising performance when using LLM-based forecasting models, and also reveal some of their critical shortcomings. By presenting this benchmark, we aim to advance multimodal forecasting, promoting models that are both accurate and accessible to decision-makers with varied technical expertise. The benchmark can be visualized at https://anon-forecast.github.io/benchmark_report_dev/.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=4F1a8nNFGK",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 11,
      "track_name": "Main Conference",
      "author": {
        "id": "~Nebojsa_Bozanic1",
        "name": "Nebojsa Bozanic",
        "name_site": null,
        "openreview_id": "~Arjun_Ashok1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://ashok-arjun.github.io/",
        "dblp_id": "https://dblp.uni-trier.de/pid/318/2945",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "ServiceNow (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 3.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 8,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "4F1a8nNFGK",
      "title": "Context is Key: A Benchmark for Forecasting with Essential Textual Information",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Forecasting is a critical task in decision making across various domains. While numerical data provides a foundation, it often lacks crucial context necessary for accurate predictions. Human forecasters frequently rely on additional information, such as background knowledge or constraints, which can be efficiently communicated through natural language. However, the ability of existing forecasting models to effectively integrate this textual information remains an open question. To address this, we introduce \"Context is Key\" (CiK), a time series forecasting benchmark that pairs numerical data with diverse types of carefully crafted textual context, requiring models to integrate both modalities. We evaluate a range of approaches, including statistical models, time series foundation models and LLM-based forecasters, and propose a simple yet effective LLM prompting method that outperforms all other tested methods on our benchmark. Our experiments highlight the importance of incorporating contextual information, demonstrate surprising performance when using LLM-based forecasting models, and also reveal some of their critical shortcomings. By presenting this benchmark, we aim to advance multimodal forecasting, promoting models that are both accurate and accessible to decision-makers with varied technical expertise. The benchmark can be visualized at https://anon-forecast.github.io/benchmark_report_dev/.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=4F1a8nNFGK",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 11,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jithendaraa_Subramanian1",
        "name": "Jithendaraa Subramanian",
        "name_site": null,
        "openreview_id": "~Jithendaraa_Subramanian1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://jithendaraa.github.io/",
        "dblp_id": "281/6755",
        "google_scholar_url": "s0BzYvYAAAAJ",
        "orcid": null,
        "linkedin_url": "jithendaraa-subramanian-85a22b176/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Toyota Research Institute (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 3.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 8,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "52XG8eexal",
      "title": "State-space models can learn in-context by gradient descent",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Deep state-space models (Deep SSMs) have shown capabilities for in-context learning on autoregressive tasks, similar to transformers. \nHowever, the architectural requirements and mechanisms enabling this in recurrent networks remain unclear. \nThis study demonstrates that state-space model architectures can perform gradient-based learning and use it for in-context learning.\nWe prove that a single structured state-space model layer, augmented with local self-attention, can reproduce the outputs of an implicit linear model with least squares loss after one step of gradient descent.\nOur key insight is that the diagonal linear recurrent layer can act as a gradient accumulator, which can be `applied' to the parameters of the implicit regression model.\nWe validate our construction by training randomly initialized augmented SSMs on simple linear regression tasks. The empirically optimized parameters match the theoretical ones, obtained analytically from the implicit model construction. \nExtensions to multi-step linear and non-linear regression yield consistent results.\nThe constructed SSM encompasses features of modern deep state-space models, with the potential for scalable training and effectiveness even in general tasks. \nThe theoretical construction elucidates the role of local self-attention and multiplicative interactions in recurrent architectures as the key ingredients for enabling the expressive power typical of foundation models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=52XG8eexal",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Harshvardhan_Mestha1",
        "name": "Harshvardhan Mestha",
        "name_site": null,
        "openreview_id": "~Harshvardhan_Mestha1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://harshvardhan-mestha.github.io/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "harshvardhan-mestha-14b0481bb/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.0,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5kMwiMnUip",
      "title": "NEMESIS \\\\ Jailbreaking LLMs with Chain of Thoughts Approach",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Large Language Models (LLMs) are increasingly being deployed across various\napplications, making the need for robust security measures crucial. This paper\nexplores multiple methods for jailbreaking these models, bypassing their secu-\nrity protocols. By examining five distinct approaches—Multishot Jailbreaking,\nthe Mirror Dimension Approach, the Cipher Method, the ”You are Answering the\nWrong Question” Method, and the Textbook Jailbreaking Method—we highlight\nthe vulnerabilities in current LLMs and emphasize the importance of fine-tuning\nand secure guardrails. Our study primarily employs chain-of-thought reasoning,\nwhich can be further enhanced through reinforcement learning techniques. Fur-\nthermore, we propose that our findings can serve as a benchmark against emerging\nsecurity measures such as LlamaGuard, providing a comprehensive evaluation of\nLLM defenses. Our findings demonstrate the effectiveness of these methods and\nsuggest directions for future work in enhancing LLM security. This research un-\nderscores the ongoing challenges in balancing LLM capabilities with robust safe-\nguards against potential misuse or manipulation.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=5kMwiMnUip",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vedanta_S_P1",
        "name": "Vedanta S P",
        "name_site": null,
        "openreview_id": "~Vedanta_S_P1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://vedantasp.framer.website",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Information Technology Kottayam (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 1.4,
        "rating_std": 0.8,
        "confidence_mean": 4.4,
        "confidence_std": 0.8,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5kMwiMnUip",
      "title": "NEMESIS \\\\ Jailbreaking LLMs with Chain of Thoughts Approach",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Large Language Models (LLMs) are increasingly being deployed across various\napplications, making the need for robust security measures crucial. This paper\nexplores multiple methods for jailbreaking these models, bypassing their secu-\nrity protocols. By examining five distinct approaches—Multishot Jailbreaking,\nthe Mirror Dimension Approach, the Cipher Method, the ”You are Answering the\nWrong Question” Method, and the Textbook Jailbreaking Method—we highlight\nthe vulnerabilities in current LLMs and emphasize the importance of fine-tuning\nand secure guardrails. Our study primarily employs chain-of-thought reasoning,\nwhich can be further enhanced through reinforcement learning techniques. Fur-\nthermore, we propose that our findings can serve as a benchmark against emerging\nsecurity measures such as LlamaGuard, providing a comprehensive evaluation of\nLLM defenses. Our findings demonstrate the effectiveness of these methods and\nsuggest directions for future work in enhancing LLM security. This research un-\nderscores the ongoing challenges in balancing LLM capabilities with robust safe-\nguards against potential misuse or manipulation.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=5kMwiMnUip",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ashiq_Firoz1",
        "name": "Ashiq Firoz",
        "name_site": null,
        "openreview_id": "~Ashiq_Firoz1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://ashiqisme.netlify.app/",
        "dblp_id": null,
        "google_scholar_url": "FmRgLIwAAAAJ",
        "orcid": null,
        "linkedin_url": "ashiq-firoz-30335a203/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Information Technology Kottayam (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 1.4,
        "rating_std": 0.8,
        "confidence_mean": 4.4,
        "confidence_std": 0.8,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5kMwiMnUip",
      "title": "NEMESIS \\\\ Jailbreaking LLMs with Chain of Thoughts Approach",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Large Language Models (LLMs) are increasingly being deployed across various\napplications, making the need for robust security measures crucial. This paper\nexplores multiple methods for jailbreaking these models, bypassing their secu-\nrity protocols. By examining five distinct approaches—Multishot Jailbreaking,\nthe Mirror Dimension Approach, the Cipher Method, the ”You are Answering the\nWrong Question” Method, and the Textbook Jailbreaking Method—we highlight\nthe vulnerabilities in current LLMs and emphasize the importance of fine-tuning\nand secure guardrails. Our study primarily employs chain-of-thought reasoning,\nwhich can be further enhanced through reinforcement learning techniques. Fur-\nthermore, we propose that our findings can serve as a benchmark against emerging\nsecurity measures such as LlamaGuard, providing a comprehensive evaluation of\nLLM defenses. Our findings demonstrate the effectiveness of these methods and\nsuggest directions for future work in enhancing LLM security. This research un-\nderscores the ongoing challenges in balancing LLM capabilities with robust safe-\nguards against potential misuse or manipulation.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=5kMwiMnUip",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sriharsha_Bodicherla1",
        "name": "Sriharsha Bodicherla",
        "name_site": null,
        "openreview_id": "~Sriharsha_Bodicherla1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "yjkJCgYAAAAJ",
        "orcid": null,
        "linkedin_url": "sriharsha-bodicherla",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Information Technology Kottayam (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 1.4,
        "rating_std": 0.8,
        "confidence_mean": 4.4,
        "confidence_std": 0.8,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5kMwiMnUip",
      "title": "NEMESIS \\\\ Jailbreaking LLMs with Chain of Thoughts Approach",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Large Language Models (LLMs) are increasingly being deployed across various\napplications, making the need for robust security measures crucial. This paper\nexplores multiple methods for jailbreaking these models, bypassing their secu-\nrity protocols. By examining five distinct approaches—Multishot Jailbreaking,\nthe Mirror Dimension Approach, the Cipher Method, the ”You are Answering the\nWrong Question” Method, and the Textbook Jailbreaking Method—we highlight\nthe vulnerabilities in current LLMs and emphasize the importance of fine-tuning\nand secure guardrails. Our study primarily employs chain-of-thought reasoning,\nwhich can be further enhanced through reinforcement learning techniques. Fur-\nthermore, we propose that our findings can serve as a benchmark against emerging\nsecurity measures such as LlamaGuard, providing a comprehensive evaluation of\nLLM defenses. Our findings demonstrate the effectiveness of these methods and\nsuggest directions for future work in enhancing LLM security. This research un-\nderscores the ongoing challenges in balancing LLM capabilities with robust safe-\nguards against potential misuse or manipulation.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=5kMwiMnUip",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Emmanuel_George_P1",
        "name": "Emmanuel George P",
        "name_site": null,
        "openreview_id": "~Emmanuel_George_P1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "emmanuel-george-p-a88a352a6/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Information Technology Kottayam (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 1.4,
        "rating_std": 0.8,
        "confidence_mean": 4.4,
        "confidence_std": 0.8,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5kMwiMnUip",
      "title": "NEMESIS \\\\ Jailbreaking LLMs with Chain of Thoughts Approach",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Large Language Models (LLMs) are increasingly being deployed across various\napplications, making the need for robust security measures crucial. This paper\nexplores multiple methods for jailbreaking these models, bypassing their secu-\nrity protocols. By examining five distinct approaches—Multishot Jailbreaking,\nthe Mirror Dimension Approach, the Cipher Method, the ”You are Answering the\nWrong Question” Method, and the Textbook Jailbreaking Method—we highlight\nthe vulnerabilities in current LLMs and emphasize the importance of fine-tuning\nand secure guardrails. Our study primarily employs chain-of-thought reasoning,\nwhich can be further enhanced through reinforcement learning techniques. Fur-\nthermore, we propose that our findings can serve as a benchmark against emerging\nsecurity measures such as LlamaGuard, providing a comprehensive evaluation of\nLLM defenses. Our findings demonstrate the effectiveness of these methods and\nsuggest directions for future work in enhancing LLM security. This research un-\nderscores the ongoing challenges in balancing LLM capabilities with robust safe-\nguards against potential misuse or manipulation.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=5kMwiMnUip",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Madhav_Rao1",
        "name": "Madhav Rao",
        "name_site": null,
        "openreview_id": "~Madhav_Rao1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://www.iiitb.ac.in/faculty/madhav-rao",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology, Bangalore (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 1.4,
        "rating_std": 0.8,
        "confidence_mean": 4.4,
        "confidence_std": 0.8,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5pFV1FxG9d",
      "title": "Improving Discrete Optimisation Via Decoupled Straight-Through Gumbel-Softmax",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Discrete representations play a crucial role in many deep learning architectures, yet their non-differentiable nature poses significant challenges for gradient-based optimization. To address this issue, various gradient estimators have been developed, including the Straight-Through Gumbel-Softmax (ST-GS) estimator, which combines the Straight-Through Estimator (STE) and the Gumbel-based reparameterization trick. However, the performance of ST-GS is highly sensitive to temperature, with its selection often compromising gradient fidelity. In this work, we propose a simple yet effective extension to ST-GS by employing decoupled temperatures for forward and backward passes, which we refer to as \"Decoupled ST-GS\". We show that our approach significantly enhances the original ST-GS through extensive experiments across multiple tasks and datasets. We further investigate the impact of our method on gradient fidelity from multiple perspectives, including the gradient gap and the bias-variance trade-off of estimated gradients. Our findings contribute to the ongoing effort to improve discrete optimization in deep learning, offering a practical solution that balances simplicity and effectiveness.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=5pFV1FxG9d",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rushi_Shah1",
        "name": "Rushi Shah",
        "name_site": null,
        "openreview_id": "~Rushi_Shah1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://shahrushi2003.github.io/about.html",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Jodhpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5sRnsubyAK",
      "title": "Neuroacoustic Patterns: Constant Q Cepstral Coefficients for the Classification of Neurodegenerative Disorders",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Early identification of neurodegenerative diseases is crucial for effective diagnosis in neurological disorders. However, the quasi-periodic nature of vocal tract sampling often results in inadequate spectral resolution in traditional spectral features, such as Mel Frequency Cepstral Coefficients (MFCC), thereby limiting their classification effectiveness. In this study, we propose the use of Constant Q Cepstral Coefficients (CQCC), which leverage geometrically spaced frequency bins to provide superior spectrotemporal resolution, particularly for capturing the fundamental frequency and its harmonics in speech signals associated with neurodegenerative disorders. Our results demonstrate that CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively. Furthermore, CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy. The effectiveness of CQCC is underpinned by the form-invariance property of the Constant Q Transform (CQT), which ensures consistent feature representation across varying pitch and tonal conditions, thereby enhancing classification robustness. Furthermore, the robustness of CQCC features against MFCC features are validated using LDA plots. These findings are validated using the Italian Parkinson’s database and the Minsk2019 database of Amyotrophic Lateral Sclerosis, underscoring the potential of CQCC to advance the classification of neurodegenerative disorders.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=5sRnsubyAK",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aastha_Kachhi1",
        "name": "Aastha Kachhi",
        "name_site": null,
        "openreview_id": "~Aastha_Kachhi1",
        "position": 1,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "7gpri-gAAAAJ",
        "orcid": null,
        "linkedin_url": "aastha-kachhi-08064b218/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Mandi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.75,
        "rating_std": 1.920286436967152,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5sRnsubyAK",
      "title": "Neuroacoustic Patterns: Constant Q Cepstral Coefficients for the Classification of Neurodegenerative Disorders",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Early identification of neurodegenerative diseases is crucial for effective diagnosis in neurological disorders. However, the quasi-periodic nature of vocal tract sampling often results in inadequate spectral resolution in traditional spectral features, such as Mel Frequency Cepstral Coefficients (MFCC), thereby limiting their classification effectiveness. In this study, we propose the use of Constant Q Cepstral Coefficients (CQCC), which leverage geometrically spaced frequency bins to provide superior spectrotemporal resolution, particularly for capturing the fundamental frequency and its harmonics in speech signals associated with neurodegenerative disorders. Our results demonstrate that CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively. Furthermore, CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy. The effectiveness of CQCC is underpinned by the form-invariance property of the Constant Q Transform (CQT), which ensures consistent feature representation across varying pitch and tonal conditions, thereby enhancing classification robustness. Furthermore, the robustness of CQCC features against MFCC features are validated using LDA plots. These findings are validated using the Italian Parkinson’s database and the Minsk2019 database of Amyotrophic Lateral Sclerosis, underscoring the potential of CQCC to advance the classification of neurodegenerative disorders.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=5sRnsubyAK",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Shashank_Ojha1",
        "name": "Shashank Ojha",
        "name_site": null,
        "openreview_id": "~Shashank_Ojha1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "shashank-ojha-a46172224/?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Mandi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.75,
        "rating_std": 1.920286436967152,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5sRnsubyAK",
      "title": "Neuroacoustic Patterns: Constant Q Cepstral Coefficients for the Classification of Neurodegenerative Disorders",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Early identification of neurodegenerative diseases is crucial for effective diagnosis in neurological disorders. However, the quasi-periodic nature of vocal tract sampling often results in inadequate spectral resolution in traditional spectral features, such as Mel Frequency Cepstral Coefficients (MFCC), thereby limiting their classification effectiveness. In this study, we propose the use of Constant Q Cepstral Coefficients (CQCC), which leverage geometrically spaced frequency bins to provide superior spectrotemporal resolution, particularly for capturing the fundamental frequency and its harmonics in speech signals associated with neurodegenerative disorders. Our results demonstrate that CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively. Furthermore, CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy. The effectiveness of CQCC is underpinned by the form-invariance property of the Constant Q Transform (CQT), which ensures consistent feature representation across varying pitch and tonal conditions, thereby enhancing classification robustness. Furthermore, the robustness of CQCC features against MFCC features are validated using LDA plots. These findings are validated using the Italian Parkinson’s database and the Minsk2019 database of Amyotrophic Lateral Sclerosis, underscoring the potential of CQCC to advance the classification of neurodegenerative disorders.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=5sRnsubyAK",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anurag_Pandey1",
        "name": "Anurag Pandey",
        "name_site": null,
        "openreview_id": "~Anurag_Pandey1",
        "position": 5,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.co.in/citations?user=WtlVdaYAAAAJ",
        "orcid": null,
        "linkedin_url": "https://in.linkedin.com/in/anurag-pandey-5244b885?",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.75,
        "rating_std": 1.920286436967152,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "6R4TGPd74N",
      "title": "Ladder Residual: Redefining Tensor Parallelism in Transformers for Accelerated Inference",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Large language model inference is both memory-intensive and time-consuming, often requiring distributed algorithms to efficiently scale. Tensor parallelism (TP) is a common technique used in multi-gpu training and inference to partition computation across multiple devices, reducing memory load and computation time. However, such parallelism necessitates fast interconnects between the devices which has been a major bottleneck and limits the gains obtained by scaling up the number of devices. We introduce Ladder Residual, a simple architectural modification applicable to all residual-based models that enable straightforward overlapping that effectively hides the latency of communication. Our insight is that in addition to systems optimization, one can also redesign the model architecture to decouple communication from computation. For a Transformer model of 8B size, applying Ladder Residual to all its layers achieves 29\\% end-to-end wall clock speed up at inference time with TP world size of 8 devices. We refer to such model as the Ladder Transformer.\nWe train a 1B and 3B Ladder Transformer from scratch and observe comparable performance to a standard dense transformer baseline. We also conduct adaptation experiments for our approach and show that it's possible to adapt parts of the Llama-3.1 8B model with minimal accuracy degradation by only retraining for 3B tokens. To further push the performance frontier, we propose another architectural modification which drops communications in the model, unlocking fast LLM inference in settings devoid of NVLink or other fast interconnects.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=6R4TGPd74N",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 10,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yoon_Kim1",
        "name": "Yoon Kim",
        "name_site": null,
        "openreview_id": "~Yoon_Kim1",
        "position": 6,
        "gender": null,
        "homepage_url": "https://people.csail.mit.edu/yoonkim/",
        "dblp_id": null,
        "google_scholar_url": "n_ts4eYAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Massachusetts Institute of Technology (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 3.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "6VuTXirQIv",
      "title": "Feature Driven Graph Coarsening for Scaling Graph Representation Learning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graphical modelling for structured data analysis has gained prominence across numerous domains. A significant computational challenge lies in efficiently capturing complex relationships within large-scale graph structures. Graph coarsening, which reduces graph size by merging nodes and edges into supernodes and superedges, enhances scalability and is crucial for graph neural networks (GNNs). However, current methods either construct graphs from large-scale attribute data or assume a pre-existing graph before coarsening, limiting their applicability, especially in domains like healthcare and finance where graph structure is often unavailable. In this paper, we present a novel framework that directly learns a coarsened graph from attribute information, reducing computational complexity and enhancing robustness against adversarial attacks, which commonly target vulnerabilities in graph structures. By integrating label information, our framework also enables semi-supervised learning, leading to improved performance on downstream tasks. Extensive experiments show that our method outperforms state-of-the-art coarsening techniques in both accuracy and computational efficiency.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=6VuTXirQIv",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manoj_Kumar4",
        "name": "Manoj Kumar",
        "name_site": null,
        "openreview_id": "~Manoj_Kumar4",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "gdL-bokAAAAJ",
        "orcid": null,
        "linkedin_url": "manoj-kumar-9042b449/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "LNM Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "6VuTXirQIv",
      "title": "Feature Driven Graph Coarsening for Scaling Graph Representation Learning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graphical modelling for structured data analysis has gained prominence across numerous domains. A significant computational challenge lies in efficiently capturing complex relationships within large-scale graph structures. Graph coarsening, which reduces graph size by merging nodes and edges into supernodes and superedges, enhances scalability and is crucial for graph neural networks (GNNs). However, current methods either construct graphs from large-scale attribute data or assume a pre-existing graph before coarsening, limiting their applicability, especially in domains like healthcare and finance where graph structure is often unavailable. In this paper, we present a novel framework that directly learns a coarsened graph from attribute information, reducing computational complexity and enhancing robustness against adversarial attacks, which commonly target vulnerabilities in graph structures. By integrating label information, our framework also enables semi-supervised learning, leading to improved performance on downstream tasks. Extensive experiments show that our method outperforms state-of-the-art coarsening techniques in both accuracy and computational efficiency.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=6VuTXirQIv",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sumit_Kumar5",
        "name": "Sumit Kumar",
        "name_site": null,
        "openreview_id": "~Sumit_Kumar5",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "sumit-kumar-9088b226",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "6VuTXirQIv",
      "title": "Feature Driven Graph Coarsening for Scaling Graph Representation Learning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graphical modelling for structured data analysis has gained prominence across numerous domains. A significant computational challenge lies in efficiently capturing complex relationships within large-scale graph structures. Graph coarsening, which reduces graph size by merging nodes and edges into supernodes and superedges, enhances scalability and is crucial for graph neural networks (GNNs). However, current methods either construct graphs from large-scale attribute data or assume a pre-existing graph before coarsening, limiting their applicability, especially in domains like healthcare and finance where graph structure is often unavailable. In this paper, we present a novel framework that directly learns a coarsened graph from attribute information, reducing computational complexity and enhancing robustness against adversarial attacks, which commonly target vulnerabilities in graph structures. By integrating label information, our framework also enables semi-supervised learning, leading to improved performance on downstream tasks. Extensive experiments show that our method outperforms state-of-the-art coarsening techniques in both accuracy and computational efficiency.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=6VuTXirQIv",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vipul_Kumar_Singh1",
        "name": "Vipul Kumar Singh",
        "name_site": null,
        "openreview_id": "~Vipul_Kumar_Singh1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "MRJqKywAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "6VuTXirQIv",
      "title": "Feature Driven Graph Coarsening for Scaling Graph Representation Learning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graphical modelling for structured data analysis has gained prominence across numerous domains. A significant computational challenge lies in efficiently capturing complex relationships within large-scale graph structures. Graph coarsening, which reduces graph size by merging nodes and edges into supernodes and superedges, enhances scalability and is crucial for graph neural networks (GNNs). However, current methods either construct graphs from large-scale attribute data or assume a pre-existing graph before coarsening, limiting their applicability, especially in domains like healthcare and finance where graph structure is often unavailable. In this paper, we present a novel framework that directly learns a coarsened graph from attribute information, reducing computational complexity and enhancing robustness against adversarial attacks, which commonly target vulnerabilities in graph structures. By integrating label information, our framework also enables semi-supervised learning, leading to improved performance on downstream tasks. Extensive experiments show that our method outperforms state-of-the-art coarsening techniques in both accuracy and computational efficiency.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=6VuTXirQIv",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sandeep_Kumar8",
        "name": "Sandeep Kumar",
        "name_site": null,
        "openreview_id": "~Sandeep_Kumar8",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/sandeepkr/home",
        "dblp_id": null,
        "google_scholar_url": "lycMMW8AAAAJ",
        "orcid": null,
        "linkedin_url": "sandeep-kumar-84463332/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "6gUrqzDNsQ",
      "title": "PackNets: A Variational Autoencoder-Like Approach for Packing Circles in Any Shape",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The problem of packing smaller objects within a larger one has long been of interest. In this work, we employ an encoder-decoder architecture, parameterized by neural networks, for circle packing. Our solution consists of an encoder that takes the index of a circle as input and outputs a point, which is then transformed by a constraint block into a valid center within the outer shape. A perturbation block perturbs this center while ensuring it remains within the corresponding radius, and the decoder estimates the circle's index based on the perturbed center. The functionality of the perturbation block is akin to adding noise to the latent space variables in variational autoencoders (VAEs); however, it differs significantly in both the method and purpose of perturbation injection, as we inject perturbation to push the centers of the circles sufficiently apart.  Additionally, unlike typical VAEs, our architecture incorporates a constraint block to ensure that the circles do not breach the boundary of the outer shape. We design the constraint block to pack both congruent and non-congruent circles within arbitrary shapes, implementing a scheduled injection of perturbation from a beta distribution in the perturbation block to gradually push the centers apart. We compare our approach to established methods, including disciplined convex-concave programming (DCCP) and other packing techniques, demonstrating competitive performance in terms of packing density—the fraction of the outer object's area covered by the circles. Our method outperforms the DCCP-based solution in the non-congruent case and approaches the best-known packing densities. To our knowledge, this is the first work to present solutions for packing circles within arbitrary shapes.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=6gUrqzDNsQ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ayush_Singhi1",
        "name": "Ayush Singhi",
        "name_site": null,
        "openreview_id": "~Ayush_Singhi1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "ayush-singhi-10a47b237/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Dharwad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.75,
        "rating_std": 1.920286436967152,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "6gUrqzDNsQ",
      "title": "PackNets: A Variational Autoencoder-Like Approach for Packing Circles in Any Shape",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The problem of packing smaller objects within a larger one has long been of interest. In this work, we employ an encoder-decoder architecture, parameterized by neural networks, for circle packing. Our solution consists of an encoder that takes the index of a circle as input and outputs a point, which is then transformed by a constraint block into a valid center within the outer shape. A perturbation block perturbs this center while ensuring it remains within the corresponding radius, and the decoder estimates the circle's index based on the perturbed center. The functionality of the perturbation block is akin to adding noise to the latent space variables in variational autoencoders (VAEs); however, it differs significantly in both the method and purpose of perturbation injection, as we inject perturbation to push the centers of the circles sufficiently apart.  Additionally, unlike typical VAEs, our architecture incorporates a constraint block to ensure that the circles do not breach the boundary of the outer shape. We design the constraint block to pack both congruent and non-congruent circles within arbitrary shapes, implementing a scheduled injection of perturbation from a beta distribution in the perturbation block to gradually push the centers apart. We compare our approach to established methods, including disciplined convex-concave programming (DCCP) and other packing techniques, demonstrating competitive performance in terms of packing density—the fraction of the outer object's area covered by the circles. Our method outperforms the DCCP-based solution in the non-congruent case and approaches the best-known packing densities. To our knowledge, this is the first work to present solutions for packing circles within arbitrary shapes.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=6gUrqzDNsQ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vivek_Pillai1",
        "name": "Vivek Pillai",
        "name_site": null,
        "openreview_id": "~Vivek_Pillai1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "vivek-pillai-7a0812235/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Dharwad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.75,
        "rating_std": 1.920286436967152,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "6gUrqzDNsQ",
      "title": "PackNets: A Variational Autoencoder-Like Approach for Packing Circles in Any Shape",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The problem of packing smaller objects within a larger one has long been of interest. In this work, we employ an encoder-decoder architecture, parameterized by neural networks, for circle packing. Our solution consists of an encoder that takes the index of a circle as input and outputs a point, which is then transformed by a constraint block into a valid center within the outer shape. A perturbation block perturbs this center while ensuring it remains within the corresponding radius, and the decoder estimates the circle's index based on the perturbed center. The functionality of the perturbation block is akin to adding noise to the latent space variables in variational autoencoders (VAEs); however, it differs significantly in both the method and purpose of perturbation injection, as we inject perturbation to push the centers of the circles sufficiently apart.  Additionally, unlike typical VAEs, our architecture incorporates a constraint block to ensure that the circles do not breach the boundary of the outer shape. We design the constraint block to pack both congruent and non-congruent circles within arbitrary shapes, implementing a scheduled injection of perturbation from a beta distribution in the perturbation block to gradually push the centers apart. We compare our approach to established methods, including disciplined convex-concave programming (DCCP) and other packing techniques, demonstrating competitive performance in terms of packing density—the fraction of the outer object's area covered by the circles. Our method outperforms the DCCP-based solution in the non-congruent case and approaches the best-known packing densities. To our knowledge, this is the first work to present solutions for packing circles within arbitrary shapes.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=6gUrqzDNsQ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rajshekhar_V_Bhat1",
        "name": "Rajshekhar V Bhat",
        "name_site": null,
        "openreview_id": "~Rajshekhar_V_Bhat1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/rajshekharbhat/home",
        "dblp_id": "176/5814.html",
        "google_scholar_url": "o2ZFG84AAAAJ",
        "orcid": "0000-0003-2140-4365",
        "linkedin_url": "rajshekhar-bhat-ab635314/?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Dharwad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.75,
        "rating_std": 1.920286436967152,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "8Ds99sdp3U",
      "title": "A Semantic Data Augmentation driven Nested Adapter for Video Moment Retrieval",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Existing transformer-based video-moment retrieval models achieve sub-optimal\nperformance when using the pretrain-finetuning learning paradigm – a pretrained\nmultimodal encoder is finetuned using the target training data. While current work\nhas explored different model architectures and training paradigms to explore this\nproblem, the problem of data dilemma has been under addressed. Specifically,\nthere exists high diversity of how semantic is captured in textual query and the\ntraining dataset only consist of limited moment-query pairs for the highly diverse moments. This work addresses this problem with a novel nested adaptor\nand a LLM-driven semantic data generation pipeline. First, a LLM-driven data\naugmentation generates queries that are semantically similar to the ground truth,\nwhich enrich the semantic boundary captured by textual query. We empirically\nanalyze the effectiveness of data augmentation, and proposed a simple yet effective quality measure to retain high quality samples. Second, we propose a novel\nnested adapter that utilises both augmented queries and human annotated queries\nfor model coarse-tuning and fine-tuning, respectively. By combining semantic\nperturbation with domain adaptation, our approach addresses the variability in\nvideo content while capturing nuanced features more effectively. Experimental\nresults on various baseline models show the efficacy of our proposed approach.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=8Ds99sdp3U",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~KAJAL_KANSAL1",
        "name": "KAJAL KANSAL",
        "name_site": null,
        "openreview_id": "~KAJAL_KANSAL1",
        "position": 2,
        "gender": "F",
        "homepage_url": "https://sites.google.com/iiitd.ac.in/kajalk/",
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.com.sg/citations?user=HEgTMvsAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "8Ds99sdp3U",
      "title": "A Semantic Data Augmentation driven Nested Adapter for Video Moment Retrieval",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Existing transformer-based video-moment retrieval models achieve sub-optimal\nperformance when using the pretrain-finetuning learning paradigm – a pretrained\nmultimodal encoder is finetuned using the target training data. While current work\nhas explored different model architectures and training paradigms to explore this\nproblem, the problem of data dilemma has been under addressed. Specifically,\nthere exists high diversity of how semantic is captured in textual query and the\ntraining dataset only consist of limited moment-query pairs for the highly diverse moments. This work addresses this problem with a novel nested adaptor\nand a LLM-driven semantic data generation pipeline. First, a LLM-driven data\naugmentation generates queries that are semantically similar to the ground truth,\nwhich enrich the semantic boundary captured by textual query. We empirically\nanalyze the effectiveness of data augmentation, and proposed a simple yet effective quality measure to retain high quality samples. Second, we propose a novel\nnested adapter that utilises both augmented queries and human annotated queries\nfor model coarse-tuning and fine-tuning, respectively. By combining semantic\nperturbation with domain adaptation, our approach addresses the variability in\nvideo content while capturing nuanced features more effectively. Experimental\nresults on various baseline models show the efficacy of our proposed approach.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=8Ds99sdp3U",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mohan_Kankanhalli1",
        "name": "Mohan Kankanhalli",
        "name_site": null,
        "openreview_id": "~Mohan_Kankanhalli1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://www.comp.nus.edu.sg/~mohan",
        "dblp_id": "09/3613.html",
        "google_scholar_url": "6Lx_eowAAAAJ",
        "orcid": "0000-0002-4846-2015",
        "linkedin_url": "mohan-kankanhalli-583417221",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "National University of Singapore (Singapore)",
        "countries": [
          "Singapore"
        ],
        "country_codes": [
          "SG"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "8hVCcrGaAu",
      "title": "EDiSon: Efficient Design-and-Control Optimization with Reinforcement Learning and Adaptive Design Reuse",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Seeking good designs is a central goal of many important domains, such as robotics, integrated circuits (IC), medicine, and materials science. These design problems are expensive, time-consuming, and traditionally performed by human experts. Moreover, the barriers to domain knowledge make it challenging to propose a universal solution that generalizes to different design problems. In this paper, we propose a new method called Efficient Design and Stable Control (EDiSon) for automatic design and control in different design problems. The key ideas of our method are (1) interactive sequential modeling of the design and control process and (2) adaptive exploration and design replay. To decompose the difficulty of learning design and control as a whole, we leverage sequential modeling for both the design process and control process, with a design policy to generate step-by-step design proposals and a control policy to optimize the objective by operating the design. With deep reinforcement learning (RL), the policies learn to find good designs by maximizing a reward signal that evaluates the quality of designs. Furthermore, we propose an adaptive exploration and replay strategy based on a design memory that maintains high-quality designs generated so far. By regulating between constructing a design from scratch or replaying a design from memory to refine it, EDiSon balances the trade-off between exploration and exploitation in the design space and stabilizes the learning of the control policy. In the experiments, we evaluate our method in robotic morphology design and Tetris-based design tasks. Our results show that our method effectively learns to explore high-quality designs and outperforms previous results in terms of design score and efficiency.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=8hVCcrGaAu",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Santiago_Miret1",
        "name": "Santiago Miret",
        "name_site": null,
        "openreview_id": "~Santiago_Miret1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://www.intel.ai/bio/santiago-miret/",
        "dblp_id": "241/5030",
        "google_scholar_url": "HLQ_te4AAAAJ",
        "orcid": "0000-0002-5121-3853",
        "linkedin_url": "santiago-miret/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Montreal (Canada)",
        "countries": [
          "Canada"
        ],
        "country_codes": [
          "CA"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "9dFCm4uZo8",
      "title": "Exploring Compositionality in Vision Transformers using Wavelet Representations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Insights into the workings of the transformer have been elicited by analyzing its representations when trained and tested on language data. In this paper, we turn an analytical lens to the representations of variants of the Vision Transformers. This work is aimed to gain insights into the geometric structure of the latent spaces of each encoding layer. We use representation-similarity measures, and representation-visualization approaches to analyse the impact of training regimes on the latent manifolds learned. We then use our approach to design a test for quantifying the extent to which these latent manifolds respect the compositional structure of the input space. We restrict our analysis to compositional structure induced by the Discrete Wavelet Transform (DWT). Interestingly, our empirical analysis reveals that ViT patch representations give notions of compositionality with respect to the DWT primitives.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=9dFCm4uZo8",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Akshad_Shyam_Purushottamdas1",
        "name": "Akshad Shyam Purushottamdas",
        "name_site": null,
        "openreview_id": "~Akshad_Shyam_Purushottamdas1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "akshadshyam",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "9dFCm4uZo8",
      "title": "Exploring Compositionality in Vision Transformers using Wavelet Representations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Insights into the workings of the transformer have been elicited by analyzing its representations when trained and tested on language data. In this paper, we turn an analytical lens to the representations of variants of the Vision Transformers. This work is aimed to gain insights into the geometric structure of the latent spaces of each encoding layer. We use representation-similarity measures, and representation-visualization approaches to analyse the impact of training regimes on the latent manifolds learned. We then use our approach to design a test for quantifying the extent to which these latent manifolds respect the compositional structure of the input space. We restrict our analysis to compositional structure induced by the Discrete Wavelet Transform (DWT). Interestingly, our empirical analysis reveals that ViT patch representations give notions of compositionality with respect to the DWT primitives.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=9dFCm4uZo8",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Pranav_K_Nayak1",
        "name": "Pranav K Nayak",
        "name_site": null,
        "openreview_id": "~Pranav_K_Nayak1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://github.com/pranavknayak",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "9dFCm4uZo8",
      "title": "Exploring Compositionality in Vision Transformers using Wavelet Representations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Insights into the workings of the transformer have been elicited by analyzing its representations when trained and tested on language data. In this paper, we turn an analytical lens to the representations of variants of the Vision Transformers. This work is aimed to gain insights into the geometric structure of the latent spaces of each encoding layer. We use representation-similarity measures, and representation-visualization approaches to analyse the impact of training regimes on the latent manifolds learned. We then use our approach to design a test for quantifying the extent to which these latent manifolds respect the compositional structure of the input space. We restrict our analysis to compositional structure induced by the Discrete Wavelet Transform (DWT). Interestingly, our empirical analysis reveals that ViT patch representations give notions of compositionality with respect to the DWT primitives.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=9dFCm4uZo8",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yashmitha_Gogineni1",
        "name": "Yashmitha Gogineni",
        "name_site": null,
        "openreview_id": "~Yashmitha_Gogineni1",
        "position": 3,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "yashmitha-gogineni/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "9dFCm4uZo8",
      "title": "Exploring Compositionality in Vision Transformers using Wavelet Representations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Insights into the workings of the transformer have been elicited by analyzing its representations when trained and tested on language data. In this paper, we turn an analytical lens to the representations of variants of the Vision Transformers. This work is aimed to gain insights into the geometric structure of the latent spaces of each encoding layer. We use representation-similarity measures, and representation-visualization approaches to analyse the impact of training regimes on the latent manifolds learned. We then use our approach to design a test for quantifying the extent to which these latent manifolds respect the compositional structure of the input space. We restrict our analysis to compositional structure induced by the Discrete Wavelet Transform (DWT). Interestingly, our empirical analysis reveals that ViT patch representations give notions of compositionality with respect to the DWT primitives.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=9dFCm4uZo8",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Konda_Reddy_Mopuri3",
        "name": "Konda Reddy Mopuri",
        "name_site": null,
        "openreview_id": "~Konda_Reddy_Mopuri3",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://krmopuri.github.io/",
        "dblp_id": "162/0085",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": "0000-0001-8894-7212",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "9h5paerJxC",
      "title": "Cluster-Segregate-Perturb (CSP): A Model-agnostic Explainability Pipeline for Spatiotemporal Land Surface Forecasting Models",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Satellite images are increasingly valuable for modeling regional climate change. Earth surface forecasting is one task that combines satellite imagery and meteorological data to understand how climate evolves over time. However, understanding the complex relationship between meteorological variables and land surface changes remains a challenge. Our paper introduces a pipeline that integrates principles from perturbation-based techniques like LIME and global explainability techniques methods like PDP, addressing the limitations of these techniques in high-dimensional spatiotemporal models. This pipeline facilitates analyses such as marginal sensitivity, correlation, and lag analysis, etc for complex land forecasting models. Using ConvLSTM for surface forecasting, we analyzed influence of variables like temperature, pressure, and precipitation on the NDVI of the surface predictions. Our study in EarthNet2021 Dataset (primarily consists of samples from the European Alps region, collected during the spring to fall seasons) revealed that precipitation had the greatest impact, followed by temperature, while pressure has little to no direct effect on NDVI. Additionally, interesting nonlinear correlations between meteorological variables and NDVI have been uncovered.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=9h5paerJxC",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Tushar_Verma1",
        "name": "Tushar Verma",
        "name_site": null,
        "openreview_id": "~Tushar_Verma1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "tushar-verma-a83722184?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "9hmDl8fFDs",
      "title": "Deep Complex Spatio-Spectral Networks with Complex Visual Inputs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Complex-valued neural networks have attracted growing attention for their ability to handle complex-valued data with enhanced representational capacity. However, their potential in computer vision remains relatively untapped. \nIn this paper, we introduce Deep Complex Spatio-Spectral Network (DCSNet), a fully complex-valued token-based, end-to-end neural network designed for binary segmentation tasks. Additionally, our DCSNet encoder can be used for image classification in the complex domain. We also propose an invertible real-to-complex (R2C) transform, which generates two complex-valued input channels, complex intensity and complex hue, while producing complex-valued images with distinct real and imaginary components.\nDCSNet operates in both spatial and spectral domains by leveraging complex-valued inputs and complex Fourier transform.\nAs a result, the complex-valued representation is maintained throughout DCSNet, and we avoid the information loss typically associated with Real$\\leftrightarrow$Complex transformations. Extensive experiments show that DCSNet surpasses existing complex-valued methods across various tasks on both real and complex-valued data and achieves competitive performance compared to existing real-valued methods, establishing a robust framework for handling both data types effectively.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=9hmDl8fFDs",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Saurabh_Yadav2",
        "name": "Saurabh Yadav",
        "name_site": null,
        "openreview_id": "~Saurabh_Yadav2",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://saurabhya.github.io",
        "dblp_id": "319/9894",
        "google_scholar_url": "NR5qe-8AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.7853571071357126,
        "confidence_mean": 3.25,
        "confidence_std": 1.299038105676658,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "9hmDl8fFDs",
      "title": "Deep Complex Spatio-Spectral Networks with Complex Visual Inputs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Complex-valued neural networks have attracted growing attention for their ability to handle complex-valued data with enhanced representational capacity. However, their potential in computer vision remains relatively untapped. \nIn this paper, we introduce Deep Complex Spatio-Spectral Network (DCSNet), a fully complex-valued token-based, end-to-end neural network designed for binary segmentation tasks. Additionally, our DCSNet encoder can be used for image classification in the complex domain. We also propose an invertible real-to-complex (R2C) transform, which generates two complex-valued input channels, complex intensity and complex hue, while producing complex-valued images with distinct real and imaginary components.\nDCSNet operates in both spatial and spectral domains by leveraging complex-valued inputs and complex Fourier transform.\nAs a result, the complex-valued representation is maintained throughout DCSNet, and we avoid the information loss typically associated with Real$\\leftrightarrow$Complex transformations. Extensive experiments show that DCSNet surpasses existing complex-valued methods across various tasks on both real and complex-valued data and achieves competitive performance compared to existing real-valued methods, establishing a robust framework for handling both data types effectively.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=9hmDl8fFDs",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Koteswar_Rao_Jerripothula3",
        "name": "Koteswar Rao Jerripothula",
        "name_site": null,
        "openreview_id": "~Koteswar_Rao_Jerripothula2",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://sites.google.com/site/koteswarraojerripothula/",
        "dblp_id": "158/9790",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=QgTEe-gAAAAJ",
        "orcid": "0000-0002-3507-3731",
        "linkedin_url": "koteswar-rao-jerripothula",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.7853571071357126,
        "confidence_mean": 3.25,
        "confidence_std": 1.299038105676658,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "B8qoU7kgSF",
      "title": "Generalization Bounds for Neural Ordinary Differential Equations and Residual Neural Networks",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Neural ordinary differential equations (neural ODEs) represent a widely-used\nclass of deep learning models characterized by continuous depth. Understand-\ning the generalization error bound is important to evaluate how well a model is\nexpected to perform on new, unseen data. Earlier works in this direction involved\nconsidering the linear case on the dynamics function (a function that models the\nevolution of state variables) of Neural ODE Marion (2024). Other related work\nis on bound for Neural Controlled ODE Bleistein & Guilloux (2023) that de-\npends on the sampling gap. We consider a class of neural ordinary differential\nequations (ODEs) with a general nonlinear function for time-dependent and time-\nindependent cases which is Lipschitz with respect to state variables. We observed\nthat the solution of the neural ODEs would be of bound variations if we assume\nthat the dynamics function of Neural ODEs is Lipschitz continuous with respect\nto the hidden state. We derive a generalization bound for the time-dependent\nand time-independent Neural ODEs.Using the fact that Neural ODEs are limiting\ncases of time-dependent Neural ODEs we obtained a bound for the residual neural\nnetworks. We showed the effect of overparameterization and domain bound in the\ngeneralization error bound. This is the first time, the generalization bound for the\nNeural ODE with a more general non-linear function has been found.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=B8qoU7kgSF",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Madhusudan_Verma1",
        "name": "Madhusudan Verma",
        "name_site": null,
        "openreview_id": "~Madhusudan_Verma1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "G7PU0H4AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "B8qoU7kgSF",
      "title": "Generalization Bounds for Neural Ordinary Differential Equations and Residual Neural Networks",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Neural ordinary differential equations (neural ODEs) represent a widely-used\nclass of deep learning models characterized by continuous depth. Understand-\ning the generalization error bound is important to evaluate how well a model is\nexpected to perform on new, unseen data. Earlier works in this direction involved\nconsidering the linear case on the dynamics function (a function that models the\nevolution of state variables) of Neural ODE Marion (2024). Other related work\nis on bound for Neural Controlled ODE Bleistein & Guilloux (2023) that de-\npends on the sampling gap. We consider a class of neural ordinary differential\nequations (ODEs) with a general nonlinear function for time-dependent and time-\nindependent cases which is Lipschitz with respect to state variables. We observed\nthat the solution of the neural ODEs would be of bound variations if we assume\nthat the dynamics function of Neural ODEs is Lipschitz continuous with respect\nto the hidden state. We derive a generalization bound for the time-dependent\nand time-independent Neural ODEs.Using the fact that Neural ODEs are limiting\ncases of time-dependent Neural ODEs we obtained a bound for the residual neural\nnetworks. We showed the effect of overparameterization and domain bound in the\ngeneralization error bound. This is the first time, the generalization bound for the\nNeural ODE with a more general non-linear function has been found.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=B8qoU7kgSF",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manoj_Kumar6",
        "name": "Manoj Kumar",
        "name_site": null,
        "openreview_id": "~Manoj_Kumar6",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/hansat/home",
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "BZr41xSleC",
      "title": "Rethinking Message Passing for Algorithmic Alignment on Graphs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Most Graph Neural Networks are based on the principle of message-passing, where all neighboring nodes exchange messages with each other simultaneously. We want to challenge this paradigm by introducing the Flood and Echo Net, a novel architecture that aligns neural computation with the principles of distributed algorithms. \nIn our method, nodes sparsely activate upon receiving a message, leading to a wave-like activation pattern that traverses the graph. Through these sparse but parallel activations, the Net becomes more expressive than traditional MPNNs which are limited by the 1-WL test and also is provably more efficient in terms of message complexity.\nMoreover, the mechanism's ability to generalize across graphs of varying sizes positions it as a practical architecture for the task of algorithmic learning. We test the Flood and Echo Net on a variety of synthetic tasks and find that the algorithmic alignment of the execution improves generalization to larger graph sizes. Moreover, our method significantly improves generalization and correct execution in terms of graph accuracy on the SALSA-CLRS benchmark.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=BZr41xSleC",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Florian_Grötschla1",
        "name": "Florian Grötschla",
        "name_site": null,
        "openreview_id": "~Florian_Grötschla1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://disco.ethz.ch/members/fgroetschla",
        "dblp_id": "334/1811",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Helmholtz Zentrum München (Germany)",
        "countries": [
          "Germany"
        ],
        "country_codes": [
          "DE"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "BsQTw0uPDX",
      "title": "Hierarchical Preference Optimization: Learning to achieve goals via feasible subgoals prediction",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "This work introduces Hierarchical Preference Optimization (HPO), a novel approach to hierarchical reinforcement learning (HRL) that addresses non-stationarity and infeasible subgoal generation issues when solving complex robotic control tasks. HPO leverages maximum entropy reinforcement learning combined with token-level Direct Preference Optimization (DPO), eliminating the need for pre-trained reference policies that are typically unavailable in challenging robotic scenarios. Mathematically, we formulate HRL as a bi-level optimization problem and transform it into a primitive-regularized DPO formulation, ensuring feasible subgoal generation and avoiding degenerate solutions. Extensive experiments on challenging robotic navigation and manipulation tasks demonstrate HPO’s impressive performance, where HPO shows an improvement of up to 35% over the baselines. Furthermore, ablation studies validate our design choices, and quantitative analyses confirm HPO’s ability to mitigate non-stationarity and infeasible subgoal generation issues in HRL.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=BsQTw0uPDX",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 8,
      "track_name": "Main Conference",
      "author": {
        "id": "~Utsav_Singh1",
        "name": "Utsav Singh",
        "name_site": null,
        "openreview_id": "~Utsav_Singh1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://www.cse.iitk.ac.in/users/utsavz/",
        "dblp_id": "241/9336",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 1.8027756377319946,
        "confidence_mean": 3.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "BuBBRn0zFD",
      "title": "Automated Discovery of Pairwise Interactions from Unstructured Data",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Pairwise interactions between perturbations to a system can provide evidence for the causal dependencies of the underlying underlying mechanisms of a system. When observations are low dimensional, hand crafted measurements, detecting interactions amounts to simple statistical tests, but it is not obvious how to detect interactions between perturbations affecting latent variables. \nWe derive two interaction tests that are based on pairwise interventions, and show how these tests can be integrated into an active learning pipeline to efficiently discover pairwise interactions between perturbations.\nWe illustrate the value of these tests in the context of biology, where\npairwise perturbation experiments are frequently used to reveal interactions\nthat are not observable from any single perturbation. \nOur tests can be run on unstructured data, such as\nthe pixels in an image, which enables a more general notion of interaction than\ntypical cell viability experiments, and can be run on cheaper experimental assays. \nWe validate on several synthetic and real biological experiments that our tests are able to identify interacting pairs effectively. \nWe evaluate our approach on a real biological experiment where we knocked out\n50 pairs of genes and measured the effect with microscopy images. We show that\nwe are able to recover significantly more known biological interactions than\nrandom search and standard active learning baselines.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=BuBBRn0zFD",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Alisandra_Kaye_Denton1",
        "name": "Alisandra Kaye Denton",
        "name_site": null,
        "openreview_id": "~Alisandra_Kaye_Denton1",
        "position": 3,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.ca/citations?hl=en",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Valence Labs (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.25,
        "confidence_std": 1.0897247358851685,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "BuBBRn0zFD",
      "title": "Automated Discovery of Pairwise Interactions from Unstructured Data",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Pairwise interactions between perturbations to a system can provide evidence for the causal dependencies of the underlying underlying mechanisms of a system. When observations are low dimensional, hand crafted measurements, detecting interactions amounts to simple statistical tests, but it is not obvious how to detect interactions between perturbations affecting latent variables. \nWe derive two interaction tests that are based on pairwise interventions, and show how these tests can be integrated into an active learning pipeline to efficiently discover pairwise interactions between perturbations.\nWe illustrate the value of these tests in the context of biology, where\npairwise perturbation experiments are frequently used to reveal interactions\nthat are not observable from any single perturbation. \nOur tests can be run on unstructured data, such as\nthe pixels in an image, which enables a more general notion of interaction than\ntypical cell viability experiments, and can be run on cheaper experimental assays. \nWe validate on several synthetic and real biological experiments that our tests are able to identify interacting pairs effectively. \nWe evaluate our approach on a real biological experiment where we knocked out\n50 pairs of genes and measured the effect with microscopy images. We show that\nwe are able to recover significantly more known biological interactions than\nrandom search and standard active learning baselines.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=BuBBRn0zFD",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aniket_Rajiv_Didolkar1",
        "name": "Aniket Rajiv Didolkar",
        "name_site": null,
        "openreview_id": "~Aniket_Rajiv_Didolkar1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://github.com/dido1998/",
        "dblp_id": "245/8589",
        "google_scholar_url": "https://scholar.google.ca/citations?user=ekvl5o0AAAAJ",
        "orcid": null,
        "linkedin_url": "aniket-didolkar-7a9b8912a",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Recursion (Canada)",
        "countries": [
          "Canada"
        ],
        "country_codes": [
          "CA"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.25,
        "confidence_std": 1.0897247358851685,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "BuBBRn0zFD",
      "title": "Automated Discovery of Pairwise Interactions from Unstructured Data",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Pairwise interactions between perturbations to a system can provide evidence for the causal dependencies of the underlying underlying mechanisms of a system. When observations are low dimensional, hand crafted measurements, detecting interactions amounts to simple statistical tests, but it is not obvious how to detect interactions between perturbations affecting latent variables. \nWe derive two interaction tests that are based on pairwise interventions, and show how these tests can be integrated into an active learning pipeline to efficiently discover pairwise interactions between perturbations.\nWe illustrate the value of these tests in the context of biology, where\npairwise perturbation experiments are frequently used to reveal interactions\nthat are not observable from any single perturbation. \nOur tests can be run on unstructured data, such as\nthe pixels in an image, which enables a more general notion of interaction than\ntypical cell viability experiments, and can be run on cheaper experimental assays. \nWe validate on several synthetic and real biological experiments that our tests are able to identify interacting pairs effectively. \nWe evaluate our approach on a real biological experiment where we knocked out\n50 pairs of genes and measured the effect with microscopy images. We show that\nwe are able to recover significantly more known biological interactions than\nrandom search and standard active learning baselines.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=BuBBRn0zFD",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Berton_Earnshaw1",
        "name": "Berton Earnshaw",
        "name_site": null,
        "openreview_id": "~Berton_Earnshaw1",
        "position": 6,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": "0000-0002-9728-2408",
        "linkedin_url": "bertonearnshaw/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Valence Labs (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.25,
        "confidence_std": 1.0897247358851685,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ByLO7p0oCF",
      "title": "DebUnc: Improving Large Language Model Agent Communication Via Uncertainty Metrics",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "To enhance Large Language Model (LLM) capabilities, multi-agent debates have been introduced, where multiple LLMs discuss solutions to a problem over several rounds of debate. However, LLMs often produce incorrect responses that appear confident, which can mislead other agents. This is partly because agents do not express their confidence levels during standard debates. To address this, we introduce DebUnc, a multi-agent debate framework that uses uncertainty metrics to assess agent confidence levels. We adapted the LLM attention mechanism to adjust token weights based on confidence levels and also explored using textual prompts to convey confidence. Our evaluations across various benchmarks show that attention-based methods are particularly effective, and that as uncertainty metrics improve, performance will continue to increase.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ByLO7p0oCF",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Alfonso_Amayuelas2",
        "name": "Alfonso Amayuelas",
        "name_site": "Alfonso Amayuelas, Shuai Zhang, Xi Rao, Ce Zhang",
        "openreview_id": "~Alfonso_Amayuelas2",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.amayuelas.me/",
        "dblp_id": "281/7669",
        "google_scholar_url": "https://scholar.google.dk/citations?user=QGQ2G28AAAAJ",
        "orcid": null,
        "linkedin_url": "alfonsoamayuelas/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of California, Santa Barbara (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.666666666666667,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "C7XoUdJ5ZC",
      "title": "FLAIR: FEDERATED LEARNING WITH AUGMENTED AND IMPROVED FEATURE REPRESENTATIONS",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Federated Learning (FL) enables collaborative model training across decentralized clients while preserving data privacy. However, its performance declines in challenging  heterogeneous data settings. To mitigate this, existing FL frameworks not only share locally trained parameters but also exchange additional information -- such as control variates, client features, and classifier characteristics -- to address the effects of class imbalance and missing classes. However, this leads to increased communication costs and heightened risks of privacy breaches. To strike a balance between communication efficiency, privacy protection, and adaptability to heterogeneous data distributions, we propose FLAIR, a novel FL approach with augmented and improved feature representations. FLAIR utilizes Class Variational Autoencoders (CVAE) for feature augmentation, mitigating class imbalance and missing class issues. It also incorporates Reptile meta-training to facilitate knowledge transfer between model updates, adapting to dynamic feature shifts. To generalize model update, FLAIR shares only local CVAE parameters instead of local model parameters, which reduces both communication costs and privacy risks. Our experiments on benchmark datasets -- such as MNIST, CIFAR-10, CIFAR-100, and TinyImageNet -- demonstrates a significant enhancement in model convergence and accuracy compared to state-of-the-art solutions, while reducing communication overhead and privacy risks.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=C7XoUdJ5ZC",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sujit_Chowdhury1",
        "name": "Sujit Chowdhury",
        "name_site": null,
        "openreview_id": "~Sujit_Chowdhury1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0000-0002-5170-8098",
        "linkedin_url": "sujit-chowdhury-bbb624b7/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Patna (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "C7XoUdJ5ZC",
      "title": "FLAIR: FEDERATED LEARNING WITH AUGMENTED AND IMPROVED FEATURE REPRESENTATIONS",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Federated Learning (FL) enables collaborative model training across decentralized clients while preserving data privacy. However, its performance declines in challenging  heterogeneous data settings. To mitigate this, existing FL frameworks not only share locally trained parameters but also exchange additional information -- such as control variates, client features, and classifier characteristics -- to address the effects of class imbalance and missing classes. However, this leads to increased communication costs and heightened risks of privacy breaches. To strike a balance between communication efficiency, privacy protection, and adaptability to heterogeneous data distributions, we propose FLAIR, a novel FL approach with augmented and improved feature representations. FLAIR utilizes Class Variational Autoencoders (CVAE) for feature augmentation, mitigating class imbalance and missing class issues. It also incorporates Reptile meta-training to facilitate knowledge transfer between model updates, adapting to dynamic feature shifts. To generalize model update, FLAIR shares only local CVAE parameters instead of local model parameters, which reduces both communication costs and privacy risks. Our experiments on benchmark datasets -- such as MNIST, CIFAR-10, CIFAR-100, and TinyImageNet -- demonstrates a significant enhancement in model convergence and accuracy compared to state-of-the-art solutions, while reducing communication overhead and privacy risks.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=C7XoUdJ5ZC",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aritra_Bhaduri1",
        "name": "Aritra Bhaduri",
        "name_site": null,
        "openreview_id": "~Aritra_Bhaduri1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "aritrabhaduri",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Patna (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "C7XoUdJ5ZC",
      "title": "FLAIR: FEDERATED LEARNING WITH AUGMENTED AND IMPROVED FEATURE REPRESENTATIONS",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Federated Learning (FL) enables collaborative model training across decentralized clients while preserving data privacy. However, its performance declines in challenging  heterogeneous data settings. To mitigate this, existing FL frameworks not only share locally trained parameters but also exchange additional information -- such as control variates, client features, and classifier characteristics -- to address the effects of class imbalance and missing classes. However, this leads to increased communication costs and heightened risks of privacy breaches. To strike a balance between communication efficiency, privacy protection, and adaptability to heterogeneous data distributions, we propose FLAIR, a novel FL approach with augmented and improved feature representations. FLAIR utilizes Class Variational Autoencoders (CVAE) for feature augmentation, mitigating class imbalance and missing class issues. It also incorporates Reptile meta-training to facilitate knowledge transfer between model updates, adapting to dynamic feature shifts. To generalize model update, FLAIR shares only local CVAE parameters instead of local model parameters, which reduces both communication costs and privacy risks. Our experiments on benchmark datasets -- such as MNIST, CIFAR-10, CIFAR-100, and TinyImageNet -- demonstrates a significant enhancement in model convergence and accuracy compared to state-of-the-art solutions, while reducing communication overhead and privacy risks.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=C7XoUdJ5ZC",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Raju_Halder1",
        "name": "Raju Halder",
        "name_site": null,
        "openreview_id": "~Raju_Halder1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.iitp.ac.in/~halder/",
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": "0000-0002-8873-8258",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Patna (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "CFKZKjrQ5r",
      "title": "FCoReBench: Can Large Language Models Solve Challenging First-Order Combinatorial Reasoning Problems?",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Can the large language models (LLMs) solve challenging first-order combinatorial\nreasoning problems such as graph coloring, knapsack, and cryptarithmetic? By\nfirst-order, we mean these problems can be instantiated with potentially an infinite\nnumber of problem instances of varying sizes. They are also challenging being\nNP-hard and requiring several reasoning steps to reach a solution. While existing\nwork has focused on coming up with datasets with hard benchmarks, there is\nlimited work which exploits the first-order nature of the problem structure. To\naddress this challenge, we present FCoReBench, a dataset of 40 such challenging\nproblems, along with scripts to generate problem instances of varying sizes and\nautomatically verify and generate their solutions. We first observe that LLMs, even\nwhen aided by symbolic solvers, perform rather poorly on our dataset, being unable\nto leverage the underlying structure of these problems. We specifically observe\na drop in performance with increasing problem size. In response, we propose a\nnew approach, SymPro-LM, which combines LLMs with both symbolic solvers\nand program interpreters, along with feedback from a few solved examples, to\nachieve huge performance gains. Our proposed approach is robust to changes in the\nproblem size, and has the unique characteristic of not requiring any LLM call during\ninference time, unlike earlier approaches. As an additional experiment, we also\ndemonstrate SymPro-LM’s effectiveness on other logical reasoning benchmarks.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=CFKZKjrQ5r",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Chinmay_Mittal1",
        "name": "Chinmay Mittal",
        "name_site": null,
        "openreview_id": "~Chinmay_Mittal1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://chinmay-mittal.netlify.app/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "chinmay-mittal-733b75200/?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "CFKZKjrQ5r",
      "title": "FCoReBench: Can Large Language Models Solve Challenging First-Order Combinatorial Reasoning Problems?",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Can the large language models (LLMs) solve challenging first-order combinatorial\nreasoning problems such as graph coloring, knapsack, and cryptarithmetic? By\nfirst-order, we mean these problems can be instantiated with potentially an infinite\nnumber of problem instances of varying sizes. They are also challenging being\nNP-hard and requiring several reasoning steps to reach a solution. While existing\nwork has focused on coming up with datasets with hard benchmarks, there is\nlimited work which exploits the first-order nature of the problem structure. To\naddress this challenge, we present FCoReBench, a dataset of 40 such challenging\nproblems, along with scripts to generate problem instances of varying sizes and\nautomatically verify and generate their solutions. We first observe that LLMs, even\nwhen aided by symbolic solvers, perform rather poorly on our dataset, being unable\nto leverage the underlying structure of these problems. We specifically observe\na drop in performance with increasing problem size. In response, we propose a\nnew approach, SymPro-LM, which combines LLMs with both symbolic solvers\nand program interpreters, along with feedback from a few solved examples, to\nachieve huge performance gains. Our proposed approach is robust to changes in the\nproblem size, and has the unique characteristic of not requiring any LLM call during\ninference time, unlike earlier approaches. As an additional experiment, we also\ndemonstrate SymPro-LM’s effectiveness on other logical reasoning benchmarks.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=CFKZKjrQ5r",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Krishna_Kartik1",
        "name": "Krishna Kartik",
        "name_site": null,
        "openreview_id": "~Krishna_Kartik1",
        "position": 2,
        "gender": null,
        "homepage_url": "https://github.com/kartikkrishna97",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "CFKZKjrQ5r",
      "title": "FCoReBench: Can Large Language Models Solve Challenging First-Order Combinatorial Reasoning Problems?",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Can the large language models (LLMs) solve challenging first-order combinatorial\nreasoning problems such as graph coloring, knapsack, and cryptarithmetic? By\nfirst-order, we mean these problems can be instantiated with potentially an infinite\nnumber of problem instances of varying sizes. They are also challenging being\nNP-hard and requiring several reasoning steps to reach a solution. While existing\nwork has focused on coming up with datasets with hard benchmarks, there is\nlimited work which exploits the first-order nature of the problem structure. To\naddress this challenge, we present FCoReBench, a dataset of 40 such challenging\nproblems, along with scripts to generate problem instances of varying sizes and\nautomatically verify and generate their solutions. We first observe that LLMs, even\nwhen aided by symbolic solvers, perform rather poorly on our dataset, being unable\nto leverage the underlying structure of these problems. We specifically observe\na drop in performance with increasing problem size. In response, we propose a\nnew approach, SymPro-LM, which combines LLMs with both symbolic solvers\nand program interpreters, along with feedback from a few solved examples, to\nachieve huge performance gains. Our proposed approach is robust to changes in the\nproblem size, and has the unique characteristic of not requiring any LLM call during\ninference time, unlike earlier approaches. As an additional experiment, we also\ndemonstrate SymPro-LM’s effectiveness on other logical reasoning benchmarks.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=CFKZKjrQ5r",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Parag_Singla1",
        "name": "Parag Singla",
        "name_site": null,
        "openreview_id": "~Parag_Singla1",
        "position": 3,
        "gender": "M",
        "homepage_url": "http://www.cse.iitd.ac.in/~parags",
        "dblp_id": "14/167",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=V49BsgMAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "CFKZKjrQ5r",
      "title": "FCoReBench: Can Large Language Models Solve Challenging First-Order Combinatorial Reasoning Problems?",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Can the large language models (LLMs) solve challenging first-order combinatorial\nreasoning problems such as graph coloring, knapsack, and cryptarithmetic? By\nfirst-order, we mean these problems can be instantiated with potentially an infinite\nnumber of problem instances of varying sizes. They are also challenging being\nNP-hard and requiring several reasoning steps to reach a solution. While existing\nwork has focused on coming up with datasets with hard benchmarks, there is\nlimited work which exploits the first-order nature of the problem structure. To\naddress this challenge, we present FCoReBench, a dataset of 40 such challenging\nproblems, along with scripts to generate problem instances of varying sizes and\nautomatically verify and generate their solutions. We first observe that LLMs, even\nwhen aided by symbolic solvers, perform rather poorly on our dataset, being unable\nto leverage the underlying structure of these problems. We specifically observe\na drop in performance with increasing problem size. In response, we propose a\nnew approach, SymPro-LM, which combines LLMs with both symbolic solvers\nand program interpreters, along with feedback from a few solved examples, to\nachieve huge performance gains. Our proposed approach is robust to changes in the\nproblem size, and has the unique characteristic of not requiring any LLM call during\ninference time, unlike earlier approaches. As an additional experiment, we also\ndemonstrate SymPro-LM’s effectiveness on other logical reasoning benchmarks.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=CFKZKjrQ5r",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Parag_Singla1_1",
        "name": "Parag Singla",
        "name_site": null,
        "openreview_id": "~Mausam_Mausam2",
        "position": 4,
        "gender": "M",
        "homepage_url": "http://www.cse.iitd.ac.in/~mausam",
        "dblp_id": "30/6391.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?hl=en",
        "orcid": "0000-0003-4088-4296",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "CgkGFeSpo0",
      "title": "Resolving Complex Social Dilemmas by Aligning Preferences with Counterfactual Regret",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Social dilemmas are situations where gains from cooperation are possible but misaligned incentives make it hard to find and stabilize prosocial joint behavior. In such situations selfish behaviors may harm the social good. In spatiotemporally complex social dilemmas, the barriers to cooperation that emerge from misaligned incentives interact with obstacles that stem from spatiotemporal complexity. In this paper, we propose a multi-agent reinforcement learning algorithm which aims to find cooperative resolutions for such complex social dilemmas. Agents maximize their own interests while also helping others, regardless of the actions their co-players take. This approach disentangles the causes of selfish reward from the causes of prosocial reward. Empirically, our method outperforms multiple baseline methods in several complex social dilemma environments.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=CgkGFeSpo0",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yali_Du1",
        "name": "Yali Du",
        "name_site": null,
        "openreview_id": "~Yali_Du1",
        "position": 4,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "DKZjYuB6gc",
      "title": "Narrowing the Focus: Learned Optimizers for Pretrained Models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "In modern deep learning, the models are learned by applying gradient updates using an optimizer, which transforms the updates based on various statistics. Optimizers are often hand-designed and tuning their hyperparameters is a big part of the training process. Learned optimizers have shown some initial promise, but are generally unsuccessful as a general optimization mechanism applicable to every problem. In this work we explore a different direction: instead of learning general optimizers, we instead specialize them to a specific training environment. We propose a novel optimizer technique that learns a layer-specific linear combination of update directions provided by a set of base optimizers, effectively adapting its strategy to the specific model and dataset. When evaluated on image classification tasks, this specialized optimizer significantly outperforms both traditional off-the-shelf methods such as Adam, as well as existing general learned optimizers. Moreover, it demonstrates robust generalization with respect to model initialization, evaluating on unseen datasets, and training durations beyond its meta-training horizon.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=DKZjYuB6gc",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Di_He1_1",
        "name": "Di He",
        "name_site": null,
        "openreview_id": "~Anirudh_Goyal1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://anirudh9119.github.io/",
        "dblp_id": "172/1039",
        "google_scholar_url": "krrh6OUAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "DXz1PDA0Wg",
      "title": "Herb-GANNet: Synthetic Data Generation through Conditional GANs for Improving Accuracy in Medicinal Leaf Classification",
      "status": "Desk Reject",
      "normalized_status": "rejected",
      "abstract": "Accurate classification of medicinal leaves is essential across various fields, including agriculture, Ayurveda, drug discovery, and biodiversity conservation. However, this task can be complex and time consuming for experts due to the complexity of plant morphology, limited public datasets, and inherent class imbalances among species. These issues not only hinder effective identification and utilization of medicinal plants but also impede research and development in related domains. This study explores the application of Conditional Generative Adversarial Networks (CGANs) to generate synthetic data aimed at improving medicinal leaf classification models. CGANs offer effective solution for augmenting datasets and addressing class imbalance issues. We employed a conditional Deep Convolution Generative Adversarial Network (cDCGAN) to produce 500 synthetic images for each of thirty different plant species. To evaluate the effectiveness of the generated data, we trained and evaluated three popular convolutional neural networks: ResNet-34, VGG-16, and EfficientNet-B1, on both the original and augmented datasets. Our results show that CGAN-generated data significantly improved the performance across all tested models. EfficientNet-B1 achieved the lowest test loss of 1.74% on the augmented dataset, while ResNet-34 exhibited the highest test accuracy of 98.26%. These findings indicate that cDCGANs can generate synthetic data that effectively mimics real images, leading to (1) larger training datasets, (2) reduced data collection cost, and (3) increased data diversity and model generalization by providing a broader range of training examples.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=DXz1PDA0Wg",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 1,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sapna_R1",
        "name": "Sapna R",
        "name_site": null,
        "openreview_id": "~Sapna_R1",
        "position": 1,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": "0000-0003-0041-9269",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Manipal University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 0.0,
        "rating_std": 0.0,
        "confidence_mean": 0.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "DnfPX10Etk",
      "title": "JOOCI: A FRAMEWORK FOR LEARNING COMPREHENSIVE SPEECH REPRESENTATIONS",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Information in speech can be divided into two categories: what is being said (content) and how it is expressed (other). Current state-of-the-art (SOTA) techniques model speech at fixed segments, usually 10-25 ms, using a single embedding. Given the orthogonal nature of other and content information, attempting to optimize both within a single embedding results in suboptimal solutions. This approach divides the model's capacity, limiting its ability to build complex hierarchical features effectively. In this work, we present an end-to-end speech representation learning framework designed to jointly optimize the other and \\enquote{content} information (JOOCI) in speech. By using separate learnable parameters, JOOCI addresses this optimization challenge by modeling other and content information independently. Our results show that JOOCI consistently outperforms other SOTA models of similar size (100 million parameters) and pre-training data used (960 hours) by a significant margin when evaluated on a range of speech downstream tasks in the SUPERB benchmark. Code and models are available at TBA.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=DnfPX10Etk",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sunayana_Sitaram1",
        "name": "Sunayana Sitaram",
        "name_site": null,
        "openreview_id": "~Sunayana_Sitaram1",
        "position": 2,
        "gender": "F",
        "homepage_url": "https://www.microsoft.com/en-us/research/people/susitara/",
        "dblp_id": "27/7642",
        "google_scholar_url": "PUxwYrkAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "DnfPX10Etk",
      "title": "JOOCI: A FRAMEWORK FOR LEARNING COMPREHENSIVE SPEECH REPRESENTATIONS",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Information in speech can be divided into two categories: what is being said (content) and how it is expressed (other). Current state-of-the-art (SOTA) techniques model speech at fixed segments, usually 10-25 ms, using a single embedding. Given the orthogonal nature of other and content information, attempting to optimize both within a single embedding results in suboptimal solutions. This approach divides the model's capacity, limiting its ability to build complex hierarchical features effectively. In this work, we present an end-to-end speech representation learning framework designed to jointly optimize the other and \\enquote{content} information (JOOCI) in speech. By using separate learnable parameters, JOOCI addresses this optimization challenge by modeling other and content information independently. Our results show that JOOCI consistently outperforms other SOTA models of similar size (100 million parameters) and pre-training data used (960 hours) by a significant margin when evaluated on a range of speech downstream tasks in the SUPERB benchmark. Code and models are available at TBA.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=DnfPX10Etk",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rajiv_Ratn_Shah1",
        "name": "Rajiv Ratn Shah",
        "name_site": null,
        "openreview_id": "~Rajiv_Ratn_Shah1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://iiitd.ac.in/rajivratn",
        "dblp_id": "134/3502",
        "google_scholar_url": "https://scholar.google.com.sg/citations?hl=en",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "E9NQUvbsT1",
      "title": "Task and Model Agnostic Differentially Private Graph Neural Networks via Coarsening",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for analyzing graph-structured data, deriving representations by aggregating information from neighboring nodes. However, this aggregation process inherently increases the risk of exposing confidential data, as a single node may influence the inference process for multiple nodes simultaneously. To mitigate this risk, researchers have explored differentially private training methods for GNN models. Existing privacy-preserving approaches, however, face significant challenges. They often incur high computational costs during training or struggle to generalize across various GNN models and task objectives. To address these limitations, we introduce Differentially Private Graph Coarsening (DPGC), a novel method that tackles two key challenges in GNN training: scalability and privacy guarantees that are independent of the downstream task or GNN model. Through comprehensive experiments on six datasets across diverse prediction tasks, we demonstrate that  DPGC sets new benchmarks in graph coarsening. Our method achieves superior compression-accuracy trade-offs while maintaining robust privacy guarantees, outperforming state-of-the-art baselines in this domain.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=E9NQUvbsT1",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anuj_Kumar_Sirohi1",
        "name": "Anuj Kumar Sirohi",
        "name_site": null,
        "openreview_id": "~Anuj_Kumar_Sirohi1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "365/3703",
        "google_scholar_url": "82E9a6YAAAAJ",
        "orcid": "0009-0004-9698-5744",
        "linkedin_url": "anuj-kumar-sirohi-96845750/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 2.160246899469287,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "E9NQUvbsT1",
      "title": "Task and Model Agnostic Differentially Private Graph Neural Networks via Coarsening",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for analyzing graph-structured data, deriving representations by aggregating information from neighboring nodes. However, this aggregation process inherently increases the risk of exposing confidential data, as a single node may influence the inference process for multiple nodes simultaneously. To mitigate this risk, researchers have explored differentially private training methods for GNN models. Existing privacy-preserving approaches, however, face significant challenges. They often incur high computational costs during training or struggle to generalize across various GNN models and task objectives. To address these limitations, we introduce Differentially Private Graph Coarsening (DPGC), a novel method that tackles two key challenges in GNN training: scalability and privacy guarantees that are independent of the downstream task or GNN model. Through comprehensive experiments on six datasets across diverse prediction tasks, we demonstrate that  DPGC sets new benchmarks in graph coarsening. Our method achieves superior compression-accuracy trade-offs while maintaining robust privacy guarantees, outperforming state-of-the-art baselines in this domain.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=E9NQUvbsT1",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anjali_Gupta3",
        "name": "Anjali Gupta",
        "name_site": null,
        "openreview_id": "~Anjali_Gupta3",
        "position": 2,
        "gender": "F",
        "homepage_url": "https://anjaliakg17.github.io/about/",
        "dblp_id": null,
        "google_scholar_url": "mnoyw8MAAAAJ",
        "orcid": "0000-0002-7208-7331",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 2.160246899469287,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "E9NQUvbsT1",
      "title": "Task and Model Agnostic Differentially Private Graph Neural Networks via Coarsening",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for analyzing graph-structured data, deriving representations by aggregating information from neighboring nodes. However, this aggregation process inherently increases the risk of exposing confidential data, as a single node may influence the inference process for multiple nodes simultaneously. To mitigate this risk, researchers have explored differentially private training methods for GNN models. Existing privacy-preserving approaches, however, face significant challenges. They often incur high computational costs during training or struggle to generalize across various GNN models and task objectives. To address these limitations, we introduce Differentially Private Graph Coarsening (DPGC), a novel method that tackles two key challenges in GNN training: scalability and privacy guarantees that are independent of the downstream task or GNN model. Through comprehensive experiments on six datasets across diverse prediction tasks, we demonstrate that  DPGC sets new benchmarks in graph coarsening. Our method achieves superior compression-accuracy trade-offs while maintaining robust privacy guarantees, outperforming state-of-the-art baselines in this domain.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=E9NQUvbsT1",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sandeep_Kumar8",
        "name": "Sandeep Kumar",
        "name_site": null,
        "openreview_id": "~Sandeep_Kumar8",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/sandeepkr/home",
        "dblp_id": null,
        "google_scholar_url": "lycMMW8AAAAJ",
        "orcid": null,
        "linkedin_url": "sandeep-kumar-84463332/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 2.160246899469287,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "E9NQUvbsT1",
      "title": "Task and Model Agnostic Differentially Private Graph Neural Networks via Coarsening",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for analyzing graph-structured data, deriving representations by aggregating information from neighboring nodes. However, this aggregation process inherently increases the risk of exposing confidential data, as a single node may influence the inference process for multiple nodes simultaneously. To mitigate this risk, researchers have explored differentially private training methods for GNN models. Existing privacy-preserving approaches, however, face significant challenges. They often incur high computational costs during training or struggle to generalize across various GNN models and task objectives. To address these limitations, we introduce Differentially Private Graph Coarsening (DPGC), a novel method that tackles two key challenges in GNN training: scalability and privacy guarantees that are independent of the downstream task or GNN model. Through comprehensive experiments on six datasets across diverse prediction tasks, we demonstrate that  DPGC sets new benchmarks in graph coarsening. Our method achieves superior compression-accuracy trade-offs while maintaining robust privacy guarantees, outperforming state-of-the-art baselines in this domain.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=E9NQUvbsT1",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Amitabha_Bagchi3",
        "name": "Amitabha Bagchi",
        "name_site": null,
        "openreview_id": "~Amitabha_Bagchi3",
        "position": 4,
        "gender": "M",
        "homepage_url": "http://www.cse.iitd.ac.in/~bagchi",
        "dblp_id": "77/5034",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 2.160246899469287,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "E9NQUvbsT1",
      "title": "Task and Model Agnostic Differentially Private Graph Neural Networks via Coarsening",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for analyzing graph-structured data, deriving representations by aggregating information from neighboring nodes. However, this aggregation process inherently increases the risk of exposing confidential data, as a single node may influence the inference process for multiple nodes simultaneously. To mitigate this risk, researchers have explored differentially private training methods for GNN models. Existing privacy-preserving approaches, however, face significant challenges. They often incur high computational costs during training or struggle to generalize across various GNN models and task objectives. To address these limitations, we introduce Differentially Private Graph Coarsening (DPGC), a novel method that tackles two key challenges in GNN training: scalability and privacy guarantees that are independent of the downstream task or GNN model. Through comprehensive experiments on six datasets across diverse prediction tasks, we demonstrate that  DPGC sets new benchmarks in graph coarsening. Our method achieves superior compression-accuracy trade-offs while maintaining robust privacy guarantees, outperforming state-of-the-art baselines in this domain.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=E9NQUvbsT1",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sayan_Ranu2",
        "name": "Sayan Ranu",
        "name_site": null,
        "openreview_id": "~Sayan_Ranu2",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://www.cse.iitd.ac.in/~sayan/index.html",
        "dblp_id": "38/768",
        "google_scholar_url": "K4w5qYUAAAAJ",
        "orcid": "0000-0003-4147-9372",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 2.160246899469287,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "EP6n8LCEK6",
      "title": "Understanding Prejudice and Fidelity of Diverge-to-Converge Multi-Agent Systems",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Large language model (LLM) agents have demonstrated substantial potential across various tasks, particularly in multi-agent systems. Among these, \\textit{Diverge-to-Converge} (D2C) frameworks stand out for their ability to iteratively diversify and converge intermediate thoughts to improve problem-solving. In this paper, we conduct a comprehensive study on the \\textit{\\textbf{prejudice}} and \\textit{\\textbf{fidelity}} of typical D2C frameworks, including both model-level and society-level frameworks. \n\\ding{182} In the \\textit{prejudice} section, we uncover an inherent \\textit{confirmation bias} in D2C systems, which not only leads to suboptimal performance, but also amplifies social biases, such as gender discrimination and political partisanship. Surprisingly, we find that by reframing open-ended problems into controlled initialized problems, this bias can be leveraged to foster more equitable and effective agent interactions, ultimately improving performance.\n\\ding{183} In the \\textit{fidelity} section, we explore the scaling laws of D2C frameworks at different granularities, revealing that increasing the number of agents enhances performance only when the system is not yet saturated---such as in complex tasks or with weaker agents. In saturated scenarios, however, adding more agents can degrade performance. \nTo facilitate further study, we develop \\texttt{APF-Bench}, a benchmark specifically designed to evaluate such inherent weaknesses of D2C frameworks. \nWe hope our findings offer instructional insights into the strengths and limitations of D2C multi-agent systems, offering guidance for developing more robust and effective collaborative AI systems.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=EP6n8LCEK6",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 10,
      "track_name": "Main Conference",
      "author": {
        "id": "~Shyam_Marjit1",
        "name": "Shyam Marjit",
        "name_site": null,
        "openreview_id": "~Shyam_Marjit1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "347/1029",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": "0000-0002-7385-4432",
        "linkedin_url": "shyam-marjit/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.5,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ERcGlGIM2D",
      "title": "BLIPEE: Fast and Robust BLIP with Adversarially Trained Early Exits",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "In recent years, Vision-Language Models (VLMs) have shown remarkable performance improvements in vision-language tasks. However, their large size poses challenges for real-world applications where inference latency is a concern. To tackle this issue, we propose employing Early Exit (EE) strategies in VLM. However, training exit classifiers in VLMs is challenging, particularly with limited labeled training data. To address this, we introduce BLIPEE, an adversarial training approach within a GAN-based framework. Here, each exit consists of a transformer layer and a classifier, and the transformer layer is adversarially trained to produce feature representations similar to the final layer, while a feature classifier serves as the discriminator. Our method focuses on performing input-adaptive inference that mitigates the overthinking issue and increases inference speed. Experimental results demonstrate the effectiveness of our approach in enhancing accuracy and model robustness by mitigating overthinking and the phenomenon of mid-crisis that we highlight. The anonymized source code is available at https://anonymous.4open.science/status/BLIPEE-3ED3.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ERcGlGIM2D",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Divya_Jyoti_Bajpai1",
        "name": "Divya Jyoti Bajpai",
        "name_site": null,
        "openreview_id": "~Divya_Jyoti_Bajpai1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://www.ieor.iitb.ac.in/node/2823",
        "dblp_id": "357/1369",
        "google_scholar_url": "J-z9diIAAAAJ",
        "orcid": null,
        "linkedin_url": "divya-jyoti-bajpai-139128209",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ERcGlGIM2D",
      "title": "BLIPEE: Fast and Robust BLIP with Adversarially Trained Early Exits",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "In recent years, Vision-Language Models (VLMs) have shown remarkable performance improvements in vision-language tasks. However, their large size poses challenges for real-world applications where inference latency is a concern. To tackle this issue, we propose employing Early Exit (EE) strategies in VLM. However, training exit classifiers in VLMs is challenging, particularly with limited labeled training data. To address this, we introduce BLIPEE, an adversarial training approach within a GAN-based framework. Here, each exit consists of a transformer layer and a classifier, and the transformer layer is adversarially trained to produce feature representations similar to the final layer, while a feature classifier serves as the discriminator. Our method focuses on performing input-adaptive inference that mitigates the overthinking issue and increases inference speed. Experimental results demonstrate the effectiveness of our approach in enhancing accuracy and model robustness by mitigating overthinking and the phenomenon of mid-crisis that we highlight. The anonymized source code is available at https://anonymous.4open.science/status/BLIPEE-3ED3.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ERcGlGIM2D",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manjesh_Kumar_Hanawal1",
        "name": "Manjesh Kumar Hanawal",
        "name_site": null,
        "openreview_id": "~Manjesh_Kumar_Hanawal1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.ieor.iitb.ac.in/mlions",
        "dblp_id": "01/8397",
        "google_scholar_url": "vtVK3KUAAAAJ",
        "orcid": "0000-0002-1807-5487",
        "linkedin_url": "manjesh-kumar-hanawal-a260055/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "EXGahWDp1E",
      "title": "Optimization Proxies using Limited Labeled Data and Training Time - A Semi-Supervised Bayesian Neural Network Approach",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Constrained optimization problems arise in various engineering system operations such as inventory management and electric power grids. However, the requirement to repeatedly solve such optimization problems with uncertain parameters poses a significant computational challenge. This work introduces a learning scheme using Bayesian Neural Networks (BNNs) to solve constrained optimization problems under limited labeled data and restricted model training times. We propose a semi-supervised BNN for this practical but complex regime, wherein training commences in a sandwiched fashion, alternating between a supervised  learning step (using labeled data) for minimizing cost, and an unsupervised learning step (using unlabeled data) for enforcing constraint feasibility. Both supervised and unsupervised steps use a Bayesian approach, where Stochastic Variational Inference is employed for approximate Bayesian inference. We show that the proposed semi-supervised learning method outperforms conventional BNN and deep neural network (DNN) architectures on important non-convex constrained optimization problems from energy network operations, achieving up to a tenfold reduction in expected maximum equality gap and halving the optimality and inequality (feasibility) gaps, without requiring any correction or projection step. By leveraging the BNN's ability to provide posterior samples at minimal computational cost, we demonstrate that a Selection via Posterior (SvP) scheme can further reduce equality gaps by more than 10%. We also provide tight and practically meaningful probabilistic confidence bounds that can be constructed using a low number of labeled testing data and readily adapted to other applications.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=EXGahWDp1E",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Parikshit_Pareek1",
        "name": "Parikshit Pareek",
        "name_site": null,
        "openreview_id": "~Parikshit_Pareek1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://psquare-lab.github.io",
        "dblp_id": "249/9445",
        "google_scholar_url": "LIWKqnYAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Roorkee (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Eaw1ZrsNUN",
      "title": "USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and $\\underline{D}$ogmatism in Long $\\underline{C}$onversations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Although prior studies have explored Stance and Dogmatism in user conversations, their datasets are constructed at the post level, treating each post as independent and randomly sampling posts from conversation threads. Thus, Stance and Dogmatism labels in these datasets cannot capture the user's opinion fluctuations expressed throughout the entire conversation context. However, identifying user's opinion fluctuations in long conversation threads on various topics can be extremely critical for enhanced personalization, market research, political campaigns, customer service, conflict resolution, targeted advertising, and content moderation. Hence, training language models to automate this task is critical. However, to train such models, gathering manual annotations has multiple challenges: 1) It is time-consuming and costly; 2) Conversation threads could be very long, increasing chances of noisy annotations; and 3) Interpreting instances where a user changes their opinion within a conversation is difficult because often such transitions are subtle and not expressed explicitly. Inspired by the recent success of large language models (LLMs) for complex natural language processing tasks, we leverage Mistral Large and GPT-4 to automate the human annotation process on the following two tasks while also providing reasoning: i) User Stance classification, which involves labeling a user's stance of a post in a conversation on a five-point scale; ii) User Dogmatism classification, which deals with labeling a user's overall opinion in the conversation on a four-point scale. The majority voting on zero-shot, one-shot, and few-shot annotations from these two LLMs on 764 multi-user Reddit conversations helps us curate the USDC dataset. USDC is then used to finetune and instruction-tune multiple deployable small language models for the 5-class stance and 4-class dogmatism classification tasks. Additionally, human annotations on 200 test conversations achieved inter-annotator agreement scores of 0.49 for stance and 0.50 for dogmatism, indicating a reasonable level of consistency between human and LLM annotations. We make the code and dataset publicly available [https://anonymous.4open.science/r/USDC-0F7F].",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Eaw1ZrsNUN",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~mounika_marreddy1",
        "name": "mounika marreddy",
        "name_site": null,
        "openreview_id": "~mounika_marreddy1",
        "position": 1,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "206/3366",
        "google_scholar_url": "Ikqyo5sAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology, Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Eaw1ZrsNUN",
      "title": "USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and $\\underline{D}$ogmatism in Long $\\underline{C}$onversations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Although prior studies have explored Stance and Dogmatism in user conversations, their datasets are constructed at the post level, treating each post as independent and randomly sampling posts from conversation threads. Thus, Stance and Dogmatism labels in these datasets cannot capture the user's opinion fluctuations expressed throughout the entire conversation context. However, identifying user's opinion fluctuations in long conversation threads on various topics can be extremely critical for enhanced personalization, market research, political campaigns, customer service, conflict resolution, targeted advertising, and content moderation. Hence, training language models to automate this task is critical. However, to train such models, gathering manual annotations has multiple challenges: 1) It is time-consuming and costly; 2) Conversation threads could be very long, increasing chances of noisy annotations; and 3) Interpreting instances where a user changes their opinion within a conversation is difficult because often such transitions are subtle and not expressed explicitly. Inspired by the recent success of large language models (LLMs) for complex natural language processing tasks, we leverage Mistral Large and GPT-4 to automate the human annotation process on the following two tasks while also providing reasoning: i) User Stance classification, which involves labeling a user's stance of a post in a conversation on a five-point scale; ii) User Dogmatism classification, which deals with labeling a user's overall opinion in the conversation on a four-point scale. The majority voting on zero-shot, one-shot, and few-shot annotations from these two LLMs on 764 multi-user Reddit conversations helps us curate the USDC dataset. USDC is then used to finetune and instruction-tune multiple deployable small language models for the 5-class stance and 4-class dogmatism classification tasks. Additionally, human annotations on 200 test conversations achieved inter-annotator agreement scores of 0.49 for stance and 0.50 for dogmatism, indicating a reasonable level of consistency between human and LLM annotations. We make the code and dataset publicly available [https://anonymous.4open.science/r/USDC-0F7F].",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Eaw1ZrsNUN",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Venkata_Charan_Chinni1",
        "name": "Venkata Charan Chinni",
        "name_site": null,
        "openreview_id": "~Venkata_Charan_Chinni1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "yHwdZLcAAAAJ",
        "orcid": null,
        "linkedin_url": "venkata-charan-chinni-4a569615a/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Eaw1ZrsNUN",
      "title": "USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and $\\underline{D}$ogmatism in Long $\\underline{C}$onversations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Although prior studies have explored Stance and Dogmatism in user conversations, their datasets are constructed at the post level, treating each post as independent and randomly sampling posts from conversation threads. Thus, Stance and Dogmatism labels in these datasets cannot capture the user's opinion fluctuations expressed throughout the entire conversation context. However, identifying user's opinion fluctuations in long conversation threads on various topics can be extremely critical for enhanced personalization, market research, political campaigns, customer service, conflict resolution, targeted advertising, and content moderation. Hence, training language models to automate this task is critical. However, to train such models, gathering manual annotations has multiple challenges: 1) It is time-consuming and costly; 2) Conversation threads could be very long, increasing chances of noisy annotations; and 3) Interpreting instances where a user changes their opinion within a conversation is difficult because often such transitions are subtle and not expressed explicitly. Inspired by the recent success of large language models (LLMs) for complex natural language processing tasks, we leverage Mistral Large and GPT-4 to automate the human annotation process on the following two tasks while also providing reasoning: i) User Stance classification, which involves labeling a user's stance of a post in a conversation on a five-point scale; ii) User Dogmatism classification, which deals with labeling a user's overall opinion in the conversation on a four-point scale. The majority voting on zero-shot, one-shot, and few-shot annotations from these two LLMs on 764 multi-user Reddit conversations helps us curate the USDC dataset. USDC is then used to finetune and instruction-tune multiple deployable small language models for the 5-class stance and 4-class dogmatism classification tasks. Additionally, human annotations on 200 test conversations achieved inter-annotator agreement scores of 0.49 for stance and 0.50 for dogmatism, indicating a reasonable level of consistency between human and LLM annotations. We make the code and dataset publicly available [https://anonymous.4open.science/r/USDC-0F7F].",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Eaw1ZrsNUN",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manish_Gupta1",
        "name": "Manish Gupta",
        "name_site": null,
        "openreview_id": "~Manish_Gupta1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/manishg/",
        "dblp_id": "g/ManishGupta1.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=eX9PSu0AAAAJ",
        "orcid": "0000-0002-2843-3110",
        "linkedin_url": "manishsgupta/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Ei9KiIzgxK",
      "title": "Synthetic Data is Sufficient for Zero-Shot Visual Generalization from Offline Data",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Offline reinforcement learning (RL) offers a promising framework for training agents using pre-collected datasets without the need for further environment interaction. However, policies trained on offline data often struggle to generalise\ndue to limited exposure to diverse states. The complexity of visual data introduces additional challenges such as noise, distractions, and spurious correlations, which can misguide the policy and increase the risk of overfitting if the training data is not sufficiently diverse. Indeed, this makes it challenging to leverage vision-based offline data in training robust agents that can generalize to unseen environments. To solve this problem, we propose a simple approach—generating additional synthetic data. We propose a two-step process, first $augmenting$ the originally collected offline data to improve zero-shot generalization by introducing diversity, then using a diffusion model to $generate$ additional data in latent space. We test our method across both continuous action spaces (Visual D4RL) and discrete action spaces (Procgen), demonstrating that it significantly improves generalization without requiring any algorithmic changes to existing model-free offline RL methods. We show that our method not only increases the diversity of the training data but also significantly reduces the generalization gap at test time while maintaining computational efficiency. We believe this approach could fuel additional progress in generating synthetic data to train more general agents in the future.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Ei9KiIzgxK",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ilija_Bogunovic2",
        "name": "Ilija Bogunovic",
        "name_site": null,
        "openreview_id": "~Ilija_Bogunovic1",
        "position": 3,
        "gender": "M",
        "homepage_url": "http://ilijabogunovic.com/",
        "dblp_id": "142/2725",
        "google_scholar_url": "xMvt3NEAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Swiss Federal Institute of Technology (Switzerland)",
        "countries": [
          "Switzerland"
        ],
        "country_codes": [
          "CH"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Exnt2DcdKD",
      "title": "NIRANTAR: Continual Learning with New Languages and Domains on Real-world Speech Data",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We present Nirantar based on a large-scale effort to collect extempore and conversational speech data from participants spanning 22 languages across diverse locations in India. Given the extensive number of languages and locations involved, data is collected in incremental batches. Each batch introduces new languages, new domains (locations), or both, creating a practical playground for continual learning (CL). Nirantar contains a total of  3250 hours of human-transcribed speech data covering 208 Indian districts across 22 languages, with 1720 hours newly released as a part of this work. The data inflow and resulting multilingual multi-domain episodes are based on real-world data collection rather than simulated episodes commonly found in existing CL datasets. In particular, the amount of data collected and the number of languages and domains involved are not uniform across episodes, reflecting a practical and real-world continual learning scenario. This dataset serves as a playground for training and evaluating CL approaches in three different scenarios: Language-Incremental (LIL), Domain-Incremental (DIL), and the novel Language-Incremental Domain-Incremental Learning (LIDIL), which has not been studied before. To establish the dataset's usefulness, we evaluate several existing CL approaches within these scenarios. Our findings indicate that the behaviour of these algorithms varies across the three scenarios, emphasizing the need for detailed independent studies of each.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Exnt2DcdKD",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Tahir_Javed1",
        "name": "Tahir Javed",
        "name_site": null,
        "openreview_id": "~Tahir_Javed1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "MGsT47cAAAAJ",
        "orcid": null,
        "linkedin_url": "tahirjmakhdoomi",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.8,
        "rating_std": 1.16619037896906,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Exnt2DcdKD",
      "title": "NIRANTAR: Continual Learning with New Languages and Domains on Real-world Speech Data",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We present Nirantar based on a large-scale effort to collect extempore and conversational speech data from participants spanning 22 languages across diverse locations in India. Given the extensive number of languages and locations involved, data is collected in incremental batches. Each batch introduces new languages, new domains (locations), or both, creating a practical playground for continual learning (CL). Nirantar contains a total of  3250 hours of human-transcribed speech data covering 208 Indian districts across 22 languages, with 1720 hours newly released as a part of this work. The data inflow and resulting multilingual multi-domain episodes are based on real-world data collection rather than simulated episodes commonly found in existing CL datasets. In particular, the amount of data collected and the number of languages and domains involved are not uniform across episodes, reflecting a practical and real-world continual learning scenario. This dataset serves as a playground for training and evaluating CL approaches in three different scenarios: Language-Incremental (LIL), Domain-Incremental (DIL), and the novel Language-Incremental Domain-Incremental Learning (LIDIL), which has not been studied before. To establish the dataset's usefulness, we evaluate several existing CL approaches within these scenarios. Our findings indicate that the behaviour of these algorithms varies across the three scenarios, emphasizing the need for detailed independent studies of each.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Exnt2DcdKD",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Kaushal_Santosh_Bhogale1",
        "name": "Kaushal Santosh Bhogale",
        "name_site": null,
        "openreview_id": "~Kaushal_Santosh_Bhogale1",
        "position": 2,
        "gender": "M",
        "homepage_url": "http://kaushalbhogale.in",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.8,
        "rating_std": 1.16619037896906,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Exnt2DcdKD",
      "title": "NIRANTAR: Continual Learning with New Languages and Domains on Real-world Speech Data",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We present Nirantar based on a large-scale effort to collect extempore and conversational speech data from participants spanning 22 languages across diverse locations in India. Given the extensive number of languages and locations involved, data is collected in incremental batches. Each batch introduces new languages, new domains (locations), or both, creating a practical playground for continual learning (CL). Nirantar contains a total of  3250 hours of human-transcribed speech data covering 208 Indian districts across 22 languages, with 1720 hours newly released as a part of this work. The data inflow and resulting multilingual multi-domain episodes are based on real-world data collection rather than simulated episodes commonly found in existing CL datasets. In particular, the amount of data collected and the number of languages and domains involved are not uniform across episodes, reflecting a practical and real-world continual learning scenario. This dataset serves as a playground for training and evaluating CL approaches in three different scenarios: Language-Incremental (LIL), Domain-Incremental (DIL), and the novel Language-Incremental Domain-Incremental Learning (LIDIL), which has not been studied before. To establish the dataset's usefulness, we evaluate several existing CL approaches within these scenarios. Our findings indicate that the behaviour of these algorithms varies across the three scenarios, emphasizing the need for detailed independent studies of each.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Exnt2DcdKD",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mitesh_M_Khapra1",
        "name": "Mitesh M Khapra",
        "name_site": null,
        "openreview_id": "~Mitesh_M_Khapra1",
        "position": 3,
        "gender": "M",
        "homepage_url": "http://www.cse.iitm.ac.in/~miteshk",
        "dblp_id": "90/7967",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=DV8z8DYAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.8,
        "rating_std": 1.16619037896906,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "FNGZqMp6Fi",
      "title": "MicroCrackAttentionNeXt: Advancing Microcrack Detection in Wave Field Analysis Using Deep Neural Networks through Feature Visualization.",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Micro Crack detection using deep neural networks(DNNs) through an automated pipeline using wave fields interacting with the damaged areas is highly sought after. However, these high dimensional spatio-temporal crack data are limited, moreover these dataset have large dimension in the temporal domain. The dataset exhibits a pronounced class imbalance, with crack pixels accounting for an average of only 5% of the total pixels per sample. This severe imbalance presents a challenge for deep learning models when dealing with various microscale cracks, as the network tends to favor the majority class, often resulting in reduced detection accuracy. This study proposes an asymmetric encoder–decoder network with Adaptive Feature Reutilization Block for micro-crack detection. The impact of various activation and loss functions were examined through feature space visualisation using manifold discovery and analysis (MDA) algorithm. The optimized architecture and training methodology achieved an accuracy of 87.74%.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=FNGZqMp6Fi",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Fatahlla_Moreh1",
        "name": "Fatahlla Moreh",
        "name_site": null,
        "openreview_id": "~Fatahlla_Moreh1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "fatahlla-moreh-926a0021b/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Aligarh Muslim University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.2,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 4.0,
        "confidence_std": 0.6324555320336759,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "FYvZCwdb6F",
      "title": "MOMENTUM MEETS VIRALITY: A NOVEL METRIC FOR UNMASKING SOCIAL BIAS IN VIRAL TWEETS",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Predicting which social media posts will go viral is a critical but complex task in the field of computational social science. Previous studies have utilized various measures to forecast the virality of tweets or Facebook posts, but these approaches exhibit limitations, particularly in the absence of a virality metric that specifically considers social biases. In this paper, we test existing metrics and introduce a new metric, $\\textbf{ViralTweet Score (VTS)}$, inspired by principles of momentum from physics to better predict a tweet's virality given that it consists of social biases. We compare this new metric with others, highlighting the advantages and disadvantages of each of them as a virality measurement metric. We release the $\\textbf{ViralTweets Dataset}$ with $\\mathbf{88.8k}$ Hindi tweets and corresponding virality labels based on our VTS metric. We also show how social biases in posts can influence their potential to go viral. We test our hypothesis that VTS is a better metric using two methodologies and we show how VTS achieves an F1 score of 0.87 based on pairwise evaluation methodology and an overall F1 score of 0.58 based on our clustering-based verification methodology. Our work offers a novel metric for understanding tweet virality for biased tweets and opens the door for more equitable and effective social media analytics by considering the role of social biases in virality.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=FYvZCwdb6F",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Nihar_Ranjan_Sahoo1",
        "name": "Nihar Ranjan Sahoo",
        "name_site": null,
        "openreview_id": "~Nihar_Ranjan_Sahoo1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://sahoonihar.github.io/",
        "dblp_id": "321/3442.html",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": "nihar-nrs26",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "FYvZCwdb6F",
      "title": "MOMENTUM MEETS VIRALITY: A NOVEL METRIC FOR UNMASKING SOCIAL BIAS IN VIRAL TWEETS",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Predicting which social media posts will go viral is a critical but complex task in the field of computational social science. Previous studies have utilized various measures to forecast the virality of tweets or Facebook posts, but these approaches exhibit limitations, particularly in the absence of a virality metric that specifically considers social biases. In this paper, we test existing metrics and introduce a new metric, $\\textbf{ViralTweet Score (VTS)}$, inspired by principles of momentum from physics to better predict a tweet's virality given that it consists of social biases. We compare this new metric with others, highlighting the advantages and disadvantages of each of them as a virality measurement metric. We release the $\\textbf{ViralTweets Dataset}$ with $\\mathbf{88.8k}$ Hindi tweets and corresponding virality labels based on our VTS metric. We also show how social biases in posts can influence their potential to go viral. We test our hypothesis that VTS is a better metric using two methodologies and we show how VTS achieves an F1 score of 0.87 based on pairwise evaluation methodology and an overall F1 score of 0.58 based on our clustering-based verification methodology. Our work offers a novel metric for understanding tweet virality for biased tweets and opens the door for more equitable and effective social media analytics by considering the role of social biases in virality.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=FYvZCwdb6F",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Pushpak_Bhattacharyya1",
        "name": "Pushpak Bhattacharyya",
        "name_site": null,
        "openreview_id": "~Pushpak_Bhattacharyya1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://www.cse.iitb.ac.in/~pb/",
        "dblp_id": "p/PushpakBhattacharyya",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=vvg-pAkAAAAJ",
        "orcid": null,
        "linkedin_url": "pushpakbh/?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Fjkree2o8N",
      "title": "OIDA-QA: A Multimodal Benchmark for Analyzing the Opioid Industry Document Archive",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The opioid crisis is a serious public health issue that requires innovative solutions for effective analysis and deeper understanding. \nDespite the vast amounts of data in the Opioid Industry Documents Archive (OIDA), the complexity, multimodal nature, and specialized characteristics of healthcare data necessitate more advanced methods and models tailored to specific data types and detailed annotations, ensuring the precision and professionalism in the analysis.\nIn this paper, we tackle this challenge by organizing the original dataset according to document attributes and constructing a benchmark with 400k training documents and 10k for testing. We extract extensive multimodal information from each document, including textual, visual, and layout information, to capture a wide range of features. Given the extracted dense information, we collect a comprehensive dataset comprising over 3 million question-answer pairs with the assistance of multiple AI models. \nWe further develop domain-specific Large Language Models (LLMs) and investigate the impact of multimodal data on task performance.\nOur benchmarking and model efforts strive to produce an AI assistant system which can efficiently process the dataset and extract valuable insights.\nPreliminary results indicate the improvements with our AI assistant in document information extraction and question-answering tasks, highlighting the effectiveness of proposed benchmark in addressing the opioid crisis.\nThe data and model will be made publicly available for research.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Fjkree2o8N",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 20,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anqi_Liu2",
        "name": "Anqi Liu",
        "name_site": null,
        "openreview_id": "~Anqi_Liu2",
        "position": 14,
        "gender": "F",
        "homepage_url": "https://anqiliu-ai.github.io/",
        "dblp_id": null,
        "google_scholar_url": "Q8yp6zQAAAAJ",
        "orcid": "0000-0002-0468-5698",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Johns Hopkins University (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "GDd5H92egZ",
      "title": "ReFeR: Improving Evaluation and Reasoning through Hierarchy of Models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Assessing the quality of outputs generated by generative models, such as large language models and vision language models, presents notable challenges. Traditional methods for evaluation typically rely on either human assessments, which are resource-intensive, or automatic metrics that often show a low correlation with human judgment. Another common approach is to use deep learning systems, which not only consume a substantial amount of compute and time but also require extensive training data. In this study, we introduce a tuning-free framework called ReFeR, designed to evaluate generative outputs, including both text and images, by leveraging a 2-level hierarchy of LLMs and VLMs themselves.  We rigorously evaluate our framework, ReFeR, across four diverse evaluation tasks. The framework not only improves the accuracy of these evaluations, surpassing previous benchmarks but also generates constructive feedback. Interestingly, the framework is also applicable to reasoning tasks. Experiments on four reasoning tasks demonstrate superior collective reasoning abilities of the framework. We present two variants of the framework: ReFeR-Turbo, optimized for accelerated performance, and ReFeR-Lite, offering a more test-time compute efficient solution. ReFeR-Lite is $\\sim12-14\\times$ more test-time compute efficient than previous works while being comparably accurate to ReFeR-Turbo.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=GDd5H92egZ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yaswanth_Narsupalli1",
        "name": "Yaswanth Narsupalli",
        "name_site": null,
        "openreview_id": "~Yaswanth_Narsupalli1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "359/0633.html",
        "google_scholar_url": "0xLN_4gAAAAJ",
        "orcid": "0009-0001-7364-8188",
        "linkedin_url": "narsupalli-yaswanth/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.4,
        "rating_std": 0.48989794855663565,
        "confidence_mean": 3.6,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "GDd5H92egZ",
      "title": "ReFeR: Improving Evaluation and Reasoning through Hierarchy of Models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Assessing the quality of outputs generated by generative models, such as large language models and vision language models, presents notable challenges. Traditional methods for evaluation typically rely on either human assessments, which are resource-intensive, or automatic metrics that often show a low correlation with human judgment. Another common approach is to use deep learning systems, which not only consume a substantial amount of compute and time but also require extensive training data. In this study, we introduce a tuning-free framework called ReFeR, designed to evaluate generative outputs, including both text and images, by leveraging a 2-level hierarchy of LLMs and VLMs themselves.  We rigorously evaluate our framework, ReFeR, across four diverse evaluation tasks. The framework not only improves the accuracy of these evaluations, surpassing previous benchmarks but also generates constructive feedback. Interestingly, the framework is also applicable to reasoning tasks. Experiments on four reasoning tasks demonstrate superior collective reasoning abilities of the framework. We present two variants of the framework: ReFeR-Turbo, optimized for accelerated performance, and ReFeR-Lite, offering a more test-time compute efficient solution. ReFeR-Lite is $\\sim12-14\\times$ more test-time compute efficient than previous works while being comparably accurate to ReFeR-Turbo.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=GDd5H92egZ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manish_Gupta1",
        "name": "Manish Gupta",
        "name_site": null,
        "openreview_id": "~Manish_Gupta1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/manishg/",
        "dblp_id": "g/ManishGupta1.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=eX9PSu0AAAAJ",
        "orcid": "0000-0002-2843-3110",
        "linkedin_url": "manishsgupta/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.4,
        "rating_std": 0.48989794855663565,
        "confidence_mean": 3.6,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "GDd5H92egZ",
      "title": "ReFeR: Improving Evaluation and Reasoning through Hierarchy of Models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Assessing the quality of outputs generated by generative models, such as large language models and vision language models, presents notable challenges. Traditional methods for evaluation typically rely on either human assessments, which are resource-intensive, or automatic metrics that often show a low correlation with human judgment. Another common approach is to use deep learning systems, which not only consume a substantial amount of compute and time but also require extensive training data. In this study, we introduce a tuning-free framework called ReFeR, designed to evaluate generative outputs, including both text and images, by leveraging a 2-level hierarchy of LLMs and VLMs themselves.  We rigorously evaluate our framework, ReFeR, across four diverse evaluation tasks. The framework not only improves the accuracy of these evaluations, surpassing previous benchmarks but also generates constructive feedback. Interestingly, the framework is also applicable to reasoning tasks. Experiments on four reasoning tasks demonstrate superior collective reasoning abilities of the framework. We present two variants of the framework: ReFeR-Turbo, optimized for accelerated performance, and ReFeR-Lite, offering a more test-time compute efficient solution. ReFeR-Lite is $\\sim12-14\\times$ more test-time compute efficient than previous works while being comparably accurate to ReFeR-Turbo.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=GDd5H92egZ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Pawan_Goyal1",
        "name": "Pawan Goyal",
        "name_site": null,
        "openreview_id": "~Pawan_Goyal1",
        "position": 5,
        "gender": "M",
        "homepage_url": "http://cse.iitkgp.ac.in/~pawang/",
        "dblp_id": "77/2307-2",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=F14FHsIAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.4,
        "rating_std": 0.48989794855663565,
        "confidence_mean": 3.6,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "GIFn3ibnKa",
      "title": "Explore To Mimic: A Reinforcement Learning Based Agent To Generate Online Signatures",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Recent advancements in utilising decision making capability of Reinforcement Learning (RL) have paved the way for innovative approaches in data generation. This research explores the application of model free on-policy RL algorithms for generating online signatures and its controlled variations. Online signatures are captured via e-pads as sequential structural coordinates. In this study, we have introduced a robust on-policy RL agent named as SIGN-Agent, capable of  generating online signatures accurately. Unlike other RL algorithms, on-policy RL directly learns from the agent's current policy, offering significant advantages in stability and faster convergence for sequential decision-making. The proposed SIGN-Agent operates in a random continuous action space with controlled exploration limits, allowing it to capture complex signature patterns while minimizing errors over time. The downstream applications of this system can be extended in diverse fields such as enhancing the robustness of signature authentication systems, supporting robotics, and even diagnosing neurological disorders. By generating reliable, human-like online signatures, our approach strengthens signature authentication systems by reducing susceptibility towards system-generated forgeries, if trained against them. Additionally, the proposed work is optimized for low-footprint edge devices, enabling it to function efficiently in the area of robotics for online signature generation tasks. Experimental results, tested on large, publicly available datasets, demonstrate the effectiveness of model free on-policy RL algorithms in generating online signature trajectories, that closely resemble user's reference signatures. Our approach highlights the potential of model free on-policy RL as an advancement in the field of data generation targeting the domain of online signatures in this research.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=GIFn3ibnKa",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anurag_Pandey1",
        "name": "Anurag Pandey",
        "name_site": null,
        "openreview_id": "~Anurag_Pandey1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.co.in/citations?user=WtlVdaYAAAAJ",
        "orcid": null,
        "linkedin_url": "https://in.linkedin.com/in/anurag-pandey-5244b885?",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Mandi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.6666666666666665,
        "rating_std": 1.8856180831641267,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "GIFn3ibnKa",
      "title": "Explore To Mimic: A Reinforcement Learning Based Agent To Generate Online Signatures",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Recent advancements in utilising decision making capability of Reinforcement Learning (RL) have paved the way for innovative approaches in data generation. This research explores the application of model free on-policy RL algorithms for generating online signatures and its controlled variations. Online signatures are captured via e-pads as sequential structural coordinates. In this study, we have introduced a robust on-policy RL agent named as SIGN-Agent, capable of  generating online signatures accurately. Unlike other RL algorithms, on-policy RL directly learns from the agent's current policy, offering significant advantages in stability and faster convergence for sequential decision-making. The proposed SIGN-Agent operates in a random continuous action space with controlled exploration limits, allowing it to capture complex signature patterns while minimizing errors over time. The downstream applications of this system can be extended in diverse fields such as enhancing the robustness of signature authentication systems, supporting robotics, and even diagnosing neurological disorders. By generating reliable, human-like online signatures, our approach strengthens signature authentication systems by reducing susceptibility towards system-generated forgeries, if trained against them. Additionally, the proposed work is optimized for low-footprint edge devices, enabling it to function efficiently in the area of robotics for online signature generation tasks. Experimental results, tested on large, publicly available datasets, demonstrate the effectiveness of model free on-policy RL algorithms in generating online signature trajectories, that closely resemble user's reference signatures. Our approach highlights the potential of model free on-policy RL as an advancement in the field of data generation targeting the domain of online signatures in this research.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=GIFn3ibnKa",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~PushapDeep_Singh2",
        "name": "PushapDeep Singh",
        "name_site": null,
        "openreview_id": "~PushapDeep_Singh2",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "https://linkedin.com/in/pushap-singh-78b5767a",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Mandi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.6666666666666665,
        "rating_std": 1.8856180831641267,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "GIFn3ibnKa",
      "title": "Explore To Mimic: A Reinforcement Learning Based Agent To Generate Online Signatures",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Recent advancements in utilising decision making capability of Reinforcement Learning (RL) have paved the way for innovative approaches in data generation. This research explores the application of model free on-policy RL algorithms for generating online signatures and its controlled variations. Online signatures are captured via e-pads as sequential structural coordinates. In this study, we have introduced a robust on-policy RL agent named as SIGN-Agent, capable of  generating online signatures accurately. Unlike other RL algorithms, on-policy RL directly learns from the agent's current policy, offering significant advantages in stability and faster convergence for sequential decision-making. The proposed SIGN-Agent operates in a random continuous action space with controlled exploration limits, allowing it to capture complex signature patterns while minimizing errors over time. The downstream applications of this system can be extended in diverse fields such as enhancing the robustness of signature authentication systems, supporting robotics, and even diagnosing neurological disorders. By generating reliable, human-like online signatures, our approach strengthens signature authentication systems by reducing susceptibility towards system-generated forgeries, if trained against them. Additionally, the proposed work is optimized for low-footprint edge devices, enabling it to function efficiently in the area of robotics for online signature generation tasks. Experimental results, tested on large, publicly available datasets, demonstrate the effectiveness of model free on-policy RL algorithms in generating online signature trajectories, that closely resemble user's reference signatures. Our approach highlights the potential of model free on-policy RL as an advancement in the field of data generation targeting the domain of online signatures in this research.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=GIFn3ibnKa",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arnav_Bhavsar1",
        "name": "Arnav Bhavsar",
        "name_site": null,
        "openreview_id": "~Arnav_Bhavsar1",
        "position": 3,
        "gender": "M",
        "homepage_url": "http://faculty.iitmandi.ac.in/~arnav/",
        "dblp_id": "134/9904.html",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=B4gJ7CoAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Mandi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.6666666666666665,
        "rating_std": 1.8856180831641267,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "GIFn3ibnKa",
      "title": "Explore To Mimic: A Reinforcement Learning Based Agent To Generate Online Signatures",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Recent advancements in utilising decision making capability of Reinforcement Learning (RL) have paved the way for innovative approaches in data generation. This research explores the application of model free on-policy RL algorithms for generating online signatures and its controlled variations. Online signatures are captured via e-pads as sequential structural coordinates. In this study, we have introduced a robust on-policy RL agent named as SIGN-Agent, capable of  generating online signatures accurately. Unlike other RL algorithms, on-policy RL directly learns from the agent's current policy, offering significant advantages in stability and faster convergence for sequential decision-making. The proposed SIGN-Agent operates in a random continuous action space with controlled exploration limits, allowing it to capture complex signature patterns while minimizing errors over time. The downstream applications of this system can be extended in diverse fields such as enhancing the robustness of signature authentication systems, supporting robotics, and even diagnosing neurological disorders. By generating reliable, human-like online signatures, our approach strengthens signature authentication systems by reducing susceptibility towards system-generated forgeries, if trained against them. Additionally, the proposed work is optimized for low-footprint edge devices, enabling it to function efficiently in the area of robotics for online signature generation tasks. Experimental results, tested on large, publicly available datasets, demonstrate the effectiveness of model free on-policy RL algorithms in generating online signature trajectories, that closely resemble user's reference signatures. Our approach highlights the potential of model free on-policy RL as an advancement in the field of data generation targeting the domain of online signatures in this research.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=GIFn3ibnKa",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aditya_Nigam1",
        "name": "Aditya Nigam",
        "name_site": null,
        "openreview_id": "~Aditya_Nigam1",
        "position": 4,
        "gender": "M",
        "homepage_url": "http://faculty.iitmandi.ac.in/~aditya/",
        "dblp_id": "60/7950",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=ffSpknUAAAAJ",
        "orcid": "0000-0003-4755-0619",
        "linkedin_url": "aditya-nigam-150b62102/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Mandi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.6666666666666665,
        "rating_std": 1.8856180831641267,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "GIFn3ibnKa",
      "title": "Explore To Mimic: A Reinforcement Learning Based Agent To Generate Online Signatures",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Recent advancements in utilising decision making capability of Reinforcement Learning (RL) have paved the way for innovative approaches in data generation. This research explores the application of model free on-policy RL algorithms for generating online signatures and its controlled variations. Online signatures are captured via e-pads as sequential structural coordinates. In this study, we have introduced a robust on-policy RL agent named as SIGN-Agent, capable of  generating online signatures accurately. Unlike other RL algorithms, on-policy RL directly learns from the agent's current policy, offering significant advantages in stability and faster convergence for sequential decision-making. The proposed SIGN-Agent operates in a random continuous action space with controlled exploration limits, allowing it to capture complex signature patterns while minimizing errors over time. The downstream applications of this system can be extended in diverse fields such as enhancing the robustness of signature authentication systems, supporting robotics, and even diagnosing neurological disorders. By generating reliable, human-like online signatures, our approach strengthens signature authentication systems by reducing susceptibility towards system-generated forgeries, if trained against them. Additionally, the proposed work is optimized for low-footprint edge devices, enabling it to function efficiently in the area of robotics for online signature generation tasks. Experimental results, tested on large, publicly available datasets, demonstrate the effectiveness of model free on-policy RL algorithms in generating online signature trajectories, that closely resemble user's reference signatures. Our approach highlights the potential of model free on-policy RL as an advancement in the field of data generation targeting the domain of online signatures in this research.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=GIFn3ibnKa",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Dr._Divya_Acharya1",
        "name": "Dr. Divya Acharya",
        "name_site": null,
        "openreview_id": "~Dr._Divya_Acharya1",
        "position": 5,
        "gender": "F",
        "homepage_url": "https://www.hcltech.com/next-ai",
        "dblp_id": null,
        "google_scholar_url": "aDWe5REAAAAJ",
        "orcid": "0000-0003-0206-6428",
        "linkedin_url": "dr-divya-acharya-634724170",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Bennett University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.6666666666666665,
        "rating_std": 1.8856180831641267,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "GIFn3ibnKa",
      "title": "Explore To Mimic: A Reinforcement Learning Based Agent To Generate Online Signatures",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Recent advancements in utilising decision making capability of Reinforcement Learning (RL) have paved the way for innovative approaches in data generation. This research explores the application of model free on-policy RL algorithms for generating online signatures and its controlled variations. Online signatures are captured via e-pads as sequential structural coordinates. In this study, we have introduced a robust on-policy RL agent named as SIGN-Agent, capable of  generating online signatures accurately. Unlike other RL algorithms, on-policy RL directly learns from the agent's current policy, offering significant advantages in stability and faster convergence for sequential decision-making. The proposed SIGN-Agent operates in a random continuous action space with controlled exploration limits, allowing it to capture complex signature patterns while minimizing errors over time. The downstream applications of this system can be extended in diverse fields such as enhancing the robustness of signature authentication systems, supporting robotics, and even diagnosing neurological disorders. By generating reliable, human-like online signatures, our approach strengthens signature authentication systems by reducing susceptibility towards system-generated forgeries, if trained against them. Additionally, the proposed work is optimized for low-footprint edge devices, enabling it to function efficiently in the area of robotics for online signature generation tasks. Experimental results, tested on large, publicly available datasets, demonstrate the effectiveness of model free on-policy RL algorithms in generating online signature trajectories, that closely resemble user's reference signatures. Our approach highlights the potential of model free on-policy RL as an advancement in the field of data generation targeting the domain of online signatures in this research.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=GIFn3ibnKa",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Basu_Verma2",
        "name": "Basu Verma",
        "name_site": null,
        "openreview_id": "~Basu_Verma2",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://vermabasu.github.io/profiles",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "HCL Technologies (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.6666666666666665,
        "rating_std": 1.8856180831641267,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "GVABHyvrRU",
      "title": "Diffusion Compose: Compositional Depth Aware Scene Editing in Diffusion Models",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "We introduce Diffusion Compose, a zero-shot approach for depth-aware scene editing using Text-to-Image diffusion models. While existing methods for 3D-aware editing focus on object-centric control, they do not support compositional depth-aware edits, such as placing objects at specific depths or combining multiple scenes realistically. We address this by incorporating depth-based multiplane scene representation in diffusion models. These planes, placed at fixed depths, can be individually edited or composed to enable 3D-aware scene modifications. However, direct manipulation of multiplane representation of diffusion latents often leads to identity loss or unrealistic blending. To overcome this, we propose a novel multiplane feature guidance technique that gradually aligns source latents with the target edit at each denoising step. We validate Diffusion Compose on two challenging tasks: a) scene composition, blending scenes with consistent depth order and scene illumination, and b) depth-aware object insertion, inserting novel objects at specified depths in a scene while preserving occlusions and scene structure and illumination. Extensive experiments demonstrate that Diffusion Compose significantly outperforms task-specific baselines for object placement and harmonization. A user study further confirms that it produces realistic, identity-preserving, and accurate depth-aware scene edits.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=GVABHyvrRU",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rishubh_Parihar1",
        "name": "Rishubh Parihar",
        "name_site": null,
        "openreview_id": "~Rishubh_Parihar1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "264/3534",
        "google_scholar_url": "RaRoJFYAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "GVABHyvrRU",
      "title": "Diffusion Compose: Compositional Depth Aware Scene Editing in Diffusion Models",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "We introduce Diffusion Compose, a zero-shot approach for depth-aware scene editing using Text-to-Image diffusion models. While existing methods for 3D-aware editing focus on object-centric control, they do not support compositional depth-aware edits, such as placing objects at specific depths or combining multiple scenes realistically. We address this by incorporating depth-based multiplane scene representation in diffusion models. These planes, placed at fixed depths, can be individually edited or composed to enable 3D-aware scene modifications. However, direct manipulation of multiplane representation of diffusion latents often leads to identity loss or unrealistic blending. To overcome this, we propose a novel multiplane feature guidance technique that gradually aligns source latents with the target edit at each denoising step. We validate Diffusion Compose on two challenging tasks: a) scene composition, blending scenes with consistent depth order and scene illumination, and b) depth-aware object insertion, inserting novel objects at specified depths in a scene while preserving occlusions and scene structure and illumination. Extensive experiments demonstrate that Diffusion Compose significantly outperforms task-specific baselines for object placement and harmonization. A user study further confirms that it produces realistic, identity-preserving, and accurate depth-aware scene edits.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=GVABHyvrRU",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sachidanand_VS1",
        "name": "Sachidanand VS",
        "name_site": null,
        "openreview_id": "~Sachidanand_VS1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": "sachidanand-v-s-449573201/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "GVABHyvrRU",
      "title": "Diffusion Compose: Compositional Depth Aware Scene Editing in Diffusion Models",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "We introduce Diffusion Compose, a zero-shot approach for depth-aware scene editing using Text-to-Image diffusion models. While existing methods for 3D-aware editing focus on object-centric control, they do not support compositional depth-aware edits, such as placing objects at specific depths or combining multiple scenes realistically. We address this by incorporating depth-based multiplane scene representation in diffusion models. These planes, placed at fixed depths, can be individually edited or composed to enable 3D-aware scene modifications. However, direct manipulation of multiplane representation of diffusion latents often leads to identity loss or unrealistic blending. To overcome this, we propose a novel multiplane feature guidance technique that gradually aligns source latents with the target edit at each denoising step. We validate Diffusion Compose on two challenging tasks: a) scene composition, blending scenes with consistent depth order and scene illumination, and b) depth-aware object insertion, inserting novel objects at specified depths in a scene while preserving occlusions and scene structure and illumination. Extensive experiments demonstrate that Diffusion Compose significantly outperforms task-specific baselines for object placement and harmonization. A user study further confirms that it produces realistic, identity-preserving, and accurate depth-aware scene edits.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=GVABHyvrRU",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sabariswaran_M1",
        "name": "Sabariswaran M",
        "name_site": null,
        "openreview_id": "~Sabariswaran_M1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://sirabas369.github.io/",
        "dblp_id": "367/0114",
        "google_scholar_url": "Klwb85AAAAAJ",
        "orcid": "0000-0002-6092-565X",
        "linkedin_url": "sabariswaran-mani-48b8b522a/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "GVABHyvrRU",
      "title": "Diffusion Compose: Compositional Depth Aware Scene Editing in Diffusion Models",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "We introduce Diffusion Compose, a zero-shot approach for depth-aware scene editing using Text-to-Image diffusion models. While existing methods for 3D-aware editing focus on object-centric control, they do not support compositional depth-aware edits, such as placing objects at specific depths or combining multiple scenes realistically. We address this by incorporating depth-based multiplane scene representation in diffusion models. These planes, placed at fixed depths, can be individually edited or composed to enable 3D-aware scene modifications. However, direct manipulation of multiplane representation of diffusion latents often leads to identity loss or unrealistic blending. To overcome this, we propose a novel multiplane feature guidance technique that gradually aligns source latents with the target edit at each denoising step. We validate Diffusion Compose on two challenging tasks: a) scene composition, blending scenes with consistent depth order and scene illumination, and b) depth-aware object insertion, inserting novel objects at specified depths in a scene while preserving occlusions and scene structure and illumination. Extensive experiments demonstrate that Diffusion Compose significantly outperforms task-specific baselines for object placement and harmonization. A user study further confirms that it produces realistic, identity-preserving, and accurate depth-aware scene edits.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=GVABHyvrRU",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Venkatesh_Babu_Radhakrishnan2",
        "name": "Venkatesh Babu Radhakrishnan",
        "name_site": null,
        "openreview_id": "~Venkatesh_Babu_Radhakrishnan2",
        "position": 4,
        "gender": "M",
        "homepage_url": "http://cds.iisc.ac.in/faculty/venky",
        "dblp_id": "20/6289",
        "google_scholar_url": "cVg7HrEAAAAJ",
        "orcid": "0000-0002-1926-1804",
        "linkedin_url": "venkatesh-babu-radhakrishnan-16568939",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "H3jGJzw0DN",
      "title": "FedPMVR: Addressing Data Heterogeneity in Federated Learning through Partial Momentum Variance Reduction",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Federated learning (FL) emerges as a promising paradigm for training machine learning models on decentralized data sources while preserving privacy. However, the presence of not independent and identically distributed (non-IID) data among the clients introduces high variance in gradient updates, posing a significant challenge to the global model's performance in terms of accuracy and convergence. To mitigate the adverse effects of data heterogeneity, we propose a novel momentum-based partial variance reduction technique. Our approach adjusts the gradient updates for the final classification layers of the client's neural network by leveraging the gradient differences between local and global models. This adjustment aims to effectively capture and mitigate client drift, a key challenge arises from the presence of non-IID data distributions across clients. We systematically explains client drifts and conduct extensive experiments on three widely-used datasets, demonstrating that our method significantly enhances global model accuracy while reducing the communication rounds needed for convergence. Notably, our momentum-based partial variance reduction technique provides a robust mechanism, rendering more efficient and effective in scenarios with inherently non-IID and heterogeneous data distributions. By addressing the critical challenge of data heterogeneity in FL, our proposed approach paves the way for more reliable and accurate model training while preserving the privacy of decentralized data sources. The code is available at the following link {https://anonymous.4open.science/r/FedPMVR-33C1}.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=H3jGJzw0DN",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Pranab_Sahoo1",
        "name": "Pranab Sahoo",
        "name_site": null,
        "openreview_id": "~Pranab_Sahoo1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "zXd4Hq4AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Patna (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "H3jGJzw0DN",
      "title": "FedPMVR: Addressing Data Heterogeneity in Federated Learning through Partial Momentum Variance Reduction",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Federated learning (FL) emerges as a promising paradigm for training machine learning models on decentralized data sources while preserving privacy. However, the presence of not independent and identically distributed (non-IID) data among the clients introduces high variance in gradient updates, posing a significant challenge to the global model's performance in terms of accuracy and convergence. To mitigate the adverse effects of data heterogeneity, we propose a novel momentum-based partial variance reduction technique. Our approach adjusts the gradient updates for the final classification layers of the client's neural network by leveraging the gradient differences between local and global models. This adjustment aims to effectively capture and mitigate client drift, a key challenge arises from the presence of non-IID data distributions across clients. We systematically explains client drifts and conduct extensive experiments on three widely-used datasets, demonstrating that our method significantly enhances global model accuracy while reducing the communication rounds needed for convergence. Notably, our momentum-based partial variance reduction technique provides a robust mechanism, rendering more efficient and effective in scenarios with inherently non-IID and heterogeneous data distributions. By addressing the critical challenge of data heterogeneity in FL, our proposed approach paves the way for more reliable and accurate model training while preserving the privacy of decentralized data sources. The code is available at the following link {https://anonymous.4open.science/r/FedPMVR-33C1}.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=H3jGJzw0DN",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ashutosh_Tripathi1",
        "name": "Ashutosh Tripathi",
        "name_site": null,
        "openreview_id": "~Ashutosh_Tripathi1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://scholar.google.com/citations?user=9ocag4gAAAAJ&hl=en",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Rajiv Gandhi Institute of Petroleum Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "H3jGJzw0DN",
      "title": "FedPMVR: Addressing Data Heterogeneity in Federated Learning through Partial Momentum Variance Reduction",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Federated learning (FL) emerges as a promising paradigm for training machine learning models on decentralized data sources while preserving privacy. However, the presence of not independent and identically distributed (non-IID) data among the clients introduces high variance in gradient updates, posing a significant challenge to the global model's performance in terms of accuracy and convergence. To mitigate the adverse effects of data heterogeneity, we propose a novel momentum-based partial variance reduction technique. Our approach adjusts the gradient updates for the final classification layers of the client's neural network by leveraging the gradient differences between local and global models. This adjustment aims to effectively capture and mitigate client drift, a key challenge arises from the presence of non-IID data distributions across clients. We systematically explains client drifts and conduct extensive experiments on three widely-used datasets, demonstrating that our method significantly enhances global model accuracy while reducing the communication rounds needed for convergence. Notably, our momentum-based partial variance reduction technique provides a robust mechanism, rendering more efficient and effective in scenarios with inherently non-IID and heterogeneous data distributions. By addressing the critical challenge of data heterogeneity in FL, our proposed approach paves the way for more reliable and accurate model training while preserving the privacy of decentralized data sources. The code is available at the following link {https://anonymous.4open.science/r/FedPMVR-33C1}.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=H3jGJzw0DN",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sriparna_Saha1",
        "name": "Sriparna Saha",
        "name_site": null,
        "openreview_id": "~Sriparna_Saha1",
        "position": 3,
        "gender": "F",
        "homepage_url": "http://www.iitp.ac.in/~sriparna",
        "dblp_id": "27/1664-1",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=Fj7jA_AAAAAJ",
        "orcid": null,
        "linkedin_url": "sriparna-saha-1a1338161/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Patna (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "IFOgfaX2Fj",
      "title": "Automated Zonal level implant loosening detection from Hip X-ray using a multi-staged approach",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Hip arthroplasty is a surgical procedure that involves the replacement of a patient’s hip joint with a prosthetic implant. While these implants are initially effective, they may eventually fail and necessitate revision surgery. It is important to identify the 3 Charnley and 7 Gruen zones around the implant and then identify the zone-wise radiolucency which indicates loosening for effective pre and post-operative planning. Despite the importance of zones, there is a lack of automation attempts in this field. In this work, we have proposed a 3-stage algorithm that detects the sanity of the image for diagnosis, segments into the zones, and then identifies radiolucency within the zones. We have demonstrated a 94% accuracy for Fit/Not Fit segregation, a 0.95 dice score for our zonal segmentation, and a 98% overall loosening accuracy. Obtaining an average dice score of 0.92 in the segmentation of zones and 0.93 accuracy on loosening detection on a blind dataset indicates the robustness of the proposed algorithm. This work will contribute to the development of more efficient and accurate models to detect implant loosening.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=IFOgfaX2Fj",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~DIVYA_MANOHARLAL_BHATIA1",
        "name": "DIVYA MANOHARLAL BHATIA",
        "name_site": null,
        "openreview_id": "~DIVYA_MANOHARLAL_BHATIA1",
        "position": 1,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "divya658bhatia/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tata Consultancy Services Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 1.6583123951777,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "IFOgfaX2Fj",
      "title": "Automated Zonal level implant loosening detection from Hip X-ray using a multi-staged approach",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Hip arthroplasty is a surgical procedure that involves the replacement of a patient’s hip joint with a prosthetic implant. While these implants are initially effective, they may eventually fail and necessitate revision surgery. It is important to identify the 3 Charnley and 7 Gruen zones around the implant and then identify the zone-wise radiolucency which indicates loosening for effective pre and post-operative planning. Despite the importance of zones, there is a lack of automation attempts in this field. In this work, we have proposed a 3-stage algorithm that detects the sanity of the image for diagnosis, segments into the zones, and then identifies radiolucency within the zones. We have demonstrated a 94% accuracy for Fit/Not Fit segregation, a 0.95 dice score for our zonal segmentation, and a 98% overall loosening accuracy. Obtaining an average dice score of 0.92 in the segmentation of zones and 0.93 accuracy on loosening detection on a blind dataset indicates the robustness of the proposed algorithm. This work will contribute to the development of more efficient and accurate models to detect implant loosening.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=IFOgfaX2Fj",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aparna_Kanakatte_Gurumurthy1",
        "name": "Aparna Kanakatte Gurumurthy",
        "name_site": null,
        "openreview_id": "~Aparna_Kanakatte_Gurumurthy1",
        "position": 2,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "https://www.linkedin.com/public-profile/settings?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_self_edit_contact-info%3BuqPakv3rSOWsCvedWskO6w%3D%3D",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tata Consultancy Services Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 1.6583123951777,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "IFOgfaX2Fj",
      "title": "Automated Zonal level implant loosening detection from Hip X-ray using a multi-staged approach",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Hip arthroplasty is a surgical procedure that involves the replacement of a patient’s hip joint with a prosthetic implant. While these implants are initially effective, they may eventually fail and necessitate revision surgery. It is important to identify the 3 Charnley and 7 Gruen zones around the implant and then identify the zone-wise radiolucency which indicates loosening for effective pre and post-operative planning. Despite the importance of zones, there is a lack of automation attempts in this field. In this work, we have proposed a 3-stage algorithm that detects the sanity of the image for diagnosis, segments into the zones, and then identifies radiolucency within the zones. We have demonstrated a 94% accuracy for Fit/Not Fit segregation, a 0.95 dice score for our zonal segmentation, and a 98% overall loosening accuracy. Obtaining an average dice score of 0.92 in the segmentation of zones and 0.93 accuracy on loosening detection on a blind dataset indicates the robustness of the proposed algorithm. This work will contribute to the development of more efficient and accurate models to detect implant loosening.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=IFOgfaX2Fj",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Murali_Poduval1",
        "name": "Murali Poduval",
        "name_site": null,
        "openreview_id": "~Murali_Poduval1",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": "250/8076.html",
        "google_scholar_url": null,
        "orcid": "0000-0002-6821-0640",
        "linkedin_url": "murali-poduval-3094b1102/?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tata Consultancy Services Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 1.6583123951777,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "IFOgfaX2Fj",
      "title": "Automated Zonal level implant loosening detection from Hip X-ray using a multi-staged approach",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Hip arthroplasty is a surgical procedure that involves the replacement of a patient’s hip joint with a prosthetic implant. While these implants are initially effective, they may eventually fail and necessitate revision surgery. It is important to identify the 3 Charnley and 7 Gruen zones around the implant and then identify the zone-wise radiolucency which indicates loosening for effective pre and post-operative planning. Despite the importance of zones, there is a lack of automation attempts in this field. In this work, we have proposed a 3-stage algorithm that detects the sanity of the image for diagnosis, segments into the zones, and then identifies radiolucency within the zones. We have demonstrated a 94% accuracy for Fit/Not Fit segregation, a 0.95 dice score for our zonal segmentation, and a 98% overall loosening accuracy. Obtaining an average dice score of 0.92 in the segmentation of zones and 0.93 accuracy on loosening detection on a blind dataset indicates the robustness of the proposed algorithm. This work will contribute to the development of more efficient and accurate models to detect implant loosening.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=IFOgfaX2Fj",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~RUPSHA_MUKHERJEE1",
        "name": "RUPSHA MUKHERJEE",
        "name_site": null,
        "openreview_id": "~RUPSHA_MUKHERJEE1",
        "position": 4,
        "gender": "F",
        "homepage_url": "https://openreview.net/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tata Consultancy Services Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 1.6583123951777,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "IZiKBis0AA",
      "title": "AI Derivation and Exploration of Antibiotic Class Spaces",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "This paper presents a novel approach to fragment-based antibiotic drug design design. We introduce a tool called FILTER, which uses chemical structure data, pathway information, and protein targets to predict pharmacokinetic properties of existing and novel drugs. We report on three distinct experiments utilizing FILTER. The first experiment is an in silico analysis that recreates the historical discovery of penicillin derivatives, validating our approach against known outcomes. The second experiment explores the combination of functional groups from different antibiotic classes to create molecules with multiple mechanisms of action. We refer to this approach as hybridization as all synthesized molecules are composed of fragments from both classes. Our final experiment is forward-looking as it explores new chemical spaces to build a library of promising compounds for further antibiotic development. Throughout all these experiments, FILTER serves as an indispensable oracle, predicting physical properties and potential therapeutic efficacy of the new molecular architectures, aiming to accelerate the drug development process and address the challenge of antibiotic resistance. Our approach represents an ongoing, significant shift from traditional drug discovery methods, emphasizing the role of innovative technologies in combating the urgent global threat of antimicrobial resistance.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=IZiKBis0AA",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Supratik_Mukhopadhyay2",
        "name": "Supratik Mukhopadhyay",
        "name_site": null,
        "openreview_id": "~Supratik_Mukhopadhyay2",
        "position": 7,
        "gender": "Not Specified",
        "homepage_url": "https://www.xprize.org/prizes/artificial-intelligence/teams/deepdrug",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "IjLumaGZ4h",
      "title": "ROSE: Reduced Overhead Stereo Event-Intensity Depth Estimation",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Stereo depth estimation using event cameras is a promising approach for real-time vision tasks, offering low-latency, high-speed data capture. However, existing methods often suffer from high computational overhead, limiting their real-time applicability. To address these challenges, we introduce ROSE (Reduced Overhead Stereo Event and Intensity) a Real-Time framework for efficient depth estimation from events and intensity images. Current approaches rely on dense networks that fail to scale with increasing data complexity, constraining both accuracy and speed. In contrast, ROSE incorporates lightweight event representation networks and optimizes the stereo matching process to reduce model size and computational load without compromising accuracy.\nWe replace conventional network components with efficient spatio-temporal representations and streamline adaptive aggregation modules, reducing computational complexity by 1000× compared to previous methods. Furthermore, we adapt event grouping strategies to better align with intensity images, improving the quality of depth estimation under various lighting and motion conditions. Extensive experiments on the DSEC and MVSEC benchmarks demonstrate that ROSE achieves real-time performance, boosting frame rates to 32.2 FPS on DSEC and 66.9 FPS on MVSEC while maintaining competitive depth accuracy. This marks a significant improvement over prior work in terms of speed and scalability, making ROSE a viable solution for real-time stereo depth estimation in resource-constrained environments. Our code and models will be released to support further advancements in the field.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=IjLumaGZ4h",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jonghyun_Choi1",
        "name": "Jonghyun Choi",
        "name_site": null,
        "openreview_id": "~Jonghyun_Choi1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://ppolon.github.io/",
        "dblp_id": "21/11103",
        "google_scholar_url": "uiGWnm4AAAAJ",
        "orcid": "0000-0002-7934-8434",
        "linkedin_url": "jonghyun-choi-459bb615/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Seoul National University (South Korea)",
        "countries": [
          "South Korea"
        ],
        "country_codes": [
          "KR"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 3.6,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "In0phMs7BK",
      "title": "Heterogeneous Federated Learning: A Dual Matching Dataset Distillation Approach",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Federated Learning (FL) often struggles with error accumulation during local training, particularly on heterogeneous data, which hampers overall performance and convergence. While dataset distillation is commonly introduced to FL to enhance efficiency, our work finds that communicating distilled data instead of models can completely get rid of the error accumulation issue, albeit at the cost of exacerbating data heterogeneity across clients. To address the amplified heterogeneity due to distilled data, we propose a novel FL algorithm termed \\textit{FedDualMatch}, which performs dual matching in the way that local distribution matching captures client data distributions while global gradient matching aligns gradients on the server. This dual approach enriches feature representations and enhances convergence stability. It proves effective for FL due to a bounded difference in the testing loss between optimal models trained on the aggregation of either distilled or original data across clients. At the same time, it can converge to within a bounded constant of the optimal model loss. Experiments on controlled heterogeneous dataset MNIST/CIFAR10 and naturally heterogeneous dataset Digital-Five/Office-Home demonstrate its advantages over the state-of-the-art methods that communicate either model or distilled data, in terms of accuracy and convergence. Notably, it maintains accuracy even when data heterogeneity significantly increases, underscoring its potential for practical applications.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=In0phMs7BK",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 8,
      "track_name": "Main Conference",
      "author": {
        "id": "~zhiqiang_xu1",
        "name": "zhiqiang xu",
        "name_site": null,
        "openreview_id": "~zhiqiang_xu1",
        "position": 8,
        "gender": "M",
        "homepage_url": "https://scholar.google.com/citations?user=0R20iBMAAAAJ&hl=en",
        "dblp_id": "72/51-3.html",
        "google_scholar_url": null,
        "orcid": "0000-0002-5693-8933",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Mohamed bin Zayed University of Artificial Intelligence (United Arab Emirates)",
        "countries": [
          "United Arab Emirates"
        ],
        "country_codes": [
          "AE"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 3.6,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "J7hIz9GXKq",
      "title": "Collaborative Compressors in Distributed Mean Estimation with Limited Communication Budge",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Distributed high dimensional mean estimation is a common aggregation routine used often in distributed optimization methods (e.g. federated learning). Most of these applications call for a communication-constrained setting where vectors, whose mean is to be estimated, have to be compressed before sharing. One could independently encode and decode these to achieve compression, but that overlooks the fact that these vectors are often similar with each other.  To exploit these similarities, recently Suresh et al., 2022, Jhunjhunwala et al., 2021, Jiang et al, 2023, proposed multiple {\\em correlation-aware compression schemes.} However, in most cases, the correlations have to be known for these schemes to work. Moreover, a theoretical analysis of graceful degradation of these correlation-aware compression schemes with increasing {\\em dissimilarity} is limited to only the $\\ell_2$-error in  the literature. \n    In this paper, we propose four different collaborative compression schemes  that agnostically exploit the similarities among vectors in a distributed setting.  Our schemes are all simple to implement and computationally efficient, while resulting in big savings in communication. We do a rigorous theoretical analysis of our proposed schemes to show how the $\\ell_2$, $\\ell_\\infty$ and cosine estimation error varies with the degree of similarity among vectors. In the process, we come up with appropriate dissimilarity-measures for these applications as well.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=J7hIz9GXKq",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Harsh_Vardhan1",
        "name": "Harsh Vardhan",
        "name_site": null,
        "openreview_id": "~Harsh_Vardhan1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of California, San Diego (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "J9Ofr1PmvX",
      "title": "UnSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The key components of machine learning are data samples for training, models for learning patterns, and loss functions for optimizing accuracy. Analogously, unlearning can potentially be achieved through anti-data samples (or anti-samples), unlearning methods, and reversed loss functions. While prior research has explored unlearning methods and reversed loss functions, the potential of anti-samples remains largely untapped. In this paper, we introduce UnSTAR: $\\underline{\\text{Un}}$learning with $\\underline{\\text{S}}$elf-$\\underline{\\text{T}}$aught $\\underline{\\text{A}}$nti-Sample $\\underline{\\text{R}}$easoning  for large language models (LLMs). Our contributions are threefold: first, we propose a novel concept of anti-sample-induced unlearning; second, we generate anti-samples by leveraging misleading rationales, which help reverse learned associations and accelerate the unlearning process; and third, we enable fine-grained targeted unlearning, allowing for the selective removal of specific associations without impacting related knowledge—something not achievable by previous works. Results demonstrate that anti-samples offer an efficient, targeted unlearning strategy for LLMs, opening new avenues for privacy-preserving machine learning and model modification.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=J9Ofr1PmvX",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yash_Sinha1",
        "name": "Yash Sinha",
        "name_site": null,
        "openreview_id": "~Yash_Sinha1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Kalinga Institute of Industrial Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 1.118033988749895,
        "confidence_mean": 3.1666666666666665,
        "confidence_std": 0.6871842709362768,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "J9Ofr1PmvX",
      "title": "UnSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The key components of machine learning are data samples for training, models for learning patterns, and loss functions for optimizing accuracy. Analogously, unlearning can potentially be achieved through anti-data samples (or anti-samples), unlearning methods, and reversed loss functions. While prior research has explored unlearning methods and reversed loss functions, the potential of anti-samples remains largely untapped. In this paper, we introduce UnSTAR: $\\underline{\\text{Un}}$learning with $\\underline{\\text{S}}$elf-$\\underline{\\text{T}}$aught $\\underline{\\text{A}}$nti-Sample $\\underline{\\text{R}}$easoning  for large language models (LLMs). Our contributions are threefold: first, we propose a novel concept of anti-sample-induced unlearning; second, we generate anti-samples by leveraging misleading rationales, which help reverse learned associations and accelerate the unlearning process; and third, we enable fine-grained targeted unlearning, allowing for the selective removal of specific associations without impacting related knowledge—something not achievable by previous works. Results demonstrate that anti-samples offer an efficient, targeted unlearning strategy for LLMs, opening new avenues for privacy-preserving machine learning and model modification.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=J9Ofr1PmvX",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mohan_Kankanhalli1",
        "name": "Mohan Kankanhalli",
        "name_site": null,
        "openreview_id": "~Mohan_Kankanhalli1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.comp.nus.edu.sg/~mohan",
        "dblp_id": "09/3613.html",
        "google_scholar_url": "6Lx_eowAAAAJ",
        "orcid": "0000-0002-4846-2015",
        "linkedin_url": "mohan-kankanhalli-583417221",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 1.118033988749895,
        "confidence_mean": 3.1666666666666665,
        "confidence_std": 0.6871842709362768,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "JaRihIHbZm",
      "title": "VideoAgent: Self-Improving Video Generation",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Video generation has been used to generate visual plans for controlling robotic systems. Given an image observation and a language instruction, previous work has generated video plans which are then converted to robot controls to be executed. However, a major bottleneck in leveraging video generation for control lies in the quality of the generated videos, which often suffer from hallucinatory content and unrealistic physics, resulting in low task success when control actions are extracted from the generated videos. While scaling up dataset and model size provides a partial solution, integrating external feedback is both natural and essential for grounding video generation in the real world. With this observation, we propose VideoAgent for self-improving generated video plans based on external feedback. Instead of directly executing the generated video plan, VideoAgent first refines the generated video plans using a novel procedure which we call self-conditioning consistency, utilizing feedback from a pretrained vision-language model (VLM). As the refined video plan is being executed, VideoAgent collects additional data from the environment to further improve video plan generation. Experiments in simulated robotic manipulation from MetaWorld and iTHOR show that VideoAgent drastically reduces hallucination, thereby boosting success rate of downstream manipulation tasks. We further illustrate that VideoAgent can effectively refine real-robot videos, providing an early indicator that robotics can be an effective tool in grounding video generation in the physical world.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=JaRihIHbZm",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sreyas_Venkataraman1",
        "name": "Sreyas Venkataraman",
        "name_site": null,
        "openreview_id": "~Sreyas_Venkataraman1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://vsreyas.github.io",
        "dblp_id": null,
        "google_scholar_url": "Lz5YGiQAAAAJ",
        "orcid": null,
        "linkedin_url": "sreyas-venkataraman-4241b9216/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 7,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "KGRV73Zcqt",
      "title": "Cross Resolution Encoding-Decoding For Detection Transformers",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Detection Transformers (DETR) are renowned object detection pipelines, however\ncomputationally efficient multiscale detection using DETR is still challenging. In\nthis paper, we propose a Cross-Resolution Encoding-Decoding (CRED) mechanism\nthat allows DETR to achieve the accuracy of high-resolution detection while\nhaving the speed of low-resolution detection. CRED is based on two modules;\nCross Resolution Attention Module (CRAM) and One Step Multiscale Attention\n(OSMA). CRAM is designed to transfer the knowledge of low-resolution encoder\noutput to a high-resolution feature. While OSMA is designed to fuse multiscale\nfeatures in a single step and produce a feature map of a desired resolution enriched\nwith multiscale information. When used in prominent DETR methods, CRED\ndelivers accuracy similar to the high-resolution DETR counterpart in roughly 50%\nfewer FLOPs. Specifically, state-of-the-art DN-DETR, when used with CRED\n(calling CRED-DETR), becomes 76% faster, with ∼ 50% reduced FLOPs than its\nhigh-resolution counterpart with 202 G FLOPs on MS-COCO benchmark. We plan\nto release pretrained CRED-DETRs for use by the community.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=KGRV73Zcqt",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ashish_Kumar2",
        "name": "Ashish Kumar",
        "name_site": null,
        "openreview_id": "~Ashish_Kumar2",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://ashishkumar822.github.io",
        "dblp_id": "34/5378-6",
        "google_scholar_url": "n-oRDEYAAAAJ",
        "orcid": null,
        "linkedin_url": "ashishkumar822/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "ScorelabsAI (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "KK29oh8jZs",
      "title": "IN the known, OUT of the ordinary: Probing OOD detection methods with Synthetic datasets.",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Out-of-distribution (OOD) detection is crucial for ensuring the reliability of machine learning models, especially in visual tasks. Most existing benchmarks focus on isolating distribution shifts and creating varying levels of detection difficulty, often relying on manual curation or classifier-based scoring with human annotations. Additionally, large-scale benchmarks are typically derivatives of ImageNet-21k classes or combinations of ImageNet with other datasets. However, no existing work offers a setup where only one attribute such as color or class changes in a controlled manner, while other attributes of the object remain constant. This limits our ability to precisely study the impact of individual attributes on OOD detection performance. We aim to address this by proposing two novel synthetic datasets, SHAPES and CHARS, designed to explore OOD detection under controlled and fine-grained distribution shifts. SHAPES consist of 2D and 3D geometric shapes with variations in color, size, position, and rotation, while CHARS consists of alphanumeric characters with similar variations. Each dataset presents three scenarios: (1) known classes with unseen attributes, (2) unseen classes with known attributes, and (3) entirely novel classes and attributes. We train 10 architectures and assess 13 OOD detection methods across the three scenarios, concentrating on the impact of  attribute shifts on OOD scores, while also conducting additional analysis on how image corruption influences OOD scores. By systematically examining how specific attribute shifts affect OOD scores and the affects of noisy test samples, we aim to bring greater transparency to where these methods succeed or fail, helping to identify their limitations under various conditions.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=KK29oh8jZs",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Amruth_Sagar1",
        "name": "Amruth Sagar",
        "name_site": null,
        "openreview_id": "~Amruth_Sagar1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "373/2332",
        "google_scholar_url": "https://scholar.google.com/citations?view_op=list_works",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "KtqZrNjvjd",
      "title": "Video Active Perception: Efficient Inference-Time Long-Form Video Understanding with Vision-Language Models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Large vision-language models (VLMs) have advanced multimodal tasks such as video question answering (QA), yet they struggle with long-form videos due to the computational burden of processing excessive tokens. Inspired by active perception theory, which posits that models gain information by acquiring data that differ from their expectations, we introduce Video Active Perception (VAP), a training-free method to enhance long-form video QA using VLMs. Our approach treats key frame selection as data acquisition in active perception and leverages a lightweight text-conditioned video generation model to represent prior world knowledge. Empirically, VAP achieves state-of-the-art zero-shot results on long-form video QA datasets such as EgoSchema, NExT-QA, ActivityNet-QA and CLEVRER, achieving an increase of up to 5.6 X efficiency by frames per question over standard GPT-4o, Gemini 1.5 Pro, and LLaVA-OV. Moreover, VAP shows stronger reasoning abilities than previous methods and effectively selects key frames relevant to questions. These findings highlight the potential of leveraging active perception to improve efficiency and effectiveness of long-form video QA.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=KtqZrNjvjd",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aditya_Agrawal3",
        "name": "Aditya Agrawal",
        "name_site": null,
        "openreview_id": "~Aditya_Agrawal3",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://aditya-agrawal-30502.netlify.app/",
        "dblp_id": null,
        "google_scholar_url": "5OP8PEEAAAAJ",
        "orcid": null,
        "linkedin_url": "aditya-agrawal-9aba24208/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Massachusetts Institute of Technology (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.8,
        "rating_std": 0.39999999999999997,
        "confidence_mean": 4.6,
        "confidence_std": 0.48989794855663565,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "KxGGZag9gW",
      "title": "EigenLoRA: Recycle trained Adapters for Resource Efficient Adaptation and Inference",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Low-Rank Adapters (LoRA) are lightweight components that have made fine-tuning large models on domain-specific tasks inexpensive. This has resulted in an abundance of adapters in a growing open-source public community. We ask the question: can these adapters be used to inform and further streamline adaptation to new tasks? We introduce EigenLoRA, a parameter-efficient fine-tuning method that uses trained adapters to perform fast adaptation on new domains with orders of magnitude fewer parameters than LoRA. Our method finds a principal subspace that aligns with the domain of the trained adapters. This allows for efficient and fast adaptation to new tasks in this domain by simply learning coefficients on the principal components of this subspace. Furthermore, EigenLoRA makes inference time task-switching memory efficient. Instead of saving and loading whole LoRAs, EigenLoRA can simply load lightweight coefficients. EigenLoRA works across a variety of domains and tasks and is a viable solution for edge-based and efficient personalization applications.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=KxGGZag9gW",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Raghavendra_Addanki1",
        "name": "Raghavendra Addanki",
        "name_site": null,
        "openreview_id": "~Raghavendra_Addanki1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://raddanki.github.io/",
        "dblp_id": "218/5579",
        "google_scholar_url": "SUPaOhgAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Adobe (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "KxGGZag9gW",
      "title": "EigenLoRA: Recycle trained Adapters for Resource Efficient Adaptation and Inference",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Low-Rank Adapters (LoRA) are lightweight components that have made fine-tuning large models on domain-specific tasks inexpensive. This has resulted in an abundance of adapters in a growing open-source public community. We ask the question: can these adapters be used to inform and further streamline adaptation to new tasks? We introduce EigenLoRA, a parameter-efficient fine-tuning method that uses trained adapters to perform fast adaptation on new domains with orders of magnitude fewer parameters than LoRA. Our method finds a principal subspace that aligns with the domain of the trained adapters. This allows for efficient and fast adaptation to new tasks in this domain by simply learning coefficients on the principal components of this subspace. Furthermore, EigenLoRA makes inference time task-switching memory efficient. Instead of saving and loading whole LoRAs, EigenLoRA can simply load lightweight coefficients. EigenLoRA works across a variety of domains and tasks and is a viable solution for edge-based and efficient personalization applications.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=KxGGZag9gW",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anqi_Liu2",
        "name": "Anqi Liu",
        "name_site": null,
        "openreview_id": "~Anqi_Liu2",
        "position": 7,
        "gender": "F",
        "homepage_url": "https://anqiliu-ai.github.io/",
        "dblp_id": null,
        "google_scholar_url": "Q8yp6zQAAAAJ",
        "orcid": "0000-0002-0468-5698",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Adobe (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "L5gZcmaHB7",
      "title": "Scaling the Heights of Learning with Hierarchical Approaches in Reinforcement Learning",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "This research explores a novel hierarchical representation learning framework designed to enhance planning and reinforcement learning (RL) in complex environments. By decoupling high-level decision-making from low-level control actions, our framework significantly improves sample efficiency and transfer learning performance across diverse tasks. We validate our approach through experiments in various environments, including Meta-World, AirSim, and Habitat AI, demonstrating that our hierarchical model consistently outperforms traditional flat models in cumulative rewards and adaptability to new tasks. This work lays the foundation for scalable AI systems capable of navigating the complexities of real-world applications.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=L5gZcmaHB7",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 1,
      "track_name": "Main Conference",
      "author": {
        "id": "~Harsha_Vardhan_Uckoo1",
        "name": "Harsha Vardhan Uckoo",
        "name_site": null,
        "openreview_id": "~Harsha_Vardhan_Uckoo1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "wJ2k3HAAAAAJ",
        "orcid": null,
        "linkedin_url": "harshauckoo/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Vellore Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 0.0,
        "rating_std": 0.0,
        "confidence_mean": 0.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "LSq9ef8ANs",
      "title": "VaQuitA: Enhancing Alignment in LLM-Assisted Zero-Shot Video Understanding",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Recent advancements in language-model-based video understanding have been progressing at a remarkable pace, spurred by the introduction of Large Language Models (LLMs). However, the focus of prior research has been predominantly on devising a projection layer that maps video features to tokens, an approach that is both rudimentary and inefficient. In our study, we introduce a cutting-edge framework, VaQuitA, designed to refine the synergy between video and textual information. At the data level, instead of sampling frames uniformly, we implement a sampling method guided by CLIP-score rankings, which enables a more aligned selection of frames with the given question. At the feature level, we integrate a trainable Video Perceiver alongside a Visual-Query Transformer (abbreviated as VQ-Former), which bolsters the interplay between the input question and the video features. We also discover that incorporating a simple prompt, ``Please be critical.'', into the LLM input can substantially enhance its video comprehension capabilities. Our experimental results indicate that VaQuitA consistently sets a new benchmark for zero-shot video question-answering tasks and is adept at producing high-quality, multi-turn video dialogues with users. The code will be released.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=LSq9ef8ANs",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Uttaran_Bhattacharya1",
        "name": "Uttaran Bhattacharya",
        "name_site": null,
        "openreview_id": "~Uttaran_Bhattacharya1",
        "position": 4,
        "gender": "M",
        "homepage_url": "http://www.cs.umd.edu/~uttaranb/",
        "dblp_id": "220/7744",
        "google_scholar_url": "xx9nrfoAAAAJ",
        "orcid": "0000-0003-2141-9276",
        "linkedin_url": "uttaran-bhattacharya/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Adobe (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.6,
        "rating_std": 0.7999999999999999,
        "confidence_mean": 3.6,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Lo98rDyfl8",
      "title": "Rainbow Generator: Generating Diverse Data for Name Only Continual Learning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Requiring extensive human supervision is often impractical for continual learning due to its cost, leading to the emergence of ‘name-only continual learning’ that only provides the name of new concepts (e.g., classes) without providing supervised samples. To address the task, recent approach uses web-scraped data but results in issues such as data imbalance, copyright, and privacy concerns. To overcome the limitations of both human supervision and webly supervision, we propose Generative name only Continual Learning (GenCL) using generative models for the name only continual learning. But naïve application of generative models results in limited diversity of generated data. So, we specifically propose a diverse prompt generation method, HIerarchical Recurrent Prompt Generation (HIRPG) as well as COmplexity-NAvigating eNsembler (CONAN) that selects samples with minimal overlap from multiple generative models. We empirically validate that the proposed GenCL outperforms prior arts, even a model trained with fully supervised data, in various tasks including image recognition and multi-modal visual reasoning. Data generated by GenCL is available at https://anonymous.4open.science/r/name-only-continual-E079.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Lo98rDyfl8",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jonghyun_Choi1",
        "name": "Jonghyun Choi",
        "name_site": null,
        "openreview_id": "~Jonghyun_Choi1",
        "position": 7,
        "gender": "M",
        "homepage_url": "https://ppolon.github.io/",
        "dblp_id": "21/11103",
        "google_scholar_url": "uiGWnm4AAAAJ",
        "orcid": "0000-0002-7934-8434",
        "linkedin_url": "jonghyun-choi-459bb615/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "M1CCA6UF0y",
      "title": "AI-Assisted Generation of Difficult Math Questions",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Current LLM training positions mathematical reasoning as a core capability. With publicly available sources fully tapped, there is an unmet demand for diverse and challenging mathematics questions. Relying solely on human experts is both time-consuming and costly, while LLM-generated questions often lack the requisite diversity and difficulty.  We present a design framework that combines the strengths of LLMs with a human-in-the-loop approach to generate a diverse array of challenging math questions. Initially, leveraging LLM metacognition skills [Didolkar et al., 2024], a strong LLM is used to extract core \"skills'' from existing math datasets.  These skills serve as the basis for generating novel and difficult questions by prompting the LLM with random pairs of core skills that must be utilized in the question. The use of two very different skills within each question makes finding such questions an ``out of distribution'' task for both LLMs and humans. Our pipeline employs LLMs to iteratively generate and refine questions and solutions through multi-turn prompting. Human annotators then verify and further refine the questions, with their efficiency enhanced via further LLM interactions. Applying this pipeline on skills extracted from MATH dataset [Hendrycks et al., 2024] resulted in **MATH$^2$** - a dataset of higher quality math questions, as evidenced by: (a)  Lower performance of all models on MATH$^2$ than on MATH (b) Higher performance on MATH when using MATH$^2$ questions as in-context examples.  Although focused on mathematics, our methodology seems applicable to other domains requiring structured reasoning, and potentially as a component of *scalable oversight*. Also of interest is a striking relationship observed between models' performance on the new dataset: the success rate on MATH$^2$ is the square on MATH. This suggests that successfully solving the question in MATH$^2$ requires a nontrivial combination of two distinct math skills.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=M1CCA6UF0y",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Di_He1_1",
        "name": "Di He",
        "name_site": null,
        "openreview_id": "~Anirudh_Goyal1",
        "position": 9,
        "gender": "M",
        "homepage_url": "https://anirudh9119.github.io/",
        "dblp_id": "172/1039",
        "google_scholar_url": "krrh6OUAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (United Kingdom)",
        "countries": [
          "United Kingdom"
        ],
        "country_codes": [
          "GB"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 12,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "N3EFTVCFWX",
      "title": "Spectral Highways: Injecting Homophily into Heterophilic Graphs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "It is widely assumed that standard GNNs perform better on graphs with high homophily, leading to the development of specialised algorithms for heterophilic datasets in recent years. In this work, we both challenge and leverage this assumption. Rather than creating new algorithms, we emphasise the importance of understanding and enriching the data. We introduce a novel data engineering technique, \\textit{Spectral Highways}, that enhances the performance of both heterophilic and non-heterophilic GNNs on heterophilic datasets. Our method augments a given heterophilic graph by adding supernodes, thereby creating a network of highways connecting spectral clusters in the graph. It facilitates additional paths to bring similar nodes closer than dissimilar ones by reducing the average shortest path lengths. We draw both intuitive and empirical connections between the relative decreases in intraclass and interclass average shortest path lengths and shifts in the graph's homophily levels, providing a novel perspective that extends beyond traditional homophily measures. We conduct extensive experiments on seven heterophilic datasets using various GNN architectures and also compare with data-centric techniques, demonstrating significant improvements in node classification performance. Furthermore, our empirical findings highlight the strong sensitivity of several recent GNNs to the random seed used for data splitting, underscoring the importance of this often-overlooked factor in GNN evaluation.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=N3EFTVCFWX",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Karan_Goyal1",
        "name": "Karan Goyal",
        "name_site": null,
        "openreview_id": "~Karan_Goyal1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": "246/8470",
        "google_scholar_url": "https://scholar.google.co.in/citations?hl=en",
        "orcid": null,
        "linkedin_url": "karan-goyal-757727a6/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "N3EFTVCFWX",
      "title": "Spectral Highways: Injecting Homophily into Heterophilic Graphs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "It is widely assumed that standard GNNs perform better on graphs with high homophily, leading to the development of specialised algorithms for heterophilic datasets in recent years. In this work, we both challenge and leverage this assumption. Rather than creating new algorithms, we emphasise the importance of understanding and enriching the data. We introduce a novel data engineering technique, \\textit{Spectral Highways}, that enhances the performance of both heterophilic and non-heterophilic GNNs on heterophilic datasets. Our method augments a given heterophilic graph by adding supernodes, thereby creating a network of highways connecting spectral clusters in the graph. It facilitates additional paths to bring similar nodes closer than dissimilar ones by reducing the average shortest path lengths. We draw both intuitive and empirical connections between the relative decreases in intraclass and interclass average shortest path lengths and shifts in the graph's homophily levels, providing a novel perspective that extends beyond traditional homophily measures. We conduct extensive experiments on seven heterophilic datasets using various GNN architectures and also compare with data-centric techniques, demonstrating significant improvements in node classification performance. Furthermore, our empirical findings highlight the strong sensitivity of several recent GNNs to the random seed used for data splitting, underscoring the importance of this often-overlooked factor in GNN evaluation.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=N3EFTVCFWX",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Saankhya_Samanta1",
        "name": "Saankhya Samanta",
        "name_site": null,
        "openreview_id": "~Saankhya_Samanta1",
        "position": 2,
        "gender": null,
        "homepage_url": "https://www.linkedin.com/in/saankhya-samanta-62a007281/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "saankhya-samanta-62a007281/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Engineering Science and Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "N3EFTVCFWX",
      "title": "Spectral Highways: Injecting Homophily into Heterophilic Graphs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "It is widely assumed that standard GNNs perform better on graphs with high homophily, leading to the development of specialised algorithms for heterophilic datasets in recent years. In this work, we both challenge and leverage this assumption. Rather than creating new algorithms, we emphasise the importance of understanding and enriching the data. We introduce a novel data engineering technique, \\textit{Spectral Highways}, that enhances the performance of both heterophilic and non-heterophilic GNNs on heterophilic datasets. Our method augments a given heterophilic graph by adding supernodes, thereby creating a network of highways connecting spectral clusters in the graph. It facilitates additional paths to bring similar nodes closer than dissimilar ones by reducing the average shortest path lengths. We draw both intuitive and empirical connections between the relative decreases in intraclass and interclass average shortest path lengths and shifts in the graph's homophily levels, providing a novel perspective that extends beyond traditional homophily measures. We conduct extensive experiments on seven heterophilic datasets using various GNN architectures and also compare with data-centric techniques, demonstrating significant improvements in node classification performance. Furthermore, our empirical findings highlight the strong sensitivity of several recent GNNs to the random seed used for data splitting, underscoring the importance of this often-overlooked factor in GNN evaluation.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=N3EFTVCFWX",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vikram_Goyal1",
        "name": "Vikram Goyal",
        "name_site": null,
        "openreview_id": "~Vikram_Goyal1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.iiitd.ac.in/vikram/",
        "dblp_id": "70/6404.html",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=YJaVmSwAAAAJ",
        "orcid": "0000-0003-0769-6381",
        "linkedin_url": "vikram-goyal-7a684213/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "N3EFTVCFWX",
      "title": "Spectral Highways: Injecting Homophily into Heterophilic Graphs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "It is widely assumed that standard GNNs perform better on graphs with high homophily, leading to the development of specialised algorithms for heterophilic datasets in recent years. In this work, we both challenge and leverage this assumption. Rather than creating new algorithms, we emphasise the importance of understanding and enriching the data. We introduce a novel data engineering technique, \\textit{Spectral Highways}, that enhances the performance of both heterophilic and non-heterophilic GNNs on heterophilic datasets. Our method augments a given heterophilic graph by adding supernodes, thereby creating a network of highways connecting spectral clusters in the graph. It facilitates additional paths to bring similar nodes closer than dissimilar ones by reducing the average shortest path lengths. We draw both intuitive and empirical connections between the relative decreases in intraclass and interclass average shortest path lengths and shifts in the graph's homophily levels, providing a novel perspective that extends beyond traditional homophily measures. We conduct extensive experiments on seven heterophilic datasets using various GNN architectures and also compare with data-centric techniques, demonstrating significant improvements in node classification performance. Furthermore, our empirical findings highlight the strong sensitivity of several recent GNNs to the random seed used for data splitting, underscoring the importance of this often-overlooked factor in GNN evaluation.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=N3EFTVCFWX",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mukesh_Mohania1",
        "name": "Mukesh Mohania",
        "name_site": null,
        "openreview_id": "~Mukesh_Mohania1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://www.iiitd.ac.in/mukesh",
        "dblp_id": "85/6670.html",
        "google_scholar_url": "zgaqvNQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "NGF1wDDBMm",
      "title": "AN INFORMATION THEORETIC EVALUATION METRIC FOR STRONG UNLEARNING",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Machine unlearning (MU) aims to remove the influence of specific data from trained models, addressing privacy concerns and ensuring compliance with regulations such as the \"right to be forgotten.\"\nEvaluating strong unlearning, where the unlearned model is indistinguishable from one retrained without the forgetting data, remains a significant challenge in deep neural networks (DNNs).\nCommon black-box metrics, such as variants of membership inference attacks and accuracy comparisons, primarily assess model outputs but often fail to capture residual information in intermediate layers.\nTo bridge this gap, we introduce the Information Difference Index (IDI), a novel white-box metric inspired by information theory.\nIDI quantifies retained information in intermediate features by measuring mutual information between those features and the labels to be forgotten, offering a more comprehensive assessment of unlearning efficacy.\nOur experiments demonstrate that IDI effectively measures the degree of unlearning across various datasets and architectures,\nproviding a reliable tool for evaluating strong unlearning in DNNs.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=NGF1wDDBMm",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jonghyun_Choi1",
        "name": "Jonghyun Choi",
        "name_site": null,
        "openreview_id": "~Jonghyun_Choi1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://ppolon.github.io/",
        "dblp_id": "21/11103",
        "google_scholar_url": "uiGWnm4AAAAJ",
        "orcid": "0000-0002-7934-8434",
        "linkedin_url": "jonghyun-choi-459bb615/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Seoul National University (South Korea)",
        "countries": [
          "South Korea"
        ],
        "country_codes": [
          "KR"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "NbbsRnPBoS",
      "title": "Faster Gradient Descent in Deep Linear Networks: The Advantage of Depth",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Gradient descent dynamics in deep linear networks has been studied under a wide range of settings. These studies have reported some negative results on the role of depth, in that, gradient descent in  deep linear networks: (i) can take exponential number of iterations to converge, (ii) can exhibit sigmoidal learning, i.e., almost no learning in initial phase followed by rapid learning, (iii) can delay convergence with increase in depth. Some of these results are also under stronger assumptions such as whitened data and balanced initialisation. These messages from prior works suggest that depth hurts the speed of convergence.\n\nIn this paper, we argue that the negative role of depth in the prior works is due to certain pitfalls which can be carefully avoided. We give a positive message on the role of depth, i.e., seen as an additional resource, depth can always be used to speed up convergence. For this purpose, we consider scalar regression with quadratic loss. In this setting, we propose a novel aligned gradient descent (AGD) algorithm for which we show that (i) linear convergence is always possible (ii) depth accelerates the speed of convergence. In AGD, feature alignment happens in first layer and the deeper layers accelerate by learning the right scale. We show acceleration in AGD happens in finite time for unwhitened data. We provide insights into the {acceleration} mechanism and also show that acceleration happens in phases. We also demonstrate the acceleration due to AGD on synthetic and benchmark datasets. Our main message is not propose AGD as a new algorithm in itself, but to demonstrate that depth is an advantage in linear networks thereby dispelling some of the past negative results on the role of depth.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=NbbsRnPBoS",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Chandra_Shekar_Lakshminarayanan2",
        "name": "Chandra Shekar Lakshminarayanan",
        "name_site": null,
        "openreview_id": "~Chandra_Shekar_Lakshminarayanan2",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://iitpkd.ac.in/people/cnarayanan",
        "dblp_id": "143/7535",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.3333333333333335,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "NbbsRnPBoS",
      "title": "Faster Gradient Descent in Deep Linear Networks: The Advantage of Depth",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Gradient descent dynamics in deep linear networks has been studied under a wide range of settings. These studies have reported some negative results on the role of depth, in that, gradient descent in  deep linear networks: (i) can take exponential number of iterations to converge, (ii) can exhibit sigmoidal learning, i.e., almost no learning in initial phase followed by rapid learning, (iii) can delay convergence with increase in depth. Some of these results are also under stronger assumptions such as whitened data and balanced initialisation. These messages from prior works suggest that depth hurts the speed of convergence.\n\nIn this paper, we argue that the negative role of depth in the prior works is due to certain pitfalls which can be carefully avoided. We give a positive message on the role of depth, i.e., seen as an additional resource, depth can always be used to speed up convergence. For this purpose, we consider scalar regression with quadratic loss. In this setting, we propose a novel aligned gradient descent (AGD) algorithm for which we show that (i) linear convergence is always possible (ii) depth accelerates the speed of convergence. In AGD, feature alignment happens in first layer and the deeper layers accelerate by learning the right scale. We show acceleration in AGD happens in finite time for unwhitened data. We provide insights into the {acceleration} mechanism and also show that acceleration happens in phases. We also demonstrate the acceleration due to AGD on synthetic and benchmark datasets. Our main message is not propose AGD as a new algorithm in itself, but to demonstrate that depth is an advantage in linear networks thereby dispelling some of the past negative results on the role of depth.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=NbbsRnPBoS",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arun_Rajkumar4",
        "name": "Arun Rajkumar",
        "name_site": "Arun Rajkumar, Vishnu Veerathu, Abdul Mir",
        "openreview_id": "~Arun_Rajkumar4",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "32/11350",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.3333333333333335,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "NbbsRnPBoS",
      "title": "Faster Gradient Descent in Deep Linear Networks: The Advantage of Depth",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Gradient descent dynamics in deep linear networks has been studied under a wide range of settings. These studies have reported some negative results on the role of depth, in that, gradient descent in  deep linear networks: (i) can take exponential number of iterations to converge, (ii) can exhibit sigmoidal learning, i.e., almost no learning in initial phase followed by rapid learning, (iii) can delay convergence with increase in depth. Some of these results are also under stronger assumptions such as whitened data and balanced initialisation. These messages from prior works suggest that depth hurts the speed of convergence.\n\nIn this paper, we argue that the negative role of depth in the prior works is due to certain pitfalls which can be carefully avoided. We give a positive message on the role of depth, i.e., seen as an additional resource, depth can always be used to speed up convergence. For this purpose, we consider scalar regression with quadratic loss. In this setting, we propose a novel aligned gradient descent (AGD) algorithm for which we show that (i) linear convergence is always possible (ii) depth accelerates the speed of convergence. In AGD, feature alignment happens in first layer and the deeper layers accelerate by learning the right scale. We show acceleration in AGD happens in finite time for unwhitened data. We provide insights into the {acceleration} mechanism and also show that acceleration happens in phases. We also demonstrate the acceleration due to AGD on synthetic and benchmark datasets. Our main message is not propose AGD as a new algorithm in itself, but to demonstrate that depth is an advantage in linear networks thereby dispelling some of the past negative results on the role of depth.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=NbbsRnPBoS",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Harish_Guruprasad_Ramaswamy1",
        "name": "Harish Guruprasad Ramaswamy",
        "name_site": null,
        "openreview_id": "~Harish_Guruprasad_Ramaswamy1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "126/1729",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.3333333333333335,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "NpBhYnUgFU",
      "title": "SuperCAT: Super Resolution and Cross Semantic Attribute-guided Transformer based Feature Refinement for Zero-Shot Remote Sensing Scene Classification",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Zero-shot learning becomes challenging in classifying scenes of unseen classes due to the typical characteristics of remote-sensing images. The intricate variations and non-uniform spatial resolutions among the scenes of remote sensing images further complicate achieving discriminative semantic knowledge. To tackle these issues, we propose a SuperCAT framework comprising a super-resolution module, a cross-semantic attribute-guided Transformer (CAT), feature-generating models, and a feature refinement (FR) module for the zero-shot scene classification in remote sensing images. First, we leverage the semantic attributes for all the classes of four benchmark remote sensing scene classification datasets to explore semantic knowledge using super-resolution effectively. Then, the semantic attribute to visual Transformer (SAVT) and visual to semantic attribute Transformer (VSAT) modules in CAT learn to obtain attribute-based visual features and visual-based attribute features, respectively. The SAVT and VSAT modules collaboratively learn and teach each other using the feature-level and prediction-level semantic collaborative losses. The feature-generating models map semantic vectors to the visual features of remote-sensing images. The FR module incorporates triplet center margin loss and semantic loop consistency loss functions to capture class-related and semantically-related discriminative features for achieving intra-class closeness and inter-class distinctiveness. Our extensive experiments on four benchmark remote sensing image scene classification datasets demonstrate the efficacy of SuperCAT over state-of-the-art approaches. The code can be accessed at https://github.com/ZSL-RSI-SC/SuperCAT.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=NpBhYnUgFU",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rambabu_Damalla1",
        "name": "Rambabu Damalla",
        "name_site": null,
        "openreview_id": "~Rambabu_Damalla1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "Y90SG6MAAAAJ",
        "orcid": "0009-0002-8495-8795",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.6666666666666665,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "NpBhYnUgFU",
      "title": "SuperCAT: Super Resolution and Cross Semantic Attribute-guided Transformer based Feature Refinement for Zero-Shot Remote Sensing Scene Classification",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Zero-shot learning becomes challenging in classifying scenes of unseen classes due to the typical characteristics of remote-sensing images. The intricate variations and non-uniform spatial resolutions among the scenes of remote sensing images further complicate achieving discriminative semantic knowledge. To tackle these issues, we propose a SuperCAT framework comprising a super-resolution module, a cross-semantic attribute-guided Transformer (CAT), feature-generating models, and a feature refinement (FR) module for the zero-shot scene classification in remote sensing images. First, we leverage the semantic attributes for all the classes of four benchmark remote sensing scene classification datasets to explore semantic knowledge using super-resolution effectively. Then, the semantic attribute to visual Transformer (SAVT) and visual to semantic attribute Transformer (VSAT) modules in CAT learn to obtain attribute-based visual features and visual-based attribute features, respectively. The SAVT and VSAT modules collaboratively learn and teach each other using the feature-level and prediction-level semantic collaborative losses. The feature-generating models map semantic vectors to the visual features of remote-sensing images. The FR module incorporates triplet center margin loss and semantic loop consistency loss functions to capture class-related and semantically-related discriminative features for achieving intra-class closeness and inter-class distinctiveness. Our extensive experiments on four benchmark remote sensing image scene classification datasets demonstrate the efficacy of SuperCAT over state-of-the-art approaches. The code can be accessed at https://github.com/ZSL-RSI-SC/SuperCAT.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=NpBhYnUgFU",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Gayathri_C1",
        "name": "Gayathri C",
        "name_site": null,
        "openreview_id": "~Gayathri_C1",
        "position": 2,
        "gender": "F",
        "homepage_url": "https://scholar.google.com/citations?hl=en&view_op=list_works&gmla=AKKJWFcBPZcJk73kla0jft-YEgcTBMUJSRjQBpFjxYX3U58KvGxNeFW2JJd_bx0jSzPT5qoL0qbulQpco9M59w&user=TgA8ejsAAAAJ",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Mahindra University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.6666666666666665,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "NpBhYnUgFU",
      "title": "SuperCAT: Super Resolution and Cross Semantic Attribute-guided Transformer based Feature Refinement for Zero-Shot Remote Sensing Scene Classification",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Zero-shot learning becomes challenging in classifying scenes of unseen classes due to the typical characteristics of remote-sensing images. The intricate variations and non-uniform spatial resolutions among the scenes of remote sensing images further complicate achieving discriminative semantic knowledge. To tackle these issues, we propose a SuperCAT framework comprising a super-resolution module, a cross-semantic attribute-guided Transformer (CAT), feature-generating models, and a feature refinement (FR) module for the zero-shot scene classification in remote sensing images. First, we leverage the semantic attributes for all the classes of four benchmark remote sensing scene classification datasets to explore semantic knowledge using super-resolution effectively. Then, the semantic attribute to visual Transformer (SAVT) and visual to semantic attribute Transformer (VSAT) modules in CAT learn to obtain attribute-based visual features and visual-based attribute features, respectively. The SAVT and VSAT modules collaboratively learn and teach each other using the feature-level and prediction-level semantic collaborative losses. The feature-generating models map semantic vectors to the visual features of remote-sensing images. The FR module incorporates triplet center margin loss and semantic loop consistency loss functions to capture class-related and semantically-related discriminative features for achieving intra-class closeness and inter-class distinctiveness. Our extensive experiments on four benchmark remote sensing image scene classification datasets demonstrate the efficacy of SuperCAT over state-of-the-art approaches. The code can be accessed at https://github.com/ZSL-RSI-SC/SuperCAT.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=NpBhYnUgFU",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rajeshreddy_Datla2",
        "name": "Rajeshreddy Datla",
        "name_site": null,
        "openreview_id": "~Dr_Rajeshreddy_Datla1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "282/2603",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": "0000-0002-2980-9175",
        "linkedin_url": "rajeshreddy-datla-phd",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Advanced Data Processing Research Institute (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.6666666666666665,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "O2CG9B2k9Q",
      "title": "Normalizing Flow Based Evaluation Metrics for Image Generation",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We propose two new evaluation metrics to assess realness of generated images based on normalizing flows: a simpler and efficient flow-based likelihood distance (FLD) and a more exact dual-flow based likelihood distance (D-FLD). Because normalizing flows can be used to compute the exact likelihood, the proposed metrics assess how closely generated images align with the distribution of real images from a given domain. This property gives the proposed metrics a few advantages over the widely used Fréchet inception distance (FID) and other recent metrics. Firstly, the proposed metrics need only a few hundred images to stabilize (converge in mean), as opposed to tens of thousands needed for FID, and at least a few thousand for the other metrics. This allows confident evaluation of even small sets of generated images, such as validation batches inside training loops. Secondly, the network used to compute the proposed metric has over an order of magnitude fewer parameters compared to Inception-V3 used to compute FID, making it computationally more efficient. For assessing the realness of generated images in new domains (e.g., x-ray images), ideally these networks should be retrained on real images to model their distinct distributions. Thus, our smaller network will be even more advantageous for new domains. Extensive experiments show that the proposed metrics have the desired monotonic relationships with the extent of image degradation of various kinds.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=O2CG9B2k9Q",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Pranav_Jeevan_P1",
        "name": "Pranav Jeevan P",
        "name_site": null,
        "openreview_id": "~Pranav_Jeevan_P1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://pranavphoenix.github.io/",
        "dblp_id": "296/3727",
        "google_scholar_url": "3GlJQ24AAAAJ",
        "orcid": "0000-0003-4110-9638",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.75,
        "rating_std": 1.920286436967152,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "O2CG9B2k9Q",
      "title": "Normalizing Flow Based Evaluation Metrics for Image Generation",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We propose two new evaluation metrics to assess realness of generated images based on normalizing flows: a simpler and efficient flow-based likelihood distance (FLD) and a more exact dual-flow based likelihood distance (D-FLD). Because normalizing flows can be used to compute the exact likelihood, the proposed metrics assess how closely generated images align with the distribution of real images from a given domain. This property gives the proposed metrics a few advantages over the widely used Fréchet inception distance (FID) and other recent metrics. Firstly, the proposed metrics need only a few hundred images to stabilize (converge in mean), as opposed to tens of thousands needed for FID, and at least a few thousand for the other metrics. This allows confident evaluation of even small sets of generated images, such as validation batches inside training loops. Secondly, the network used to compute the proposed metric has over an order of magnitude fewer parameters compared to Inception-V3 used to compute FID, making it computationally more efficient. For assessing the realness of generated images in new domains (e.g., x-ray images), ideally these networks should be retrained on real images to model their distinct distributions. Thus, our smaller network will be even more advantageous for new domains. Extensive experiments show that the proposed metrics have the desired monotonic relationships with the extent of image degradation of various kinds.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=O2CG9B2k9Q",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Neeraj_Nixon1",
        "name": "Neeraj Nixon",
        "name_site": null,
        "openreview_id": "~Neeraj_Nixon1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "ioR-MBgAAAAJ",
        "orcid": null,
        "linkedin_url": "neerajnixon/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.75,
        "rating_std": 1.920286436967152,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Ox2A1WoKLm",
      "title": "Towards Robust Concept Erasure in Diffusion Models: Unlearning Identity, Nudity and Artistic Styles",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Diffusion models have achieved remarkable success in generative tasks across various domains. However, the increasing demand for content moderation and the removal of specific concepts from these models has introduced the challenge of \\textit{unlearning}. In this work, we present a suite of robust methodologies that significantly enhance the unlearning process by employing advanced loss functions within knowledge distillation frameworks. Specifically, we utilize the Cramer-Wold distance and Jensen-Shannon (JS) divergence to facilitate more efficient and versatile concept removal. Although current non-learning techniques are effective in certain scenarios, they are typically limited to specific categories such as identity, nudity, or artistic style. In contrast, our proposed methods demonstrate robust versatility, seamlessly adapting to and performing effectively across a wide range of concept erasure categories. Our approach outperforms existing techniques, achieving consistent results across different unlearning categories and showcasing its broad applicability. Through extensive experiments, we show that our method not only surpasses previous benchmarks but also addresses key limitations of current unlearning techniques, paving the way for more responsible use of text-to-image diffusion models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Ox2A1WoKLm",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Umakanta_Maharana1",
        "name": "Umakanta Maharana",
        "name_site": null,
        "openreview_id": "~Umakanta_Maharana1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://umakantamaharana.github.io/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "umakanta-maharana-b6b140169",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Kalinga Institute of Industrial Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Ox2A1WoKLm",
      "title": "Towards Robust Concept Erasure in Diffusion Models: Unlearning Identity, Nudity and Artistic Styles",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Diffusion models have achieved remarkable success in generative tasks across various domains. However, the increasing demand for content moderation and the removal of specific concepts from these models has introduced the challenge of \\textit{unlearning}. In this work, we present a suite of robust methodologies that significantly enhance the unlearning process by employing advanced loss functions within knowledge distillation frameworks. Specifically, we utilize the Cramer-Wold distance and Jensen-Shannon (JS) divergence to facilitate more efficient and versatile concept removal. Although current non-learning techniques are effective in certain scenarios, they are typically limited to specific categories such as identity, nudity, or artistic style. In contrast, our proposed methods demonstrate robust versatility, seamlessly adapting to and performing effectively across a wide range of concept erasure categories. Our approach outperforms existing techniques, achieving consistent results across different unlearning categories and showcasing its broad applicability. Through extensive experiments, we show that our method not only surpasses previous benchmarks but also addresses key limitations of current unlearning techniques, paving the way for more responsible use of text-to-image diffusion models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Ox2A1WoKLm",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aakash_Sen_Sharma1",
        "name": "Aakash Sen Sharma",
        "name_site": null,
        "openreview_id": "~Aakash_Sen_Sharma1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://aakash.is-a.dev",
        "dblp_id": null,
        "google_scholar_url": "_ikHtpUAAAAJ",
        "orcid": null,
        "linkedin_url": "aakashsharma72/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Kalinga Institute of Industrial Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Ox2A1WoKLm",
      "title": "Towards Robust Concept Erasure in Diffusion Models: Unlearning Identity, Nudity and Artistic Styles",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Diffusion models have achieved remarkable success in generative tasks across various domains. However, the increasing demand for content moderation and the removal of specific concepts from these models has introduced the challenge of \\textit{unlearning}. In this work, we present a suite of robust methodologies that significantly enhance the unlearning process by employing advanced loss functions within knowledge distillation frameworks. Specifically, we utilize the Cramer-Wold distance and Jensen-Shannon (JS) divergence to facilitate more efficient and versatile concept removal. Although current non-learning techniques are effective in certain scenarios, they are typically limited to specific categories such as identity, nudity, or artistic style. In contrast, our proposed methods demonstrate robust versatility, seamlessly adapting to and performing effectively across a wide range of concept erasure categories. Our approach outperforms existing techniques, achieving consistent results across different unlearning categories and showcasing its broad applicability. Through extensive experiments, we show that our method not only surpasses previous benchmarks but also addresses key limitations of current unlearning techniques, paving the way for more responsible use of text-to-image diffusion models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Ox2A1WoKLm",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yash_Sinha1",
        "name": "Yash Sinha",
        "name_site": null,
        "openreview_id": "~Yash_Sinha1",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of South Florida (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Ox2A1WoKLm",
      "title": "Towards Robust Concept Erasure in Diffusion Models: Unlearning Identity, Nudity and Artistic Styles",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Diffusion models have achieved remarkable success in generative tasks across various domains. However, the increasing demand for content moderation and the removal of specific concepts from these models has introduced the challenge of \\textit{unlearning}. In this work, we present a suite of robust methodologies that significantly enhance the unlearning process by employing advanced loss functions within knowledge distillation frameworks. Specifically, we utilize the Cramer-Wold distance and Jensen-Shannon (JS) divergence to facilitate more efficient and versatile concept removal. Although current non-learning techniques are effective in certain scenarios, they are typically limited to specific categories such as identity, nudity, or artistic style. In contrast, our proposed methods demonstrate robust versatility, seamlessly adapting to and performing effectively across a wide range of concept erasure categories. Our approach outperforms existing techniques, achieving consistent results across different unlearning categories and showcasing its broad applicability. Through extensive experiments, we show that our method not only surpasses previous benchmarks but also addresses key limitations of current unlearning techniques, paving the way for more responsible use of text-to-image diffusion models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Ox2A1WoKLm",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mohan_Kankanhalli1",
        "name": "Mohan Kankanhalli",
        "name_site": null,
        "openreview_id": "~Mohan_Kankanhalli1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://www.comp.nus.edu.sg/~mohan",
        "dblp_id": "09/3613.html",
        "google_scholar_url": "6Lx_eowAAAAJ",
        "orcid": "0000-0002-4846-2015",
        "linkedin_url": "mohan-kankanhalli-583417221",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Kalinga Institute of Industrial Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "PD3I0iOYOd",
      "title": "ConDa: Fast Federated Unlearning with Contribution Dampening",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Federated learning (FL) has enabled collaborative model training across decentralized data sources or clients. While adding new participants to a shared model does not pose great technical hurdles, the removal of a participant and their related information contained in the shared model remains a challenge. To address this problem, federated unlearning has emerged as a critical research direction, seeking to remove information from globally trained models without harming the model performance on the remaining data. Most modern federated unlearning methods use costly approaches such as the use of remaining clients data to retrain the global model or methods that would require heavy computation on client or server side. We introduce Contribution Dampening (\\textsc{ConDa}), a framework that performs efficient unlearning by tracking down the parameters which affect the global model for each client and performs synaptic dampening on the parameters of the global model that have privacy infringing contributions from the forgetting client. Our technique does not require clients data or any kind of retraining and it does not put any computational overhead on either the client or server side. We perform experiments on multiple datasets and demonstrate that \\textsc{ConDa} is effective to forget a client’s data. In experiments conducted on the MNIST, CIFAR10, and CIFAR100 datasets, \\textsc{ConDa} proves to be the fastest federated unlearning method, outperforming the nearest state-of-the-art approach by at least 100×. Our emphasis is on the non-IID Federated Learning setting, which presents the greatest challenge for unlearning. Additionally, we validate \\textsc{ConDa}'s robustness through backdoor and membership inference attacks. We envision this work as a crucial component for FL in adhering to legal and ethical requirements.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=PD3I0iOYOd",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Pushkar_Niroula1",
        "name": "Pushkar Niroula",
        "name_site": null,
        "openreview_id": "~Stefan_Schoepf1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "353/0887",
        "google_scholar_url": "GTvLmf0AAAAJ",
        "orcid": null,
        "linkedin_url": "schoepfstefan/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Cambridge (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.6666666666666665,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "PD3I0iOYOd",
      "title": "ConDa: Fast Federated Unlearning with Contribution Dampening",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Federated learning (FL) has enabled collaborative model training across decentralized data sources or clients. While adding new participants to a shared model does not pose great technical hurdles, the removal of a participant and their related information contained in the shared model remains a challenge. To address this problem, federated unlearning has emerged as a critical research direction, seeking to remove information from globally trained models without harming the model performance on the remaining data. Most modern federated unlearning methods use costly approaches such as the use of remaining clients data to retrain the global model or methods that would require heavy computation on client or server side. We introduce Contribution Dampening (\\textsc{ConDa}), a framework that performs efficient unlearning by tracking down the parameters which affect the global model for each client and performs synaptic dampening on the parameters of the global model that have privacy infringing contributions from the forgetting client. Our technique does not require clients data or any kind of retraining and it does not put any computational overhead on either the client or server side. We perform experiments on multiple datasets and demonstrate that \\textsc{ConDa} is effective to forget a client’s data. In experiments conducted on the MNIST, CIFAR10, and CIFAR100 datasets, \\textsc{ConDa} proves to be the fastest federated unlearning method, outperforming the nearest state-of-the-art approach by at least 100×. Our emphasis is on the non-IID Federated Learning setting, which presents the greatest challenge for unlearning. Additionally, we validate \\textsc{ConDa}'s robustness through backdoor and membership inference attacks. We envision this work as a crucial component for FL in adhering to legal and ethical requirements.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=PD3I0iOYOd",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Stefan_Schoepf1",
        "name": "Stefan Schoepf",
        "name_site": null,
        "openreview_id": "~Alexandra_Brintrup1",
        "position": 4,
        "gender": "F",
        "homepage_url": "https://www.ifm.eng.cam.ac.uk/people/ab702/",
        "dblp_id": "85/1303",
        "google_scholar_url": "8HJL8cAAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Cambridge (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.6666666666666665,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "PabAln0jjB",
      "title": "Right Now, Wrong Then: Non-Stationary Direct Preference Optimization under Preference Drift",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Current Large Language Model (LLM) preference optimization algorithms do not\naccount for temporal preference drift, which can lead to severe misalignment. To\naddress this limitation, we propose an offline fine-tuning algorithm Non-Stationary\nDirect Preference Optimisation (NS-DPO) which models time-dependent reward\nfunctions with a Dynamic Bradley-Terry model. NS-DPO applies exponential\nweighting, by introducing a discount parameter in the loss function, which pro-\nportionally focuses learning on more time-relevant datapoints. We theoretically\nanalyse the convergence of NS-DPO, providing upper bounds on the estimation\nerror and regret caused by non-stationary preferences. Finally, we demonstrate\nthe effectiveness of NS-DPO1 for fine-tuning LLMs in scenarios with drifting\npreferences. By simulating preference drift using popular LLM reward models\nand datasets accordingly, we show that NS-DPO fine-tuned LLMs remain robust\nunder non-stationarity, significantly outperforming baseline algorithms that ignore\ntemporal preference changes, without sacrificing performance in stationary cases.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=PabAln0jjB",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ilija_Bogunovic2",
        "name": "Ilija Bogunovic",
        "name_site": null,
        "openreview_id": "~Ilija_Bogunovic1",
        "position": 5,
        "gender": "M",
        "homepage_url": "http://ilijabogunovic.com/",
        "dblp_id": "142/2725",
        "google_scholar_url": "xMvt3NEAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Swiss Federal Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.666666666666667,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Pr4JkJVlmz",
      "title": "MAQL: Speeding up Q-learning with a model-assist",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "In reinforcement learning, model free methods such as Q-learning and policy gradient are extremely popular due to their simplicity but require a huge amount of data for training. Model based methods on the other hand, are proven to be sample efficient in various environments but are unfortunately computationally expensive. It is therefore only prudent to investigate and design algorithms that have best of features from both these classes of algorithms. In this work, we propose MAQL, a model-assisted Q-learning algorithm that is not only computationally inexpensive but also offers low sample complexity. We illustrate its superior performance to vanilla Q-learning in various RL environments and particularly demonstrate its utility in learning the Gittins/Whittles index in Rested/Restless Bandits respectively. We aim to spur discussion on how model-assists can help boost the performance of existing RL algorithms.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Pr4JkJVlmz",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~S_Akash1",
        "name": "S Akash",
        "name_site": null,
        "openreview_id": "~S_Akash1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "akash-s-473781263/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Patna (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Pr4JkJVlmz",
      "title": "MAQL: Speeding up Q-learning with a model-assist",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "In reinforcement learning, model free methods such as Q-learning and policy gradient are extremely popular due to their simplicity but require a huge amount of data for training. Model based methods on the other hand, are proven to be sample efficient in various environments but are unfortunately computationally expensive. It is therefore only prudent to investigate and design algorithms that have best of features from both these classes of algorithms. In this work, we propose MAQL, a model-assisted Q-learning algorithm that is not only computationally inexpensive but also offers low sample complexity. We illustrate its superior performance to vanilla Q-learning in various RL environments and particularly demonstrate its utility in learning the Gittins/Whittles index in Rested/Restless Bandits respectively. We aim to spur discussion on how model-assists can help boost the performance of existing RL algorithms.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Pr4JkJVlmz",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Tejas_Bodas1",
        "name": "Tejas Bodas",
        "name_site": null,
        "openreview_id": "~Tejas_Bodas1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "7lj4UY8AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "R7edIYodis",
      "title": "SIRD: Transformers Assisted Step by Step Symbolic Integration",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Recently, deep learning has gained popularity in solving statistical or approximate problems. However, working with symbolic data has been challenging for neural networks. Despite this, the natural sciences are making strides in utilizing deep learning for various use cases. In this work, we aim to solve the problem of symbolic integration by using deep learning through integral rule prediction, enabling faster search and better interpretability. We propose a novel symbolic integration rules dataset containing 27 million distinct functions and integration rule pairs. We show that by combining a transformer model trained on this dataset into SymPy's integral_steps function, the number of branches explored during the depth-first-search procedure was reduced by a factor of 3 and successfully solve functions that the original version was unable to handle.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=R7edIYodis",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vaibhav_Sharma1",
        "name": "Vaibhav Sharma",
        "name_site": null,
        "openreview_id": "~Vaibhav_Sharma1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "cxSNCngAAAAJ",
        "orcid": null,
        "linkedin_url": "vaibhav-sharma-5a2a3b151/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "ShareChat (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "R9W6fFlr8W",
      "title": "A primal-dual algorithm for variational image reconstruction with learned convex regularizers",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We address the optimization problem in a data-driven variational reconstruction framework, where the regularizer is parameterized by an input-convex neural network (ICNN). While gradient-based methods are commonly used to solve such problems, they struggle to effectively handle non-smoothness which often leads to slow convergence. Moreover, the nested structure of the neural network complicates the application of standard non-smooth optimization techniques, such as proximal algorithms. To overcome these challenges, we reformulate the problem and eliminate the network's nested structure. By relating this reformulation to epigraphical projections of the activation functions, we transform the problem into a convex optimization problem that can be efficiently solved using a primal-dual algorithm. We also prove that this reformulation is equivalent to the original variational problem. Through experiments on several imaging tasks, we demonstrate that the proposed approach outperforms subgradient methods in terms of both speed and stability.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=R9W6fFlr8W",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Subhadip_Mukherjee1",
        "name": "Subhadip Mukherjee",
        "name_site": null,
        "openreview_id": "~Subhadip_Mukherjee1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/subhadip-mukherjee/home",
        "dblp_id": "120/7054",
        "google_scholar_url": "https://scholar.google.se/citations?user=a4UlE_MAAAAJ",
        "orcid": "0000-0002-7957-8758",
        "linkedin_url": "subhadip-mukherjee-11b925101/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (United Kingdom)",
        "countries": [
          "United Kingdom"
        ],
        "country_codes": [
          "GB"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.0,
        "confidence_mean": 4.2,
        "confidence_std": 0.7483314773547882,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "RBqvU12SHz",
      "title": "Structural Probing with Feature Interaction",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Measuring nonlinear feature interaction is an established approach to understanding complex patterns of attribution in many models. In this paper, we use Shapley Taylor interaction indices (STII) to analyze the impact of underlying data structure on model representations in a variety of modalities, tasks, and architectures. Considering linguistic structure in masked and auto-regressive language models (MLMs and ALMs), we find that STII increases within idiomatic expressions and that Transformer ALMs scale STII with syntactic distance, just as LSTM-based ALMs do. Our speech model findings reflect the phonetic principal that the openness of the oral cavity determines how much a phoneme's acoustics vary based on context. Our wide range of results illustrates the benefits of interdisciplinary work and domain expertise in interpretability research.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=RBqvU12SHz",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Divyansh_Singhvi1",
        "name": "Divyansh Singhvi",
        "name_site": null,
        "openreview_id": "~Divyansh_Singhvi1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://divyanshsinghvi.github.io/",
        "dblp_id": null,
        "google_scholar_url": "7AaPJF8AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Patna (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.25,
        "rating_std": 1.7853571071357126,
        "confidence_mean": 3.0,
        "confidence_std": 1.224744871391589,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "RwiUmrEHgR",
      "title": "Long Tail Classification Through Cost Sensitive Loss Functions",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Class imbalance in the data introduces significant challenges in training machine models especially with long-tailed datasets. Specifically, it leads to biased models that overfit with respect to the dominant classes while under-performing on the minority classes. This, in turn,  results in seemingly satisfactory yet biased overall results. Hence, the above biasing needs to be controlled such that the desired generalizability of the model is not entirely compromised. To that end,  we introduce a novel Cost-Sensitive Loss (CSL) function designed to dynamically adjust class weights, and incorporate a reinforcement learning mechanism to optimize these adjustments. The proposed CSL function can be seamlessly integrated with existing loss functions, to enhance performance on imbalanced datasets, rendering them robust and scalable. We implemented the above CSL function in form of a framework which leverages reinforcement learning  to optimally apply these adjustments over consecutive training epochs.  Experimental Results on  benchmark datasets demonstrate that our proposed approach significantly outperforms state-of-the-art methods. The results indicate that our approach can  provide an optimal trade-off in the model accuracy and generalization with diverse kinds of imbalanced data.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=RwiUmrEHgR",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Varad_Shinde1",
        "name": "Varad Shinde",
        "name_site": null,
        "openreview_id": "~Varad_Shinde1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "VFmzDP8AAAAJ",
        "orcid": null,
        "linkedin_url": "varad-shinde-b0428722b?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bhilai (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "RwiUmrEHgR",
      "title": "Long Tail Classification Through Cost Sensitive Loss Functions",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Class imbalance in the data introduces significant challenges in training machine models especially with long-tailed datasets. Specifically, it leads to biased models that overfit with respect to the dominant classes while under-performing on the minority classes. This, in turn,  results in seemingly satisfactory yet biased overall results. Hence, the above biasing needs to be controlled such that the desired generalizability of the model is not entirely compromised. To that end,  we introduce a novel Cost-Sensitive Loss (CSL) function designed to dynamically adjust class weights, and incorporate a reinforcement learning mechanism to optimize these adjustments. The proposed CSL function can be seamlessly integrated with existing loss functions, to enhance performance on imbalanced datasets, rendering them robust and scalable. We implemented the above CSL function in form of a framework which leverages reinforcement learning  to optimally apply these adjustments over consecutive training epochs.  Experimental Results on  benchmark datasets demonstrate that our proposed approach significantly outperforms state-of-the-art methods. The results indicate that our approach can  provide an optimal trade-off in the model accuracy and generalization with diverse kinds of imbalanced data.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=RwiUmrEHgR",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Nikhil_Kumar_Shrey1",
        "name": "Nikhil Kumar Shrey",
        "name_site": null,
        "openreview_id": "~Nikhil_Kumar_Shrey1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://nikhilshrey.vercel.app/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "nikhil-shrey/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bhilai (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "RwiUmrEHgR",
      "title": "Long Tail Classification Through Cost Sensitive Loss Functions",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Class imbalance in the data introduces significant challenges in training machine models especially with long-tailed datasets. Specifically, it leads to biased models that overfit with respect to the dominant classes while under-performing on the minority classes. This, in turn,  results in seemingly satisfactory yet biased overall results. Hence, the above biasing needs to be controlled such that the desired generalizability of the model is not entirely compromised. To that end,  we introduce a novel Cost-Sensitive Loss (CSL) function designed to dynamically adjust class weights, and incorporate a reinforcement learning mechanism to optimize these adjustments. The proposed CSL function can be seamlessly integrated with existing loss functions, to enhance performance on imbalanced datasets, rendering them robust and scalable. We implemented the above CSL function in form of a framework which leverages reinforcement learning  to optimally apply these adjustments over consecutive training epochs.  Experimental Results on  benchmark datasets demonstrate that our proposed approach significantly outperforms state-of-the-art methods. The results indicate that our approach can  provide an optimal trade-off in the model accuracy and generalization with diverse kinds of imbalanced data.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=RwiUmrEHgR",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~SUBHAJIT_SIDHANTA1",
        "name": "SUBHAJIT SIDHANTA",
        "name_site": null,
        "openreview_id": "~SUBHAJIT_SIDHANTA1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://sites.google.com/iitbhilai.ac.in/subhajit/home",
        "dblp_id": "117/7682.html",
        "google_scholar_url": "DshDwzEAAAAJ",
        "orcid": null,
        "linkedin_url": "subhajit-sidhanta-0902167",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "RwiUmrEHgR",
      "title": "Long Tail Classification Through Cost Sensitive Loss Functions",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Class imbalance in the data introduces significant challenges in training machine models especially with long-tailed datasets. Specifically, it leads to biased models that overfit with respect to the dominant classes while under-performing on the minority classes. This, in turn,  results in seemingly satisfactory yet biased overall results. Hence, the above biasing needs to be controlled such that the desired generalizability of the model is not entirely compromised. To that end,  we introduce a novel Cost-Sensitive Loss (CSL) function designed to dynamically adjust class weights, and incorporate a reinforcement learning mechanism to optimize these adjustments. The proposed CSL function can be seamlessly integrated with existing loss functions, to enhance performance on imbalanced datasets, rendering them robust and scalable. We implemented the above CSL function in form of a framework which leverages reinforcement learning  to optimally apply these adjustments over consecutive training epochs.  Experimental Results on  benchmark datasets demonstrate that our proposed approach significantly outperforms state-of-the-art methods. The results indicate that our approach can  provide an optimal trade-off in the model accuracy and generalization with diverse kinds of imbalanced data.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=RwiUmrEHgR",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Harshil_Bhargava1",
        "name": "Harshil Bhargava",
        "name_site": null,
        "openreview_id": "~Harshil_Bhargava1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "harshil-bhargava-53279424a/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bhilai (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "RwiUmrEHgR",
      "title": "Long Tail Classification Through Cost Sensitive Loss Functions",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Class imbalance in the data introduces significant challenges in training machine models especially with long-tailed datasets. Specifically, it leads to biased models that overfit with respect to the dominant classes while under-performing on the minority classes. This, in turn,  results in seemingly satisfactory yet biased overall results. Hence, the above biasing needs to be controlled such that the desired generalizability of the model is not entirely compromised. To that end,  we introduce a novel Cost-Sensitive Loss (CSL) function designed to dynamically adjust class weights, and incorporate a reinforcement learning mechanism to optimize these adjustments. The proposed CSL function can be seamlessly integrated with existing loss functions, to enhance performance on imbalanced datasets, rendering them robust and scalable. We implemented the above CSL function in form of a framework which leverages reinforcement learning  to optimally apply these adjustments over consecutive training epochs.  Experimental Results on  benchmark datasets demonstrate that our proposed approach significantly outperforms state-of-the-art methods. The results indicate that our approach can  provide an optimal trade-off in the model accuracy and generalization with diverse kinds of imbalanced data.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=RwiUmrEHgR",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Supratik_Mukhopadhyay2",
        "name": "Supratik Mukhopadhyay",
        "name_site": null,
        "openreview_id": "~Supratik_Mukhopadhyay2",
        "position": 5,
        "gender": "Not Specified",
        "homepage_url": "https://www.xprize.org/prizes/artificial-intelligence/teams/deepdrug",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Louisiana State University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "RwiUmrEHgR",
      "title": "Long Tail Classification Through Cost Sensitive Loss Functions",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Class imbalance in the data introduces significant challenges in training machine models especially with long-tailed datasets. Specifically, it leads to biased models that overfit with respect to the dominant classes while under-performing on the minority classes. This, in turn,  results in seemingly satisfactory yet biased overall results. Hence, the above biasing needs to be controlled such that the desired generalizability of the model is not entirely compromised. To that end,  we introduce a novel Cost-Sensitive Loss (CSL) function designed to dynamically adjust class weights, and incorporate a reinforcement learning mechanism to optimize these adjustments. The proposed CSL function can be seamlessly integrated with existing loss functions, to enhance performance on imbalanced datasets, rendering them robust and scalable. We implemented the above CSL function in form of a framework which leverages reinforcement learning  to optimally apply these adjustments over consecutive training epochs.  Experimental Results on  benchmark datasets demonstrate that our proposed approach significantly outperforms state-of-the-art methods. The results indicate that our approach can  provide an optimal trade-off in the model accuracy and generalization with diverse kinds of imbalanced data.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=RwiUmrEHgR",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Linta_Islam1",
        "name": "Linta Islam",
        "name_site": null,
        "openreview_id": "~Linta_Islam1",
        "position": 6,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "308/0541.html",
        "google_scholar_url": "7Ker9eUAAAAJ",
        "orcid": "0000-0002-6187-5519",
        "linkedin_url": "lintaislam/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Louisiana State University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "RwiUmrEHgR",
      "title": "Long Tail Classification Through Cost Sensitive Loss Functions",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Class imbalance in the data introduces significant challenges in training machine models especially with long-tailed datasets. Specifically, it leads to biased models that overfit with respect to the dominant classes while under-performing on the minority classes. This, in turn,  results in seemingly satisfactory yet biased overall results. Hence, the above biasing needs to be controlled such that the desired generalizability of the model is not entirely compromised. To that end,  we introduce a novel Cost-Sensitive Loss (CSL) function designed to dynamically adjust class weights, and incorporate a reinforcement learning mechanism to optimize these adjustments. The proposed CSL function can be seamlessly integrated with existing loss functions, to enhance performance on imbalanced datasets, rendering them robust and scalable. We implemented the above CSL function in form of a framework which leverages reinforcement learning  to optimally apply these adjustments over consecutive training epochs.  Experimental Results on  benchmark datasets demonstrate that our proposed approach significantly outperforms state-of-the-art methods. The results indicate that our approach can  provide an optimal trade-off in the model accuracy and generalization with diverse kinds of imbalanced data.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=RwiUmrEHgR",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yimin_Zhu1",
        "name": "Yimin Zhu",
        "name_site": null,
        "openreview_id": "~Yimin_Zhu1",
        "position": 7,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "7FsB4zIAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Louisiana State University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "SI6zocV2SS",
      "title": "CAN - CONTINUOUSLY ADAPTING NETWORKS",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Catastrophic forgetting is a fundamental challenge in neural networks that prevents continuous learning, which is one of the properties essential for achieving true general artificial intelligence. When trained sequentially on multiple tasks, conventional neural networks overwrite previously learned knowledge, hindering their ability to retain and apply past experiences. However, people and other animals can learn new things continuously without forgetting them. To overcome this problem, we devised an architecture that preserves significant task-specific connections by combining selective neuron freezing with Hebbian learning principles. Hebbian learning enables the network to adaptively strengthen synaptic connections depending on parameter activation. It is inspired by the synaptic plasticity seen in brains. By preserving the most important neurons using selective neuron freezing, new tasks can be trained without changing them. Experiments conducted on standard datasets show that our model significantly reduces the risk of catastrophic forgetting, allowing the network to learn continually.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=SI6zocV2SS",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Harikrishna_Satheesh_Pillai1",
        "name": "Harikrishna Satheesh Pillai",
        "name_site": null,
        "openreview_id": "~Harikrishna_Satheesh_Pillai1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://harikrishna-al.github.io/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "harikrishnapillai303",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Amrita Vishwa Vidyapeetham (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 1.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "SI6zocV2SS",
      "title": "CAN - CONTINUOUSLY ADAPTING NETWORKS",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Catastrophic forgetting is a fundamental challenge in neural networks that prevents continuous learning, which is one of the properties essential for achieving true general artificial intelligence. When trained sequentially on multiple tasks, conventional neural networks overwrite previously learned knowledge, hindering their ability to retain and apply past experiences. However, people and other animals can learn new things continuously without forgetting them. To overcome this problem, we devised an architecture that preserves significant task-specific connections by combining selective neuron freezing with Hebbian learning principles. Hebbian learning enables the network to adaptively strengthen synaptic connections depending on parameter activation. It is inspired by the synaptic plasticity seen in brains. By preserving the most important neurons using selective neuron freezing, new tasks can be trained without changing them. Experiments conducted on standard datasets show that our model significantly reduces the risk of catastrophic forgetting, allowing the network to learn continually.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=SI6zocV2SS",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Pakhi_Banchalia1",
        "name": "Pakhi Banchalia",
        "name_site": null,
        "openreview_id": "~Pakhi_Banchalia1",
        "position": 2,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "pakhi07/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Amrita Vishwa Vidyapeetham (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 1.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "SUEXRbzq9l",
      "title": "Estimating Statistical Similarity Between Product Distributions",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We investigate the problem of computing the *statistical* or *total variation (TV) similarity* between distributions $P$ and $Q$, which is defined as $s_{\\mathrm{TV}}(P,Q) := 1 - d_{\\mathrm{TV}}(P, Q)$, where $d_{\\mathrm{TV}}$ is the total variation distance between $P$ and $Q$.\nStatistical similarity is a basic measure of similarity between distributions with several natural interpretations.\nWe focus on the case when $P$ and $Q$ are products of Bernoulli trials.\nRecent work has established, somewhat surprisingly, that even for this simple class of distributions exactly computing the TV distance (and hence statistical similarity) is \\#$\\mathsf{P}$-hard.\nThis motivates the question of designing multiplicative approximation algorithms for these computational tasks.\nIt is known that the TV distance computation admits a fully polynomial-time deterministic approximation scheme (FPTAS).\nIt remained an open question whether efficient approximation schemes exist for estimating the statistical similarity between two product distributions.\nIn this work, we affirmatively answer this question by designing an FPTAS for estimating the statistical similarity between two product distributions.\nTo obtain our result, we introduce a new variant of the knapsack problem, which we call multidimensional Masked Knapsack problem, and design an FPTAS to estimate the number of solutions to this problem.\nThis result might be of independent interest.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=SUEXRbzq9l",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sutanu_Gayen1",
        "name": "Sutanu Gayen",
        "name_site": null,
        "openreview_id": "~Sutanu_Gayen1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "183/2766",
        "google_scholar_url": "aqd7jKoAAAAJ",
        "orcid": "0000-0003-3300-1627",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.6,
        "rating_std": 1.3564659966250536,
        "confidence_mean": 3.4,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "TSTgP4W3ga",
      "title": "Learnable Stability-Aware Unstructured Grid Coarsening Using Graph Neural Networks for Accelerated Physics Simulations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Efficient simulations of complex physical systems described by partial differential equations (PDE) require computational methods that can reduce the resource demands without sacrificing the accuracy. Traditionally, this is achieved by ``upscaling'' the simulation grids or by aggregating cells based on a priori information. Here, we introduce a novel framework based on graph neural networks (GNN) for learnable self-supervised differentiable coarsening of unstructured computational grids. We leverage graph-based representation of the physical system and offer a graph coarsening method which preserves the underlying physical properties together with the stability of the chosen numerical scheme. This is achieved by minimizing the error between the output of the simulations using coarsened and original graph. We demonstrate the approach on several example differential equations, modeling sub-surface flow and wave propagation. We demonstrate that the model exhibits ability to maintain high fidelity in simulation outputs even after 95\\% reduction on the nodes, significantly reducing computational overhead. We also show that the model exhibits generalizability to unseen scenarios, thereby outperforming the baselines. Thus, the developed approach demonstrates the ability to accelerate simulation without comprising accuracy and hence has potential for accelerating physical simulations in various domains.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=TSTgP4W3ga",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 8,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sayan_Ranu2",
        "name": "Sayan Ranu",
        "name_site": null,
        "openreview_id": "~Sayan_Ranu2",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://www.cse.iitd.ac.in/~sayan/index.html",
        "dblp_id": "38/768",
        "google_scholar_url": "K4w5qYUAAAAJ",
        "orcid": "0000-0003-4147-9372",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (Russian Federation)",
        "countries": [
          "Russian Federation"
        ],
        "country_codes": [
          "UN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.25,
        "confidence_std": 1.0897247358851685,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "TSTgP4W3ga",
      "title": "Learnable Stability-Aware Unstructured Grid Coarsening Using Graph Neural Networks for Accelerated Physics Simulations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Efficient simulations of complex physical systems described by partial differential equations (PDE) require computational methods that can reduce the resource demands without sacrificing the accuracy. Traditionally, this is achieved by ``upscaling'' the simulation grids or by aggregating cells based on a priori information. Here, we introduce a novel framework based on graph neural networks (GNN) for learnable self-supervised differentiable coarsening of unstructured computational grids. We leverage graph-based representation of the physical system and offer a graph coarsening method which preserves the underlying physical properties together with the stability of the chosen numerical scheme. This is achieved by minimizing the error between the output of the simulations using coarsened and original graph. We demonstrate the approach on several example differential equations, modeling sub-surface flow and wave propagation. We demonstrate that the model exhibits ability to maintain high fidelity in simulation outputs even after 95\\% reduction on the nodes, significantly reducing computational overhead. We also show that the model exhibits generalizability to unseen scenarios, thereby outperforming the baselines. Thus, the developed approach demonstrates the ability to accelerate simulation without comprising accuracy and hence has potential for accelerating physical simulations in various domains.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=TSTgP4W3ga",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 8,
      "track_name": "Main Conference",
      "author": {
        "id": "~N_M_Anoop_Krishnan1",
        "name": "N M Anoop Krishnan",
        "name_site": null,
        "openreview_id": "~N_M_Anoop_Krishnan1",
        "position": 6,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.co.in/citations?user=fGnjHcEAAAAJ",
        "orcid": "0000-0003-1500-4947",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (Russian Federation)",
        "countries": [
          "Russian Federation"
        ],
        "country_codes": [
          "UN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.25,
        "confidence_std": 1.0897247358851685,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "UAzVXdgheU",
      "title": "How To Be A Good Teacher? Process Strong Pretrained Models For Effective Knowledge Distillation",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Transferring the world knowledge encoded in pretrained models through knowledge distillation is an effective approach to improve the performance of small, task-specific production models. However, the effectiveness of such knowledge transfer drops greatly for strong models that are pretrained in a large scale. In this paper, we explore methods to preprocess strong pretrained models to improve the effectiveness of its knowledge transfer. From a mutual information perspective of distillation effectiveness, we propose to incorporate mutual information-aware optimization into the fine-tuning of strong pretrained models. For small or highly-imbalanced downstream datasets where such optimization is less effective, we further propose to heuristically reweight the MLP blocks, which is inspired by our observation that top MLP blocks often cause the loss of mutual information. Our method enables small student models to benefit from those pretrained models among the strongest.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=UAzVXdgheU",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Noveen_Sachdeva2",
        "name": "Noveen Sachdeva",
        "name_site": null,
        "openreview_id": "~Noveen_Sachdeva2",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.noveens.com/",
        "dblp_id": "216/7290",
        "google_scholar_url": "i6tMWAoAAAAJ",
        "orcid": null,
        "linkedin_url": "noveensachdeva/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.666666666666667,
        "rating_std": 1.247219128924647,
        "confidence_mean": 4.333333333333333,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "UK0jrVGCg2",
      "title": "Accelerated Diffusion using Closed-form Discriminator Guidance",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Diffusion models are a state-of-the-art generative modeling framework that transform noise to images via Langevin sampling, guided by the score, which is the gradient of the logarithm of the data distribution. Recent works have shown empirically that the generation quality can be improved when guided by classifier network, which is typically the discriminator trained in a generative adversarial network (GAN) setting. In this paper, we propose a theoretical framework to analyze the effect of the GAN discriminator on Langevin-based sampling, and show that in IPM GANs, the optimal generator matches {\\it score-like} functions, involving the flow-field of the kernel associated with a chosen IPM constraint space. Further, we show that IPM-GAN optimization can be seen as one of smoothed score-matching, where the scores of the data and the generator distributions are convolved with the kernel associated with the constraint. The proposed approach serves to unify score-based training and optimization of IPM-GANs. Based on these insights, we demonstrate that closed-form discriminator guidance, using a kernel-based implementation, results in  improvements (in terms of CLIP-FID and KID metrics) when applied atop baseline diffusion models. We demonstrate these results by applying closed-form discriminator guidance to denoising diffusion implicit model (DDIM) and latent diffusion model (LDM) settings on the FFHQ and CelebA-HQ datasets. We also demonstrate improvements to accelerated time-step-shifted diffusion, when coupled with a wavelet-based noise estimator for latent-space image generation.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=UK0jrVGCg2",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Siddarth_Asokan1",
        "name": "Siddarth Asokan",
        "name_site": null,
        "openreview_id": "~Siddarth_Asokan1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://siddarthasokan.com",
        "dblp_id": "277/5532",
        "google_scholar_url": "tM4SYUQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 2.6666666666666665,
        "confidence_std": 1.247219128924647,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "UK0jrVGCg2",
      "title": "Accelerated Diffusion using Closed-form Discriminator Guidance",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Diffusion models are a state-of-the-art generative modeling framework that transform noise to images via Langevin sampling, guided by the score, which is the gradient of the logarithm of the data distribution. Recent works have shown empirically that the generation quality can be improved when guided by classifier network, which is typically the discriminator trained in a generative adversarial network (GAN) setting. In this paper, we propose a theoretical framework to analyze the effect of the GAN discriminator on Langevin-based sampling, and show that in IPM GANs, the optimal generator matches {\\it score-like} functions, involving the flow-field of the kernel associated with a chosen IPM constraint space. Further, we show that IPM-GAN optimization can be seen as one of smoothed score-matching, where the scores of the data and the generator distributions are convolved with the kernel associated with the constraint. The proposed approach serves to unify score-based training and optimization of IPM-GANs. Based on these insights, we demonstrate that closed-form discriminator guidance, using a kernel-based implementation, results in  improvements (in terms of CLIP-FID and KID metrics) when applied atop baseline diffusion models. We demonstrate these results by applying closed-form discriminator guidance to denoising diffusion implicit model (DDIM) and latent diffusion model (LDM) settings on the FFHQ and CelebA-HQ datasets. We also demonstrate improvements to accelerated time-step-shifted diffusion, when coupled with a wavelet-based noise estimator for latent-space image generation.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=UK0jrVGCg2",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Nishanth_Shetty1",
        "name": "Nishanth Shetty",
        "name_site": null,
        "openreview_id": "~Nishanth_Shetty1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://nishanth-shetty.github.io/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0009-0001-0158-4656",
        "linkedin_url": "nishetty/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 2.6666666666666665,
        "confidence_std": 1.247219128924647,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "URGbPppsY8",
      "title": "Socia: Training Large Language Models To Simulate Social Constructs and Interventions",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Large language models (LLMs) have become ubiquitous in various applications. Recently, multiple research studies have tried to simulate social constructs, like opinions, culture, and interventions such as experiments. However, despite this progress, there is much scope of improvement in simulating social constructs. Further, it is crucial that LLMs reflect the opinions of the users they are interacting with. \nCurrent methods that train LLMs to simulate human opinions rely heavily on human-annotated datasets, which are expensive, difficult to scale, and often biased toward specific demographic subgroups. Instead of relying on small, annotated opinion datasets, we introduce a novel approach for unsupervised LLM training on behavioral data. Our approach is based on the maxim in psychology that social transactions are the only observable facets of a society. Leveraging this insight, we developed SOCIA50M comprising over 50 million samples derived from 1.5 million advertisements, including content and demographic viewing behaviors.\nWe train LLMs on SOCIA50M, demonstrating significant improvements over existing simulation techniques across multiple opinions and cultural alignment benchmarks, including GlobalOpinionQA, OpinionQA, CultureNLI, and CultureBank, without explicitly finetuning on these datasets. We further show using the Time-shared Experiments for Social Sciences (TESS) that LLMs trained on behavior data can be used to predict the outcomes of social science experiments, a novel insight on the predictive power of behavioral training signals.\n\nOur approach addresses key limitations of current methods, offering improved scalability, demographic representation, and adaptability to evolving societal views. Our results suggest the potential for easily available social transaction data to replace or complement traditional expert-annotation-based alignment techniques.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=URGbPppsY8",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aanisha_Bhattacharyya2",
        "name": "Aanisha Bhattacharyya",
        "name_site": null,
        "openreview_id": "~Aanisha_Bhattacharyya2",
        "position": 1,
        "gender": "F",
        "homepage_url": "https://www.linkedin.com/in/aanisha-bhattacharyya/",
        "dblp_id": null,
        "google_scholar_url": "PkCeGdoAAAAJ",
        "orcid": null,
        "linkedin_url": "aanisha-bhattacharyya/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Adobe (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 0.0,
        "rating_std": 0.0,
        "confidence_mean": 0.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "URGbPppsY8",
      "title": "Socia: Training Large Language Models To Simulate Social Constructs and Interventions",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Large language models (LLMs) have become ubiquitous in various applications. Recently, multiple research studies have tried to simulate social constructs, like opinions, culture, and interventions such as experiments. However, despite this progress, there is much scope of improvement in simulating social constructs. Further, it is crucial that LLMs reflect the opinions of the users they are interacting with. \nCurrent methods that train LLMs to simulate human opinions rely heavily on human-annotated datasets, which are expensive, difficult to scale, and often biased toward specific demographic subgroups. Instead of relying on small, annotated opinion datasets, we introduce a novel approach for unsupervised LLM training on behavioral data. Our approach is based on the maxim in psychology that social transactions are the only observable facets of a society. Leveraging this insight, we developed SOCIA50M comprising over 50 million samples derived from 1.5 million advertisements, including content and demographic viewing behaviors.\nWe train LLMs on SOCIA50M, demonstrating significant improvements over existing simulation techniques across multiple opinions and cultural alignment benchmarks, including GlobalOpinionQA, OpinionQA, CultureNLI, and CultureBank, without explicitly finetuning on these datasets. We further show using the Time-shared Experiments for Social Sciences (TESS) that LLMs trained on behavior data can be used to predict the outcomes of social science experiments, a novel insight on the predictive power of behavioral training signals.\n\nOur approach addresses key limitations of current methods, offering improved scalability, demographic representation, and adaptability to evolving societal views. Our results suggest the potential for easily available social transaction data to replace or complement traditional expert-annotation-based alignment techniques.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=URGbPppsY8",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Susmit_Agrawal1",
        "name": "Susmit Agrawal",
        "name_site": null,
        "openreview_id": "~Susmit_Agrawal1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://susmit-a.github.io",
        "dblp_id": "278/3579",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": "0000-0002-7701-131X",
        "linkedin_url": "susmitagrawal",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 0.0,
        "rating_std": 0.0,
        "confidence_mean": 0.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "URGbPppsY8",
      "title": "Socia: Training Large Language Models To Simulate Social Constructs and Interventions",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Large language models (LLMs) have become ubiquitous in various applications. Recently, multiple research studies have tried to simulate social constructs, like opinions, culture, and interventions such as experiments. However, despite this progress, there is much scope of improvement in simulating social constructs. Further, it is crucial that LLMs reflect the opinions of the users they are interacting with. \nCurrent methods that train LLMs to simulate human opinions rely heavily on human-annotated datasets, which are expensive, difficult to scale, and often biased toward specific demographic subgroups. Instead of relying on small, annotated opinion datasets, we introduce a novel approach for unsupervised LLM training on behavioral data. Our approach is based on the maxim in psychology that social transactions are the only observable facets of a society. Leveraging this insight, we developed SOCIA50M comprising over 50 million samples derived from 1.5 million advertisements, including content and demographic viewing behaviors.\nWe train LLMs on SOCIA50M, demonstrating significant improvements over existing simulation techniques across multiple opinions and cultural alignment benchmarks, including GlobalOpinionQA, OpinionQA, CultureNLI, and CultureBank, without explicitly finetuning on these datasets. We further show using the Time-shared Experiments for Social Sciences (TESS) that LLMs trained on behavior data can be used to predict the outcomes of social science experiments, a novel insight on the predictive power of behavioral training signals.\n\nOur approach addresses key limitations of current methods, offering improved scalability, demographic representation, and adaptability to evolving societal views. Our results suggest the potential for easily available social transaction data to replace or complement traditional expert-annotation-based alignment techniques.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=URGbPppsY8",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Tarun_Ram_Menta1",
        "name": "Tarun Ram Menta",
        "name_site": null,
        "openreview_id": "~Tarun_Ram_Menta1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "290/7394",
        "google_scholar_url": "8HC8W9EAAAAJ",
        "orcid": null,
        "linkedin_url": "tarun-ram-menta-50b4121b9",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Adobe (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 0.0,
        "rating_std": 0.0,
        "confidence_mean": 0.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "URGbPppsY8",
      "title": "Socia: Training Large Language Models To Simulate Social Constructs and Interventions",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Large language models (LLMs) have become ubiquitous in various applications. Recently, multiple research studies have tried to simulate social constructs, like opinions, culture, and interventions such as experiments. However, despite this progress, there is much scope of improvement in simulating social constructs. Further, it is crucial that LLMs reflect the opinions of the users they are interacting with. \nCurrent methods that train LLMs to simulate human opinions rely heavily on human-annotated datasets, which are expensive, difficult to scale, and often biased toward specific demographic subgroups. Instead of relying on small, annotated opinion datasets, we introduce a novel approach for unsupervised LLM training on behavioral data. Our approach is based on the maxim in psychology that social transactions are the only observable facets of a society. Leveraging this insight, we developed SOCIA50M comprising over 50 million samples derived from 1.5 million advertisements, including content and demographic viewing behaviors.\nWe train LLMs on SOCIA50M, demonstrating significant improvements over existing simulation techniques across multiple opinions and cultural alignment benchmarks, including GlobalOpinionQA, OpinionQA, CultureNLI, and CultureBank, without explicitly finetuning on these datasets. We further show using the Time-shared Experiments for Social Sciences (TESS) that LLMs trained on behavior data can be used to predict the outcomes of social science experiments, a novel insight on the predictive power of behavioral training signals.\n\nOur approach addresses key limitations of current methods, offering improved scalability, demographic representation, and adaptability to evolving societal views. Our results suggest the potential for easily available social transaction data to replace or complement traditional expert-annotation-based alignment techniques.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=URGbPppsY8",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yaman_Kumar1",
        "name": "Yaman Kumar",
        "name_site": null,
        "openreview_id": "~Yaman_Kumar1",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/yaman-kumar/",
        "dblp_id": "239/5601",
        "google_scholar_url": "https://scholar.google.co.in/citations?hl=en",
        "orcid": "0000-0001-7880-8219",
        "linkedin_url": "yaman-kumar/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 0.0,
        "rating_std": 0.0,
        "confidence_mean": 0.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "UkGrcekmSZ",
      "title": "Leveraging deep learning for comprehensive classification of renal diseases: A transfer learning approach",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The nightmare of cancer as a leading cause of premature deaths worldwide is becoming real and turns out to be one of the major problems of humanity nowadays. Cancer diagnostics at the early stage is Critical to cancer recovery and survival. In this context, renal diseases, including kidney cysts, stones, and tumors, pose significant global health challenges, affecting approximately 12\\% of the population and contributing to chronic kidney disease (CKD). Notably, renal cancer ranks as the tenth most prevalent cancer type, accounting for 2.7\\% of all cancer cases. This work presents a deep learning (DL) framework utilizing transfer learning (TL) for the early detection of renal diseases and categorizing the conditions into four binary classifications: Cyst\\_vs\\_Normal, Cyst\\_vs\\_Stone, Cyst\\_vs\\_Tumor, and Stone\\_vs\\_Tumor, allowing for a more specific understanding of each stage. By analyzing CT scans and microscopic histopathology images, the framework employs convolutional neural networks (CNNs) with pre-trained models to facilitate automatic and precise classification of renal conditions. Specifically, two CNN models ResNet-50 and EfficientNetV2 are implemented, providing a comprehensive analysis of each stage of the DL architecture. Comparative evaluations of training outcomes across various datasets revealed that EfficientNetV2 performed marginally better than ResNet-50, achieving an impressive testing accuracy of up to 100\\% for all cases. These results underscore the effectiveness of the DL-based system and highlight its potential for widespread clinical application in renal disease diagnosis.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=UkGrcekmSZ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 1,
      "track_name": "Main Conference",
      "author": {
        "id": "~Agniva_Banerjee1",
        "name": "Agniva Banerjee",
        "name_site": null,
        "openreview_id": "~Agniva_Banerjee1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "agniva-banerjee-700113237/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science Education and Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.0,
        "rating_std": 1.0,
        "confidence_mean": 4.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "UzgMX1rwGc",
      "title": "Smart Placement Enhanced Vision: Enhancing 3D-Detection With Learned 3D Placement",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "The diversity and scale of annotated real-world 3D datasets limit the performance of monocular 3D detectors. Although data augmentation holds potential, creating realistic, scene-aware augmentations for outdoor environments presents a significant challenge.\nExisting augmentation methods majorly focus on realistic object appearance by advancing the rendering quality. However, we show that object placement is equally important for downstream 3D detection performance. The main challenge, however, for realistic placement, is to automatically identify the plausible physical properties (location, scale, and orientation) for placing objects in real-world scenes. To this end, we propose Smart-Placement, a novel 3D scene-aware augmentation method for generating diverse and realistic augmentations. In particular, given a background scene, we train a placement network to learn a distribution over plausible 3D bounding boxes. Subsequently, we render realistic cars from 3D assets and place them according to the locations sampled from the learned distribution. Through extensive empirical evaluation on standard benchmark datasets - KITTI and NuScenes, we show that our proposed augmentation method significantly boosts the performance of several existing monocular 3D detectors, setting a new state-of-the-art benchmark, while being highly data efficient.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=UzgMX1rwGc",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rishubh_Parihar1",
        "name": "Rishubh Parihar",
        "name_site": null,
        "openreview_id": "~Rishubh_Parihar1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "264/3534",
        "google_scholar_url": "RaRoJFYAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "UzgMX1rwGc",
      "title": "Smart Placement Enhanced Vision: Enhancing 3D-Detection With Learned 3D Placement",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "The diversity and scale of annotated real-world 3D datasets limit the performance of monocular 3D detectors. Although data augmentation holds potential, creating realistic, scene-aware augmentations for outdoor environments presents a significant challenge.\nExisting augmentation methods majorly focus on realistic object appearance by advancing the rendering quality. However, we show that object placement is equally important for downstream 3D detection performance. The main challenge, however, for realistic placement, is to automatically identify the plausible physical properties (location, scale, and orientation) for placing objects in real-world scenes. To this end, we propose Smart-Placement, a novel 3D scene-aware augmentation method for generating diverse and realistic augmentations. In particular, given a background scene, we train a placement network to learn a distribution over plausible 3D bounding boxes. Subsequently, we render realistic cars from 3D assets and place them according to the locations sampled from the learned distribution. Through extensive empirical evaluation on standard benchmark datasets - KITTI and NuScenes, we show that our proposed augmentation method significantly boosts the performance of several existing monocular 3D detectors, setting a new state-of-the-art benchmark, while being highly data efficient.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=UzgMX1rwGc",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Srinjay_Sarkar1",
        "name": "Srinjay Sarkar",
        "name_site": null,
        "openreview_id": "~Srinjay_Sarkar1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "244/7955",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "srinjay-sarkar-1501b9112/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "UzgMX1rwGc",
      "title": "Smart Placement Enhanced Vision: Enhancing 3D-Detection With Learned 3D Placement",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "The diversity and scale of annotated real-world 3D datasets limit the performance of monocular 3D detectors. Although data augmentation holds potential, creating realistic, scene-aware augmentations for outdoor environments presents a significant challenge.\nExisting augmentation methods majorly focus on realistic object appearance by advancing the rendering quality. However, we show that object placement is equally important for downstream 3D detection performance. The main challenge, however, for realistic placement, is to automatically identify the plausible physical properties (location, scale, and orientation) for placing objects in real-world scenes. To this end, we propose Smart-Placement, a novel 3D scene-aware augmentation method for generating diverse and realistic augmentations. In particular, given a background scene, we train a placement network to learn a distribution over plausible 3D bounding boxes. Subsequently, we render realistic cars from 3D assets and place them according to the locations sampled from the learned distribution. Through extensive empirical evaluation on standard benchmark datasets - KITTI and NuScenes, we show that our proposed augmentation method significantly boosts the performance of several existing monocular 3D detectors, setting a new state-of-the-art benchmark, while being highly data efficient.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=UzgMX1rwGc",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sarthak_Vora1",
        "name": "Sarthak Vora",
        "name_site": null,
        "openreview_id": "~Sarthak_Vora1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://sarthak-22.github.io",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "sarthak-22",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of California, Los Angeles (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "UzgMX1rwGc",
      "title": "Smart Placement Enhanced Vision: Enhancing 3D-Detection With Learned 3D Placement",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "The diversity and scale of annotated real-world 3D datasets limit the performance of monocular 3D detectors. Although data augmentation holds potential, creating realistic, scene-aware augmentations for outdoor environments presents a significant challenge.\nExisting augmentation methods majorly focus on realistic object appearance by advancing the rendering quality. However, we show that object placement is equally important for downstream 3D detection performance. The main challenge, however, for realistic placement, is to automatically identify the plausible physical properties (location, scale, and orientation) for placing objects in real-world scenes. To this end, we propose Smart-Placement, a novel 3D scene-aware augmentation method for generating diverse and realistic augmentations. In particular, given a background scene, we train a placement network to learn a distribution over plausible 3D bounding boxes. Subsequently, we render realistic cars from 3D assets and place them according to the locations sampled from the learned distribution. Through extensive empirical evaluation on standard benchmark datasets - KITTI and NuScenes, we show that our proposed augmentation method significantly boosts the performance of several existing monocular 3D detectors, setting a new state-of-the-art benchmark, while being highly data efficient.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=UzgMX1rwGc",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Venkatesh_Babu_Radhakrishnan2",
        "name": "Venkatesh Babu Radhakrishnan",
        "name_site": null,
        "openreview_id": "~Venkatesh_Babu_Radhakrishnan2",
        "position": 5,
        "gender": "M",
        "homepage_url": "http://cds.iisc.ac.in/faculty/venky",
        "dblp_id": "20/6289",
        "google_scholar_url": "cVg7HrEAAAAJ",
        "orcid": "0000-0002-1926-1804",
        "linkedin_url": "venkatesh-babu-radhakrishnan-16568939",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "VAvZ4oinpa",
      "title": "Video Generation with Learned Action Prior",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Long-term stochastic video generation remains challenging, especially with moving cameras. This scenario introduces complex interactions between camera movement and observed pixels, resulting in intricate spatio-temporal dynamics and partial observability issues. Current approaches often focus on pixel-level image reconstruction, neglecting explicit modeling of camera motion dynamics. Our proposed solution incorporates camera motion or action as an extended part of the observed image state, employing a multi-modal learning framework to simultaneously model both image and action. We introduce three models: (i) Video Generation with Learning Action Prior (VG-LeAP) that treats the image-action pair as an augmented state generated from a single latent stochastic process and uses variational inference to learn the image-action latent prior; (ii) Causal-LeAP, which establishes a causal relationship between action and the observed image frame, and learns a seperate action prior, conditioned on the observed image states along with the image prior; and (iii) RAFI, which integrates the augmented image-action state concept with a conditional flow matching framework, demonstrating that this action-conditioned image generation concept can be extended to other transformer-based architectures. Through comprehensive empirical studies on robotic video dataset, RoAM, we highlight the importance of multi-modal training in addressing partially observable video generation problems.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=VAvZ4oinpa",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Meenakshi_Sarkar1",
        "name": "Meenakshi Sarkar",
        "name_site": null,
        "openreview_id": "~Meenakshi_Sarkar1",
        "position": 1,
        "gender": null,
        "homepage_url": "https://sites.google.com/view/meenakshisarkar",
        "dblp_id": "228/7716",
        "google_scholar_url": "PPsneeEAAAAJ",
        "orcid": "0000-0001-5786-6997",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "VAvZ4oinpa",
      "title": "Video Generation with Learned Action Prior",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Long-term stochastic video generation remains challenging, especially with moving cameras. This scenario introduces complex interactions between camera movement and observed pixels, resulting in intricate spatio-temporal dynamics and partial observability issues. Current approaches often focus on pixel-level image reconstruction, neglecting explicit modeling of camera motion dynamics. Our proposed solution incorporates camera motion or action as an extended part of the observed image state, employing a multi-modal learning framework to simultaneously model both image and action. We introduce three models: (i) Video Generation with Learning Action Prior (VG-LeAP) that treats the image-action pair as an augmented state generated from a single latent stochastic process and uses variational inference to learn the image-action latent prior; (ii) Causal-LeAP, which establishes a causal relationship between action and the observed image frame, and learns a seperate action prior, conditioned on the observed image states along with the image prior; and (iii) RAFI, which integrates the augmented image-action state concept with a conditional flow matching framework, demonstrating that this action-conditioned image generation concept can be extended to other transformer-based architectures. Through comprehensive empirical studies on robotic video dataset, RoAM, we highlight the importance of multi-modal training in addressing partially observable video generation problems.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=VAvZ4oinpa",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Devansh_Bhardwaj1",
        "name": "Devansh Bhardwaj",
        "name_site": null,
        "openreview_id": "~Devansh_Bhardwaj1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://fireshadow05.github.io/",
        "dblp_id": null,
        "google_scholar_url": "kBHnXToAAAAJ",
        "orcid": null,
        "linkedin_url": "devansh-bhardwaj-3b18b923a/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Roorkee (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "VZC9aJoI6a",
      "title": "PromptWizard: Task-Aware Prompt Optimization Framework",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Large language models (LLMs) have transformed AI across diverse domains, with \\textit{prompting} being central to their success in guiding model outputs. However, manual prompt engineering is both labor-intensive and domain-specific, necessitating the need for automated solutions. We introduce PromptWizard, a novel, fully automated framework for discrete prompt optimization, utilizing a self-evolving, self-adapting mechanism. Through a feedback-driven critique and synthesis process, PromptWizard achieves an effective balance between exploration and exploitation, iteratively refining both prompt instructions and in-context examples to generate human-readable, task-specific prompts. This guided approach systematically improves prompt quality, resulting in superior performance across 45 tasks. PromptWizard excels even with limited training data, smaller LLMs, and various LLM architectures. Additionally, our cost analysis reveals a substantial reduction in API calls, token usage, and overall cost, demonstrating PromptWizard's efficiency, scalability, and advantages over existing prompt optimization strategies.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=VZC9aJoI6a",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Eshaan_Agarwal1",
        "name": "Eshaan Agarwal",
        "name_site": null,
        "openreview_id": "~Eshaan_Agarwal1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "eshaanagarwal",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.4,
        "rating_std": 1.2,
        "confidence_mean": 3.8,
        "confidence_std": 0.7483314773547882,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ViRDmDAfjg",
      "title": "Task Facet Learning: A Structured Approach to Prompt Optimization",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Given a task in the form of a basic description and its training examples, prompt optimization is the problem of synthesizing the given information into a text prompt for a large language model. Humans solve this problem by also considering the different facets that define a task (e.g., counter-examples, explanations, analogies) and including them in the prompt. However, it is unclear whether existing algorithmic approaches, based on iteratively editing a given prompt or automatically selecting a few in-context examples, can cover the multiple facets required to solve a complex task.  In this work, we view prompt optimization as that of learning multiple facets of a task from a set of training examples. We exploit structure in the prompt optimization problem and break down a prompt into loosely coupled semantic sections. The proposed algorithm, UniPrompt, (1) clusters the input space and uses clustered batches so that each batch likely corresponds to a different facet of the task, and (2) utilizes a feedback mechanism to propose adding, editing or deleting a section, which in turn is aggregated over a batch to capture generalizable facets. Empirical evaluation on multiple datasets and a real-world task shows that prompts generated using UniPrompt obtain higher accuracy than human-tuned prompts and those from state-of-the-art methods. In particular, our algorithm can generate long, complex prompts that existing methods are unable to generate.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ViRDmDAfjg",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Gurusha_Juneja2",
        "name": "Gurusha Juneja",
        "name_site": null,
        "openreview_id": "~Gautam_Jajoo1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://gautamjajoo.github.io/",
        "dblp_id": "389/3634",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "gautamjajoo/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ViRDmDAfjg",
      "title": "Task Facet Learning: A Structured Approach to Prompt Optimization",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Given a task in the form of a basic description and its training examples, prompt optimization is the problem of synthesizing the given information into a text prompt for a large language model. Humans solve this problem by also considering the different facets that define a task (e.g., counter-examples, explanations, analogies) and including them in the prompt. However, it is unclear whether existing algorithmic approaches, based on iteratively editing a given prompt or automatically selecting a few in-context examples, can cover the multiple facets required to solve a complex task.  In this work, we view prompt optimization as that of learning multiple facets of a task from a set of training examples. We exploit structure in the prompt optimization problem and break down a prompt into loosely coupled semantic sections. The proposed algorithm, UniPrompt, (1) clusters the input space and uses clustered batches so that each batch likely corresponds to a different facet of the task, and (2) utilizes a feedback mechanism to propose adding, editing or deleting a section, which in turn is aggregated over a batch to capture generalizable facets. Empirical evaluation on multiple datasets and a real-world task shows that prompts generated using UniPrompt obtain higher accuracy than human-tuned prompts and those from state-of-the-art methods. In particular, our algorithm can generate long, complex prompts that existing methods are unable to generate.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ViRDmDAfjg",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Amit_Sharma3",
        "name": "Amit Sharma",
        "name_site": null,
        "openreview_id": "~Amit_Sharma3",
        "position": 5,
        "gender": "M",
        "homepage_url": "http://amitsharma.in/",
        "dblp_id": "72/2540-7",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=CXgQufgAAAAJ",
        "orcid": "0000-0002-2086-3191",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of California, Santa Barbara (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "VpeAsLmcvg",
      "title": "Singular Value Adaptation for Parameter-Efficient Fine Tuning",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Parameter-Efficient Fine-Tuning (PEFT) has become a crucial approach in handling the growing complexity of large models and vast datasets across multiple fields such as Computer Vision or Natural Language Processing. Among the most promising of these methods are Low-Rank Adaptation (LoRA) and its derivatives, which fine-tune a pre-trained weight matrix $\\mathbf{W}$ by introducing a low-rank update matrix $\\mathbf{\\Delta W}$. While these approaches have demonstrated strong empirical performance, they remain largely heuristic, with little theoretical grounding to explain their behavior or guide the design of $\\mathbf{\\Delta W}$ for different objectives. This lack of theoretical insight limits our understanding of when these methods are most effective and how they can be systematically improved. In this paper, we propose a theoretical framework for analyzing and designing LoRA-based methods, with a focus on the formulation of $\\mathbf{\\Delta W}$. By establishing a deeper understanding of the interplay between $\\mathbf{W}$ and $\\mathbf{\\Delta W}$, we aim to enable more efficient and targeted fine-tuning strategies, opening the door to novel variants that strike an optimal balance between performance and efficiency. Our proposed method - \\textbf{Si}ngular \\textbf{V}alue \\textbf{A}daptation - uses insights from our theoretical framework to incorporate inductive biases on the formulation of $\\mathbf{\\Delta W}$, leading to a PEFT method that is up to 50$\\times$ more parameter efficient that LoRA, while achieving comparable or better performance across various vision and language tasks.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=VpeAsLmcvg",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Susmit_Agrawal1",
        "name": "Susmit Agrawal",
        "name_site": null,
        "openreview_id": "~Susmit_Agrawal1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://susmit-a.github.io",
        "dblp_id": "278/3579",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": "0000-0002-7701-131X",
        "linkedin_url": "susmitagrawal",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "VpeAsLmcvg",
      "title": "Singular Value Adaptation for Parameter-Efficient Fine Tuning",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Parameter-Efficient Fine-Tuning (PEFT) has become a crucial approach in handling the growing complexity of large models and vast datasets across multiple fields such as Computer Vision or Natural Language Processing. Among the most promising of these methods are Low-Rank Adaptation (LoRA) and its derivatives, which fine-tune a pre-trained weight matrix $\\mathbf{W}$ by introducing a low-rank update matrix $\\mathbf{\\Delta W}$. While these approaches have demonstrated strong empirical performance, they remain largely heuristic, with little theoretical grounding to explain their behavior or guide the design of $\\mathbf{\\Delta W}$ for different objectives. This lack of theoretical insight limits our understanding of when these methods are most effective and how they can be systematically improved. In this paper, we propose a theoretical framework for analyzing and designing LoRA-based methods, with a focus on the formulation of $\\mathbf{\\Delta W}$. By establishing a deeper understanding of the interplay between $\\mathbf{W}$ and $\\mathbf{\\Delta W}$, we aim to enable more efficient and targeted fine-tuning strategies, opening the door to novel variants that strike an optimal balance between performance and efficiency. Our proposed method - \\textbf{Si}ngular \\textbf{V}alue \\textbf{A}daptation - uses insights from our theoretical framework to incorporate inductive biases on the formulation of $\\mathbf{\\Delta W}$, leading to a PEFT method that is up to 50$\\times$ more parameter efficient that LoRA, while achieving comparable or better performance across various vision and language tasks.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=VpeAsLmcvg",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Krishn_Vishwas_Kher1",
        "name": "Krishn Vishwas Kher",
        "name_site": null,
        "openreview_id": "~Krishn_Vishwas_Kher1",
        "position": 2,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "VpeAsLmcvg",
      "title": "Singular Value Adaptation for Parameter-Efficient Fine Tuning",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Parameter-Efficient Fine-Tuning (PEFT) has become a crucial approach in handling the growing complexity of large models and vast datasets across multiple fields such as Computer Vision or Natural Language Processing. Among the most promising of these methods are Low-Rank Adaptation (LoRA) and its derivatives, which fine-tune a pre-trained weight matrix $\\mathbf{W}$ by introducing a low-rank update matrix $\\mathbf{\\Delta W}$. While these approaches have demonstrated strong empirical performance, they remain largely heuristic, with little theoretical grounding to explain their behavior or guide the design of $\\mathbf{\\Delta W}$ for different objectives. This lack of theoretical insight limits our understanding of when these methods are most effective and how they can be systematically improved. In this paper, we propose a theoretical framework for analyzing and designing LoRA-based methods, with a focus on the formulation of $\\mathbf{\\Delta W}$. By establishing a deeper understanding of the interplay between $\\mathbf{W}$ and $\\mathbf{\\Delta W}$, we aim to enable more efficient and targeted fine-tuning strategies, opening the door to novel variants that strike an optimal balance between performance and efficiency. Our proposed method - \\textbf{Si}ngular \\textbf{V}alue \\textbf{A}daptation - uses insights from our theoretical framework to incorporate inductive biases on the formulation of $\\mathbf{\\Delta W}$, leading to a PEFT method that is up to 50$\\times$ more parameter efficient that LoRA, while achieving comparable or better performance across various vision and language tasks.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=VpeAsLmcvg",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Swarnim_Maheshwari1",
        "name": "Swarnim Maheshwari",
        "name_site": null,
        "openreview_id": "~Swarnim_Maheshwari1",
        "position": 3,
        "gender": "Not Specified",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "swarnim-maheshwari-0b2067162/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Mohamed bin Zayed University of Artificial Intelligence (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Vszt1FDElj",
      "title": "Coarsening to Conceal: Enabling Privacy-Preserving Federated Learning for Graph Data",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "With the escalating demand for privacy-preserving machine learning, federated learning (FL) stands out by enabling collaboration among decentralized entities. Utilizing graph representations of data enhances learning for graph-level tasks, crucial for FL with data distributed across local repositories. Despite its benefits, stringent privacy regulations often compromise FL's performance. Previous methods aimed at ensuring privacy introduce performance degradation and computational overhead. In response to these challenges, we propose using graph coarsening—a simple yet effective method—to enhance the security and privacy of FL on graph data. Our approach posits that graph coarsening alone can suffice for privacy guarantees, as model parameters obtained from training on the coarsened graph effectively conceal sensitive information susceptible to privacy attacks. Through comprehensive application and analysis, we demonstrate the efficacy of graph coarsening within an FL setup, taking both the graph matrix and node features as input, and jointly learning the coarsened graph matrix and feature matrix while ensuring desired properties. The resultant coarsened graph representations are then utilized to train model parameters, subsequently communicated within an FL framework for downstream tasks such as classification. Extensive experimentation across various datasets confirms that graph coarsening ensures privacy while enhancing performance with minimal trade-offs compared to traditional differential privacy (DP) methods without adding extra complexity overhead.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Vszt1FDElj",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ekta_Srivastava1",
        "name": "Ekta Srivastava",
        "name_site": null,
        "openreview_id": "~Ekta_Srivastava1",
        "position": 1,
        "gender": "F",
        "homepage_url": "https://misn.iitd.ac.in/",
        "dblp_id": null,
        "google_scholar_url": "TuezPkMAAAAJ",
        "orcid": null,
        "linkedin_url": "ektasrivastava1806/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Vszt1FDElj",
      "title": "Coarsening to Conceal: Enabling Privacy-Preserving Federated Learning for Graph Data",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "With the escalating demand for privacy-preserving machine learning, federated learning (FL) stands out by enabling collaboration among decentralized entities. Utilizing graph representations of data enhances learning for graph-level tasks, crucial for FL with data distributed across local repositories. Despite its benefits, stringent privacy regulations often compromise FL's performance. Previous methods aimed at ensuring privacy introduce performance degradation and computational overhead. In response to these challenges, we propose using graph coarsening—a simple yet effective method—to enhance the security and privacy of FL on graph data. Our approach posits that graph coarsening alone can suffice for privacy guarantees, as model parameters obtained from training on the coarsened graph effectively conceal sensitive information susceptible to privacy attacks. Through comprehensive application and analysis, we demonstrate the efficacy of graph coarsening within an FL setup, taking both the graph matrix and node features as input, and jointly learning the coarsened graph matrix and feature matrix while ensuring desired properties. The resultant coarsened graph representations are then utilized to train model parameters, subsequently communicated within an FL framework for downstream tasks such as classification. Extensive experimentation across various datasets confirms that graph coarsening ensures privacy while enhancing performance with minimal trade-offs compared to traditional differential privacy (DP) methods without adding extra complexity overhead.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Vszt1FDElj",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manoj_Kumar4",
        "name": "Manoj Kumar",
        "name_site": null,
        "openreview_id": "~Manoj_Kumar4",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "gdL-bokAAAAJ",
        "orcid": null,
        "linkedin_url": "manoj-kumar-9042b449/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "LNM Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Vszt1FDElj",
      "title": "Coarsening to Conceal: Enabling Privacy-Preserving Federated Learning for Graph Data",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "With the escalating demand for privacy-preserving machine learning, federated learning (FL) stands out by enabling collaboration among decentralized entities. Utilizing graph representations of data enhances learning for graph-level tasks, crucial for FL with data distributed across local repositories. Despite its benefits, stringent privacy regulations often compromise FL's performance. Previous methods aimed at ensuring privacy introduce performance degradation and computational overhead. In response to these challenges, we propose using graph coarsening—a simple yet effective method—to enhance the security and privacy of FL on graph data. Our approach posits that graph coarsening alone can suffice for privacy guarantees, as model parameters obtained from training on the coarsened graph effectively conceal sensitive information susceptible to privacy attacks. Through comprehensive application and analysis, we demonstrate the efficacy of graph coarsening within an FL setup, taking both the graph matrix and node features as input, and jointly learning the coarsened graph matrix and feature matrix while ensuring desired properties. The resultant coarsened graph representations are then utilized to train model parameters, subsequently communicated within an FL framework for downstream tasks such as classification. Extensive experimentation across various datasets confirms that graph coarsening ensures privacy while enhancing performance with minimal trade-offs compared to traditional differential privacy (DP) methods without adding extra complexity overhead.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Vszt1FDElj",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Kumar_Arjun1",
        "name": "Kumar Arjun",
        "name_site": null,
        "openreview_id": "~Kumar_Arjun1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "kumar-arjun-36760a234/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Vszt1FDElj",
      "title": "Coarsening to Conceal: Enabling Privacy-Preserving Federated Learning for Graph Data",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "With the escalating demand for privacy-preserving machine learning, federated learning (FL) stands out by enabling collaboration among decentralized entities. Utilizing graph representations of data enhances learning for graph-level tasks, crucial for FL with data distributed across local repositories. Despite its benefits, stringent privacy regulations often compromise FL's performance. Previous methods aimed at ensuring privacy introduce performance degradation and computational overhead. In response to these challenges, we propose using graph coarsening—a simple yet effective method—to enhance the security and privacy of FL on graph data. Our approach posits that graph coarsening alone can suffice for privacy guarantees, as model parameters obtained from training on the coarsened graph effectively conceal sensitive information susceptible to privacy attacks. Through comprehensive application and analysis, we demonstrate the efficacy of graph coarsening within an FL setup, taking both the graph matrix and node features as input, and jointly learning the coarsened graph matrix and feature matrix while ensuring desired properties. The resultant coarsened graph representations are then utilized to train model parameters, subsequently communicated within an FL framework for downstream tasks such as classification. Extensive experimentation across various datasets confirms that graph coarsening ensures privacy while enhancing performance with minimal trade-offs compared to traditional differential privacy (DP) methods without adding extra complexity overhead.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Vszt1FDElj",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sandeep_Kumar8",
        "name": "Sandeep Kumar",
        "name_site": null,
        "openreview_id": "~Sandeep_Kumar8",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/sandeepkr/home",
        "dblp_id": null,
        "google_scholar_url": "lycMMW8AAAAJ",
        "orcid": null,
        "linkedin_url": "sandeep-kumar-84463332/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "VzdycorGTt",
      "title": "packetLSTM: Dynamic LSTM Framework for Streaming Data with Varying Feature Space",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We study the online learning problem characterized by the varying input feature space of streaming data. Although LSTMs have been employed to effectively capture the temporal nature of streaming data, they cannot handle the dimension-varying streams in an online learning setting. Therefore, we propose a dynamic LSTM-based novel method, packetLSTM, to model the dimension-varying streams. The packetLSTM's dynamic framework consists of an evolving packet of LSTMs, each dedicated to processing one input feature. Each LSTM retains the local information of its corresponding feature, while a shared common memory consolidates global information. This configuration facilitates continuous learning and mitigates the issue of forgetting, even when certain features are absent for extended time periods. The idea of utilizing one LSTM per feature coupled with a dimension-invariant operator for information aggregation enhances the dynamic nature of packetLSTM. This dynamic nature is evidenced by the model's ability to activate, deactivate, and add new LSTMs as required, thus seamlessly accommodating varying input dimensions. The packetLSTM achieves state-of-the-art results on five datasets, and its underlying principle is extended to other RNN types, like GRU and vanilla RNN.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=VzdycorGTt",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Karaka_Prasanth_Naidu1",
        "name": "Karaka Prasanth Naidu",
        "name_site": null,
        "openreview_id": "~Karaka_Prasanth_Naidu1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "prasanth-naidu-karaka-a7162019b/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology (IIT) Dhanbad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 1.8027756377319946,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "WOyjgWu92E",
      "title": "Benchmarking Positional Encodings for GNNs and Graph Transformers",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Recent advances in Graph Neural Networks (GNNs) and Graph Transformers (GTs) have been driven by innovations in architectures and Positional Encodings (PEs), which are critical for augmenting node features and capturing graph topology. PEs are essential for GTs, where topological information would otherwise be lost without message-passing. However, PEs are often tested alongside novel architectures, making it difficult to isolate their effect on established models. To address this, we present a comprehensive benchmark of PEs in a unified framework that includes both message-passing GNNs and GTs. We also establish theoretical connections between MPNNs and GTs and introduce a sparsified GRIT attention mechanism to examine the influence of global connectivity. Our findings demonstrate that previously untested combinations of GNN architectures and PEs can outperform existing methods, offering a more comprehensive picture of the state-of-the-art. To support future research and experimentation in our framework, we make the code publicly available.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=WOyjgWu92E",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Florian_Grötschla1",
        "name": "Florian Grötschla",
        "name_site": null,
        "openreview_id": "~Florian_Grötschla1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://disco.ethz.ch/members/fgroetschla",
        "dblp_id": "334/1811",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "ETH Zurich (Switzerland)",
        "countries": [
          "Switzerland"
        ],
        "country_codes": [
          "CH"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.6,
        "rating_std": 0.7999999999999999,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "WVLBWiKxjM",
      "title": "Deep Learning for Micro-Scale Crack Detection on Imbalanced Datasets Using Key Point Localization",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Internal crack detection has been a subject of focus in structural health monitoring. By focusing on crack detection in structural datasets, it is demonstrated that deep learning (DL) methods can effectively analyse seismic wave fields interacting with micro-scale cracks, which are beyond the resolution of conventional visual inspection.\n\nThis work explores a novel application of DL based key point detection technique, where cracks are localized by predicting the coordinates of four key points that define a bounding region of the crack.\nThe study not only opens new research directions for non-visual applications but also effectively mitigates the impact of imbalanced data which poses a challenge for previous DL models, as it can be biased toward predicting the majority class (non-crack regions). Popular DL techniques, such as the Inception blocks are used and investigated. \nThe model shows an overall reduction in loss when applied to micro-scale crack detection and is reflected in the lower average deviation between the location of actual and predicted cracks, with an average IOU being 0.511 for all micro cracks (> 0.00 µm) and 0.631 for larger micro cracks (> 4 µm).",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=WVLBWiKxjM",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Fatahlla_Moreh1",
        "name": "Fatahlla Moreh",
        "name_site": null,
        "openreview_id": "~Fatahlla_Moreh1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "fatahlla-moreh-926a0021b/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Aligarh Muslim University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.2649110640673518,
        "confidence_mean": 4.4,
        "confidence_std": 0.8,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "XYFBmp08sP",
      "title": "CIDA3D: Conformal Inference aided unsupervised Domain Adaptation for 3D-Aware Classification",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Cognitive Science studies show that human perception becomes robust to occlusions and other nuisances due to internal 3D representations of objects. This idea has been incorporated into computer vision models to improve their ability to understand and reason about the 3D world. However, collecting 3D annotations in vision datasets is expensive. This makes the robustness of the perception model to distribution shifts challenging. We introduce Conformal Inference aided unsupervised Domain Adaptation (CIDA)-3D for the complex setting of multiclass pose estimation. Our method adapts category level pose estimation (3D) models in nuisance ridden target domains directly from images without class label information, by harnessing uncertainty in model predictions (using conformal sets). This allows for significantly better and computationally efficient adaptation to target domains with synthetic and real-world noise. We also show a robust adaptation from fully synthetic data to complex real-world domains. To the best of our knowledge, this method is the first to attempt unsupervised domain adaptation for robust 3D-aware classification and multiclass pose estimation in real-world scenarios by adapting models trained on procedurally generated synthetic data.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=XYFBmp08sP",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anqi_Liu2",
        "name": "Anqi Liu",
        "name_site": null,
        "openreview_id": "~Anqi_Liu2",
        "position": 3,
        "gender": "F",
        "homepage_url": "https://anqiliu-ai.github.io/",
        "dblp_id": null,
        "google_scholar_url": "Q8yp6zQAAAAJ",
        "orcid": "0000-0002-0468-5698",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Illinois at Chicago (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.0,
        "confidence_mean": 2.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Y6KUBkUimC",
      "title": "Scalable Ranked Preference Optimization for Text-to-Image Generation",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Direct Preference Optimization (DPO) has emerged as a powerful approach to align text-to-image (T2I) models with human feedback. Unfortunately, successful application of DPO to T2I models requires a huge amount of resources to collect and label large-scale datasets, e.g., millions of generated paired images annotated with human preferences. In addition, these human preference datasets can get outdated quickly as the rapid improvements of T2I models lead to higher quality images. In this work, we investigate a scalable approach for collecting large-scale and fully synthetic datasets for DPO training. Specifically, the preferences for paired images are generated using a pre-trained reward function, eliminating the need for involving humans in the annotation process, greatly improving the dataset collection efficiency. Moreover, we demonstrate that such datasets allow averaging predictions across multiple models and collecting ranked preferences as opposed to pairwise preferences. Furthermore, we introduce RankDPO to enhance DPO-based methods using the ranking feedback. Applying RankDPO on SDXL and SD3-Medium models with our synthetically generated preference dataset ``Syn-Pic'' improves both prompt-following (on benchmarks like T2I-Compbench, GenEval, and DPG-Bench) and visual quality (through user studies). This pipeline presents a practical and scalable solution to develop better preference datasets to enhance the performance and safety of text-to-image models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=Y6KUBkUimC",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Shyamgopal_Karthik1",
        "name": "Shyamgopal Karthik",
        "name_site": "Shyamgopal Karthik, Ameya Prabhu, Puneet Dokania, Vineet Gandhi",
        "openreview_id": "~Shyamgopal_Karthik1",
        "position": 1,
        "gender": null,
        "homepage_url": "https://sgk98.github.io/",
        "dblp_id": "251/8983",
        "google_scholar_url": "MofhemMAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Tübingen (Germany)",
        "countries": [
          "Germany"
        ],
        "country_codes": [
          "DE"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "YcbE2K3i2E",
      "title": "SaTran: An efficient Transformer exploiting Spatiotemporal Redundancies for Satellite Image Time Series Representation Learning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Earth observation applications like crop yield prediction, solar energy prediction, land cover classification, etc., need large size Satellite Image Time Series (SITS) leading to huge computational requirements. A couple of BERT-based models exist which work at pixel level unable to exploit spatial correlation among pixels and also require ground truth at pixel granularity during fine-tuning, rendering them infeasible for prediction tasks. The  models based on Vision Transformer factorize spatial and time dimensions and first process images and then time series of image embeddings. However, in many cases, SITS require simultaneous analysis of both dimensions. We present a transformer, SaTran, which focuses on non-redundant patch tubes to overcome the limitations listed above. Transformers developed for RGB videos are found lacking when applied to SITS data characterized by the presence of patches with spatiotemporal redundancy persisting throughout the time series. SITS data also has patches where temporal redundancy lasts only for a few timestamps. The salient features of SaTran include: 1) an automatic patch tube selection mechanism which ignores spatiotemporally redundant patches; 2) exploitation of spatial correlation between pixels by the processing of patch tubes and handling of their temporal redundancy using tube masking; 3) two-fold handling of redundancy and distributed application of VideoMAE enables space and time efficient processing of large size SITS; and 4) learning end task agnostic representation of entire time series. Extensive experimentation shows that SaTran outperforms competing models and exhibit state-of-the-art performance for various earth observation applications. The code is available on (.. will be given after acceptance..).",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=YcbE2K3i2E",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arshveer_Kaur1",
        "name": "Arshveer Kaur",
        "name_site": null,
        "openreview_id": "~Arshveer_Kaur1",
        "position": 1,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "_9GhcucAAAAJ",
        "orcid": null,
        "linkedin_url": "arshveer-kaur-8361a493/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.6,
        "rating_std": 0.7999999999999999,
        "confidence_mean": 3.6,
        "confidence_std": 0.8,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "YcbE2K3i2E",
      "title": "SaTran: An efficient Transformer exploiting Spatiotemporal Redundancies for Satellite Image Time Series Representation Learning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Earth observation applications like crop yield prediction, solar energy prediction, land cover classification, etc., need large size Satellite Image Time Series (SITS) leading to huge computational requirements. A couple of BERT-based models exist which work at pixel level unable to exploit spatial correlation among pixels and also require ground truth at pixel granularity during fine-tuning, rendering them infeasible for prediction tasks. The  models based on Vision Transformer factorize spatial and time dimensions and first process images and then time series of image embeddings. However, in many cases, SITS require simultaneous analysis of both dimensions. We present a transformer, SaTran, which focuses on non-redundant patch tubes to overcome the limitations listed above. Transformers developed for RGB videos are found lacking when applied to SITS data characterized by the presence of patches with spatiotemporal redundancy persisting throughout the time series. SITS data also has patches where temporal redundancy lasts only for a few timestamps. The salient features of SaTran include: 1) an automatic patch tube selection mechanism which ignores spatiotemporally redundant patches; 2) exploitation of spatial correlation between pixels by the processing of patch tubes and handling of their temporal redundancy using tube masking; 3) two-fold handling of redundancy and distributed application of VideoMAE enables space and time efficient processing of large size SITS; and 4) learning end task agnostic representation of entire time series. Extensive experimentation shows that SaTran outperforms competing models and exhibit state-of-the-art performance for various earth observation applications. The code is available on (.. will be given after acceptance..).",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=YcbE2K3i2E",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Poonam_Goyal1",
        "name": "Poonam Goyal",
        "name_site": null,
        "openreview_id": "~Poonam_Goyal1",
        "position": 2,
        "gender": "F",
        "homepage_url": "https://www.bits-pilani.ac.in/pilani/poonam-goyal/",
        "dblp_id": "96/25",
        "google_scholar_url": "enDV3hsAAAAJ",
        "orcid": null,
        "linkedin_url": "poonam-goyal-74a385221/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.6,
        "rating_std": 0.7999999999999999,
        "confidence_mean": 3.6,
        "confidence_std": 0.8,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "YcbE2K3i2E",
      "title": "SaTran: An efficient Transformer exploiting Spatiotemporal Redundancies for Satellite Image Time Series Representation Learning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Earth observation applications like crop yield prediction, solar energy prediction, land cover classification, etc., need large size Satellite Image Time Series (SITS) leading to huge computational requirements. A couple of BERT-based models exist which work at pixel level unable to exploit spatial correlation among pixels and also require ground truth at pixel granularity during fine-tuning, rendering them infeasible for prediction tasks. The  models based on Vision Transformer factorize spatial and time dimensions and first process images and then time series of image embeddings. However, in many cases, SITS require simultaneous analysis of both dimensions. We present a transformer, SaTran, which focuses on non-redundant patch tubes to overcome the limitations listed above. Transformers developed for RGB videos are found lacking when applied to SITS data characterized by the presence of patches with spatiotemporal redundancy persisting throughout the time series. SITS data also has patches where temporal redundancy lasts only for a few timestamps. The salient features of SaTran include: 1) an automatic patch tube selection mechanism which ignores spatiotemporally redundant patches; 2) exploitation of spatial correlation between pixels by the processing of patch tubes and handling of their temporal redundancy using tube masking; 3) two-fold handling of redundancy and distributed application of VideoMAE enables space and time efficient processing of large size SITS; and 4) learning end task agnostic representation of entire time series. Extensive experimentation shows that SaTran outperforms competing models and exhibit state-of-the-art performance for various earth observation applications. The code is available on (.. will be given after acceptance..).",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=YcbE2K3i2E",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~C_Niranjan1",
        "name": "C Niranjan",
        "name_site": null,
        "openreview_id": "~C_Niranjan1",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.6,
        "rating_std": 0.7999999999999999,
        "confidence_mean": 3.6,
        "confidence_std": 0.8,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ZpcQfTNtKv",
      "title": "Quantile Activation: Correcting a failure mode of ML models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "An established failure mode for machine learning models occurs when the same features are equally likely to belong to class $0$ and class $1$.. In such cases, any ML model cannot to correctly classify the sample. However, a solvable case emerges when the probabilities of class $0$ and $1$ vary with the \"context distribution\". To the best of our knowledge, standard neural network architectures like MLPs or CNNs are not equipped to handle this.\n\nIn this article, we propose a simple activation function, quantile activation (QACT), that addresses this problem without significantly increasing computational costs. The core idea is to \"adapt\" the outputs of each neuron to its *context distribution*. The proposed quantile activation, QACT, produces the \"relative quantile\" of the sample in its context distribution, rather than the actual values, as in traditional networks.\n\nA practical example where the same sample can have different labels arises in cases of inherent distribution shift. We validate the proposed activation function under such shifts, using datasets designed to test robustness against distortions—CIFAR10C, CIFAR100C, MNISTC, TinyImagenetC. Our results demonstrate significantly better generalization across distortions compared to conventional classifiers, across various architectures. Although this paper presents a proof of concept, we find that this approach unexpectedly outperforms DINOv2 (small) under large distortions, despite DINOv2 being trained with a much larger network and dataset.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ZpcQfTNtKv",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aditya_Challa1",
        "name": "Aditya Challa",
        "name_site": null,
        "openreview_id": "~Aditya_Challa1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 1.7853571071357126,
        "confidence_mean": 3.75,
        "confidence_std": 1.0897247358851685,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ZpcQfTNtKv",
      "title": "Quantile Activation: Correcting a failure mode of ML models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "An established failure mode for machine learning models occurs when the same features are equally likely to belong to class $0$ and class $1$.. In such cases, any ML model cannot to correctly classify the sample. However, a solvable case emerges when the probabilities of class $0$ and $1$ vary with the \"context distribution\". To the best of our knowledge, standard neural network architectures like MLPs or CNNs are not equipped to handle this.\n\nIn this article, we propose a simple activation function, quantile activation (QACT), that addresses this problem without significantly increasing computational costs. The core idea is to \"adapt\" the outputs of each neuron to its *context distribution*. The proposed quantile activation, QACT, produces the \"relative quantile\" of the sample in its context distribution, rather than the actual values, as in traditional networks.\n\nA practical example where the same sample can have different labels arises in cases of inherent distribution shift. We validate the proposed activation function under such shifts, using datasets designed to test robustness against distortions—CIFAR10C, CIFAR100C, MNISTC, TinyImagenetC. Our results demonstrate significantly better generalization across distortions compared to conventional classifiers, across various architectures. Although this paper presents a proof of concept, we find that this approach unexpectedly outperforms DINOv2 (small) under large distortions, despite DINOv2 being trained with a much larger network and dataset.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ZpcQfTNtKv",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Laurent_Najman1",
        "name": "Laurent Najman",
        "name_site": null,
        "openreview_id": "~Laurent_Najman1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://laurentnajman.org",
        "dblp_id": "68/4192",
        "google_scholar_url": "https://scholar.google.fr/citations?user=j-2_cT0AAAAJ",
        "orcid": "0000-0002-6190-0235",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 1.7853571071357126,
        "confidence_mean": 3.75,
        "confidence_std": 1.0897247358851685,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ZpcQfTNtKv",
      "title": "Quantile Activation: Correcting a failure mode of ML models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "An established failure mode for machine learning models occurs when the same features are equally likely to belong to class $0$ and class $1$.. In such cases, any ML model cannot to correctly classify the sample. However, a solvable case emerges when the probabilities of class $0$ and $1$ vary with the \"context distribution\". To the best of our knowledge, standard neural network architectures like MLPs or CNNs are not equipped to handle this.\n\nIn this article, we propose a simple activation function, quantile activation (QACT), that addresses this problem without significantly increasing computational costs. The core idea is to \"adapt\" the outputs of each neuron to its *context distribution*. The proposed quantile activation, QACT, produces the \"relative quantile\" of the sample in its context distribution, rather than the actual values, as in traditional networks.\n\nA practical example where the same sample can have different labels arises in cases of inherent distribution shift. We validate the proposed activation function under such shifts, using datasets designed to test robustness against distortions—CIFAR10C, CIFAR100C, MNISTC, TinyImagenetC. Our results demonstrate significantly better generalization across distortions compared to conventional classifiers, across various architectures. Although this paper presents a proof of concept, we find that this approach unexpectedly outperforms DINOv2 (small) under large distortions, despite DINOv2 being trained with a much larger network and dataset.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ZpcQfTNtKv",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Snehanshu_Saha1",
        "name": "Snehanshu Saha",
        "name_site": null,
        "openreview_id": "~Snehanshu_Saha1",
        "position": 4,
        "gender": "Not Specified",
        "homepage_url": "https://www.bits-pilani.ac.in/goa/snehanshus/profile",
        "dblp_id": "130/3938",
        "google_scholar_url": "C-Qm2LcAAAAJ",
        "orcid": "0000-0002-8458-604X",
        "linkedin_url": "snehanshusaha/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 1.7853571071357126,
        "confidence_mean": 3.75,
        "confidence_std": 1.0897247358851685,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ZxQD6oYIOm",
      "title": "Cross-Cultural Recipe Transformation via Neural Network and Encoder-Based Models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Every cuisine has a culinary fingerprint characterized by its idiosyncratic ingredient composition. Transforming the culinary signature of a recipe is a creative endeavor. Traditionally, such fusion recipes have arisen from creative human interventions as a product of trial and error. Herein, we present a framework to transform the culinary signature of a recipe from one regional cuisine to another. A clustering-based computational strategy was developed, which replaces the ingredients of a recipe, one at a time, to achieve the transformation of the cuisine. We used a neural network-based Word2Vec-Doc2Vec model and three encoder-based BERT models to capture the context of an ingredient within the culinary landscape. The performance of recipe transformation strategies was evaluated by scoring their success at ‘Recipe Transformation’ and manually assessing the most frequent ingredient replacements for every fusion experiment. We observe that the encoder-based models perform better at transforming recipes with fewer ingredient replacements needed, suggesting that BERT-based models are better at providing more meaningful ingredient replacements to transform the culinary signature of recipes. The percentage of successful recipe transformations in the case of Word2Vec-Doc2Vec, BERT-Mean Pooling, BERT-CLS Pooling, and BERT-SBERT model are 99.95%, 43.1%, 41.65%, and 41.45% respectively, indicating that the neural network-based model can better cluster the cuisine-wise ingredient embeddings. On the other hand, for a successful recipe transformation, the average percentage of ingredients replaced for Word2Vec-Doc2Vec, BERT-Mean Pooling, BERT-CLS Pooling, and BERT-SBERT model are 77%, 52.3%, 51.6% and 51.5%, respectively. Our study shows a way forward for implementing cross-cultural fusion of recipes.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ZxQD6oYIOm",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vibhuti_Dhar_Khanduri1",
        "name": "Vibhuti Dhar Khanduri",
        "name_site": null,
        "openreview_id": "~Vibhuti_Dhar_Khanduri1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "vibhuti-dhar-khanduri/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ZxQD6oYIOm",
      "title": "Cross-Cultural Recipe Transformation via Neural Network and Encoder-Based Models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Every cuisine has a culinary fingerprint characterized by its idiosyncratic ingredient composition. Transforming the culinary signature of a recipe is a creative endeavor. Traditionally, such fusion recipes have arisen from creative human interventions as a product of trial and error. Herein, we present a framework to transform the culinary signature of a recipe from one regional cuisine to another. A clustering-based computational strategy was developed, which replaces the ingredients of a recipe, one at a time, to achieve the transformation of the cuisine. We used a neural network-based Word2Vec-Doc2Vec model and three encoder-based BERT models to capture the context of an ingredient within the culinary landscape. The performance of recipe transformation strategies was evaluated by scoring their success at ‘Recipe Transformation’ and manually assessing the most frequent ingredient replacements for every fusion experiment. We observe that the encoder-based models perform better at transforming recipes with fewer ingredient replacements needed, suggesting that BERT-based models are better at providing more meaningful ingredient replacements to transform the culinary signature of recipes. The percentage of successful recipe transformations in the case of Word2Vec-Doc2Vec, BERT-Mean Pooling, BERT-CLS Pooling, and BERT-SBERT model are 99.95%, 43.1%, 41.65%, and 41.45% respectively, indicating that the neural network-based model can better cluster the cuisine-wise ingredient embeddings. On the other hand, for a successful recipe transformation, the average percentage of ingredients replaced for Word2Vec-Doc2Vec, BERT-Mean Pooling, BERT-CLS Pooling, and BERT-SBERT model are 77%, 52.3%, 51.6% and 51.5%, respectively. Our study shows a way forward for implementing cross-cultural fusion of recipes.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ZxQD6oYIOm",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mansi_Goel1",
        "name": "Mansi Goel",
        "name_site": null,
        "openreview_id": "~Mansi_Goel1",
        "position": 2,
        "gender": "F",
        "homepage_url": "https://mansigoel01.github.io/",
        "dblp_id": "218/8417",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=4_X0c9AAAAAJ",
        "orcid": null,
        "linkedin_url": "https://linkedin.com/in/mansigoel01/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ZxQD6oYIOm",
      "title": "Cross-Cultural Recipe Transformation via Neural Network and Encoder-Based Models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Every cuisine has a culinary fingerprint characterized by its idiosyncratic ingredient composition. Transforming the culinary signature of a recipe is a creative endeavor. Traditionally, such fusion recipes have arisen from creative human interventions as a product of trial and error. Herein, we present a framework to transform the culinary signature of a recipe from one regional cuisine to another. A clustering-based computational strategy was developed, which replaces the ingredients of a recipe, one at a time, to achieve the transformation of the cuisine. We used a neural network-based Word2Vec-Doc2Vec model and three encoder-based BERT models to capture the context of an ingredient within the culinary landscape. The performance of recipe transformation strategies was evaluated by scoring their success at ‘Recipe Transformation’ and manually assessing the most frequent ingredient replacements for every fusion experiment. We observe that the encoder-based models perform better at transforming recipes with fewer ingredient replacements needed, suggesting that BERT-based models are better at providing more meaningful ingredient replacements to transform the culinary signature of recipes. The percentage of successful recipe transformations in the case of Word2Vec-Doc2Vec, BERT-Mean Pooling, BERT-CLS Pooling, and BERT-SBERT model are 99.95%, 43.1%, 41.65%, and 41.45% respectively, indicating that the neural network-based model can better cluster the cuisine-wise ingredient embeddings. On the other hand, for a successful recipe transformation, the average percentage of ingredients replaced for Word2Vec-Doc2Vec, BERT-Mean Pooling, BERT-CLS Pooling, and BERT-SBERT model are 77%, 52.3%, 51.6% and 51.5%, respectively. Our study shows a way forward for implementing cross-cultural fusion of recipes.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ZxQD6oYIOm",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Lakshay1",
        "name": "Lakshay",
        "name_site": null,
        "openreview_id": "~Lakshay1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "lakshay-dabas-27782421a?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_contact_details%3Bk40O865sR8iho5x%2BHk296A%3D%3D",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ZxQD6oYIOm",
      "title": "Cross-Cultural Recipe Transformation via Neural Network and Encoder-Based Models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Every cuisine has a culinary fingerprint characterized by its idiosyncratic ingredient composition. Transforming the culinary signature of a recipe is a creative endeavor. Traditionally, such fusion recipes have arisen from creative human interventions as a product of trial and error. Herein, we present a framework to transform the culinary signature of a recipe from one regional cuisine to another. A clustering-based computational strategy was developed, which replaces the ingredients of a recipe, one at a time, to achieve the transformation of the cuisine. We used a neural network-based Word2Vec-Doc2Vec model and three encoder-based BERT models to capture the context of an ingredient within the culinary landscape. The performance of recipe transformation strategies was evaluated by scoring their success at ‘Recipe Transformation’ and manually assessing the most frequent ingredient replacements for every fusion experiment. We observe that the encoder-based models perform better at transforming recipes with fewer ingredient replacements needed, suggesting that BERT-based models are better at providing more meaningful ingredient replacements to transform the culinary signature of recipes. The percentage of successful recipe transformations in the case of Word2Vec-Doc2Vec, BERT-Mean Pooling, BERT-CLS Pooling, and BERT-SBERT model are 99.95%, 43.1%, 41.65%, and 41.45% respectively, indicating that the neural network-based model can better cluster the cuisine-wise ingredient embeddings. On the other hand, for a successful recipe transformation, the average percentage of ingredients replaced for Word2Vec-Doc2Vec, BERT-Mean Pooling, BERT-CLS Pooling, and BERT-SBERT model are 77%, 52.3%, 51.6% and 51.5%, respectively. Our study shows a way forward for implementing cross-cultural fusion of recipes.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ZxQD6oYIOm",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ganesh_Bagler1",
        "name": "Ganesh Bagler",
        "name_site": null,
        "openreview_id": "~Ganesh_Bagler1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://cosylab.iiitd.edu.in/",
        "dblp_id": null,
        "google_scholar_url": "qyth_0QAAAAJ",
        "orcid": "0000-0003-1924-6070",
        "linkedin_url": "ganeshbagler/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "b9ZG7cI8ic",
      "title": "Generalization of FedAvg Under Constrained Polyak-Lojasiewicz Type Conditions: A Single Hidden Layer Neural Network Analysis",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "In this work, we study the optimization and the generalization performance of the widely used FedAvg algorithm for solving Federated Learning (FL) problems. We analyze the generalization performance of FedAvg by handling the optimization error and the Rademacher complexity. Towards handling optimization error, we propose novel constrained Polyak-Lojasiewicz (PL)-type conditions on the objective function that ensure the existence of a global optimal to which FedAvg converges linearly after $\\mathcal{O}( \\log ({1}/{\\epsilon}))$ rounds of communication, where $\\epsilon$ is the desired optimality gap. Importantly, we demonstrate that a class of single hidden layer neural networks satisfies the proposed constrained PL-type conditions required to establish the linear convergence of FedAvg as long as $m > {nK}/{d}$, where $m$ is the width of the neural network, $K$ is the number of clients, $n$ is the number of samples at each client, and $d$ is the feature dimension. We then bound the Rademacher complexity for this class of neural networks and establish that both Rademacher complexity and the generalization error of FedAvg decrease at an optimal rate of $\\mathcal{O}({1}/{\\sqrt{n}})$. We further show that increasing the number of clients $K$ decreases the generalization error at the rate of $\\mathcal{O}({1}/{\\sqrt{n}} + {1}/{\\sqrt{nK}})$.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=b9ZG7cI8ic",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sumit_Sah1",
        "name": "Sumit Sah",
        "name_site": null,
        "openreview_id": "~Sumit_Sah1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "sumit-sah1824/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Dharwad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "b9ZG7cI8ic",
      "title": "Generalization of FedAvg Under Constrained Polyak-Lojasiewicz Type Conditions: A Single Hidden Layer Neural Network Analysis",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "In this work, we study the optimization and the generalization performance of the widely used FedAvg algorithm for solving Federated Learning (FL) problems. We analyze the generalization performance of FedAvg by handling the optimization error and the Rademacher complexity. Towards handling optimization error, we propose novel constrained Polyak-Lojasiewicz (PL)-type conditions on the objective function that ensure the existence of a global optimal to which FedAvg converges linearly after $\\mathcal{O}( \\log ({1}/{\\epsilon}))$ rounds of communication, where $\\epsilon$ is the desired optimality gap. Importantly, we demonstrate that a class of single hidden layer neural networks satisfies the proposed constrained PL-type conditions required to establish the linear convergence of FedAvg as long as $m > {nK}/{d}$, where $m$ is the width of the neural network, $K$ is the number of clients, $n$ is the number of samples at each client, and $d$ is the feature dimension. We then bound the Rademacher complexity for this class of neural networks and establish that both Rademacher complexity and the generalization error of FedAvg decrease at an optimal rate of $\\mathcal{O}({1}/{\\sqrt{n}})$. We further show that increasing the number of clients $K$ decreases the generalization error at the rate of $\\mathcal{O}({1}/{\\sqrt{n}} + {1}/{\\sqrt{nK}})$.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=b9ZG7cI8ic",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Shruti_P_Maralappanavar1",
        "name": "Shruti P Maralappanavar",
        "name_site": null,
        "openreview_id": "~Shruti_P_Maralappanavar1",
        "position": 2,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Dharwad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "b9ZG7cI8ic",
      "title": "Generalization of FedAvg Under Constrained Polyak-Lojasiewicz Type Conditions: A Single Hidden Layer Neural Network Analysis",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "In this work, we study the optimization and the generalization performance of the widely used FedAvg algorithm for solving Federated Learning (FL) problems. We analyze the generalization performance of FedAvg by handling the optimization error and the Rademacher complexity. Towards handling optimization error, we propose novel constrained Polyak-Lojasiewicz (PL)-type conditions on the objective function that ensure the existence of a global optimal to which FedAvg converges linearly after $\\mathcal{O}( \\log ({1}/{\\epsilon}))$ rounds of communication, where $\\epsilon$ is the desired optimality gap. Importantly, we demonstrate that a class of single hidden layer neural networks satisfies the proposed constrained PL-type conditions required to establish the linear convergence of FedAvg as long as $m > {nK}/{d}$, where $m$ is the width of the neural network, $K$ is the number of clients, $n$ is the number of samples at each client, and $d$ is the feature dimension. We then bound the Rademacher complexity for this class of neural networks and establish that both Rademacher complexity and the generalization error of FedAvg decrease at an optimal rate of $\\mathcal{O}({1}/{\\sqrt{n}})$. We further show that increasing the number of clients $K$ decreases the generalization error at the rate of $\\mathcal{O}({1}/{\\sqrt{n}} + {1}/{\\sqrt{nK}})$.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=b9ZG7cI8ic",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Bharath_B_N1",
        "name": "Bharath B N",
        "name_site": null,
        "openreview_id": "~Bharath_B_N1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://bharathbettagere.github.io/mywebpage/",
        "dblp_id": "162/0207.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=AOuGtukAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Wayne State University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "blwWIKpwpL",
      "title": "VLP: Vision-Language Preference Learning for Embodied Manipulation",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Reward engineering is one of the key challenges in Reinforcement Learning (RL). Preference-based RL effectively addresses this issue by learning from human feedback. However, it is both time-consuming and expensive to collect human preference labels. In this paper, we propose a novel Vision-Language Preference learning framework, named VLP, which learns a vision-language preference model to provide preference feedback for embodied manipulation tasks. To achieve this, we define three types of language-conditioned preferences and construct a vision-language preference dataset, which contains versatile implicit preference orders without human annotations. The preference model learns to extract language-related features, and then serves as a preference annotator in various downstream tasks. The policy can be learned according to the annotated preferences via reward learning or direct policy optimization. Extensive empirical results on simulated embodied manipulation tasks demonstrate that our method provides accurate preferences and generalizes to unseen tasks and unseen language, outperforming the baselines by a large margin. The code and videos of our method are available on the website: https://VLPref.github.io.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=blwWIKpwpL",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yali_Du1",
        "name": "Yali Du",
        "name_site": null,
        "openreview_id": "~Yali_Du1",
        "position": 5,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tsinghua University (China)",
        "countries": [
          "China"
        ],
        "country_codes": [
          "CN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.5,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "c87QZPTVVm",
      "title": "Think Beyond Size: Dynamic Prompting for More Effective Reasoning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Pretrained large language models (LLMs) are increasingly utilized across a wide range of natural language processing (NLP) tasks due to their impressive capabilities as few-shot learners. Recent techniques, such as chain-of-thought (CoT) prompting, have significantly advanced multi-step reasoning by introducing step-by-step decomposition, achieving state-of-the-art results on complex reasoning benchmarks. However, these approaches often rely on static prompting templates that do not adapt to task complexity or errors during the reasoning process. In this work, we introduce Adaptive Prompting, a dynamic and iterative framework designed to enhance reasoning by incorporating real-time adjustments to prompt structures and validation mechanisms. Experimental results demonstrate that Adaptive Prompting significantly improves performance on diverse reasoning benchmarks, including arithmetic reasoning (GSM8K, MultiArith), logical reasoning and commonsense tasks, achieving substantial accuracy gains compared to static prompting baselines. By integrating guided prompts, intermediate validation, and self-corrective steps, our approach enables smaller models to achieve competitive performance with larger counterparts, such as GPT-4, while maintaining computational efficiency. The framework achieves this without requiring fine-tuning or task-specific training data, highlighting the untapped potential of iterative reasoning methods.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=c87QZPTVVm",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 1,
      "track_name": "Main Conference",
      "author": {
        "id": "~Kamesh_R1",
        "name": "Kamesh R",
        "name_site": null,
        "openreview_id": "~Kamesh_R1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "9TREU28AAAAJ",
        "orcid": "0009-0001-8059-7059",
        "linkedin_url": "https://linkedin.in/kamesh-r",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Sathyabama University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "cUuOKnjVQJ",
      "title": "Plan-RAG: Planning-guided Retrieval Augmented Generation",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We introduce Planning-guided Retrieval Augmented Generation (Plan-RAG), a novel framework that augments the retrieve-then-reason paradigm of existing RAG frameworks to plan-then-retrieve. Plan-RAG formulates a reasoning plan as a directed acyclic graph (DAG), decomposing queries into interrelated atomic sub-queries. Answer generation follows the DAG structure, allowing significant gains in efficiency through parallelized retrieval and generation. While state-of-the-art RAG solutions require extensive data generation and fine-tuning of language models (LMs), Plan-RAG incorporates frozen LMs as plug-and-play experts to generate high-quality answers. Compared to existing RAG solutions, Plan-RAG demonstrates significant improvements in reducing hallucinations and bolstering attribution due to its structured sub-query decomposition. Plan-RAG offers a new perspective on integrating external knowledge in LMs while ensuring attribution by design, contributing towards more reliable and interpretable LM-based systems.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=cUuOKnjVQJ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Amit_Sharma3",
        "name": "Amit Sharma",
        "name_site": null,
        "openreview_id": "~Amit_Sharma3",
        "position": 6,
        "gender": "M",
        "homepage_url": "http://amitsharma.in/",
        "dblp_id": "72/2540-7",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=CXgQufgAAAAJ",
        "orcid": "0000-0002-2086-3191",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ech9J3xl9X",
      "title": "Narrow Transformer: Mono-lingual Code SLM for Desktop",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "This paper presents NT-Java-1.1B, an open-source specialized code language model built on StarCoderBase-1.1B, designed for coding tasks in Java programming. NT-Java-1.1B achieves state-of-the-art performance, surpassing its base model and majority of other models of similar size on MultiPL-E Java code benchmark. While there have been studies on extending large, generic pre-trained models to improve proficiency in specific programming languages like Python, similar investigations on small code models for other programming languages are lacking. Large code models require specialized hardware like GPUs for inference, highlighting the need for research into building small code models that can be deployed on developer desktops. This paper addresses this research gap by focusing on the development of a small Java code model, NT-Java-1.1B, and its quantized versions, which performs comparably to open models around 1.1B on MultiPL-E Java code benchmarks, making them ideal for desktop deployment. This paper establishes the foundation for specialized models across languages and sizes for a family of NT Models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ech9J3xl9X",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Kamalkumar_Rathinasamy1",
        "name": "Kamalkumar Rathinasamy",
        "name_site": null,
        "openreview_id": "~Kamalkumar_Rathinasamy1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "eJZPhbgAAAAJ",
        "orcid": null,
        "linkedin_url": "kaml/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Infosys Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ech9J3xl9X",
      "title": "Narrow Transformer: Mono-lingual Code SLM for Desktop",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "This paper presents NT-Java-1.1B, an open-source specialized code language model built on StarCoderBase-1.1B, designed for coding tasks in Java programming. NT-Java-1.1B achieves state-of-the-art performance, surpassing its base model and majority of other models of similar size on MultiPL-E Java code benchmark. While there have been studies on extending large, generic pre-trained models to improve proficiency in specific programming languages like Python, similar investigations on small code models for other programming languages are lacking. Large code models require specialized hardware like GPUs for inference, highlighting the need for research into building small code models that can be deployed on developer desktops. This paper addresses this research gap by focusing on the development of a small Java code model, NT-Java-1.1B, and its quantized versions, which performs comparably to open models around 1.1B on MultiPL-E Java code benchmarks, making them ideal for desktop deployment. This paper establishes the foundation for specialized models across languages and sizes for a family of NT Models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ech9J3xl9X",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Balaji_A_J1",
        "name": "Balaji A J",
        "name_site": null,
        "openreview_id": "~Balaji_A_J1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "VX3kQYsAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Infosys Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ech9J3xl9X",
      "title": "Narrow Transformer: Mono-lingual Code SLM for Desktop",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "This paper presents NT-Java-1.1B, an open-source specialized code language model built on StarCoderBase-1.1B, designed for coding tasks in Java programming. NT-Java-1.1B achieves state-of-the-art performance, surpassing its base model and majority of other models of similar size on MultiPL-E Java code benchmark. While there have been studies on extending large, generic pre-trained models to improve proficiency in specific programming languages like Python, similar investigations on small code models for other programming languages are lacking. Large code models require specialized hardware like GPUs for inference, highlighting the need for research into building small code models that can be deployed on developer desktops. This paper addresses this research gap by focusing on the development of a small Java code model, NT-Java-1.1B, and its quantized versions, which performs comparably to open models around 1.1B on MultiPL-E Java code benchmarks, making them ideal for desktop deployment. This paper establishes the foundation for specialized models across languages and sizes for a family of NT Models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ech9J3xl9X",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ankush_Kumar1",
        "name": "Ankush Kumar",
        "name_site": null,
        "openreview_id": "~Ankush_Kumar1",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": "ping2ankush/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Infosys Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ech9J3xl9X",
      "title": "Narrow Transformer: Mono-lingual Code SLM for Desktop",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "This paper presents NT-Java-1.1B, an open-source specialized code language model built on StarCoderBase-1.1B, designed for coding tasks in Java programming. NT-Java-1.1B achieves state-of-the-art performance, surpassing its base model and majority of other models of similar size on MultiPL-E Java code benchmark. While there have been studies on extending large, generic pre-trained models to improve proficiency in specific programming languages like Python, similar investigations on small code models for other programming languages are lacking. Large code models require specialized hardware like GPUs for inference, highlighting the need for research into building small code models that can be deployed on developer desktops. This paper addresses this research gap by focusing on the development of a small Java code model, NT-Java-1.1B, and its quantized versions, which performs comparably to open models around 1.1B on MultiPL-E Java code benchmarks, making them ideal for desktop deployment. This paper establishes the foundation for specialized models across languages and sizes for a family of NT Models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ech9J3xl9X",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Gagan_Gayari1",
        "name": "Gagan Gayari",
        "name_site": null,
        "openreview_id": "~Gagan_Gayari1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "https://in.linkedin.com/in/gagangayari",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Infosys Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ech9J3xl9X",
      "title": "Narrow Transformer: Mono-lingual Code SLM for Desktop",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "This paper presents NT-Java-1.1B, an open-source specialized code language model built on StarCoderBase-1.1B, designed for coding tasks in Java programming. NT-Java-1.1B achieves state-of-the-art performance, surpassing its base model and majority of other models of similar size on MultiPL-E Java code benchmark. While there have been studies on extending large, generic pre-trained models to improve proficiency in specific programming languages like Python, similar investigations on small code models for other programming languages are lacking. Large code models require specialized hardware like GPUs for inference, highlighting the need for research into building small code models that can be deployed on developer desktops. This paper addresses this research gap by focusing on the development of a small Java code model, NT-Java-1.1B, and its quantized versions, which performs comparably to open models around 1.1B on MultiPL-E Java code benchmarks, making them ideal for desktop deployment. This paper establishes the foundation for specialized models across languages and sizes for a family of NT Models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ech9J3xl9X",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Harshini_K1",
        "name": "Harshini K",
        "name_site": null,
        "openreview_id": "~Harshini_K1",
        "position": 5,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "vixvH9kAAAAJ",
        "orcid": null,
        "linkedin_url": "https://linkedin.com/in/harshinikumar",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Infosys Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ech9J3xl9X",
      "title": "Narrow Transformer: Mono-lingual Code SLM for Desktop",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "This paper presents NT-Java-1.1B, an open-source specialized code language model built on StarCoderBase-1.1B, designed for coding tasks in Java programming. NT-Java-1.1B achieves state-of-the-art performance, surpassing its base model and majority of other models of similar size on MultiPL-E Java code benchmark. While there have been studies on extending large, generic pre-trained models to improve proficiency in specific programming languages like Python, similar investigations on small code models for other programming languages are lacking. Large code models require specialized hardware like GPUs for inference, highlighting the need for research into building small code models that can be deployed on developer desktops. This paper addresses this research gap by focusing on the development of a small Java code model, NT-Java-1.1B, and its quantized versions, which performs comparably to open models around 1.1B on MultiPL-E Java code benchmarks, making them ideal for desktop deployment. This paper establishes the foundation for specialized models across languages and sizes for a family of NT Models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ech9J3xl9X",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rajab_Ali_Mondal1",
        "name": "Rajab Ali Mondal",
        "name_site": null,
        "openreview_id": "~Rajab_Ali_Mondal1",
        "position": 6,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": "rajab-ali-mondal-a6554a246/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Infosys Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ech9J3xl9X",
      "title": "Narrow Transformer: Mono-lingual Code SLM for Desktop",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "This paper presents NT-Java-1.1B, an open-source specialized code language model built on StarCoderBase-1.1B, designed for coding tasks in Java programming. NT-Java-1.1B achieves state-of-the-art performance, surpassing its base model and majority of other models of similar size on MultiPL-E Java code benchmark. While there have been studies on extending large, generic pre-trained models to improve proficiency in specific programming languages like Python, similar investigations on small code models for other programming languages are lacking. Large code models require specialized hardware like GPUs for inference, highlighting the need for research into building small code models that can be deployed on developer desktops. This paper addresses this research gap by focusing on the development of a small Java code model, NT-Java-1.1B, and its quantized versions, which performs comparably to open models around 1.1B on MultiPL-E Java code benchmarks, making them ideal for desktop deployment. This paper establishes the foundation for specialized models across languages and sizes for a family of NT Models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ech9J3xl9X",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sreenivasa_Raghavan_K_S1",
        "name": "Sreenivasa Raghavan K S",
        "name_site": null,
        "openreview_id": "~Sreenivasa_Raghavan_K_S1",
        "position": 7,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "https://in.linkedin.com/in/k-s-sreenivasa-raghavan-a61345161",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Infosys Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ech9J3xl9X",
      "title": "Narrow Transformer: Mono-lingual Code SLM for Desktop",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "This paper presents NT-Java-1.1B, an open-source specialized code language model built on StarCoderBase-1.1B, designed for coding tasks in Java programming. NT-Java-1.1B achieves state-of-the-art performance, surpassing its base model and majority of other models of similar size on MultiPL-E Java code benchmark. While there have been studies on extending large, generic pre-trained models to improve proficiency in specific programming languages like Python, similar investigations on small code models for other programming languages are lacking. Large code models require specialized hardware like GPUs for inference, highlighting the need for research into building small code models that can be deployed on developer desktops. This paper addresses this research gap by focusing on the development of a small Java code model, NT-Java-1.1B, and its quantized versions, which performs comparably to open models around 1.1B on MultiPL-E Java code benchmarks, making them ideal for desktop deployment. This paper establishes the foundation for specialized models across languages and sizes for a family of NT Models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ech9J3xl9X",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Binyuan_Hui1_1",
        "name": "Binyuan Hui",
        "name_site": null,
        "openreview_id": "~Swayam_Singh1",
        "position": 8,
        "gender": "M",
        "homepage_url": "https://swayaminsync.github.io/",
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.com/citations?view_op=list_works",
        "orcid": null,
        "linkedin_url": "swayam-singh-406610213/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ech9J3xl9X",
      "title": "Narrow Transformer: Mono-lingual Code SLM for Desktop",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "This paper presents NT-Java-1.1B, an open-source specialized code language model built on StarCoderBase-1.1B, designed for coding tasks in Java programming. NT-Java-1.1B achieves state-of-the-art performance, surpassing its base model and majority of other models of similar size on MultiPL-E Java code benchmark. While there have been studies on extending large, generic pre-trained models to improve proficiency in specific programming languages like Python, similar investigations on small code models for other programming languages are lacking. Large code models require specialized hardware like GPUs for inference, highlighting the need for research into building small code models that can be deployed on developer desktops. This paper addresses this research gap by focusing on the development of a small Java code model, NT-Java-1.1B, and its quantized versions, which performs comparably to open models around 1.1B on MultiPL-E Java code benchmarks, making them ideal for desktop deployment. This paper establishes the foundation for specialized models across languages and sizes for a family of NT Models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ech9J3xl9X",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mohammed_Rafee_Tarafdar1",
        "name": "Mohammed Rafee Tarafdar",
        "name_site": null,
        "openreview_id": "~Mohammed_Rafee_Tarafdar1",
        "position": 9,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "https://in.linkedin.com/in/rafeetarafdar",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Infosys Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "f6GMwpxXHG",
      "title": "ZEPHYR GAN: REDEFINING GAN WITH FLEXIBLE GRADIENT CONTROL",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Generative adversarial networks (GANs) are renowned for their ability to generate highly realistic and diverse data samples. However, the performance of GANs is heavily dependent on the choice of loss functions, and commonly used losses such as cross-entropy and least squares are often susceptible to outliers, vanishing gradients, and training instability. To overcome these limitations, we introduce zephyr loss—a novel, convex, smooth, and Lipschitz continuous loss function designed to enhance robustness and provide flexible gradient control. Leveraging this new loss function, we propose ZGAN, a refined GAN model that guarantees a unique optimal discriminator and stabilizes the overall training dynamics. Furthermore, we demonstrate that optimizing ZGAN's generator objective minimizes a weighted total variation between the real and generated data distributions. Through rigorous theoretical analysis, including convergence proofs, we substantiate the robustness and effectiveness of ZGAN, positioning it as a compelling and reliable alternative for stable GAN training. Extensive experiments further demonstrate that ZGAN surpasses leading methods in generative modeling.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=f6GMwpxXHG",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anuradha_Kumari1",
        "name": "Anuradha Kumari",
        "name_site": null,
        "openreview_id": "~Anuradha_Kumari1",
        "position": 1,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "344/7992",
        "google_scholar_url": "zFtsQjsAAAAJ",
        "orcid": "0000-0002-9056-8761",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Indore (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.2,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 4.2,
        "confidence_std": 0.7483314773547882,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "f6GMwpxXHG",
      "title": "ZEPHYR GAN: REDEFINING GAN WITH FLEXIBLE GRADIENT CONTROL",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Generative adversarial networks (GANs) are renowned for their ability to generate highly realistic and diverse data samples. However, the performance of GANs is heavily dependent on the choice of loss functions, and commonly used losses such as cross-entropy and least squares are often susceptible to outliers, vanishing gradients, and training instability. To overcome these limitations, we introduce zephyr loss—a novel, convex, smooth, and Lipschitz continuous loss function designed to enhance robustness and provide flexible gradient control. Leveraging this new loss function, we propose ZGAN, a refined GAN model that guarantees a unique optimal discriminator and stabilizes the overall training dynamics. Furthermore, we demonstrate that optimizing ZGAN's generator objective minimizes a weighted total variation between the real and generated data distributions. Through rigorous theoretical analysis, including convergence proofs, we substantiate the robustness and effectiveness of ZGAN, positioning it as a compelling and reliable alternative for stable GAN training. Extensive experiments further demonstrate that ZGAN surpasses leading methods in generative modeling.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=f6GMwpxXHG",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ritik_Mishra1",
        "name": "Ritik Mishra",
        "name_site": null,
        "openreview_id": "~Ritik_Mishra1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://sites.google.com/iiti.ac.in/ritikmishra/home",
        "dblp_id": null,
        "google_scholar_url": "ZPcMuC8AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Indore (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.2,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 4.2,
        "confidence_std": 0.7483314773547882,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "f6GMwpxXHG",
      "title": "ZEPHYR GAN: REDEFINING GAN WITH FLEXIBLE GRADIENT CONTROL",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Generative adversarial networks (GANs) are renowned for their ability to generate highly realistic and diverse data samples. However, the performance of GANs is heavily dependent on the choice of loss functions, and commonly used losses such as cross-entropy and least squares are often susceptible to outliers, vanishing gradients, and training instability. To overcome these limitations, we introduce zephyr loss—a novel, convex, smooth, and Lipschitz continuous loss function designed to enhance robustness and provide flexible gradient control. Leveraging this new loss function, we propose ZGAN, a refined GAN model that guarantees a unique optimal discriminator and stabilizes the overall training dynamics. Furthermore, we demonstrate that optimizing ZGAN's generator objective minimizes a weighted total variation between the real and generated data distributions. Through rigorous theoretical analysis, including convergence proofs, we substantiate the robustness and effectiveness of ZGAN, positioning it as a compelling and reliable alternative for stable GAN training. Extensive experiments further demonstrate that ZGAN surpasses leading methods in generative modeling.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=f6GMwpxXHG",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~M._Tanveer1",
        "name": "M. Tanveer",
        "name_site": null,
        "openreview_id": "~M._Tanveer1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.iiti.ac.in/people/~mtanveer/",
        "dblp_id": null,
        "google_scholar_url": "sdu678oAAAAJ",
        "orcid": "0000-0002-5727-3697",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Indore (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.2,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 4.2,
        "confidence_std": 0.7483314773547882,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "fSxiromxAq",
      "title": "Sparse Causal Model: A Novel Approach for Causal Discovery and Attributions on Sparse Dataset",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "This paper introduces a novel approach to tackle the challenges of causal modeling and attribution in sparse and non-continuous data with limited feature knowledge. Traditional methods rely on static inputs and lack adaptability to dynamic changes in causal relationships, resulting in a limited understanding and goodness-of-fit. We introduce a unique causal discovery framework on real-world sparse datasets to address this challenge. We leverage a Directed Acyclic Graph (DAG) by discovering causal relationships between the variables by identifying confounder-treatment pairs that make the variable selection process robust and efficient. We propose a three-stage causal model that uses multiple distinct regressors such as likelihood-based, tree-based, and Generalized Additive Models (GAMs). Furthermore, we introduce a Model Score by including the sensitivity analysis involving random shuffling confounders and treatments to select the best optimal model. We implement a partial dependency approach to understand the attribution of variables, contributing by adding a 53% increase in the R2 score compared to traditional methods. This research underscores the limitations of conventional approaches in addressing real-world challenges to address practical scenarios effectively.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=fSxiromxAq",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~kalyani_pakhale1",
        "name": "kalyani pakhale",
        "name_site": null,
        "openreview_id": "~kalyani_pakhale1",
        "position": 1,
        "gender": "F",
        "homepage_url": "https://www.tredence.com/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "fxarGPFMmB",
      "title": "Reasoning with trees: interpreting CNNs using hierarchies",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Challenges remain in providing interpretable explanations for neural network reasoning in explainable AI (xAI). Existing methods like Integrated Gradients produce noisy maps, and LIME, while intuitive, may deviate from the model’s reasoning. We introduce a framework that uses hierarchical segmentation techniques for faithful and interpretable explanations of Convolutional Neural Networks (CNNs). Our method constructs model-based hierarchical segmentations that maintain the model’s reasoning fidelity and allow both human-centric and model-centric segmentation. This approach can be combined with various xAI methods and provides multiscale explanations that help identify biases and improve understanding of neural network decision-making. Experiments show that our framework, xAiTrees, delivers highly interpretable and faithful model explanations, not only surpassing traditional xAI methods but shedding new light on a novel approach to enhancing xAI interpretability. Code at: https://anonymous.4open.science/r/reasoning_with_trees-F3E1.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=fxarGPFMmB",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Laurent_Najman1",
        "name": "Laurent Najman",
        "name_site": null,
        "openreview_id": "~Laurent_Najman1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://laurentnajman.org",
        "dblp_id": "68/4192",
        "google_scholar_url": "https://scholar.google.fr/citations?user=j-2_cT0AAAAJ",
        "orcid": "0000-0002-6190-0235",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Ecole Supérieure d'Ingénieurs en Electronique et Electrotechnique (France)",
        "countries": [
          "France"
        ],
        "country_codes": [
          "FR"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "gjC91PwBZy",
      "title": "GC4NC: A Benchmark Framework for Graph Condensation on Node Classification with New Insights",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Graph condensation (GC) is an emerging technique designed to learn a significantly smaller graph that retains the essential information of the original graph. This condensed graph has shown promise in accelerating graph neural networks while preserving performance comparable to those achieved with the original, larger graphs. Additionally, this technique facilitates downstream applications like neural architecture search and deepens our understanding of redundancies in large graphs. Despite the rapid development of GC methods, particularly for node classification, a unified evaluation framework is still lacking to systematically compare different GC methods or clarify key design choices for improving their effectiveness. To bridge these gaps, we introduce **GC4NC**, a comprehensive framework for evaluating diverse GC methods on node classification across multiple dimensions including performance, efficiency, privacy preservation, denoising ability, NAS effectiveness, and transferability. Our systematic evaluation offers novel insights into how condensed graphs behave and the critical design choices that drive their success. These findings pave the way for future advancements in GC methods, enhancing both performance and expanding their real-world applications. The code is available at https://anonymous.4open.science/r/GC4NC-1620.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=gjC91PwBZy",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Noveen_Sachdeva2",
        "name": "Noveen Sachdeva",
        "name_site": null,
        "openreview_id": "~Noveen_Sachdeva2",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.noveens.com/",
        "dblp_id": "216/7290",
        "google_scholar_url": "i6tMWAoAAAAJ",
        "orcid": null,
        "linkedin_url": "noveensachdeva/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.0,
        "confidence_mean": 3.25,
        "confidence_std": 1.0897247358851685,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "h3unlS2VWz",
      "title": "How well does GPT-4o understand vision? Solving standard computer vision tasks with multimodal foundation models",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Multimodal foundation models, such as GPT-4o, have made remarkable progress recently. However, it is not clear exactly where these models stand in terms of understanding vision. {In this paper, we \\textbf{quantify the performance of popular multimodal foundation models} (GPT-4o, Gemini Pro, Claude 3.5 Sonnet, Qwen2-VL) \\textbf{at standard computer vision tasks} (semantic segmentation, object detection, image classification, depth and surface normal prediction) and \\textbf{using established datasets} (e.g., COCO, ImageNet and its variants, etc).} \n\nThe main challenges to performing this are: \\textbf{1)} the models are trained to output text and cannot natively express versatile domains, such as segments or 3D geometry, and \\textbf{2)} many of the leading models are proprietary and accessible only at an API level, i.e., there is no weight access to adapt them. We address these challenges by translating standard vision tasks into equivalent text-promptable and API-compatible tasks via {prompt chaining}. \n\nWe observe that \\textbf{1)} the models are not close to the state-of-the-art at any tasks, and \\textbf{2)} they perform semantic tasks notably better than geometric ones. However, \\textbf{3)} they are respectable generalists; this is remarkable as they are presumably trained on only image-text-based tasks primarily. \\textbf{4)} While the prompting techniques affect the performance, better models exhibit less sensitivity to prompt variations. \\textbf{5)} GPT-4o performs the best, getting the top position in 5 out of 6 tasks.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=h3unlS2VWz",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rahul_Ramachandran3",
        "name": "Rahul Ramachandran",
        "name_site": null,
        "openreview_id": "~Rahul_Ramachandran3",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://rahuboy.github.io/",
        "dblp_id": null,
        "google_scholar_url": "uRUnZOIAAAAJ",
        "orcid": null,
        "linkedin_url": "rahul-ramachandran-a56726225/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.5,
        "confidence_mean": 3.75,
        "confidence_std": 1.0897247358851685,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "hz3NtNpDNv",
      "title": "Hottel Zone Physics-Constrained Networks for Furnaces",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "This paper investigates a novel approach to improve the temperature profile prediction of furnaces in foundation industries, crucial for sustainable manufacturing. While existing methods like the Hottel Zone model are accurate, they lack real-time inference capabilities. Deep learning methods excel in speed and prediction but require careful generalization for real-world applications. We propose a regularization technique that leverages the Hottel Zone method to make deep neural networks physics-aware, improving prediction accuracy for furnace temperature profiles. Our approach demonstrates effectiveness on various neural network architectures, including Multi-Layer Perceptrons (MLP), Long Short-Term Memory (LSTM) and Kolmogorov-Arnold Networks (KANs). We also discussion the data generation involved.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=hz3NtNpDNv",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ujjal_Kr_Dutta1",
        "name": "Ujjal Kr Dutta",
        "name_site": null,
        "openreview_id": "~Ujjal_Kr_Dutta1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/ujjal-kr-dutta/",
        "dblp_id": "https://dblp.uni-trier.de/pid/226/2714",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=Af3v7CUAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Myntra (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "iQ0aOGx6dc",
      "title": "Graph Regularized Encoder Training for Extreme Classification",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Deep extreme classification (XC) aims to train an encoder and label classifiers to tag a data point with the most relevant subset of labels from a very large universe of labels. XC applications in ranking, recommendation and tagging routinely encounter tail labels, for which the amount of training data is exceedingly small. One way to tackle the tail label problem is to use additional data - often structured as a graph associated with documents and labels - graph metadata. Graph Convolutional Networks (GCNs) present a convenient but computationally expensive way to leverage this graph metadata and enhance model accuracies in these settings. However, GCNs struggle to make predictions for a novel test point when it has no edge in the graph. The paper notices that in these settings, it is much more effective to use graph data to regularize encoder training than to implement a GCN. Based on these insights, an alternative paradigm RAMEN  is presented to utilize graph metadata in XC settings that offers a significant performance boost with zero increase in inference computational costs. RAMEN scales to datasets with millions of labels and offers prediction accuracy up to 15% higher on benchmark datasets than state of the art methods, including those that use graph metadata to train GCNs. RAMEN also offers 10% higher accuracy over the best baseline on a proprietary recommendation dataset sourced from click logs of a popular search engine. Code for RAMEN  will be released publicly upon acceptance.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=iQ0aOGx6dc",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 13,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anshul_Mittal2",
        "name": "Anshul Mittal",
        "name_site": null,
        "openreview_id": "~Anshul_Mittal2",
        "position": 1,
        "gender": "M",
        "homepage_url": "http://anshulmittal.org",
        "dblp_id": null,
        "google_scholar_url": "8TDNQMQAAAAJ",
        "orcid": "0000-0002-4137-0126",
        "linkedin_url": "anshumitts/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "iQ0aOGx6dc",
      "title": "Graph Regularized Encoder Training for Extreme Classification",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Deep extreme classification (XC) aims to train an encoder and label classifiers to tag a data point with the most relevant subset of labels from a very large universe of labels. XC applications in ranking, recommendation and tagging routinely encounter tail labels, for which the amount of training data is exceedingly small. One way to tackle the tail label problem is to use additional data - often structured as a graph associated with documents and labels - graph metadata. Graph Convolutional Networks (GCNs) present a convenient but computationally expensive way to leverage this graph metadata and enhance model accuracies in these settings. However, GCNs struggle to make predictions for a novel test point when it has no edge in the graph. The paper notices that in these settings, it is much more effective to use graph data to regularize encoder training than to implement a GCN. Based on these insights, an alternative paradigm RAMEN  is presented to utilize graph metadata in XC settings that offers a significant performance boost with zero increase in inference computational costs. RAMEN scales to datasets with millions of labels and offers prediction accuracy up to 15% higher on benchmark datasets than state of the art methods, including those that use graph metadata to train GCNs. RAMEN also offers 10% higher accuracy over the best baseline on a proprietary recommendation dataset sourced from click logs of a popular search engine. Code for RAMEN  will be released publicly upon acceptance.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=iQ0aOGx6dc",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 13,
      "track_name": "Main Conference",
      "author": {
        "id": "~Siddarth_Asokan1",
        "name": "Siddarth Asokan",
        "name_site": null,
        "openreview_id": "~Siddarth_Asokan1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://siddarthasokan.com",
        "dblp_id": "277/5532",
        "google_scholar_url": "tM4SYUQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "iQ0aOGx6dc",
      "title": "Graph Regularized Encoder Training for Extreme Classification",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Deep extreme classification (XC) aims to train an encoder and label classifiers to tag a data point with the most relevant subset of labels from a very large universe of labels. XC applications in ranking, recommendation and tagging routinely encounter tail labels, for which the amount of training data is exceedingly small. One way to tackle the tail label problem is to use additional data - often structured as a graph associated with documents and labels - graph metadata. Graph Convolutional Networks (GCNs) present a convenient but computationally expensive way to leverage this graph metadata and enhance model accuracies in these settings. However, GCNs struggle to make predictions for a novel test point when it has no edge in the graph. The paper notices that in these settings, it is much more effective to use graph data to regularize encoder training than to implement a GCN. Based on these insights, an alternative paradigm RAMEN  is presented to utilize graph metadata in XC settings that offers a significant performance boost with zero increase in inference computational costs. RAMEN scales to datasets with millions of labels and offers prediction accuracy up to 15% higher on benchmark datasets than state of the art methods, including those that use graph metadata to train GCNs. RAMEN also offers 10% higher accuracy over the best baseline on a proprietary recommendation dataset sourced from click logs of a popular search engine. Code for RAMEN  will be released publicly upon acceptance.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=iQ0aOGx6dc",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 13,
      "track_name": "Main Conference",
      "author": {
        "id": "~Suchith_Chidananda_Prabhu1",
        "name": "Suchith Chidananda Prabhu",
        "name_site": null,
        "openreview_id": "~Suchith_Chidananda_Prabhu1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://suchith720.github.io",
        "dblp_id": null,
        "google_scholar_url": "-UmeTCYAAAAJ",
        "orcid": "0009-0007-4647-3304",
        "linkedin_url": "suchith-chidananda-prabhu-9a65a9158/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "iQ0aOGx6dc",
      "title": "Graph Regularized Encoder Training for Extreme Classification",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Deep extreme classification (XC) aims to train an encoder and label classifiers to tag a data point with the most relevant subset of labels from a very large universe of labels. XC applications in ranking, recommendation and tagging routinely encounter tail labels, for which the amount of training data is exceedingly small. One way to tackle the tail label problem is to use additional data - often structured as a graph associated with documents and labels - graph metadata. Graph Convolutional Networks (GCNs) present a convenient but computationally expensive way to leverage this graph metadata and enhance model accuracies in these settings. However, GCNs struggle to make predictions for a novel test point when it has no edge in the graph. The paper notices that in these settings, it is much more effective to use graph data to regularize encoder training than to implement a GCN. Based on these insights, an alternative paradigm RAMEN  is presented to utilize graph metadata in XC settings that offers a significant performance boost with zero increase in inference computational costs. RAMEN scales to datasets with millions of labels and offers prediction accuracy up to 15% higher on benchmark datasets than state of the art methods, including those that use graph metadata to train GCNs. RAMEN also offers 10% higher accuracy over the best baseline on a proprietary recommendation dataset sourced from click logs of a popular search engine. Code for RAMEN  will be released publicly upon acceptance.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=iQ0aOGx6dc",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 13,
      "track_name": "Main Conference",
      "author": {
        "id": "~Soumen_Chakrabarti1",
        "name": "Soumen Chakrabarti",
        "name_site": null,
        "openreview_id": "~Soumen_Chakrabarti1",
        "position": 11,
        "gender": "Not Specified",
        "homepage_url": "https://www.cse.iitb.ac.in/~soumen/",
        "dblp_id": "c/SChakrabarti",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=LfF2zfQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "iZI1vCiTTA",
      "title": "Mechanistic Behavior Editing of Language Models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Large Language Models trained on web-scale text acquire language generation abilities that can solve a wide range of tasks, particularly when task knowledge is refined into the generative prior using in-context examples. However, spurious features learned from noisy data hinder their generalizability. Supervised finetuning can introduce task specificity, but introduce data inefficiency. Prior studies indicate that (i) noisy neural circuitries coexist with generalizable ones within LLMs, and (ii) finetuning typically enhances (or suppresses) existing abilities without introducing newer ones. Building upon these, we propose TaRot, a novel method for task adaptation. TaRot intervenes in the neural circuitries using learnable rotation matrices that are optimized using Bayesian Optimization, on labelled samples in the order of standard few-shot prompting examples. Experiments on multiple classification and generation tasks using LLMs of varying sizes reveal the efficacy of TaRot, improving upon both zero- as well as few-shot performance, with average improvements (across models and tasks) of 23.81% and 11.15%, respectively",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=iZI1vCiTTA",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Tanmoy_Chakraborty2",
        "name": "Tanmoy Chakraborty",
        "name_site": null,
        "openreview_id": "~Tanmoy_Chakraborty2",
        "position": 3,
        "gender": "M",
        "homepage_url": "http://tanmoychak.com",
        "dblp_id": "65/2136-2.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=C5S9JnIAAAAJ",
        "orcid": "0000-0002-0210-0369",
        "linkedin_url": "tanmoy-chakraborty-89553324/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "igaxFI1gBA",
      "title": "Temporal Causal Discovery and Generative Prediction of Vehicular CO$_2$ emission",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Global warming from greenhouse gas emissions is humanity's largest environmental hazard. Greenhouse gases, like CO$_2$ emissions from transportation, notably cars, contribute to the greenhouse effect. Effective CO$_2$ emission monitoring is needed to regulate vehicle emissions. Few studies have predicted automobile CO$_2$ emissions using OBD port data. For precise and effective prediction, the system must capture the underlying cause-effect structure between vehicular parameters that may contribute to the emission of CO$_2$ in the transportation sector. Thus, we present a causal RNN-based generative deep learning architecture that predicts vehicle CO$_2$ emissions using OBD-II data while keeping the underlying causal structure. Most widely used real-life datasets lack causal relationships between features or components, so we use our proposed architecture to discover and learn the underlying causal structure as an adjacency matrix during training and employ that during forecasting. Our framework learns a sparse adjacency matrix by imposing a sparsity-encouraging penalty on model weights and allowing some weights to be zero. This matrix is capable of capturing the causal relationships between all variable pairs. In this work, we first train the model with widely used synthetic datasets with known causal structure among variables, then we apply it to the state-of-the-art OBD-II dataset to find the internal causal structure among the vehicular parameters and perform causal inference to predict CO$_2$ emission. Experimental results reveal that our causal discovery and forecasting method surpasses state-of-the-art methods for the tasks of causal discovery in terms of AUROC, forecasting on multivariate causal time series data, and OBD-II dataset in terms of MMD, RMSE, and MAE. After successful completion, we will release the code (Code for review - \\href{https://anonymous.4open.science/r/causal-obd-co2-0A0C}{https://anonymous.4open.science/r/causal-obd-co2-0A0C}).",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=igaxFI1gBA",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ayanabha_Ghosh1",
        "name": "Ayanabha Ghosh",
        "name_site": null,
        "openreview_id": "~Ayanabha_Ghosh1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/ayanabha",
        "dblp_id": null,
        "google_scholar_url": "oB4N3H4AAAAJ",
        "orcid": "0000-0002-6518-1047",
        "linkedin_url": "https://linkedin.com/in/ayanabha-ghosh-cs",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.666666666666667,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ihwRfc4RNw",
      "title": "MatText: Do Language Models Need More than Text & Scale for Materials Modeling?",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Effectively representing materials as text has the potential to leverage the vast advancements of large language models (LLMs) for discovering new materials. While LLMs have shown remarkable success in various domains, their application to materials science remains underexplored. A fundamental challenge is the lack of understanding of how to best utilize text-based representations for materials modeling. This challenge is further compounded by the absence of a comprehensive benchmark to rigorously evaluate the capabilities and limitations of these textual representations in capturing the complexity of material systems. To address this gap, we propose MatText, a suite of benchmarking tools and datasets designed to systematically evaluate the performance of language models in modeling materials. MatText encompasses nine distinct text-based representations for material systems, including several novel representations. Each representation incorporates unique inductive biases that capture relevant information and integrate prior physical knowledge about materials. Additionally, MatText provides essential tools for training and benchmarking the performance of language models in the context of materials science. These tools include standardized dataset splits for each representation across a range of dataset sizes, probes for evaluating sensitivity to geometric factors, and tools for seamlessly converting crystal structures into text. Using MatText, we conduct an extensive analysis of the capabilities of language models in modeling materials with different representations and dataset scales. Our findings reveal that current language models consistently struggle to capture the geometric information crucial for materials modeling across all representations. Instead, these models tend to leverage local information, which is emphasized in some of our novel representations. Our analysis underscores MatText's ability to reveal shortcomings of text-based methods for materials design.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ihwRfc4RNw",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Santiago_Miret1",
        "name": "Santiago Miret",
        "name_site": null,
        "openreview_id": "~Santiago_Miret1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.intel.ai/bio/santiago-miret/",
        "dblp_id": "241/5030",
        "google_scholar_url": "HLQ_te4AAAAJ",
        "orcid": "0000-0002-5121-3853",
        "linkedin_url": "santiago-miret/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Intel (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.0,
        "confidence_mean": 4.0,
        "confidence_std": 1.224744871391589,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 19,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "j83R1R3euh",
      "title": "LEVERAGING LEARNING RATE GRADIENTS FOR AUTOMATIC LEARNING RATE SELECTION",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Selecting an optimal learning rate (LR) is crucial for training deep neural networks, significantly affecting both convergence speed and final model performance. Determining this optimal LR typically involves two key challenges: choosing an appropriate initial LR and selecting an LR scheduler for adjusting the LR during training. This paper focuses on the former challenge—selecting the initial LR. Traditionally, this task relies on manual tuning or heuristic methods, often involving extensive trial-and-error or computationally expensive search strategies like grid search or random search. We propose an algorithm, Automatic Learning Rate Selection (ALRS), to find the initial LR without the need for manual intervention. ALRS leverages the gradient of the LR itself — a less explored approach in the field. ALRS is a computationally lightweight pre-training process that automatically selects the initial LR by iterative refinements using the LR gradient, specifically analyzing its sign information, combined with suitable search algorithms. This approach efficiently converges to the optimal LR in a stable and robust manner across various optimizers and network architectures. \n\nWe evaluate our technique on standard deep learning benchmarks, including MNIST with a CNN and CIFAR-10 and CIFAR-100 with ResNet-18, using both SGD and Adam optimizers. Our experiments demonstrate that the automatically determined LRs achieve performance comparable to manually tuned LRs and state-of-the-art results.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=j83R1R3euh",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Amit_Hogadi1",
        "name": "Amit Hogadi",
        "name_site": null,
        "openreview_id": "~Amit_Hogadi1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.com/citations?view_op=list_works",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science Education and Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "j83R1R3euh",
      "title": "LEVERAGING LEARNING RATE GRADIENTS FOR AUTOMATIC LEARNING RATE SELECTION",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Selecting an optimal learning rate (LR) is crucial for training deep neural networks, significantly affecting both convergence speed and final model performance. Determining this optimal LR typically involves two key challenges: choosing an appropriate initial LR and selecting an LR scheduler for adjusting the LR during training. This paper focuses on the former challenge—selecting the initial LR. Traditionally, this task relies on manual tuning or heuristic methods, often involving extensive trial-and-error or computationally expensive search strategies like grid search or random search. We propose an algorithm, Automatic Learning Rate Selection (ALRS), to find the initial LR without the need for manual intervention. ALRS leverages the gradient of the LR itself — a less explored approach in the field. ALRS is a computationally lightweight pre-training process that automatically selects the initial LR by iterative refinements using the LR gradient, specifically analyzing its sign information, combined with suitable search algorithms. This approach efficiently converges to the optimal LR in a stable and robust manner across various optimizers and network architectures. \n\nWe evaluate our technique on standard deep learning benchmarks, including MNIST with a CNN and CIFAR-10 and CIFAR-100 with ResNet-18, using both SGD and Adam optimizers. Our experiments demonstrate that the automatically determined LRs achieve performance comparable to manually tuned LRs and state-of-the-art results.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=j83R1R3euh",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Girish_Kulkarni3",
        "name": "Girish Kulkarni",
        "name_site": null,
        "openreview_id": "~Girish_Kulkarni3",
        "position": 2,
        "gender": null,
        "homepage_url": "https://sites.google.com/site/girishkulkarniwebpage/home",
        "dblp_id": null,
        "google_scholar_url": "q5IkYOAAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tata Institute of Fundamental Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "k6OQ9VTZBZ",
      "title": "Sketch-Plan-Generalize: Learning Inductive Representations for Grounded Spatial Concepts",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Our goal is to enable embodied agents to learn inductive representations for grounded spatial concepts, e.g., learning staircase as an inductive composition of towers of increasing height. Given few human demonstrations, we seek a learning architecture that infers a succinct inductive *program* representation that *explains* the observed instances. The approach should generalize to learning novel structures of different sizes or complexity expressed as a hierarchical composition of previously learned concepts.  Existing approaches that use code generation capabilities of pre-trained large (visual) language models, as well as purely neural models, show poor generalization to *a-priori* unseen complex concepts. Our key insight is to factor inductive concept learning as: (i) *Sketch:* detecting and inferring a coarse signature of a new concept (ii) *Plan:* performing MCTS search over grounded action sequences (iii) *Generalize:* abstracting out  grounded plans as inductive programs. Our pipeline facilitates generalization and modular re-use enabling continual concept learning.  Our approach combines the benefits of code generation ability of large language models (LLMs) along with grounded neural representations, resulting in neuro-symbolic programs that show stronger inductive generalization on the task of constructing complex structures vis-'a-vis LLM-only and purely neural approaches. Further, we demonstrate reasoning and planning capabilities with learned concepts for embodied instruction following.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=k6OQ9VTZBZ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Namasivayam_Kalithasan1",
        "name": "Namasivayam Kalithasan",
        "name_site": null,
        "openreview_id": "~Sachit_Sachdeva1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://www.linkedin.com/in/sachit-sachdeva-559769214/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "k6OQ9VTZBZ",
      "title": "Sketch-Plan-Generalize: Learning Inductive Representations for Grounded Spatial Concepts",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Our goal is to enable embodied agents to learn inductive representations for grounded spatial concepts, e.g., learning staircase as an inductive composition of towers of increasing height. Given few human demonstrations, we seek a learning architecture that infers a succinct inductive *program* representation that *explains* the observed instances. The approach should generalize to learning novel structures of different sizes or complexity expressed as a hierarchical composition of previously learned concepts.  Existing approaches that use code generation capabilities of pre-trained large (visual) language models, as well as purely neural models, show poor generalization to *a-priori* unseen complex concepts. Our key insight is to factor inductive concept learning as: (i) *Sketch:* detecting and inferring a coarse signature of a new concept (ii) *Plan:* performing MCTS search over grounded action sequences (iii) *Generalize:* abstracting out  grounded plans as inductive programs. Our pipeline facilitates generalization and modular re-use enabling continual concept learning.  Our approach combines the benefits of code generation ability of large language models (LLMs) along with grounded neural representations, resulting in neuro-symbolic programs that show stronger inductive generalization on the task of constructing complex structures vis-'a-vis LLM-only and purely neural approaches. Further, we demonstrate reasoning and planning capabilities with learned concepts for embodied instruction following.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=k6OQ9VTZBZ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sachit_Sachdeva1",
        "name": "Sachit Sachdeva",
        "name_site": null,
        "openreview_id": "~Vishal_Bindal2",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "vishal-bindal/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "k6OQ9VTZBZ",
      "title": "Sketch-Plan-Generalize: Learning Inductive Representations for Grounded Spatial Concepts",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Our goal is to enable embodied agents to learn inductive representations for grounded spatial concepts, e.g., learning staircase as an inductive composition of towers of increasing height. Given few human demonstrations, we seek a learning architecture that infers a succinct inductive *program* representation that *explains* the observed instances. The approach should generalize to learning novel structures of different sizes or complexity expressed as a hierarchical composition of previously learned concepts.  Existing approaches that use code generation capabilities of pre-trained large (visual) language models, as well as purely neural models, show poor generalization to *a-priori* unseen complex concepts. Our key insight is to factor inductive concept learning as: (i) *Sketch:* detecting and inferring a coarse signature of a new concept (ii) *Plan:* performing MCTS search over grounded action sequences (iii) *Generalize:* abstracting out  grounded plans as inductive programs. Our pipeline facilitates generalization and modular re-use enabling continual concept learning.  Our approach combines the benefits of code generation ability of large language models (LLMs) along with grounded neural representations, resulting in neuro-symbolic programs that show stronger inductive generalization on the task of constructing complex structures vis-'a-vis LLM-only and purely neural approaches. Further, we demonstrate reasoning and planning capabilities with learned concepts for embodied instruction following.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=k6OQ9VTZBZ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Himanshu_Gaurav_Singh2",
        "name": "Himanshu Gaurav Singh",
        "name_site": null,
        "openreview_id": "~Arnav_Tuli1",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "arnav-tuli-b8299a200/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "k6OQ9VTZBZ",
      "title": "Sketch-Plan-Generalize: Learning Inductive Representations for Grounded Spatial Concepts",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Our goal is to enable embodied agents to learn inductive representations for grounded spatial concepts, e.g., learning staircase as an inductive composition of towers of increasing height. Given few human demonstrations, we seek a learning architecture that infers a succinct inductive *program* representation that *explains* the observed instances. The approach should generalize to learning novel structures of different sizes or complexity expressed as a hierarchical composition of previously learned concepts.  Existing approaches that use code generation capabilities of pre-trained large (visual) language models, as well as purely neural models, show poor generalization to *a-priori* unseen complex concepts. Our key insight is to factor inductive concept learning as: (i) *Sketch:* detecting and inferring a coarse signature of a new concept (ii) *Plan:* performing MCTS search over grounded action sequences (iii) *Generalize:* abstracting out  grounded plans as inductive programs. Our pipeline facilitates generalization and modular re-use enabling continual concept learning.  Our approach combines the benefits of code generation ability of large language models (LLMs) along with grounded neural representations, resulting in neuro-symbolic programs that show stronger inductive generalization on the task of constructing complex structures vis-'a-vis LLM-only and purely neural approaches. Further, we demonstrate reasoning and planning capabilities with learned concepts for embodied instruction following.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=k6OQ9VTZBZ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vishal_Bindal2",
        "name": "Vishal Bindal",
        "name_site": null,
        "openreview_id": "~Gurarmaan_Singh_Panjeta1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "gurarmaanpanjeta",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of California, Berkeley (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "k6OQ9VTZBZ",
      "title": "Sketch-Plan-Generalize: Learning Inductive Representations for Grounded Spatial Concepts",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Our goal is to enable embodied agents to learn inductive representations for grounded spatial concepts, e.g., learning staircase as an inductive composition of towers of increasing height. Given few human demonstrations, we seek a learning architecture that infers a succinct inductive *program* representation that *explains* the observed instances. The approach should generalize to learning novel structures of different sizes or complexity expressed as a hierarchical composition of previously learned concepts.  Existing approaches that use code generation capabilities of pre-trained large (visual) language models, as well as purely neural models, show poor generalization to *a-priori* unseen complex concepts. Our key insight is to factor inductive concept learning as: (i) *Sketch:* detecting and inferring a coarse signature of a new concept (ii) *Plan:* performing MCTS search over grounded action sequences (iii) *Generalize:* abstracting out  grounded plans as inductive programs. Our pipeline facilitates generalization and modular re-use enabling continual concept learning.  Our approach combines the benefits of code generation ability of large language models (LLMs) along with grounded neural representations, resulting in neuro-symbolic programs that show stronger inductive generalization on the task of constructing complex structures vis-'a-vis LLM-only and purely neural approaches. Further, we demonstrate reasoning and planning capabilities with learned concepts for embodied instruction following.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=k6OQ9VTZBZ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Parag_Singla1",
        "name": "Parag Singla",
        "name_site": null,
        "openreview_id": "~Parag_Singla1",
        "position": 7,
        "gender": "M",
        "homepage_url": "http://www.cse.iitd.ac.in/~parags",
        "dblp_id": "14/167",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=V49BsgMAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "kMT8ujhYbA",
      "title": "Catastrophic Cyber Capabilities Benchmark (3CB): Robustly Evaluating LLM Agent Cyber Offense Capabilities",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "LLM agents have the potential to revolutionize defensive cyber operations, but their offensive capabilities are not yet fully understood. To prepare for emerging threats, model developers and governments are evaluating the cyber capabilities of foundation models. However, these assessments often lack transparency and a comprehensive focus on offensive capabilities. In response, we introduce the Catastrophic Cyber Capabilities Benchmark (3CB), a novel framework designed to rigorously assess the real-world offensive capabilities of LLM agents. Our evaluation of modern LLMs on 3CB reveals that frontier models, such as GPT-4o and Claude 3.5 Sonnet, can perform offensive tasks such as reconnaissance and exploitation across domains ranging from binary analysis to web technologies. Conversely, smaller open-source models exhibit limited offensive capabilities. Our software solution and the corresponding benchmark provides a critical tool to reduce the gap between rapidly improving capabilities and robustness of cyber offense evaluations, aiding in the safer deployment and regulation of these powerful technologies.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=kMT8ujhYbA",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Esben_Kran1",
        "name": "Esben Kran",
        "name_site": null,
        "openreview_id": "~Esben_Kran1",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://apartresearch.com",
        "dblp_id": null,
        "google_scholar_url": "SH5diRUAAAAJ",
        "orcid": "0000-0003-0710-2635",
        "linkedin_url": "esbenkc/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 2.0548046676563256,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 6,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "kMz43DyCKA",
      "title": "Playing For You: Text Prompt-guided Joint Audio-visual Generation for Narrating Faces using Multi-entangled Latent Space",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We present a novel approach for generating realistic speaking and taking faces by synthesizing a person’s voice and facial movements from a static image, a voice profile, and a target text. The model encodes the prompt/driving text, a driving image and the voice profile of an individual and then combines them to pass it to the multi-entangled latent space to foster key-vale and query for audio and video modality generation pipeline. The multi-entangled latent space is responsible for establishing the spatiotemporal person-specific features between the modalities. Further, entangled features are passed to the respective decoder of each modality for output audio and video generation. Our experiments and analysis through standard metrics showcase the effectiveness of our model. All model checkpoints, code and the proposed dataset can be found at: https://github.com/Playing-for-you.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=kMz43DyCKA",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aashish_Chandra1",
        "name": "Aashish Chandra",
        "name_site": null,
        "openreview_id": "~Aashish_Chandra1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "aashish-chandra",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 1.0954451150103321,
        "confidence_mean": 3.0,
        "confidence_std": 0.6324555320336759,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "kMz43DyCKA",
      "title": "Playing For You: Text Prompt-guided Joint Audio-visual Generation for Narrating Faces using Multi-entangled Latent Space",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We present a novel approach for generating realistic speaking and taking faces by synthesizing a person’s voice and facial movements from a static image, a voice profile, and a target text. The model encodes the prompt/driving text, a driving image and the voice profile of an individual and then combines them to pass it to the multi-entangled latent space to foster key-vale and query for audio and video modality generation pipeline. The multi-entangled latent space is responsible for establishing the spatiotemporal person-specific features between the modalities. Further, entangled features are passed to the respective decoder of each modality for output audio and video generation. Our experiments and analysis through standard metrics showcase the effectiveness of our model. All model checkpoints, code and the proposed dataset can be found at: https://github.com/Playing-for-you.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=kMz43DyCKA",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aashutosh_A_V1",
        "name": "Aashutosh A V",
        "name_site": null,
        "openreview_id": "~Aashutosh_A_V1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "aashutosh-av/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 1.0954451150103321,
        "confidence_mean": 3.0,
        "confidence_std": 0.6324555320336759,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "kMz43DyCKA",
      "title": "Playing For You: Text Prompt-guided Joint Audio-visual Generation for Narrating Faces using Multi-entangled Latent Space",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We present a novel approach for generating realistic speaking and taking faces by synthesizing a person’s voice and facial movements from a static image, a voice profile, and a target text. The model encodes the prompt/driving text, a driving image and the voice profile of an individual and then combines them to pass it to the multi-entangled latent space to foster key-vale and query for audio and video modality generation pipeline. The multi-entangled latent space is responsible for establishing the spatiotemporal person-specific features between the modalities. Further, entangled features are passed to the respective decoder of each modality for output audio and video generation. Our experiments and analysis through standard metrics showcase the effectiveness of our model. All model checkpoints, code and the proposed dataset can be found at: https://github.com/Playing-for-you.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=kMz43DyCKA",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sk_Aziz_Ali2",
        "name": "Sk Aziz Ali",
        "name_site": null,
        "openreview_id": "~Sk_Aziz_Ali2",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://skazizali.com",
        "dblp_id": null,
        "google_scholar_url": "zywjMeMAAAAJ",
        "orcid": "0000-0003-3701-2008",
        "linkedin_url": "sk-ali-208070118/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 1.0954451150103321,
        "confidence_mean": 3.0,
        "confidence_std": 0.6324555320336759,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "kMz43DyCKA",
      "title": "Playing For You: Text Prompt-guided Joint Audio-visual Generation for Narrating Faces using Multi-entangled Latent Space",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We present a novel approach for generating realistic speaking and taking faces by synthesizing a person’s voice and facial movements from a static image, a voice profile, and a target text. The model encodes the prompt/driving text, a driving image and the voice profile of an individual and then combines them to pass it to the multi-entangled latent space to foster key-vale and query for audio and video modality generation pipeline. The multi-entangled latent space is responsible for establishing the spatiotemporal person-specific features between the modalities. Further, entangled features are passed to the respective decoder of each modality for output audio and video generation. Our experiments and analysis through standard metrics showcase the effectiveness of our model. All model checkpoints, code and the proposed dataset can be found at: https://github.com/Playing-for-you.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=kMz43DyCKA",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abhijit_Das2",
        "name": "Abhijit Das",
        "name_site": null,
        "openreview_id": "~Abhijit_Das2",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://sites.google.com/site/dasabhijit2048",
        "dblp_id": "73/1871-1.html",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 1.0954451150103321,
        "confidence_mean": 3.0,
        "confidence_std": 0.6324555320336759,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "lAkke7Yj1T",
      "title": "Paramanu: A Family of Novel Efficient Generative Foundation Language Models for Indian Languages",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "We present PARAMANU (which means \"atom\" in multiple Indian languages), a family of novel language models for Indian languages.\nIt is a collection of auto-regressive monolingual, bilingual, and multilingual Indian language models pretrained from scratch, currently covering 10 Indian languages (Assamese, Bangla, Hindi, Konkani, Maithili, Marathi, Odia, Sanskrit, Tamil, Telugu) across 5 scripts (Bangla, Devanagari, Odia, Tamil, Telugu).\nThe models are pretrained with a context size of 1024 on a single GPU, and are of varying sizes ranging from 13.29\\,M to 367.5\\,M parameters. We proposed a RoPE embedding scaling method that enables us to pretrain language models from scratch at larger sequence length context size on single GPU without increased GPU memory. We have also developed an efficient and advanced novel tokenizer with least fertility score among existing LLMs for Indian languages using a combination of BPE and Unigram that can also tokenize unseen languages written in the same script or the Roman script. We also proposed language specific tokenization for multilingual models and domain specific tokenization for monolingual language models. In order to avoid the \"curse of multi-linguality\" in our multilingual \"mParamanu\" model, we pretrained on comparable corpora by typological grouping using the same script. We proposed and performed pretraining for more than 1 epoch of training for most of our language models. From our results, we observed the language transfer phenomenon from low resource to high resource within languages of the same script and typology. We performed human evaluation of our pretrained models for open end text generation on grammar, coherence, creativity, and factuality metrics for several languages.\nOur Paramanu models outperformed standard and multilingual large language models (LLMs) by a large margin in performance despite being smaller in size by 64 to 20 times. We studied the impact of language specific tokenization versus language agnostic tokenization for bilingual language modeling. We also studied the impact of BPE versus Unigram tokenization for Devanagari script languages. We further created instruction-tuning datasets and instruction-tuned our pretrained models on 23,000 instructions in respective languages except Hindi, for which we used 75,000 instructions. Comparison with multilingual LLMs on various commonsense reasoning benchmarks for natural language understanding, natural language inference, and machine reading comprehension shows the advantage of our models. The performance of our Paramanu models leads to the conclusion that high quality generative language models are possible without high amount of compute power (FLOPS) and enormous number of parameters.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=lAkke7Yj1T",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arnab_Bhattacharya1",
        "name": "Arnab Bhattacharya",
        "name_site": null,
        "openreview_id": "~Arnab_Bhattacharya1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.cse.iitk.ac.in/users/arnabb/",
        "dblp_id": "48/2626-1",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=Sk-JV9QAAAAJ",
        "orcid": "0000-0001-7331-0788",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "lF9QXpfNHm",
      "title": "Efficient Open-world Test Time Adaptation of Vision Language Models",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "In dynamic real-world settings, models must adapt to changing data distributions, a challenge known as Test Time Adaptation (TTA). This becomes even more challenging in scenarios where test samples arrive sequentially, and the model must handle open-set conditions by distinguishing between known and unknown classes. Towards this goal, we propose ROSITA, a novel framework for Open set Single Image Test Time Adaptation using Vision-Language Models (VLMs). To enable the separation of known and unknown classes, ROSITA employs a specific contrastive loss, termed ReDUCe loss, which leverages feature banks storing reliable test samples. This approach facilitates efficient adaptation of known class samples to domain shifts while equipping the model to accurately reject unfamiliar samples. Our method sets a new benchmark for this problem, validated through extensive experiments across diverse real-world test environments. Our code is anonymously released at https://github.com/anon-tta/ROSITA.git",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=lF9QXpfNHm",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manogna_Sreenivas1",
        "name": "Manogna Sreenivas",
        "name_site": null,
        "openreview_id": "~Manogna_Sreenivas1",
        "position": 1,
        "gender": "F",
        "homepage_url": "https://manogna-s.github.io",
        "dblp_id": "340/5390",
        "google_scholar_url": "ytQg9qIAAAAJ",
        "orcid": null,
        "linkedin_url": "manogna-s-59350498",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.666666666666667,
        "rating_std": 1.247219128924647,
        "confidence_mean": 4.666666666666667,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "lF9QXpfNHm",
      "title": "Efficient Open-world Test Time Adaptation of Vision Language Models",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "In dynamic real-world settings, models must adapt to changing data distributions, a challenge known as Test Time Adaptation (TTA). This becomes even more challenging in scenarios where test samples arrive sequentially, and the model must handle open-set conditions by distinguishing between known and unknown classes. Towards this goal, we propose ROSITA, a novel framework for Open set Single Image Test Time Adaptation using Vision-Language Models (VLMs). To enable the separation of known and unknown classes, ROSITA employs a specific contrastive loss, termed ReDUCe loss, which leverages feature banks storing reliable test samples. This approach facilitates efficient adaptation of known class samples to domain shifts while equipping the model to accurately reject unfamiliar samples. Our method sets a new benchmark for this problem, validated through extensive experiments across diverse real-world test environments. Our code is anonymously released at https://github.com/anon-tta/ROSITA.git",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=lF9QXpfNHm",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Soma_Biswas1",
        "name": "Soma Biswas",
        "name_site": null,
        "openreview_id": "~Soma_Biswas1",
        "position": 2,
        "gender": "F",
        "homepage_url": "http://www.ee.iisc.ac.in/new/people/faculty/soma.biswas/index.html",
        "dblp_id": "82/2665",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.666666666666667,
        "rating_std": 1.247219128924647,
        "confidence_mean": 4.666666666666667,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "mJKhn7Ey4y",
      "title": "DIPPER: Direct Preference Optimization for Primitive-Enabled Hierarchical Reinforcement Learning",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Hierarchical reinforcement learning (HRL) is an elegant framework for learning efficient control policies to perform complex robotic tasks, especially in sparse reward settings. However, concurrently learning policies at multiple hierarchical levels often suffers from training instability due to non-stationary behavior of lower-level primitives. In this work, we introduce DIPPER, an efficient hierarchical framework that leverages Direct Preference Optimization (DPO) to mitigate non-stationarity at the higher level, while using reinforcement learning to train the corresponding primitives at the lower level. We observe that directly applying DPO to the higher level in HRL is ineffective and leads to infeasible subgoal generation issues. To address this, we develop a novel, principled framework based on lower-level primitive regularization of upper-level policy learning. We provide a theoretical justification for the proposed framework utilizing bi-level optimization. The application of DPO also necessitates the development of a novel reference policy formulation for feasible subgoal generation. To validate our approach, we conduct extensive experimental analyses on a variety of challenging, sparse-reward robotic navigation and manipulation tasks. Our results demonstrate that DIPPER shows impressive performance and demonstrates an improvement of up to 40% over the baselines in complex sparse robotic control tasks.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=mJKhn7Ey4y",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 8,
      "track_name": "Main Conference",
      "author": {
        "id": "~Utsav_Singh1",
        "name": "Utsav Singh",
        "name_site": null,
        "openreview_id": "~Utsav_Singh1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://www.cse.iitk.ac.in/users/utsavz/",
        "dblp_id": "241/9336",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.920286436967152,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "mLxxv5gts0",
      "title": "Gaussian Mixture Vector Quantization with Aggregated Categorical Posterior",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "The vector quantization is a widely used method to map continuous representation to discrete space and has important application in tokenization for generative mode, bottlenecking information and many other tasks in machine learning. \nVector Quantized Variational Autoencoder (VQ-VAE) is a type of variational autoencoder using discrete embedding as latent. We generalize the technique further, enriching the probabilistic framework with a Gaussian mixture as the underlying generative model. This framework leverages a codebook of latent means and adaptive variances to capture complex data distributions. This principled framework avoids various heuristics and strong assumptions that are needed with the VQ-VAE to address training instability and to improve codebook utilization.  This approach integrates the benefits of both discrete and continuous representations within a variational Bayesian framework. Furthermore, by introducing the \\textit{Aggregated Categorical Posterior Evidence Lower Bound} (ALBO), we offer a principled alternative optimization objective that aligns variational distributions with the generative model. Our experiments demonstrate that GM-VQ improves codebook utilization and reduces information loss without relying on handcrafted heuristics.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=mLxxv5gts0",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jiawei_WU5",
        "name": "Jiawei WU",
        "name_site": null,
        "openreview_id": "~Jiawei_WU5",
        "position": 2,
        "gender": null,
        "homepage_url": "https://github.com/Christina327",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Jodhpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.8,
        "rating_std": 1.6,
        "confidence_mean": 3.8,
        "confidence_std": 0.7483314773547882,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "mLxxv5gts0",
      "title": "Gaussian Mixture Vector Quantization with Aggregated Categorical Posterior",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "The vector quantization is a widely used method to map continuous representation to discrete space and has important application in tokenization for generative mode, bottlenecking information and many other tasks in machine learning. \nVector Quantized Variational Autoencoder (VQ-VAE) is a type of variational autoencoder using discrete embedding as latent. We generalize the technique further, enriching the probabilistic framework with a Gaussian mixture as the underlying generative model. This framework leverages a codebook of latent means and adaptive variances to capture complex data distributions. This principled framework avoids various heuristics and strong assumptions that are needed with the VQ-VAE to address training instability and to improve codebook utilization.  This approach integrates the benefits of both discrete and continuous representations within a variational Bayesian framework. Furthermore, by introducing the \\textit{Aggregated Categorical Posterior Evidence Lower Bound} (ALBO), we offer a principled alternative optimization objective that aligns variational distributions with the generative model. Our experiments demonstrate that GM-VQ improves codebook utilization and reduces information loss without relying on handcrafted heuristics.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=mLxxv5gts0",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rushi_Shah1",
        "name": "Rushi Shah",
        "name_site": null,
        "openreview_id": "~Rushi_Shah1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://shahrushi2003.github.io/about.html",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Montreal (Canada)",
        "countries": [
          "Canada"
        ],
        "country_codes": [
          "CA"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.8,
        "rating_std": 1.6,
        "confidence_mean": 3.8,
        "confidence_std": 0.7483314773547882,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "mMXCMoU95Y",
      "title": "CAuSE: Post-hoc Natural Language Explanation of Multimodal Classifiers through Causal Abstraction",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The increasing integration of AI models in critical areas, such as healthcare, finance, and security has raised concerns about their black-box nature, limiting trust and accountability. To ensure robust and trustworthy AI, interpretability is essential. In this paper, we propose CAuSE (Causal Abstraction under Simulated Explanation), a novel framework for post-hoc explanation of multimodal classifiers. Unlike existing interpretability methods, such as Amnesic Probing and Integrated Gradients, CAuSE generates causally faithful natural language explanations of fine-tuned multimodal classifiers' decisions. CAuSE integrates Interchange Intervention Training (IIT) within a Language Model (LM) based module to simulate the causal reasoning behind a classifier's outputs. We introduce a novel metric Counterfactual F1 score to measure causal faithfulness and demonstrate that CAuSE achieves state-of-the-art performance on this metric. We also provide a rigorous theoretical underpinning for causal abstraction between two neural networks and implement this within our CAuSE framework. This ensures that CAuSE’s natural language explanations are not only simulations of the classifier’s behavior but also reflect its underlying causal processes. Our method is task-agnostic and achieves state-of-the-art results on benchmark multimodal classification datasets, such as e-SNLI-VE and Facebook Hateful Memes, offering a scalable, faithful solution for interpretability in multimodal classifiers.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=mMXCMoU95Y",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Dibyanayan_Bandyopadhyay1",
        "name": "Dibyanayan Bandyopadhyay",
        "name_site": null,
        "openreview_id": "~Dibyanayan_Bandyopadhyay1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": "243/2978.html",
        "google_scholar_url": "t_kZ1qsAAAAJ",
        "orcid": "0000-0001-5279-6344",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Patna (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.6666666666666665,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "mMXCMoU95Y",
      "title": "CAuSE: Post-hoc Natural Language Explanation of Multimodal Classifiers through Causal Abstraction",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The increasing integration of AI models in critical areas, such as healthcare, finance, and security has raised concerns about their black-box nature, limiting trust and accountability. To ensure robust and trustworthy AI, interpretability is essential. In this paper, we propose CAuSE (Causal Abstraction under Simulated Explanation), a novel framework for post-hoc explanation of multimodal classifiers. Unlike existing interpretability methods, such as Amnesic Probing and Integrated Gradients, CAuSE generates causally faithful natural language explanations of fine-tuned multimodal classifiers' decisions. CAuSE integrates Interchange Intervention Training (IIT) within a Language Model (LM) based module to simulate the causal reasoning behind a classifier's outputs. We introduce a novel metric Counterfactual F1 score to measure causal faithfulness and demonstrate that CAuSE achieves state-of-the-art performance on this metric. We also provide a rigorous theoretical underpinning for causal abstraction between two neural networks and implement this within our CAuSE framework. This ensures that CAuSE’s natural language explanations are not only simulations of the classifier’s behavior but also reflect its underlying causal processes. Our method is task-agnostic and achieves state-of-the-art results on benchmark multimodal classification datasets, such as e-SNLI-VE and Facebook Hateful Memes, offering a scalable, faithful solution for interpretability in multimodal classifiers.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=mMXCMoU95Y",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Soham_Bhattacharjee1",
        "name": "Soham Bhattacharjee",
        "name_site": null,
        "openreview_id": "~Soham_Bhattacharjee1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "168/7063.html",
        "google_scholar_url": null,
        "orcid": "0009-0008-5033-6334",
        "linkedin_url": "soham-bhattacharjee-0a3915235/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Patna (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.6666666666666665,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "mMXCMoU95Y",
      "title": "CAuSE: Post-hoc Natural Language Explanation of Multimodal Classifiers through Causal Abstraction",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The increasing integration of AI models in critical areas, such as healthcare, finance, and security has raised concerns about their black-box nature, limiting trust and accountability. To ensure robust and trustworthy AI, interpretability is essential. In this paper, we propose CAuSE (Causal Abstraction under Simulated Explanation), a novel framework for post-hoc explanation of multimodal classifiers. Unlike existing interpretability methods, such as Amnesic Probing and Integrated Gradients, CAuSE generates causally faithful natural language explanations of fine-tuned multimodal classifiers' decisions. CAuSE integrates Interchange Intervention Training (IIT) within a Language Model (LM) based module to simulate the causal reasoning behind a classifier's outputs. We introduce a novel metric Counterfactual F1 score to measure causal faithfulness and demonstrate that CAuSE achieves state-of-the-art performance on this metric. We also provide a rigorous theoretical underpinning for causal abstraction between two neural networks and implement this within our CAuSE framework. This ensures that CAuSE’s natural language explanations are not only simulations of the classifier’s behavior but also reflect its underlying causal processes. Our method is task-agnostic and achieves state-of-the-art results on benchmark multimodal classification datasets, such as e-SNLI-VE and Facebook Hateful Memes, offering a scalable, faithful solution for interpretability in multimodal classifiers.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=mMXCMoU95Y",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Asif_Ekbal1",
        "name": "Asif Ekbal",
        "name_site": null,
        "openreview_id": "~Asif_Ekbal1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://ekbalasif.github.io",
        "dblp_id": "11/3590",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=IAL_F04AAAAJ",
        "orcid": "0000-0003-3612-8834",
        "linkedin_url": "asif-ekbal-3b8a4517/?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.6666666666666665,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "mTgMLy2iPt",
      "title": "Policy Gradient with Tree Expansion",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Policy gradient methods are notorious for having a large variance and high sample complexity. To mitigate this, we introduce SoftTreeMax---a generalization of softmax that employs planning. In SoftTreeMax, we extend the traditional logits with the multi-step discounted cumulative reward, topped with the logits of future states. We analyze SoftTreeMax and explain how tree expansion helps to reduce its gradient variance. We prove that the variance depends on the chosen tree-expansion policy. Specifically, we show that the closer the induced transitions are to being state-independent, the stronger the variance decay. With approximate forward models, we prove that the resulting gradient bias diminishes with the approximation error while retaining the same variance reduction. Ours is the first result to bound the gradient bias for an approximate model. In a practical implementation of SoftTreeMax we utilize a parallel GPU-based simulator for fast and efficient tree expansion. Using this implementation in Atari, we show that SoftTreeMax reduces the gradient variance by three orders of magnitude. This leads to better sample complexity and improved performance compared to distributed PPO.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=mTgMLy2iPt",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Gugan_Thoppe1",
        "name": "Gugan Thoppe",
        "name_site": null,
        "openreview_id": "~Gugan_Thoppe1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "117/3710",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=X5zV3s8AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 1.8027756377319946,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "mscnV6JZkT",
      "title": "Distributed Gradient Descent with Many Local Steps in Overparameterized Models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "In distributed training of machine learning models, gradient descent with local iterative steps is a very popular method, variants of which are commonly known as Local-SGD or the Federated Averaging (FedAvg). In this method, gradient steps based on local datasets are taken independently in distributed compute nodes to update  the local models, which are then aggregated intermittently. Although the existing convergence analysis suggests that with heterogeneous data, FedAvg encounters quick performance degradation as the number of local steps increases, it is shown to work quite well in practice, especially in the distributed training of large language models. In this work we try to explain this good performance from a viewpoint of implicit bias in Local Gradient Descent (Local-GD) with a large number of local steps. In overparameterized regime, the gradient descent at each compute node would lead the model to a specific direction locally. We characterize the dynamics of the aggregated global model and compare it to the centralized model trained with all of the data in one place. In particular, we analyze the implicit bias of gradient descent on linear models, for both regression and classification tasks. Our analysis shows that the aggregated global model  converges exactly to the centralized model for regression tasks, and converges (in direction) to the same feasible set as centralized model  for classification tasks. We further propose a Modified Local-GD with a refined aggregation and theoretically show it converges to the centralized model in direction for linear classification. We empirically verified our theoretical findings in linear models and also conducted experiments on distributed fine-tuning of pretrained neural networks to further apply our theory.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=mscnV6JZkT",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Harsh_Vardhan1",
        "name": "Harsh Vardhan",
        "name_site": null,
        "openreview_id": "~Harsh_Vardhan1",
        "position": 2,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of California, San Diego (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "n6YVISFrcN",
      "title": "Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech Evaluation",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Despite rapid advancements in TTS models, a consistent and robust human evaluation framework is still lacking. For example, MOS tests fail to differentiate between similar models, and CMOS's pairwise comparisons are time-intensive. The MUSHRA test is a promising alternative for evaluating multiple TTS systems simultaneously, but in this work we show that its reliance on matching human reference speech unduly penalises the scores of modern TTS systems that can exceed human speech quality. More specifically, we conduct a comprehensive assessment of the MUSHRA test, focusing on its sensitivity to factors such as rater variability, listener fatigue, and reference bias. Based on our extensive evaluation involving 471 human listeners across Hindi and Tamil we identify two primary shortcomings: (i) \\textit{reference-matching bias}, where raters are unduly influenced by the human reference, and (ii) \\textit{judgement ambiguity}, arising from a lack of clear fine-grained guidelines. To address these issues, we propose two refined variants of the MUSHRA test. The first variant enables fairer ratings for synthesized samples that surpass human reference quality. The second variant reduces ambiguity, as indicated by the relatively lower variance across raters. By combining these approaches, we achieve both more reliable and more fine-grained assessments. We also release MANGO, a massive dataset of 47,100 human ratings, the first-of-its-kind collection for Indian languages, aiding in analyzing human preferences and developing automatic metrics for evaluating TTS systems.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=n6YVISFrcN",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 11,
      "track_name": "Main Conference",
      "author": {
        "id": "~Praveen_Srinivasa_Varadhan1",
        "name": "Praveen Srinivasa Varadhan",
        "name_site": null,
        "openreview_id": "~Praveen_Srinivasa_Varadhan1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "283/5316.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=CpGhZUYAAAAJ",
        "orcid": null,
        "linkedin_url": "svp19/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "n6YVISFrcN",
      "title": "Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech Evaluation",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Despite rapid advancements in TTS models, a consistent and robust human evaluation framework is still lacking. For example, MOS tests fail to differentiate between similar models, and CMOS's pairwise comparisons are time-intensive. The MUSHRA test is a promising alternative for evaluating multiple TTS systems simultaneously, but in this work we show that its reliance on matching human reference speech unduly penalises the scores of modern TTS systems that can exceed human speech quality. More specifically, we conduct a comprehensive assessment of the MUSHRA test, focusing on its sensitivity to factors such as rater variability, listener fatigue, and reference bias. Based on our extensive evaluation involving 471 human listeners across Hindi and Tamil we identify two primary shortcomings: (i) \\textit{reference-matching bias}, where raters are unduly influenced by the human reference, and (ii) \\textit{judgement ambiguity}, arising from a lack of clear fine-grained guidelines. To address these issues, we propose two refined variants of the MUSHRA test. The first variant enables fairer ratings for synthesized samples that surpass human reference quality. The second variant reduces ambiguity, as indicated by the relatively lower variance across raters. By combining these approaches, we achieve both more reliable and more fine-grained assessments. We also release MANGO, a massive dataset of 47,100 human ratings, the first-of-its-kind collection for Indian languages, aiding in analyzing human preferences and developing automatic metrics for evaluating TTS systems.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=n6YVISFrcN",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 11,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ashwin_Sankar1",
        "name": "Ashwin Sankar",
        "name_site": null,
        "openreview_id": "~Ashwin_Sankar1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "328/0752.html",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": "https://linkedin.com/in/ashwin-s2000",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "AI4Bharat (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "n6YVISFrcN",
      "title": "Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech Evaluation",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Despite rapid advancements in TTS models, a consistent and robust human evaluation framework is still lacking. For example, MOS tests fail to differentiate between similar models, and CMOS's pairwise comparisons are time-intensive. The MUSHRA test is a promising alternative for evaluating multiple TTS systems simultaneously, but in this work we show that its reliance on matching human reference speech unduly penalises the scores of modern TTS systems that can exceed human speech quality. More specifically, we conduct a comprehensive assessment of the MUSHRA test, focusing on its sensitivity to factors such as rater variability, listener fatigue, and reference bias. Based on our extensive evaluation involving 471 human listeners across Hindi and Tamil we identify two primary shortcomings: (i) \\textit{reference-matching bias}, where raters are unduly influenced by the human reference, and (ii) \\textit{judgement ambiguity}, arising from a lack of clear fine-grained guidelines. To address these issues, we propose two refined variants of the MUSHRA test. The first variant enables fairer ratings for synthesized samples that surpass human reference quality. The second variant reduces ambiguity, as indicated by the relatively lower variance across raters. By combining these approaches, we achieve both more reliable and more fine-grained assessments. We also release MANGO, a massive dataset of 47,100 human ratings, the first-of-its-kind collection for Indian languages, aiding in analyzing human preferences and developing automatic metrics for evaluating TTS systems.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=n6YVISFrcN",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 11,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anirudh_Gupta1",
        "name": "Anirudh Gupta",
        "name_site": null,
        "openreview_id": "~Anirudh_Gupta1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "anirudh-gupta-a5b26622/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Gan Studios Pvt Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "n6YVISFrcN",
      "title": "Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech Evaluation",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Despite rapid advancements in TTS models, a consistent and robust human evaluation framework is still lacking. For example, MOS tests fail to differentiate between similar models, and CMOS's pairwise comparisons are time-intensive. The MUSHRA test is a promising alternative for evaluating multiple TTS systems simultaneously, but in this work we show that its reliance on matching human reference speech unduly penalises the scores of modern TTS systems that can exceed human speech quality. More specifically, we conduct a comprehensive assessment of the MUSHRA test, focusing on its sensitivity to factors such as rater variability, listener fatigue, and reference bias. Based on our extensive evaluation involving 471 human listeners across Hindi and Tamil we identify two primary shortcomings: (i) \\textit{reference-matching bias}, where raters are unduly influenced by the human reference, and (ii) \\textit{judgement ambiguity}, arising from a lack of clear fine-grained guidelines. To address these issues, we propose two refined variants of the MUSHRA test. The first variant enables fairer ratings for synthesized samples that surpass human reference quality. The second variant reduces ambiguity, as indicated by the relatively lower variance across raters. By combining these approaches, we achieve both more reliable and more fine-grained assessments. We also release MANGO, a massive dataset of 47,100 human ratings, the first-of-its-kind collection for Indian languages, aiding in analyzing human preferences and developing automatic metrics for evaluating TTS systems.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=n6YVISFrcN",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 11,
      "track_name": "Main Conference",
      "author": {
        "id": "~Shiva_Kumar_Marepally1",
        "name": "Shiva Kumar Marepally",
        "name_site": null,
        "openreview_id": "~Shiva_Kumar_Marepally1",
        "position": 6,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "shivaio/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "n6YVISFrcN",
      "title": "Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech Evaluation",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Despite rapid advancements in TTS models, a consistent and robust human evaluation framework is still lacking. For example, MOS tests fail to differentiate between similar models, and CMOS's pairwise comparisons are time-intensive. The MUSHRA test is a promising alternative for evaluating multiple TTS systems simultaneously, but in this work we show that its reliance on matching human reference speech unduly penalises the scores of modern TTS systems that can exceed human speech quality. More specifically, we conduct a comprehensive assessment of the MUSHRA test, focusing on its sensitivity to factors such as rater variability, listener fatigue, and reference bias. Based on our extensive evaluation involving 471 human listeners across Hindi and Tamil we identify two primary shortcomings: (i) \\textit{reference-matching bias}, where raters are unduly influenced by the human reference, and (ii) \\textit{judgement ambiguity}, arising from a lack of clear fine-grained guidelines. To address these issues, we propose two refined variants of the MUSHRA test. The first variant enables fairer ratings for synthesized samples that surpass human reference quality. The second variant reduces ambiguity, as indicated by the relatively lower variance across raters. By combining these approaches, we achieve both more reliable and more fine-grained assessments. We also release MANGO, a massive dataset of 47,100 human ratings, the first-of-its-kind collection for Indian languages, aiding in analyzing human preferences and developing automatic metrics for evaluating TTS systems.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=n6YVISFrcN",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 11,
      "track_name": "Main Conference",
      "author": {
        "id": "~Suvrat_Bhooshan1",
        "name": "Suvrat Bhooshan",
        "name_site": null,
        "openreview_id": "~Suvrat_Bhooshan1",
        "position": 10,
        "gender": null,
        "homepage_url": "https://research.fb.com/people/bhooshan-suvrat/",
        "dblp_id": null,
        "google_scholar_url": "9zUHCNoAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "n6YVISFrcN",
      "title": "Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech Evaluation",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Despite rapid advancements in TTS models, a consistent and robust human evaluation framework is still lacking. For example, MOS tests fail to differentiate between similar models, and CMOS's pairwise comparisons are time-intensive. The MUSHRA test is a promising alternative for evaluating multiple TTS systems simultaneously, but in this work we show that its reliance on matching human reference speech unduly penalises the scores of modern TTS systems that can exceed human speech quality. More specifically, we conduct a comprehensive assessment of the MUSHRA test, focusing on its sensitivity to factors such as rater variability, listener fatigue, and reference bias. Based on our extensive evaluation involving 471 human listeners across Hindi and Tamil we identify two primary shortcomings: (i) \\textit{reference-matching bias}, where raters are unduly influenced by the human reference, and (ii) \\textit{judgement ambiguity}, arising from a lack of clear fine-grained guidelines. To address these issues, we propose two refined variants of the MUSHRA test. The first variant enables fairer ratings for synthesized samples that surpass human reference quality. The second variant reduces ambiguity, as indicated by the relatively lower variance across raters. By combining these approaches, we achieve both more reliable and more fine-grained assessments. We also release MANGO, a massive dataset of 47,100 human ratings, the first-of-its-kind collection for Indian languages, aiding in analyzing human preferences and developing automatic metrics for evaluating TTS systems.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=n6YVISFrcN",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 11,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mitesh_M_Khapra1",
        "name": "Mitesh M Khapra",
        "name_site": null,
        "openreview_id": "~Mitesh_M_Khapra1",
        "position": 11,
        "gender": "M",
        "homepage_url": "http://www.cse.iitm.ac.in/~miteshk",
        "dblp_id": "90/7967",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=DV8z8DYAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nIBmwm7ixo",
      "title": "VColRL: Learn to Solve the Vertex Coloring Problem Using Reinforcement Learning",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "We present VColRL, a reinforcement learning framework designed to solve the vertex coloring problem (VCP), where the objective is to assign colors to the vertices of a graph with the minimum number of colors, such that no two adjacent vertices share the same color. The framework is built on a novel Markov Decision Process (MDP) configuration to effectively capture the dynamics of the VCP, developed after evaluating various MDP configurations. Our experimental results demonstrate that VColRL achieves competitive performance in terms of using fewer colors as compared to advanced mathematical solvers and other metaheuristic approaches while being significantly faster. Additionally, our results show that VColRL generalizes well across different types of graphs.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=nIBmwm7ixo",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abhinav_Anand4",
        "name": "Abhinav Anand",
        "name_site": null,
        "openreview_id": "~Abhinav_Anand4",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://www.cse.iitk.ac.in/users/abhinavanand/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "https://in.linkedin.com/in/abhinav-anand-1a3510194",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.0,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.9428090415820634,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nIBmwm7ixo",
      "title": "VColRL: Learn to Solve the Vertex Coloring Problem Using Reinforcement Learning",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "We present VColRL, a reinforcement learning framework designed to solve the vertex coloring problem (VCP), where the objective is to assign colors to the vertices of a graph with the minimum number of colors, such that no two adjacent vertices share the same color. The framework is built on a novel Markov Decision Process (MDP) configuration to effectively capture the dynamics of the VCP, developed after evaluating various MDP configurations. Our experimental results demonstrate that VColRL achieves competitive performance in terms of using fewer colors as compared to advanced mathematical solvers and other metaheuristic approaches while being significantly faster. Additionally, our results show that VColRL generalizes well across different types of graphs.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=nIBmwm7ixo",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Subrahmanya_Swamy_Peruru1",
        "name": "Subrahmanya Swamy Peruru",
        "name_site": null,
        "openreview_id": "~Subrahmanya_Swamy_Peruru1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://home.iitk.ac.in/~swamyp/",
        "dblp_id": "162/0082",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=Z62m_8QAAAAJ",
        "orcid": "0000-0003-1237-4811",
        "linkedin_url": "subrahmanya-swamy-peruru-6bb35838/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.0,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.9428090415820634,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nIBmwm7ixo",
      "title": "VColRL: Learn to Solve the Vertex Coloring Problem Using Reinforcement Learning",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "We present VColRL, a reinforcement learning framework designed to solve the vertex coloring problem (VCP), where the objective is to assign colors to the vertices of a graph with the minimum number of colors, such that no two adjacent vertices share the same color. The framework is built on a novel Markov Decision Process (MDP) configuration to effectively capture the dynamics of the VCP, developed after evaluating various MDP configurations. Our experimental results demonstrate that VColRL achieves competitive performance in terms of using fewer colors as compared to advanced mathematical solvers and other metaheuristic approaches while being significantly faster. Additionally, our results show that VColRL generalizes well across different types of graphs.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=nIBmwm7ixo",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Amitangshu_Pal1",
        "name": "Amitangshu Pal",
        "name_site": null,
        "openreview_id": "~Amitangshu_Pal1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.cse.iitk.ac.in/users/amitangshu/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.0,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.9428090415820634,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nb3VjILNVs",
      "title": "Low Compute Unlearning via Sparse Representations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Machine \\emph{unlearning}, which involves erasing knowledge about a \\emph{forget set} from a trained model, can prove to be \ncostly and infeasible using existing techniques. We propose a  low compute unlearning technique based on a discrete representational bottleneck. We show that the proposed technique efficiently unlearns the forget set and incurs negligible damage to the model's performance on the rest of the data set. We evaluate the proposed technique on the problem of *class unlearning* using four datasets: CIFAR-10, CIFAR-100, LACUNA-100 and ImageNet-1k. We compare the proposed technique to SCRUB, a state-of-the-art approach which uses knowledge distillation for unlearning. Across all three datasets, the  proposed technique performs as well as, if not better than SCRUB while incurring minimal computational cost.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=nb3VjILNVs",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 8,
      "track_name": "Main Conference",
      "author": {
        "id": "~Di_He1_1",
        "name": "Di He",
        "name_site": null,
        "openreview_id": "~Anirudh_Goyal1",
        "position": 8,
        "gender": "M",
        "homepage_url": "https://anirudh9119.github.io/",
        "dblp_id": "172/1039",
        "google_scholar_url": "krrh6OUAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (Canada)",
        "countries": [
          "Canada"
        ],
        "country_codes": [
          "CA"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.7853571071357126,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nyuaoVnVCa",
      "title": "EMERGENCE OF GROUNDED, OPTIMALLY COMPOSITIONAL SPATIAL LANGUAGE AMONG HOMOGENEOUS AGENTS",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "A mechanism of effective communication is integral to human existence. An\nessential aspect of a functional communication scheme among a rational human\npopulation involves an efficient,  adaptive, and coherent apparatus to convey one’s goal to others. Such an effective macro characteristic can\nemerge in a finite population through adaptive learning via trial and error\nat the individual (micro) level, with nearly consistent individual learning faculty and experience across the population. In this paper, we study and hypothesize\n pertinent aspects of glossogenetics, specifically primal human communication mechanisms, through computational modeling. In particular, we model the\nprocess as a language game within the fabric of a decentralized, multi-agent\ndeep reinforcement learning setting, where the agents with local learning and neural\ncognitive faculties interact through a series of dialogues. Our homogeneous agents seek to achieve the principle of least effort and overcome the poverty of stimulus through efficient concept selection, guided feedback and mirror learning. In our examinations,\nwe observe the emergence of successful and structured communication among static and dynamic agent populations through consistent and continual learning.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=nyuaoVnVCa",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vikas_Kumar4",
        "name": "Vikas Kumar",
        "name_site": null,
        "openreview_id": "~Vikas_Kumar4",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "vizzard110/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.3333333333333335,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "o1SGGW53GF",
      "title": "NativQA: Multilingual Culturally-Aligned Natural Queries for LLMs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Natural Question Answering (QA) datasets play a crucial role in evaluating the capabilities of large language models (LLMs), ensuring their effectiveness in real-world applications. Despite the numerous QA datasets that have been developed, there is a notable lack of region-specific datasets generated by native users in their own languages. This gap hinders the effective benchmarking of LLMs for regional and cultural specificities. Furthermore, it also limits the development of fine-tuned models. In this study, we propose a scalable, language-independent framework, NativQA, to seamlessly construct culturally and regionally aligned QA datasets in native languages, for LLM evaluation and tuning. We demonstrate the efficacy of the proposed framework by designing a multilingual natural QA dataset, \\mnqa, consisting of ~64k manually annotated QA pairs in seven languages, ranging from high to extremely low resource, based on queries from native speakers from 9 regions covering 18 topics. We benchmark open- and closed-source LLMs with the MultiNativQA dataset. We also showcase the framework efficacy in constructing fine-tuning data especially for low-resource and dialectally-rich languages. We made both the framework NativQA and MultiNativQA dataset publicly available for the community (https://anonymous.com/).",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=o1SGGW53GF",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sahinur_Rahman_Laskar1",
        "name": "Sahinur Rahman Laskar",
        "name_site": null,
        "openreview_id": "~Sahinur_Rahman_Laskar1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://sahinurlaskar.github.io/",
        "dblp_id": "247/6547",
        "google_scholar_url": "fbqD9i8AAAAJ",
        "orcid": "0000-0002-8413-2718",
        "linkedin_url": "dr-sahinur-rahman-laskar-0683ab1b0?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_contact_details%3B4RMUjiZIRy6u56LXEIqbiQ%3D%3D",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Petroleum and Energy Studies (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 2.0463381929681126,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "o4X6UM18rI",
      "title": "Bayes-Nash Generative Privacy Protection Against Membership Inference Attacks",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Membership inference attacks (MIAs) expose significant privacy risks by determining whether an individual’s data is in a dataset. While differential privacy (DP) mitigates such risks, it faces challenges in general when achieving an optimal balance between privacy and utility, often requiring intractable sensitivity calculations and limiting flexibility in complex compositions. We propose a game-theoretic framework that models privacy protection as a Bayesian game between a defender and an attacker, solved using a general-sum Generative Adversarial Network (general-sum GAN). The Bayes Generative Privacy (BGP) response, based on cross-entropy loss, defines the attacker’s optimal strategy, leading to the Bayes-Nash Generative Privacy (BNGP) strategy, which achieves the optimal privacy-utility trade-off tailored to the defender’s preferences. The BNGP strategy avoids sensitivity calculations, supports compositions of correlated mechanisms, and is robust to the attacker’s heterogeneous preferences over true and false positives. A case study on binary dataset summary statistics demonstrates its superiority over likelihood ratio test (LRT)-based attacks, including the uniformly most powerful LRT. Empirical results confirm BNGP’s effectiveness.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=o4X6UM18rI",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rajat_K._De1",
        "name": "Rajat K. De",
        "name_site": null,
        "openreview_id": "~Rajat_K._De1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "62/2543",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Statistical Institute (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 2.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ofiZbAmrZh",
      "title": "Consistency-based Black-box Uncertainty Quantification for Text-to-SQL by Similarity Aggregation",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "When does a large language model (LLM) know what it does not know? Uncertainty quantification (UQ) provides an estimate of the confidence in an LLM's generated output and is therefore increasingly recognized as a crucial component of trusted AI systems. UQ is particularly important for complex generative tasks such as \\emph{text-to-SQL}, where an LLM helps users gain insights about data stored in noisy and large databases by translating their natural language queries to structured query language (SQL). \\emph{Black-box} UQ methods do not require access to internal model information from the generating LLM, and therefore have numerous real-world advantages, such as robustness to system changes, adaptability to choice of LLM (including those with commercialized APIs), reduced costs, and substantial computational tractability. In this paper, we investigate the effectiveness of black-box UQ techniques for text-to-SQL, where the consistency between a generated output and other sampled generations is used as a proxy for estimating its confidence. We propose a high-level non-verbalized \\emph{similarity aggregation} approach that is suitable for complex generative tasks, including specific techniques that train confidence estimation models using small training sets. Through an extensive empirical study over various text-to-SQL datasets and models, we provide recommendations for the choice of sampling technique and similarity metric. The experiments demonstrate that our proposed similarity aggregation techniques result in better calibrated confidence estimates as compared to the closest baselines, but also highlight how there is room for improvement on downstream tasks such as selective generation.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ofiZbAmrZh",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Balaji_Ganesan1",
        "name": "Balaji Ganesan",
        "name_site": null,
        "openreview_id": "~Balaji_Ganesan1",
        "position": 2,
        "gender": "M",
        "homepage_url": "http://researcher.watson.ibm.com/researcher/view.php?person=in-bganesa1",
        "dblp_id": "205/0377",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=G4ze57oAAAAJ",
        "orcid": "0000-0002-2605-7537",
        "linkedin_url": "balajinix",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "IBM (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "pFjzF7dIgg",
      "title": "UnCLe: An Unlearning Framework for Continual Learning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Recent advances in deep learning require models to exhibit continual learning capability, allowing them to learn new tasks and progressively accumulate knowledge without forgetting old tasks. Concurrently, there are growing concerns and regulatory requirements to meet privacy and safety by discarding some knowledge through machine unlearning. With the rapidly rising relevance of continual learning and machine unlearning, we consider them together under a unified framework in this paper. However, the conflicting nature of past data unavailability arising from continual learning makes it challenging to perform unlearning with existing methods which assume data availability. Moreover, in the proposed setup, where tasks are repeatedly learned and unlearned in a sequence, it is another challenge to maintain the stability of the tasks that need to be retained. To address these challenges, we propose UnCLe, an Unlearning Framework for Continual Learning designed to learn tasks incrementally and unlearn tasks without access to past data. To perform data-free unlearning, UnCLe leverages hypernetworks in conjunction with an unlearning objective that seeks to selectively align task-specific parameters with noise. Our experiments on popular benchmarks demonstrate UnCLe's consistent unlearning completeness and ability to preserve task stability over long sequences.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=pFjzF7dIgg",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vishnuprasadh_Kumaravelu2",
        "name": "Vishnuprasadh Kumaravelu",
        "name_site": null,
        "openreview_id": "~Vishnuprasadh_Kumaravelu2",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "LGJaD-UAAAAJ",
        "orcid": null,
        "linkedin_url": "vis-prasadh/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "pFjzF7dIgg",
      "title": "UnCLe: An Unlearning Framework for Continual Learning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Recent advances in deep learning require models to exhibit continual learning capability, allowing them to learn new tasks and progressively accumulate knowledge without forgetting old tasks. Concurrently, there are growing concerns and regulatory requirements to meet privacy and safety by discarding some knowledge through machine unlearning. With the rapidly rising relevance of continual learning and machine unlearning, we consider them together under a unified framework in this paper. However, the conflicting nature of past data unavailability arising from continual learning makes it challenging to perform unlearning with existing methods which assume data availability. Moreover, in the proposed setup, where tasks are repeatedly learned and unlearned in a sequence, it is another challenge to maintain the stability of the tasks that need to be retained. To address these challenges, we propose UnCLe, an Unlearning Framework for Continual Learning designed to learn tasks incrementally and unlearn tasks without access to past data. To perform data-free unlearning, UnCLe leverages hypernetworks in conjunction with an unlearning objective that seeks to selectively align task-specific parameters with noise. Our experiments on popular benchmarks demonstrate UnCLe's consistent unlearning completeness and ability to preserve task stability over long sequences.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=pFjzF7dIgg",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sayanta_Adhikari2",
        "name": "Sayanta Adhikari",
        "name_site": null,
        "openreview_id": "~Sayanta_Adhikari2",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0009-0008-3717-9223",
        "linkedin_url": "sayanta-adhikari/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "pFjzF7dIgg",
      "title": "UnCLe: An Unlearning Framework for Continual Learning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Recent advances in deep learning require models to exhibit continual learning capability, allowing them to learn new tasks and progressively accumulate knowledge without forgetting old tasks. Concurrently, there are growing concerns and regulatory requirements to meet privacy and safety by discarding some knowledge through machine unlearning. With the rapidly rising relevance of continual learning and machine unlearning, we consider them together under a unified framework in this paper. However, the conflicting nature of past data unavailability arising from continual learning makes it challenging to perform unlearning with existing methods which assume data availability. Moreover, in the proposed setup, where tasks are repeatedly learned and unlearned in a sequence, it is another challenge to maintain the stability of the tasks that need to be retained. To address these challenges, we propose UnCLe, an Unlearning Framework for Continual Learning designed to learn tasks incrementally and unlearn tasks without access to past data. To perform data-free unlearning, UnCLe leverages hypernetworks in conjunction with an unlearning objective that seeks to selectively align task-specific parameters with noise. Our experiments on popular benchmarks demonstrate UnCLe's consistent unlearning completeness and ability to preserve task stability over long sequences.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=pFjzF7dIgg",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~P._K._Srijith1",
        "name": "P. K. Srijith",
        "name_site": null,
        "openreview_id": "~Srijith_P_K1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://sites.google.com/site/pksrijith/home",
        "dblp_id": "120/8712",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=C1YpEWsAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "pKMpmbuKnd",
      "title": "Constrained Posterior Sampling: Time Series Generation with Hard Constraints",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Generating realistic time series samples is crucial for stress-testing models and protecting user privacy by using synthetic data. In engineering and safety-critical applications, these samples must meet certain hard constraints that are domain-specific or naturally imposed by physics or nature. Consider, for example, generating electricity demand patterns with constraints on peak demand times. This can be used to stress-test the functioning of power grids during adverse weather conditions. Existing approaches for generating constrained time series are either not scalable or degrade sample quality. To address these challenges, we introduce Constrained Posterior Sampling (CPS), a diffusion-based sampling algorithm that aims to project the posterior mean estimate into the constraint set after each denoising update. Notably, CPS scales to a large number of constraints ($\\sim100$) without requiring additional training. We provide theoretical justifications highlighting the impact of our projection step on sampling. Empirically, CPS outperforms state-of-the-art methods in sample quality and similarity to real time series by around 10\\% and 42\\%, respectively, on real-world stocks, traffic, and air quality datasets.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=pKMpmbuKnd",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Litu_Rout1",
        "name": "Litu Rout",
        "name_site": "Litu Rout, Alexander Korotin, Evgeny Burnaev",
        "openreview_id": "~Litu_Rout1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://liturout.github.io/",
        "dblp_id": "206/6445",
        "google_scholar_url": "https://scholar.google.co.in/citations?hl=en",
        "orcid": null,
        "linkedin_url": "litu-rout-sac-isro/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Texas at Austin (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "pRCTRC6icM",
      "title": "SCAN: Bootstrapping Contrastive Pre-training for Data Efficiency",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "While contrastive pre-training is widely employed, its data efficiency problem has remained relatively under-explored thus far. Existing methods often rely on static coreset selection algorithms to pre-identify important data for training. However, this static nature renders them unable to dynamically track the data usefulness throughout pre-training, leading to subpar pre-trained models. To address this challenge, our paper introduces a novel dynamic bootstrapping dataset pruning method. It involves pruning data preparation followed by dataset mutation operations, both of which undergo iterative and dynamic updates. We apply this method to two prevalent contrastive pre-training frameworks: CLIP and MoCo, representing vision-language and vision-centric domains, respectively. In particular, we individually pre-train seven CLIP models on two large-scale image-text pair datasets, and two MoCo models on the ImageNet dataset, resulting in a total of 16 pre-trained models. With a data pruning rate of 30-35% across all 16 models, our method exhibits only marginal performance degradation (less than 1% on average) compared to corresponding models trained on the full dataset counterparts across various downstream datasets, and also surpasses several baselines with a large performance margin. Additionally, the byproduct from our method, i.e., coresets derived from the original datasets after pre-training, also demonstrates significant superiority in terms of downstream performance over other coreset selection approaches.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=pRCTRC6icM",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mohan_Kankanhalli1",
        "name": "Mohan Kankanhalli",
        "name_site": null,
        "openreview_id": "~Mohan_Kankanhalli1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.comp.nus.edu.sg/~mohan",
        "dblp_id": "09/3613.html",
        "google_scholar_url": "6Lx_eowAAAAJ",
        "orcid": "0000-0002-4846-2015",
        "linkedin_url": "mohan-kankanhalli-583417221",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "National University of Singapore (Singapore)",
        "countries": [
          "Singapore"
        ],
        "country_codes": [
          "SG"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "pTyEnkuSQ0",
      "title": "Large Language Models have Intrinsic Self-Correction Ability",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Large language models (LLMs) have attracted significant attention for their exceptional abilities in various natural language processing tasks, but they suffer from hallucinations that will cause performance degradation. One promising solution to improve the LLMs' performance is to ask LLMs to revise their answer after generation, a technique known as self-correction. Among the two types of self-correction, intrinsic self-correction is considered a promising direction because it does not utilize external knowledge. However, recent works doubt the validity of LLM's ability to conduct intrinsic self-correction. In this paper, we present a novel perspective on the intrinsic self-correction capabilities of LLMs through theoretical analyses and empirical experiments. In addition, we identify two critical factors for successful self-correction: zero temperature and fair prompts. Leveraging these factors, we demonstrate that intrinsic self-correction ability is exhibited across multiple existing LLMs. Our findings offer insights into the fundamental theories underlying the self-correction behavior of LLMs and remark on the importance of unbiased prompts and zero temperature settings in harnessing their full potential.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=pTyEnkuSQ0",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 11,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ruiyang_Qin1",
        "name": "Ruiyang Qin",
        "name_site": null,
        "openreview_id": "~Ruiyang_Qin1",
        "position": 9,
        "gender": "M",
        "homepage_url": "https://ruiyangqin2016.github.io/",
        "dblp_id": "280/1019",
        "google_scholar_url": "https://scholar.google.ca/citations?user=c26FtWIAAAAJ",
        "orcid": "0000-0003-0827-2257",
        "linkedin_url": "ruiyang-qin-gatech/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Notre Dame (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 2.8613807855648994,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 15,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "pdzHpQbGrn",
      "title": "ACTIVE TEST TIME PROMPT LEARNING IN VISION- LANGUAGE MODELS",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Test Time Optimisation is a setting where a model is made to learn new parameters on-the-fly during inference with the help of those very samples it is supposed to be tested on. Learning prompts at test time to improve the performance of Vision Language Models(VLMs) in downstream tasks has become a popular setting in recent times. In this paper, we propose a new framework for the Test Time Prompt Tuning in Pre-trained VLMs which incorporates actively sampled labels in the learning process to improve the performance of the model in downstream test-time settings. Our problem setting is underexplored yet well-motivated by considerations such as performance, efficiency and real-life applicability. Active Learning can be especially beneficial in the test-time setting in providing the option to query the true label when the model is uncertain in a real-life scenario and Prompt Tuning provides the advantage due to parameter efficiency. Our method is guided by these two principles and successfully combines the two to come up with a test-time optimisation scheme that is evaluated to be an improvement over existing methods under a fair evaluation protocol.  We conduct experiments across 10 cross-dataset transfer datasets and 4 domain-generalisation datasets to show consistent improvement over the state-of-the-art.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=pdzHpQbGrn",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Dhruv_Sarkar1",
        "name": "Dhruv Sarkar",
        "name_site": null,
        "openreview_id": "~Dhruv_Sarkar1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "dhruv-sarkar-b85175227/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "pdzHpQbGrn",
      "title": "ACTIVE TEST TIME PROMPT LEARNING IN VISION- LANGUAGE MODELS",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Test Time Optimisation is a setting where a model is made to learn new parameters on-the-fly during inference with the help of those very samples it is supposed to be tested on. Learning prompts at test time to improve the performance of Vision Language Models(VLMs) in downstream tasks has become a popular setting in recent times. In this paper, we propose a new framework for the Test Time Prompt Tuning in Pre-trained VLMs which incorporates actively sampled labels in the learning process to improve the performance of the model in downstream test-time settings. Our problem setting is underexplored yet well-motivated by considerations such as performance, efficiency and real-life applicability. Active Learning can be especially beneficial in the test-time setting in providing the option to query the true label when the model is uncertain in a real-life scenario and Prompt Tuning provides the advantage due to parameter efficiency. Our method is guided by these two principles and successfully combines the two to come up with a test-time optimisation scheme that is evaluated to be an improvement over existing methods under a fair evaluation protocol.  We conduct experiments across 10 cross-dataset transfer datasets and 4 domain-generalisation datasets to show consistent improvement over the state-of-the-art.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=pdzHpQbGrn",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aprameyo_Chakrabartty1",
        "name": "Aprameyo Chakrabartty",
        "name_site": null,
        "openreview_id": "~Aprameyo_Chakrabartty1",
        "position": 2,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "aprameyo-chakrabartty-088a0b151?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "pdzHpQbGrn",
      "title": "ACTIVE TEST TIME PROMPT LEARNING IN VISION- LANGUAGE MODELS",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Test Time Optimisation is a setting where a model is made to learn new parameters on-the-fly during inference with the help of those very samples it is supposed to be tested on. Learning prompts at test time to improve the performance of Vision Language Models(VLMs) in downstream tasks has become a popular setting in recent times. In this paper, we propose a new framework for the Test Time Prompt Tuning in Pre-trained VLMs which incorporates actively sampled labels in the learning process to improve the performance of the model in downstream test-time settings. Our problem setting is underexplored yet well-motivated by considerations such as performance, efficiency and real-life applicability. Active Learning can be especially beneficial in the test-time setting in providing the option to query the true label when the model is uncertain in a real-life scenario and Prompt Tuning provides the advantage due to parameter efficiency. Our method is guided by these two principles and successfully combines the two to come up with a test-time optimisation scheme that is evaluated to be an improvement over existing methods under a fair evaluation protocol.  We conduct experiments across 10 cross-dataset transfer datasets and 4 domain-generalisation datasets to show consistent improvement over the state-of-the-art.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=pdzHpQbGrn",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Bibhudatta_Bhanja1",
        "name": "Bibhudatta Bhanja",
        "name_site": null,
        "openreview_id": "~Bibhudatta_Bhanja1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "bibhudatta-bhanja-933672226/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "pdzHpQbGrn",
      "title": "ACTIVE TEST TIME PROMPT LEARNING IN VISION- LANGUAGE MODELS",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Test Time Optimisation is a setting where a model is made to learn new parameters on-the-fly during inference with the help of those very samples it is supposed to be tested on. Learning prompts at test time to improve the performance of Vision Language Models(VLMs) in downstream tasks has become a popular setting in recent times. In this paper, we propose a new framework for the Test Time Prompt Tuning in Pre-trained VLMs which incorporates actively sampled labels in the learning process to improve the performance of the model in downstream test-time settings. Our problem setting is underexplored yet well-motivated by considerations such as performance, efficiency and real-life applicability. Active Learning can be especially beneficial in the test-time setting in providing the option to query the true label when the model is uncertain in a real-life scenario and Prompt Tuning provides the advantage due to parameter efficiency. Our method is guided by these two principles and successfully combines the two to come up with a test-time optimisation scheme that is evaluated to be an improvement over existing methods under a fair evaluation protocol.  We conduct experiments across 10 cross-dataset transfer datasets and 4 domain-generalisation datasets to show consistent improvement over the state-of-the-art.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=pdzHpQbGrn",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abir_Das4",
        "name": "Abir Das",
        "name_site": null,
        "openreview_id": "~Abir_Das4",
        "position": 4,
        "gender": "M",
        "homepage_url": "http://cse.iitkgp.ac.in/~adas/",
        "dblp_id": "141/1311",
        "google_scholar_url": "L4yEk2UAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "piRU8xOurs",
      "title": "TreeTop: Topology-Aware Fine-Tuning for LLM Conversation Tree Understanding",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "While Large Language Models (LLMs) have dominated a wide diversity of natural language tasks, improving their capabilities on \\emph{structured} inputs such as graphs remains an open challenge. We introduce $\\texttt{TreeTop}$, a pre-training framework for LLMs that significantly improves their ability to understand and reason over structural relationships in multi-party, threaded discussions, such as those found on social media platforms. $\\texttt{TreeTop}$ is a novel set of 17 QA-style tasks specifically designed to allow LLMs to selectively focus on both the structure of and content in discussion graphs. We find that LLMs fine-tuned with $\\texttt{TreeTop}$ outperform their counterparts in every setting: zero-shot/few-shot performance on unseen pretraining tasks as well as downstream social media inference tasks (e.g.rumor detection), as well as fine-tuned performance on the downstream tasks, including their challenging \"early-detection\" variants. In particular, $\\texttt{Gemini Pro}$ fine-tuned with $\\texttt{TreeTop}$ and further fine-tuned on downstream tasks surpasses both vanilla $\\texttt{Gemini Pro}$ and state-of-the-art GNN baselines. Our framework paves the way for LLMs with enhanced capabilities on heavily-structured inputs.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=piRU8xOurs",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rahul_Madhavan1",
        "name": "Rahul Madhavan",
        "name_site": null,
        "openreview_id": "~Rahul_Madhavan1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "290/2008",
        "google_scholar_url": "HrM2xRcAAAAJ",
        "orcid": null,
        "linkedin_url": "rahul-madhavan/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "puGvShnqeA",
      "title": "Interpreting Adversarial Attacks and Defenses using Architectures with Enhanced Interpretability",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Adversarial attacks in deep learning represent a significant threat to the integrity and\nreliability of machine learning models. These attacks involve intentionally crafting\nperturbations to input data that, while often imperceptible to humans, can lead\nto incorrect predictions by the model. This phenomenon exposes vulnerabilities\nin deep learning systems across various applications, from image recognition to\nnatural language processing. Adversarial training has been a popular defence\ntechnique against these adversarial attacks. The research community has been\nincreasingly interested in interpreting robust models and understanding how they\ndefend against attacks.\nIn this work, we capitalize on a network architecture, namely Deep Linearly Gated\nNetworks (DLGN), which has better interpretation capabilities than regular network\narchitectures. Using this architecture, we interpret robust models trained using PGD\nadversarial training  and compare them with standard training. Feature networks\nin these architectures act as feature extractors, making them the only medium\nthrough which an adversary can attack the model. So, we use the feature network\nin this architecture with fully connected layers to analyse properties like alignment\nof the hyperplanes, hyperplane relation with PCA, and sub-network overlap among\nclasses and compare these properties between robust and standard models. We\nalso consider this architecture having CNN layers wherein we qualitatively and\nquantitatively contrast gating patterns between robust and standard models. We\nuse ideas from visualization to understand the representations used by robust and\nstandard models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=puGvShnqeA",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Akshay_G_Rao1",
        "name": "Akshay G Rao",
        "name_site": null,
        "openreview_id": "~Akshay_G_Rao1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "akshaygrao/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "puGvShnqeA",
      "title": "Interpreting Adversarial Attacks and Defenses using Architectures with Enhanced Interpretability",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Adversarial attacks in deep learning represent a significant threat to the integrity and\nreliability of machine learning models. These attacks involve intentionally crafting\nperturbations to input data that, while often imperceptible to humans, can lead\nto incorrect predictions by the model. This phenomenon exposes vulnerabilities\nin deep learning systems across various applications, from image recognition to\nnatural language processing. Adversarial training has been a popular defence\ntechnique against these adversarial attacks. The research community has been\nincreasingly interested in interpreting robust models and understanding how they\ndefend against attacks.\nIn this work, we capitalize on a network architecture, namely Deep Linearly Gated\nNetworks (DLGN), which has better interpretation capabilities than regular network\narchitectures. Using this architecture, we interpret robust models trained using PGD\nadversarial training  and compare them with standard training. Feature networks\nin these architectures act as feature extractors, making them the only medium\nthrough which an adversary can attack the model. So, we use the feature network\nin this architecture with fully connected layers to analyse properties like alignment\nof the hyperplanes, hyperplane relation with PCA, and sub-network overlap among\nclasses and compare these properties between robust and standard models. We\nalso consider this architecture having CNN layers wherein we qualitatively and\nquantitatively contrast gating patterns between robust and standard models. We\nuse ideas from visualization to understand the representations used by robust and\nstandard models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=puGvShnqeA",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Chandra_Shekar_Lakshminarayanan2",
        "name": "Chandra Shekar Lakshminarayanan",
        "name_site": null,
        "openreview_id": "~Chandra_Shekar_Lakshminarayanan2",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://iitpkd.ac.in/people/cnarayanan",
        "dblp_id": "143/7535",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "puGvShnqeA",
      "title": "Interpreting Adversarial Attacks and Defenses using Architectures with Enhanced Interpretability",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Adversarial attacks in deep learning represent a significant threat to the integrity and\nreliability of machine learning models. These attacks involve intentionally crafting\nperturbations to input data that, while often imperceptible to humans, can lead\nto incorrect predictions by the model. This phenomenon exposes vulnerabilities\nin deep learning systems across various applications, from image recognition to\nnatural language processing. Adversarial training has been a popular defence\ntechnique against these adversarial attacks. The research community has been\nincreasingly interested in interpreting robust models and understanding how they\ndefend against attacks.\nIn this work, we capitalize on a network architecture, namely Deep Linearly Gated\nNetworks (DLGN), which has better interpretation capabilities than regular network\narchitectures. Using this architecture, we interpret robust models trained using PGD\nadversarial training  and compare them with standard training. Feature networks\nin these architectures act as feature extractors, making them the only medium\nthrough which an adversary can attack the model. So, we use the feature network\nin this architecture with fully connected layers to analyse properties like alignment\nof the hyperplanes, hyperplane relation with PCA, and sub-network overlap among\nclasses and compare these properties between robust and standard models. We\nalso consider this architecture having CNN layers wherein we qualitatively and\nquantitatively contrast gating patterns between robust and standard models. We\nuse ideas from visualization to understand the representations used by robust and\nstandard models.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=puGvShnqeA",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arun_Rajkumar4",
        "name": "Arun Rajkumar",
        "name_site": "Arun Rajkumar, Vishnu Veerathu, Abdul Mir",
        "openreview_id": "~Arun_Rajkumar4",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "32/11350",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "q3MYZQ3es8",
      "title": "tBen: Benchmarking and Testing the Rule-Based Temporal Logic Reasoning Ability of Large Language Models with DatalogMTL",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Large language models (LLMs) are increasingly adopted for a variety of tasks, including multi-hop question answering, knowledge probing, and symbolic commonsense reasoning. While LLMs have advanced the state-of-the-art in these areas, their ability to explicitly solve rule-based temporal logic reasoning problems—a complex cognitive process involving the understanding, representation, and manipulation of temporal information such as events, their durations, and relationships—remains unexplored. To enhance understanding of LLM performance in this common task widely explored in the traditional symbolic AI field, we have developed a new set of synthetic benchmarks for rule-based temporal logic reasoning tBen. Our tBen benchmarks are built within the context of DatalogMTL, a powerful knowledge representation language for reasoning about the properties of systems that evolve over time, in which we provide flexible configurations for customizing temporal rules and task complexity.\n\nWe evaluated the close-sourced GPT-4o and the open-sourced Llama-3 using three common prompting settings—$\\textit{zero-shot}$, $\\textit{few-shot}$, and $\\textit{zero-shot-CoT}$—on our synthetic benchmarks. Our key findings are as follows: (i) Without generating the reasoning process (chain-of-thought), even  advanced LLMs like GPT-4o exhibited nearly random performance on these rule-based temporal logic reasoning tasks. However, with chain-of-thought prompting, LLMs demonstrated preliminary temporal logical reasoning abilities; (ii) Both GPT-4o and Llama-3 were unable to solve temporal logical reasoning problems involving recursion, indicating a lack of advanced complex reasoning capabilities in understanding symbolic representations involving time; (iii) There is significant room for improvement in leveraging large language models to address problems widely explored in the traditional logic-based AI domain. Prompts and datasets are available in the appendix, and a datasheet for tBen is also provided.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=q3MYZQ3es8",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~zhiqiang_xu1",
        "name": "zhiqiang xu",
        "name_site": null,
        "openreview_id": "~zhiqiang_xu1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://scholar.google.com/citations?user=0R20iBMAAAAJ&hl=en",
        "dblp_id": "72/51-3.html",
        "google_scholar_url": null,
        "orcid": "0000-0002-5693-8933",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Mohamed bin Zayed University of Artificial Intelligence (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.0,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qIJenSdGbW",
      "title": "Noise Prompt Learning: Learning the Winning Tickets for Diffusion Sampling",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Text-to-image diffusion model is a popular paradigm that synthesizes personalized images by providing a text prompt and a random Gaussian noise. While people observe that some noises are winning tickets that can achieve better text-image alignment and higher human preference than others, we still lack a machine learning framework to obtain those winning noises. To learn winning noises for diffusion sampling, we mainly make three contributions in this paper. First, we identify a new concept termed the $\\textit{noise prompt}$, which aims at turning a random Gaussian noise into a winning noise ticket by adding a small desirable perturbation derived from the text prompt. Following the concept, we first formulate the $\\textit{noise prompt learning}$ framework that systematically learns \"prompted'' winning noise tickets associated with a text prompt for diffusion models. Second, we design a noise prompt data collection pipeline and collect a large-scale $\\textit{noise prompt dataset}$ (NPD) that contains 100k pairs of random noises and winning noises with the associated text prompts. With the prepared NPD as the training dataset, we trained a small $\\textit{noise prompt network}$ (NPNet) that can directly learn to transform a random noise ticket into a winning noise ticket. The learned winning noise perturbation can be considered as a kind of prompt for noise, as it is rich in semantic information and tailored to the given text prompt. Third, our extensive experiments demonstrate the impressive effectiveness and generalization of NPNet on improving the quality of synthesized images across various diffusion models, including SDXL, DreamShaper-xl-v2-turbo, and Hunyuan-DiT. Moreover, NPNet is a small and efficient controller that acts as a plug-and-play module with very limited additional inference and computational costs, as it just provides a winning noise instead of a random noise without accessing the original pipeline.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qIJenSdGbW",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~zhiqiang_xu1",
        "name": "zhiqiang xu",
        "name_site": null,
        "openreview_id": "~zhiqiang_xu1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://scholar.google.com/citations?user=0R20iBMAAAAJ&hl=en",
        "dblp_id": "72/51-3.html",
        "google_scholar_url": null,
        "orcid": "0000-0002-5693-8933",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Hong Kong University of Science and Technology (China)",
        "countries": [
          "China"
        ],
        "country_codes": [
          "CN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 3.8,
        "confidence_std": 0.39999999999999997,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qXwVXj03nO",
      "title": "A collaborative Multi-Agent LLM Approach for Knowledge Graph Curation and query from multimodal data sources",
      "status": "Desk Reject",
      "normalized_status": "rejected",
      "abstract": "Retrieval-Augmented Generation (RAG) systems have demonstrated considerable effectiveness in querying private, short, unstructured data; however, they often encounter challenges in delivering accurate factual answers when working with larger corpora, frequently lacking context and failing to establish domain relationships. In this paper, we introduce a novel collaborative multi agent Retrieval-Augmented Generation (CoMaKG-RAG) framework designed to enhance the capabilities of large language models (LLMs) in complex information retrieval scenarios involving multimodal data sources.Our framework comprises a pool of customized collaborative agents, including a query generator agent, a domain model generator agent, a domain model populator agent, a knowledge graph curator agent, and a knowledge graph query agent, each tailored through a developed customization model and historical domain questions. The query generator formulates relevant queries related to text and image chunks within documents, while the domain model generator constructs a structured domain model based on these queries. The domain model populator agent enriches the model by integrating additional text and image fragments, and the knowledge graph generator assembles a comprehensive unified knowledge graph using Neo4j.Each agent interacts with one another, evaluates outputs, and provides feedback to enhance the overall process. Ultimately, user queries are transformed into cipher queries using the knowledge graph query agent, processed by a unified knowledge graph engine, and converted back into natural language responses. This approach enhances information retrieval from multimodal sources by mitigating hallucinations, generic responses, incomplete responses, and factual inaccuracies. We evaluated our method against the publicly available technical report \"Operations & Maintenance Best Practices\" and state-of-the-art knowledge graph generation and query software, Neo4j Graph Builder. Our results demonstrate that our method identifies a substantially higher number of entities and uncovers unique, contextually significant relationships, surpassing the performance of the graph builder in both the quantity and quality of extracted information. The proposed agentic graph RAG system was evaluated on both factual and descriptive queries and was able to provide accurate responses for both text and image-based questions, whereas the Neo4j graph performed sub optimally.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qXwVXj03nO",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ankur_Krishna1",
        "name": "Ankur Krishna",
        "name_site": null,
        "openreview_id": "~Ankur_Krishna1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "ankur-krishna-2b280173",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tata Consultancy Services Limited (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 0.0,
        "rating_std": 0.0,
        "confidence_mean": 0.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qXwVXj03nO",
      "title": "A collaborative Multi-Agent LLM Approach for Knowledge Graph Curation and query from multimodal data sources",
      "status": "Desk Reject",
      "normalized_status": "rejected",
      "abstract": "Retrieval-Augmented Generation (RAG) systems have demonstrated considerable effectiveness in querying private, short, unstructured data; however, they often encounter challenges in delivering accurate factual answers when working with larger corpora, frequently lacking context and failing to establish domain relationships. In this paper, we introduce a novel collaborative multi agent Retrieval-Augmented Generation (CoMaKG-RAG) framework designed to enhance the capabilities of large language models (LLMs) in complex information retrieval scenarios involving multimodal data sources.Our framework comprises a pool of customized collaborative agents, including a query generator agent, a domain model generator agent, a domain model populator agent, a knowledge graph curator agent, and a knowledge graph query agent, each tailored through a developed customization model and historical domain questions. The query generator formulates relevant queries related to text and image chunks within documents, while the domain model generator constructs a structured domain model based on these queries. The domain model populator agent enriches the model by integrating additional text and image fragments, and the knowledge graph generator assembles a comprehensive unified knowledge graph using Neo4j.Each agent interacts with one another, evaluates outputs, and provides feedback to enhance the overall process. Ultimately, user queries are transformed into cipher queries using the knowledge graph query agent, processed by a unified knowledge graph engine, and converted back into natural language responses. This approach enhances information retrieval from multimodal sources by mitigating hallucinations, generic responses, incomplete responses, and factual inaccuracies. We evaluated our method against the publicly available technical report \"Operations & Maintenance Best Practices\" and state-of-the-art knowledge graph generation and query software, Neo4j Graph Builder. Our results demonstrate that our method identifies a substantially higher number of entities and uncovers unique, contextually significant relationships, surpassing the performance of the graph builder in both the quantity and quality of extracted information. The proposed agentic graph RAG system was evaluated on both factual and descriptive queries and was able to provide accurate responses for both text and image-based questions, whereas the Neo4j graph performed sub optimally.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qXwVXj03nO",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~surya_ardham1",
        "name": "surya ardham",
        "name_site": null,
        "openreview_id": "~surya_ardham1",
        "position": 2,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "surya-ardham-9a98b3139",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Walchand College of Engineering (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 0.0,
        "rating_std": 0.0,
        "confidence_mean": 0.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qit4pa6PpY",
      "title": "Evaluating the Instruction-following Abilities of Language Models using Knowledge Tasks",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "In this work, we focus our attention on developing a benchmark for instruction-following where it is easy to verify both task performance as well as instruction-following capabilities. We adapt existing knowledge benchmarks and augment them with instructions that are a) conditional on correctly answering the knowledge task or b) use the space of candidate options in multiple-choice knowledge-answering tasks. This allows us to study model characteristics, such as their change in performance on the knowledge tasks in the presence of answer-modifying instructions and distractor instructions. In contrast to existing benchmarks for instruction following, we not only measure instruction-following capabilities but also use LLM-free methods to study task performance. We study a series of openly available large language models of varying parameter sizes (1B-405B) and closed source models namely GPT-4o-mini, GPT-4o. We find that even large-scale instruction-tuned LLMs fail to follow simple instructions in zero-shot settings. We release our dataset, the benchmark, code, and results for future work.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qit4pa6PpY",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rudra_Murthy1",
        "name": "Rudra Murthy",
        "name_site": null,
        "openreview_id": "~Rudra_Murthy1",
        "position": 1,
        "gender": "M",
        "homepage_url": "http://murthyrudra.github.io",
        "dblp_id": "216/7282",
        "google_scholar_url": "5bjj_9cAAAAJ",
        "orcid": "0000-0002-6236-1931",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "IBM (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qotIZREPZf",
      "title": "CGD: Modifying the Loss Landscape by Gradient Regularization",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Line-search methods are commonly used to solve optimization problems. The simplest line search method is the steepest descent where we always move in the direction of the negative gradient. Newton’s method on the other hand is a second-order method that uses the curvature information in the Hessian to pick the descent direction. In this work, we propose a new line-search method called Constrained Gradient Descent (CGD) that implicitly changes the landscape of the objective function for efficient optimization. CGD is formulated as a solution to the constrained version of the original problem where the constraint is on a function of the gradient. We optimize the corresponding Lagrangian function thereby favourably changing the landscape of the objective function. This results in a line search procedure where the Lagrangian penalty acts as a control over the descent direction and can therefore be used to iterate over points that have smaller gradient values, compared to iterates of vanilla steepest descent. We reinterpret and draw parallels with the Explicit Gradient Regularization (EGR) method, discussing its drawbacks and potential enhancements. Numerical experiments are conducted on synthetic test functions to illustrate the performance of CGD and its variants.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qotIZREPZf",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Shikhar_Saxena1",
        "name": "Shikhar Saxena",
        "name_site": null,
        "openreview_id": "~Shikhar_Saxena1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0000-0002-0386-6534",
        "linkedin_url": "underzated/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.0,
        "rating_std": 1.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qotIZREPZf",
      "title": "CGD: Modifying the Loss Landscape by Gradient Regularization",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Line-search methods are commonly used to solve optimization problems. The simplest line search method is the steepest descent where we always move in the direction of the negative gradient. Newton’s method on the other hand is a second-order method that uses the curvature information in the Hessian to pick the descent direction. In this work, we propose a new line-search method called Constrained Gradient Descent (CGD) that implicitly changes the landscape of the objective function for efficient optimization. CGD is formulated as a solution to the constrained version of the original problem where the constraint is on a function of the gradient. We optimize the corresponding Lagrangian function thereby favourably changing the landscape of the objective function. This results in a line search procedure where the Lagrangian penalty acts as a control over the descent direction and can therefore be used to iterate over points that have smaller gradient values, compared to iterates of vanilla steepest descent. We reinterpret and draw parallels with the Explicit Gradient Regularization (EGR) method, discussing its drawbacks and potential enhancements. Numerical experiments are conducted on synthetic test functions to illustrate the performance of CGD and its variants.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qotIZREPZf",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Tejas_Bodas1",
        "name": "Tejas Bodas",
        "name_site": null,
        "openreview_id": "~Tejas_Bodas1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "7lj4UY8AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.0,
        "rating_std": 1.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qotIZREPZf",
      "title": "CGD: Modifying the Loss Landscape by Gradient Regularization",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Line-search methods are commonly used to solve optimization problems. The simplest line search method is the steepest descent where we always move in the direction of the negative gradient. Newton’s method on the other hand is a second-order method that uses the curvature information in the Hessian to pick the descent direction. In this work, we propose a new line-search method called Constrained Gradient Descent (CGD) that implicitly changes the landscape of the objective function for efficient optimization. CGD is formulated as a solution to the constrained version of the original problem where the constraint is on a function of the gradient. We optimize the corresponding Lagrangian function thereby favourably changing the landscape of the objective function. This results in a line search procedure where the Lagrangian penalty acts as a control over the descent direction and can therefore be used to iterate over points that have smaller gradient values, compared to iterates of vanilla steepest descent. We reinterpret and draw parallels with the Explicit Gradient Regularization (EGR) method, discussing its drawbacks and potential enhancements. Numerical experiments are conducted on synthetic test functions to illustrate the performance of CGD and its variants.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qotIZREPZf",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arti_Yardi1",
        "name": "Arti Yardi",
        "name_site": null,
        "openreview_id": "~Arti_Yardi1",
        "position": 3,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.co.in/citations?user=Y_JgKxAAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.0,
        "rating_std": 1.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qvwcK4Uz8z",
      "title": "CASE: Challenger Arm Sampling for Efficient In-Context Reasoning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The in-context learning paradigm with LLMs has been instrumental in advancing applications that require complex reasoning over natural language. An optimal selection of few-shot examples (exemplars) is essential for constructing effective prompts under a limited budget.\nIn this paper, we frame the problem of exemplar selection for In-Context Reasoning (ICR) as a top-m best arms identification problem. A key challenge in this context is the exponentially large number of arms that need to be evaluated to identify the m-best arms. We propose CASE (Challenger Arm Sampling for Exemplar selection), a novel selective exploration strategy that maintains a shortlist of ``challenger'' arms, which are current candidates for the top-m arms. In each iteration, only the arms from this shortlist and the current top-m set are pulled, thereby reducing sample complexity and, consequently, the number of LLM evaluations. Furthermore, we model the scores of exemplar subsets (arms) using a parameterized linear scoring function, leading to a stochastic linear bandits setting. In this setting, CASE identifies the top-m arms with significantly fewer evaluations than existing state-of-the-art methods. CASE effectively works with black box LLMs and selects a static set of few-shot examples, resulting in an extremely efficient scheme for in-context reasoning. The exemplars selected with CASE show surprising performance gains of up to 15.19% compared to state-of-the-art exemplar selection methods. We release our code and data (https://anonymous.4open.science/r/CASE_exemplar_bandits-7403).",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qvwcK4Uz8z",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Kiran_Purohit1",
        "name": "Kiran Purohit",
        "name_site": null,
        "openreview_id": "~Kiran_Purohit1",
        "position": 1,
        "gender": "F",
        "homepage_url": "https://kiranpurohit.github.io/",
        "dblp_id": "293/8210",
        "google_scholar_url": "KvaPPWAAAAAJ",
        "orcid": "0000-0002-5512-3441",
        "linkedin_url": "kiranpurohit789/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qvwcK4Uz8z",
      "title": "CASE: Challenger Arm Sampling for Efficient In-Context Reasoning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The in-context learning paradigm with LLMs has been instrumental in advancing applications that require complex reasoning over natural language. An optimal selection of few-shot examples (exemplars) is essential for constructing effective prompts under a limited budget.\nIn this paper, we frame the problem of exemplar selection for In-Context Reasoning (ICR) as a top-m best arms identification problem. A key challenge in this context is the exponentially large number of arms that need to be evaluated to identify the m-best arms. We propose CASE (Challenger Arm Sampling for Exemplar selection), a novel selective exploration strategy that maintains a shortlist of ``challenger'' arms, which are current candidates for the top-m arms. In each iteration, only the arms from this shortlist and the current top-m set are pulled, thereby reducing sample complexity and, consequently, the number of LLM evaluations. Furthermore, we model the scores of exemplar subsets (arms) using a parameterized linear scoring function, leading to a stochastic linear bandits setting. In this setting, CASE identifies the top-m arms with significantly fewer evaluations than existing state-of-the-art methods. CASE effectively works with black box LLMs and selects a static set of few-shot examples, resulting in an extremely efficient scheme for in-context reasoning. The exemplars selected with CASE show surprising performance gains of up to 15.19% compared to state-of-the-art exemplar selection methods. We release our code and data (https://anonymous.4open.science/r/CASE_exemplar_bandits-7403).",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qvwcK4Uz8z",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sourangshu_Bhattacharya1",
        "name": "Sourangshu Bhattacharya",
        "name_site": null,
        "openreview_id": "~Sourangshu_Bhattacharya1",
        "position": 3,
        "gender": "M",
        "homepage_url": "http://cse.iitkgp.ac.in/~sourangshu/",
        "dblp_id": "http://dblp.uni-trier.de/pers/hd/b/Bhattacharya:Sourangshu",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=IixRsP0AAAAJ",
        "orcid": null,
        "linkedin_url": "sourangshubhattacharya",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "rAylWUIKtu",
      "title": "Benchmark Inflation: Revealing LLM Performance Gaps Using Retro-Holdouts",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The training data for many Large Language Models (LLMs) is contaminated with test data. This means that public benchmarks used to assess LLMs are compromised, suggesting a performance gap between benchmark scores and actual capabilities. Ideally, a private holdout set could be used to accurately verify scores. Unfortunately, such datasets do not exist for most benchmarks, and post-hoc construction of sufficiently similar datasets is non-trivial. To address these issues, we introduce a systematic methodology for (i) retrospectively constructing a holdout dataset for a target dataset, (ii) demonstrating the statistical indistinguishability of this retro-holdout dataset, and (iii) comparing LLMs on the two datasets to quantify the performance gap due to the dataset's public availability. Applying these methods to TruthfulQA, we construct and release Retro-Misconceptions, on which we evaluate twenty LLMs and find that some have inflated scores by as much as 16 percentage points. Our results demonstrate that public benchmark scores do not always accurately assess model properties, and underscore the importance of improved data practices in the field.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=rAylWUIKtu",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jacob_Haimes1",
        "name": "Jacob Haimes",
        "name_site": null,
        "openreview_id": "~Jacob_Haimes1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://jacob-haimes.github.io",
        "dblp_id": null,
        "google_scholar_url": "F2BtIR0AAAAJ",
        "orcid": null,
        "linkedin_url": "jacob-haimes/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Apart Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "rAylWUIKtu",
      "title": "Benchmark Inflation: Revealing LLM Performance Gaps Using Retro-Holdouts",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The training data for many Large Language Models (LLMs) is contaminated with test data. This means that public benchmarks used to assess LLMs are compromised, suggesting a performance gap between benchmark scores and actual capabilities. Ideally, a private holdout set could be used to accurately verify scores. Unfortunately, such datasets do not exist for most benchmarks, and post-hoc construction of sufficiently similar datasets is non-trivial. To address these issues, we introduce a systematic methodology for (i) retrospectively constructing a holdout dataset for a target dataset, (ii) demonstrating the statistical indistinguishability of this retro-holdout dataset, and (iii) comparing LLMs on the two datasets to quantify the performance gap due to the dataset's public availability. Applying these methods to TruthfulQA, we construct and release Retro-Misconceptions, on which we evaluate twenty LLMs and find that some have inflated scores by as much as 16 percentage points. Our results demonstrate that public benchmark scores do not always accurately assess model properties, and underscore the importance of improved data practices in the field.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=rAylWUIKtu",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vassil_Tashev1",
        "name": "Vassil Tashev",
        "name_site": null,
        "openreview_id": "~Vassil_Tashev1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "vassil-t-250510195/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Apart Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "rAylWUIKtu",
      "title": "Benchmark Inflation: Revealing LLM Performance Gaps Using Retro-Holdouts",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The training data for many Large Language Models (LLMs) is contaminated with test data. This means that public benchmarks used to assess LLMs are compromised, suggesting a performance gap between benchmark scores and actual capabilities. Ideally, a private holdout set could be used to accurately verify scores. Unfortunately, such datasets do not exist for most benchmarks, and post-hoc construction of sufficiently similar datasets is non-trivial. To address these issues, we introduce a systematic methodology for (i) retrospectively constructing a holdout dataset for a target dataset, (ii) demonstrating the statistical indistinguishability of this retro-holdout dataset, and (iii) comparing LLMs on the two datasets to quantify the performance gap due to the dataset's public availability. Applying these methods to TruthfulQA, we construct and release Retro-Misconceptions, on which we evaluate twenty LLMs and find that some have inflated scores by as much as 16 percentage points. Our results demonstrate that public benchmark scores do not always accurately assess model properties, and underscore the importance of improved data practices in the field.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=rAylWUIKtu",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Clement_Neo1",
        "name": "Clement Neo",
        "name_site": null,
        "openreview_id": "~Clement_Neo1",
        "position": 5,
        "gender": null,
        "homepage_url": "https://clementneo.com",
        "dblp_id": "367/9292",
        "google_scholar_url": "Y2-g_2cAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Apart Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "rAylWUIKtu",
      "title": "Benchmark Inflation: Revealing LLM Performance Gaps Using Retro-Holdouts",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The training data for many Large Language Models (LLMs) is contaminated with test data. This means that public benchmarks used to assess LLMs are compromised, suggesting a performance gap between benchmark scores and actual capabilities. Ideally, a private holdout set could be used to accurately verify scores. Unfortunately, such datasets do not exist for most benchmarks, and post-hoc construction of sufficiently similar datasets is non-trivial. To address these issues, we introduce a systematic methodology for (i) retrospectively constructing a holdout dataset for a target dataset, (ii) demonstrating the statistical indistinguishability of this retro-holdout dataset, and (iii) comparing LLMs on the two datasets to quantify the performance gap due to the dataset's public availability. Applying these methods to TruthfulQA, we construct and release Retro-Misconceptions, on which we evaluate twenty LLMs and find that some have inflated scores by as much as 16 percentage points. Our results demonstrate that public benchmark scores do not always accurately assess model properties, and underscore the importance of improved data practices in the field.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=rAylWUIKtu",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Esben_Kran1",
        "name": "Esben Kran",
        "name_site": null,
        "openreview_id": "~Esben_Kran1",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://apartresearch.com",
        "dblp_id": null,
        "google_scholar_url": "SH5diRUAAAAJ",
        "orcid": "0000-0003-0710-2635",
        "linkedin_url": "esbenkc/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Apart Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "rKMz6cDE7W",
      "title": "One Pass Streaming Algorithm for Super Long Token Attention Approximation in Sublinear Space",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Attention computation takes both the time complexity of $O(n^2)$ and the space complexity of $O(n^2)$ simultaneously, which makes deploying Large Language Models (LLMs) in streaming applications that involve long contexts requiring substantial computational resources. In recent OpenAI DevDay (Nov 6, 2023), OpenAI released a new model that is able to support a 128K-long document, in our paper, we focus on the memory-efficient issue when context length $n$ is much greater than 128K ($n \\gg 2^d$). Considering a single-layer self-attention with Query, Key, and Value matrices $Q, K, V \\in \\mathbb{R}^{n \\times d}$, the polynomial method approximates the attention output $T \\in \\mathbb{R}^{n \\times d}$. It accomplishes this by constructing $U_1, U_2 \\in \\mathbb{R}^{n \\times t}$ to expedite attention ${\\sf Attn}(Q, K, V)$  computation within $n^{1+o(1)}$ time executions. Despite this, computing the approximated attention matrix $U_1U_2^\\top \\in \\mathbb{R}^{n \\times n}$ still necessitates $O(n^2)$ space, leading to significant memory usage. In response to these challenges, we introduce a new algorithm that only reads one pass of the data in a streaming fashion. This method employs sublinear space  $o(n)$ to store three sketch matrices, alleviating the need for exact $K, V$ storage. Notably, our algorithm exhibits exceptional memory-efficient performance with super-long tokens. As the token length $n$ increases, our error guarantee diminishes while the memory usage remains nearly constant. This unique attribute underscores the potential of our technique in efficiently handling LLMs in streaming applications.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=rKMz6cDE7W",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Raghavendra_Addanki1",
        "name": "Raghavendra Addanki",
        "name_site": null,
        "openreview_id": "~Raghavendra_Addanki1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://raddanki.github.io/",
        "dblp_id": "218/5579",
        "google_scholar_url": "SUPaOhgAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Adobe (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.3333333333333335,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.9428090415820634,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 6,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "rSNkMy4OkJ",
      "title": "From Eww to Woo: Detection of Mental Health Disturbing Images in Social Media",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Exposure to distressing images on social media, such as gore and other graphic content, can lead to significant mental health issues and disturbances. This paper introduces a novel dataset specifically curated to include such harmful images, aiming to facilitate the development of machine learning models capable of detecting and filtering these types of content. By training on this dataset, the proposed models demonstrate the ability to accurately identify and flag disturbing images, thereby contributing to the mitigation of mental health risks associated with prolonged exposure to harmful visual content on social media platforms. The proposed dataset is benchmarked on various state of the art models with the accuracy 70.15\\%. This work represents a critical step towards creating safer online environments and protecting users' mental well-being.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=rSNkMy4OkJ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~MSVPJ_Sathvik1",
        "name": "MSVPJ Sathvik",
        "name_site": null,
        "openreview_id": "~MSVPJ_Sathvik1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "361/6920",
        "google_scholar_url": "JGOEv7wAAAAJ",
        "orcid": "0000-0003-4544-4011",
        "linkedin_url": "msvpj-sathvik-a2b712262/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology, Dharwad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "rSNkMy4OkJ",
      "title": "From Eww to Woo: Detection of Mental Health Disturbing Images in Social Media",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Exposure to distressing images on social media, such as gore and other graphic content, can lead to significant mental health issues and disturbances. This paper introduces a novel dataset specifically curated to include such harmful images, aiming to facilitate the development of machine learning models capable of detecting and filtering these types of content. By training on this dataset, the proposed models demonstrate the ability to accurately identify and flag disturbing images, thereby contributing to the mitigation of mental health risks associated with prolonged exposure to harmful visual content on social media platforms. The proposed dataset is benchmarked on various state of the art models with the accuracy 70.15\\%. This work represents a critical step towards creating safer online environments and protecting users' mental well-being.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=rSNkMy4OkJ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yalamanchi_Sreedweep_Sharma1",
        "name": "Yalamanchi Sreedweep Sharma",
        "name_site": null,
        "openreview_id": "~Yalamanchi_Sreedweep_Sharma1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "sreedweep",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Sreenidhi Institute of Science & Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.0,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "s9SVlWOcLt",
      "title": "Proto Successor Measure: Representing the space of all possible solutions of Reinforcement Learning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Having explored an environment, intelligent agents should be able to transfer their knowledge to most downstream tasks within that environment. \nReferred to as ``zero-shot learning,\" this ability remains elusive for general-purpose reinforcement learning algorithms.  While recent works have attempted to produce zero-shot RL agents, they make assumptions about the nature of the tasks or the structure of the MDP. We present \\emph{Proto Successor Measure}: the basis set for all possible solutions of Reinforcement Learning in a dynamical system. We provably show that any possible policy can be represented using an affine combination of these policy independent basis functions. Given a reward function at test time, we simply need to find the right set of linear weights to combine these basis corresponding to the optimal policy.  We derive a practical algorithm to learn these basis functions using only interaction data from the environment and show that our approach can produce the optimal policy at test time for any given reward function without additional environmental interactions.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=s9SVlWOcLt",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Siddhant_Agarwal1",
        "name": "Siddhant Agarwal",
        "name_site": null,
        "openreview_id": "~Siddhant_Agarwal1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://agarwalsiddhant10.github.io/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "siddhant-agarwal-688a31156/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Texas at Austin (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sFTnUbN45F",
      "title": "Color is a Third Wheel in Shape-Texture Bias",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "When faced with conflicting shape and texture cues, it is well established that con-\ntemporary neural networks rely on shape cues less often than humans do. Measur-\ning this gap in preference of shape cues allows us to move towards networks with\nan increased shape bias. Complementary to previous works, our work posits that\nthere is an unexplored yet crucial confounding factor in this debate: color. We\nhypothesize that color affects how conflicts between shape and texture cues are\nresolved. We test our hypothesis across two dimensions, namely, color variations\nand model architectures. To test our hypothesis on an increasing scale of color\nvariation, we propose color-variants with the following characteristics: a) only\nmagnitude is preserved, b) discrete colors, c) continuous variation in the color\nspace, and d) adversarial color variation. To test our hypothesis across the second\ndimension, we perform our analysis on two model classes, namely, ViT and CLIP.\nThis necessitates a new way of measuring shape bias for which we propose a new\nmetric: Shape Precedence. Our findings extend to the varying nature of shape\nbias across model architectures and color distortions at both a global and a local\n(patch) level.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=sFTnUbN45F",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vatsala_Nema1",
        "name": "Vatsala Nema",
        "name_site": null,
        "openreview_id": "~Vatsala_Nema1",
        "position": 1,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "vatsala-nema/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 0.0,
        "rating_std": 0.0,
        "confidence_mean": 0.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sFTnUbN45F",
      "title": "Color is a Third Wheel in Shape-Texture Bias",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "When faced with conflicting shape and texture cues, it is well established that con-\ntemporary neural networks rely on shape cues less often than humans do. Measur-\ning this gap in preference of shape cues allows us to move towards networks with\nan increased shape bias. Complementary to previous works, our work posits that\nthere is an unexplored yet crucial confounding factor in this debate: color. We\nhypothesize that color affects how conflicts between shape and texture cues are\nresolved. We test our hypothesis across two dimensions, namely, color variations\nand model architectures. To test our hypothesis on an increasing scale of color\nvariation, we propose color-variants with the following characteristics: a) only\nmagnitude is preserved, b) discrete colors, c) continuous variation in the color\nspace, and d) adversarial color variation. To test our hypothesis across the second\ndimension, we perform our analysis on two model classes, namely, ViT and CLIP.\nThis necessitates a new way of measuring shape bias for which we propose a new\nmetric: Shape Precedence. Our findings extend to the varying nature of shape\nbias across model architectures and color distortions at both a global and a local\n(patch) level.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=sFTnUbN45F",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aditya_Pola1",
        "name": "Aditya Pola",
        "name_site": null,
        "openreview_id": "~Aditya_Pola1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "pola-aditya/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 0.0,
        "rating_std": 0.0,
        "confidence_mean": 0.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sFTnUbN45F",
      "title": "Color is a Third Wheel in Shape-Texture Bias",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "When faced with conflicting shape and texture cues, it is well established that con-\ntemporary neural networks rely on shape cues less often than humans do. Measur-\ning this gap in preference of shape cues allows us to move towards networks with\nan increased shape bias. Complementary to previous works, our work posits that\nthere is an unexplored yet crucial confounding factor in this debate: color. We\nhypothesize that color affects how conflicts between shape and texture cues are\nresolved. We test our hypothesis across two dimensions, namely, color variations\nand model architectures. To test our hypothesis on an increasing scale of color\nvariation, we propose color-variants with the following characteristics: a) only\nmagnitude is preserved, b) discrete colors, c) continuous variation in the color\nspace, and d) adversarial color variation. To test our hypothesis across the second\ndimension, we perform our analysis on two model classes, namely, ViT and CLIP.\nThis necessitates a new way of measuring shape bias for which we propose a new\nmetric: Shape Precedence. Our findings extend to the varying nature of shape\nbias across model architectures and color distortions at both a global and a local\n(patch) level.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=sFTnUbN45F",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Balaji_Krishnamurthy1_1",
        "name": "Balaji Krishnamurthy",
        "name_site": null,
        "openreview_id": "~Vineeth_Balasubramanian1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://people.iith.ac.in/vineethnb/",
        "dblp_id": "88/4691",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=7soDcboAAAAJ",
        "orcid": "0000-0003-2656-0375",
        "linkedin_url": "vineethnb?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 0.0,
        "rating_std": 0.0,
        "confidence_mean": 0.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sRdByVBvZq",
      "title": "A shot of Cognac to forget bad memories: Corrective Unlearning in GNNs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graph Neural Networks (GNNs) are increasingly being used for a variety of ML applications on graph data.  As graph data does not follow the independently and identically distributed (i.i.d) assumption, adversarial manipulations or incorrect data can propagate to other datapoints through message passing, deteriorating the model's performance. To allow model developers to remove the adverse effects of manipulated entities from a trained GNN, we study the recently formulated problem of _Corrective Unlearning_. We find that current graph unlearning methods fail to unlearn the effect of manipulations even when the whole manipulated set is known. We introduce a new graph unlearning method, ***Cognac***, which can unlearn the effect of the manipulation set even when only $5$\\% of it is identified. It recovers most of the performance of a strong oracle with fully corrected training data, even beating retraining from scratch without the deletion set while being 8x more efficient. We hope our work guides GNN developers in fixing harmful effects due to issues in real-world data post-training.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=sRdByVBvZq",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Varshita_Kolipaka1",
        "name": "Varshita Kolipaka",
        "name_site": null,
        "openreview_id": "~Varshita_Kolipaka1",
        "position": 1,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "varshitakolipaka/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology, Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sRdByVBvZq",
      "title": "A shot of Cognac to forget bad memories: Corrective Unlearning in GNNs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graph Neural Networks (GNNs) are increasingly being used for a variety of ML applications on graph data.  As graph data does not follow the independently and identically distributed (i.i.d) assumption, adversarial manipulations or incorrect data can propagate to other datapoints through message passing, deteriorating the model's performance. To allow model developers to remove the adverse effects of manipulated entities from a trained GNN, we study the recently formulated problem of _Corrective Unlearning_. We find that current graph unlearning methods fail to unlearn the effect of manipulations even when the whole manipulated set is known. We introduce a new graph unlearning method, ***Cognac***, which can unlearn the effect of the manipulation set even when only $5$\\% of it is identified. It recovers most of the performance of a strong oracle with fully corrected training data, even beating retraining from scratch without the deletion set while being 8x more efficient. We hope our work guides GNN developers in fixing harmful effects due to issues in real-world data post-training.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=sRdByVBvZq",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Akshit_Sinha2",
        "name": "Akshit Sinha",
        "name_site": null,
        "openreview_id": "~Akshit_Sinha2",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0009-0006-0926-5437",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sRdByVBvZq",
      "title": "A shot of Cognac to forget bad memories: Corrective Unlearning in GNNs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graph Neural Networks (GNNs) are increasingly being used for a variety of ML applications on graph data.  As graph data does not follow the independently and identically distributed (i.i.d) assumption, adversarial manipulations or incorrect data can propagate to other datapoints through message passing, deteriorating the model's performance. To allow model developers to remove the adverse effects of manipulated entities from a trained GNN, we study the recently formulated problem of _Corrective Unlearning_. We find that current graph unlearning methods fail to unlearn the effect of manipulations even when the whole manipulated set is known. We introduce a new graph unlearning method, ***Cognac***, which can unlearn the effect of the manipulation set even when only $5$\\% of it is identified. It recovers most of the performance of a strong oracle with fully corrected training data, even beating retraining from scratch without the deletion set while being 8x more efficient. We hope our work guides GNN developers in fixing harmful effects due to issues in real-world data post-training.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=sRdByVBvZq",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Debangan_Mishra1",
        "name": "Debangan Mishra",
        "name_site": null,
        "openreview_id": "~Debangan_Mishra1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "394/5439",
        "google_scholar_url": "PnRWab4AAAAJ",
        "orcid": null,
        "linkedin_url": "debangan-mishra-1a1a34209/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology, Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sRdByVBvZq",
      "title": "A shot of Cognac to forget bad memories: Corrective Unlearning in GNNs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graph Neural Networks (GNNs) are increasingly being used for a variety of ML applications on graph data.  As graph data does not follow the independently and identically distributed (i.i.d) assumption, adversarial manipulations or incorrect data can propagate to other datapoints through message passing, deteriorating the model's performance. To allow model developers to remove the adverse effects of manipulated entities from a trained GNN, we study the recently formulated problem of _Corrective Unlearning_. We find that current graph unlearning methods fail to unlearn the effect of manipulations even when the whole manipulated set is known. We introduce a new graph unlearning method, ***Cognac***, which can unlearn the effect of the manipulation set even when only $5$\\% of it is identified. It recovers most of the performance of a strong oracle with fully corrected training data, even beating retraining from scratch without the deletion set while being 8x more efficient. We hope our work guides GNN developers in fixing harmful effects due to issues in real-world data post-training.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=sRdByVBvZq",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sumit_Kumar6",
        "name": "Sumit Kumar",
        "name_site": null,
        "openreview_id": "~Sumit_Kumar6",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "D834jRsAAAAJ",
        "orcid": null,
        "linkedin_url": "sumitkk10/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology, Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sRdByVBvZq",
      "title": "A shot of Cognac to forget bad memories: Corrective Unlearning in GNNs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graph Neural Networks (GNNs) are increasingly being used for a variety of ML applications on graph data.  As graph data does not follow the independently and identically distributed (i.i.d) assumption, adversarial manipulations or incorrect data can propagate to other datapoints through message passing, deteriorating the model's performance. To allow model developers to remove the adverse effects of manipulated entities from a trained GNN, we study the recently formulated problem of _Corrective Unlearning_. We find that current graph unlearning methods fail to unlearn the effect of manipulations even when the whole manipulated set is known. We introduce a new graph unlearning method, ***Cognac***, which can unlearn the effect of the manipulation set even when only $5$\\% of it is identified. It recovers most of the performance of a strong oracle with fully corrected training data, even beating retraining from scratch without the deletion set while being 8x more efficient. We hope our work guides GNN developers in fixing harmful effects due to issues in real-world data post-training.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=sRdByVBvZq",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arvindh_Arun1",
        "name": "Arvindh Arun",
        "name_site": null,
        "openreview_id": "~Arvindh_Arun1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://arvindh75.github.io/",
        "dblp_id": "322/6851",
        "google_scholar_url": "MtlFa6gAAAAJ",
        "orcid": "0000-0003-3469-6539",
        "linkedin_url": "arvindh75/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Stuttgart (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sRdByVBvZq",
      "title": "A shot of Cognac to forget bad memories: Corrective Unlearning in GNNs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graph Neural Networks (GNNs) are increasingly being used for a variety of ML applications on graph data.  As graph data does not follow the independently and identically distributed (i.i.d) assumption, adversarial manipulations or incorrect data can propagate to other datapoints through message passing, deteriorating the model's performance. To allow model developers to remove the adverse effects of manipulated entities from a trained GNN, we study the recently formulated problem of _Corrective Unlearning_. We find that current graph unlearning methods fail to unlearn the effect of manipulations even when the whole manipulated set is known. We introduce a new graph unlearning method, ***Cognac***, which can unlearn the effect of the manipulation set even when only $5$\\% of it is identified. It recovers most of the performance of a strong oracle with fully corrected training data, even beating retraining from scratch without the deletion set while being 8x more efficient. We hope our work guides GNN developers in fixing harmful effects due to issues in real-world data post-training.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=sRdByVBvZq",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Shashwat_Goel1",
        "name": "Shashwat Goel",
        "name_site": null,
        "openreview_id": "~Shashwat_Goel1",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://shash42.github.io/",
        "dblp_id": "300/8333.html",
        "google_scholar_url": "exaNV-0AAAAJ",
        "orcid": null,
        "linkedin_url": "shashwatgoel42/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Max Planck Institute (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sRdByVBvZq",
      "title": "A shot of Cognac to forget bad memories: Corrective Unlearning in GNNs",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Graph Neural Networks (GNNs) are increasingly being used for a variety of ML applications on graph data.  As graph data does not follow the independently and identically distributed (i.i.d) assumption, adversarial manipulations or incorrect data can propagate to other datapoints through message passing, deteriorating the model's performance. To allow model developers to remove the adverse effects of manipulated entities from a trained GNN, we study the recently formulated problem of _Corrective Unlearning_. We find that current graph unlearning methods fail to unlearn the effect of manipulations even when the whole manipulated set is known. We introduce a new graph unlearning method, ***Cognac***, which can unlearn the effect of the manipulation set even when only $5$\\% of it is identified. It recovers most of the performance of a strong oracle with fully corrected training data, even beating retraining from scratch without the deletion set while being 8x more efficient. We hope our work guides GNN developers in fixing harmful effects due to issues in real-world data post-training.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=sRdByVBvZq",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ponnurangam_Kumaraguru3",
        "name": "Ponnurangam Kumaraguru",
        "name_site": null,
        "openreview_id": "~Ponnurangam_Kumaraguru3",
        "position": 7,
        "gender": null,
        "homepage_url": "https://precog.iiit.ac.in/",
        "dblp_id": "97/5147.html",
        "google_scholar_url": "MfzQyP8AAAAJ",
        "orcid": null,
        "linkedin_url": "ponguru/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sceqRsa0oo",
      "title": "SPEED: Selective Prediction for Early Exit DNNs",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Inference latency and trustworthiness of Deep Neural Networks (DNNs) are the bottlenecks in deploying them in critical applications like autonomous driving.  Early Exit (EE) DDNs overcome the latency issues by allowing samples to exit from intermediary layers if they attain high confidence scores on the predicted class. However, the DNNs are known to exhibit overconfidence, which can lead to many samples exiting early and render EE strategies untrustworthy. We use Selective Prediction (SP) to overcome this issue by checking the hardness of the samples rather than just relying on the confidence score alone.  We propose SPEED, a novel approach that uses Deferral Classifiers (DCs) at each layer to check the hardness of samples before performing EEs. The DCs at each layer identify if a sample is hard and either differ its inference to the next layer or directly send it to an expert. Early detection of hard samples and using an expert for inference prevents the wastage of computational resources and improves trust. We also investigate the generalization capability of DCs trained on one domain when applied to other domains where target domain data is not readily available. We observe that EE aided with SP improves both accuracy and latency. Our method minimizes the risk by 50% with a speedup of $2.05\\times$ as compared to the final layer. The anonymized source code is available at https://anonymous.4open.science/r/SPEED-35DC/README.md.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=sceqRsa0oo",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Divya_Jyoti_Bajpai1",
        "name": "Divya Jyoti Bajpai",
        "name_site": null,
        "openreview_id": "~Divya_Jyoti_Bajpai1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://www.ieor.iitb.ac.in/node/2823",
        "dblp_id": "357/1369",
        "google_scholar_url": "J-z9diIAAAAJ",
        "orcid": null,
        "linkedin_url": "divya-jyoti-bajpai-139128209",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 3.6,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sceqRsa0oo",
      "title": "SPEED: Selective Prediction for Early Exit DNNs",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Inference latency and trustworthiness of Deep Neural Networks (DNNs) are the bottlenecks in deploying them in critical applications like autonomous driving.  Early Exit (EE) DDNs overcome the latency issues by allowing samples to exit from intermediary layers if they attain high confidence scores on the predicted class. However, the DNNs are known to exhibit overconfidence, which can lead to many samples exiting early and render EE strategies untrustworthy. We use Selective Prediction (SP) to overcome this issue by checking the hardness of the samples rather than just relying on the confidence score alone.  We propose SPEED, a novel approach that uses Deferral Classifiers (DCs) at each layer to check the hardness of samples before performing EEs. The DCs at each layer identify if a sample is hard and either differ its inference to the next layer or directly send it to an expert. Early detection of hard samples and using an expert for inference prevents the wastage of computational resources and improves trust. We also investigate the generalization capability of DCs trained on one domain when applied to other domains where target domain data is not readily available. We observe that EE aided with SP improves both accuracy and latency. Our method minimizes the risk by 50% with a speedup of $2.05\\times$ as compared to the final layer. The anonymized source code is available at https://anonymous.4open.science/r/SPEED-35DC/README.md.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=sceqRsa0oo",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Bundeliya_Harsh_Jitendrakumar1",
        "name": "Bundeliya Harsh Jitendrakumar",
        "name_site": null,
        "openreview_id": "~Bundeliya_Harsh_Jitendrakumar1",
        "position": 2,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 3.6,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sceqRsa0oo",
      "title": "SPEED: Selective Prediction for Early Exit DNNs",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Inference latency and trustworthiness of Deep Neural Networks (DNNs) are the bottlenecks in deploying them in critical applications like autonomous driving.  Early Exit (EE) DDNs overcome the latency issues by allowing samples to exit from intermediary layers if they attain high confidence scores on the predicted class. However, the DNNs are known to exhibit overconfidence, which can lead to many samples exiting early and render EE strategies untrustworthy. We use Selective Prediction (SP) to overcome this issue by checking the hardness of the samples rather than just relying on the confidence score alone.  We propose SPEED, a novel approach that uses Deferral Classifiers (DCs) at each layer to check the hardness of samples before performing EEs. The DCs at each layer identify if a sample is hard and either differ its inference to the next layer or directly send it to an expert. Early detection of hard samples and using an expert for inference prevents the wastage of computational resources and improves trust. We also investigate the generalization capability of DCs trained on one domain when applied to other domains where target domain data is not readily available. We observe that EE aided with SP improves both accuracy and latency. Our method minimizes the risk by 50% with a speedup of $2.05\\times$ as compared to the final layer. The anonymized source code is available at https://anonymous.4open.science/r/SPEED-35DC/README.md.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=sceqRsa0oo",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manjesh_Kumar_Hanawal1",
        "name": "Manjesh Kumar Hanawal",
        "name_site": null,
        "openreview_id": "~Manjesh_Kumar_Hanawal1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.ieor.iitb.ac.in/mlions",
        "dblp_id": "01/8397",
        "google_scholar_url": "vtVK3KUAAAAJ",
        "orcid": "0000-0002-1807-5487",
        "linkedin_url": "manjesh-kumar-hanawal-a260055/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 3.6,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "t1LfiWCYux",
      "title": "Understanding Depth and Height Perception in Large Visual-Language Models",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Geometric understanding—including depth and height perception—is fundamental to intelligence and crucial for navigating our environment. Despite the impressive capabilities of large Vision Language Models (VLMs), it remains unclear how well they possess the geometric understanding required for practical applications in visual perception. In this work, we focus on evaluating the geometric understanding of these models, specifically targeting their ability to perceive the depth and height of objects in an image. To address this, we introduce GeoMeter, a suite of benchmark datasets—encompassing 2D and 3D scenarios—to rigorously evaluate these aspects. By benchmarking 18 state-of-the-art VLMs, we found that although they excel in perceiving basic geometric properties like shape and size, they consistently struggle with depth and height perception. Our analysis reveal that these challenges stem from shortcomings in their depth and height reasoning capabilities and inherent biases. This study aims to pave the way for developing VLMs with enhanced geometric understanding by emphasizing depth and height perception as critical components necessary for real-world applications.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=t1LfiWCYux",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rishit_Garg1",
        "name": "Rishit Garg",
        "name_site": null,
        "openreview_id": "~Rishit_Garg1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "rishit-garg-112564193/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.0,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "te30nmLaFf",
      "title": "Teaching Transformers Causal Reasoning through Axiomatic Training",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "For text-based AI systems to interact in the real world, causal reasoning is an essential skill. Since active interventions are costly to execute, we study to what extent an agent can learn  causal reasoning from symbolic demonstrations of causal axioms. Specifically, we consider an axiomatic training setup where an agent learns from multiple demonstrations of a causal axiom (or rule), rather than incorporating the axiom as an inductive bias or inferring it from data values. A key question is whether the agent would learn to generalize from the axiom demonstrations to new scenarios. For example, if a transformer model is trained on demonstrations of the causal transitivity axiom over small graphs, would it generalize to applying the transitivity axiom over large graphs? \nOur results, based on a novel axiomatic training scheme, indicate that such generalization is possible. For the transitivity axiom, we find that a 67 million parameter transformer model, when trained on linear causal chains (along with some noisy variations) can generalize well to new kinds of graphs, including longer causal chains, causal chains with reversed order, and graphs with branching; even when it is not explicitly trained for such settings. We extend axiomatic training to a harder task of inferring causation from correlation statements and find similar generalization. On both tasks, our model performs at par (or even better) than many larger language models such as GPT-4, Gemini Pro, and Phi-3. Overall, our axiomatic training framework provides a new paradigm of learning causal reasoning in language models that can be extended to arbitrary axioms, as long as sufficient demonstrations can be generated.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=te30nmLaFf",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abbavaram_Gowtham_Reddy1",
        "name": "Abbavaram Gowtham Reddy",
        "name_site": null,
        "openreview_id": "~Abbavaram_Gowtham_Reddy1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://gautam0707.github.io",
        "dblp_id": "294/8798",
        "google_scholar_url": "Iewg-GAAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "CISPA Helmholtz Center for Information Security (Germany)",
        "countries": [
          "Germany"
        ],
        "country_codes": [
          "DE"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "te30nmLaFf",
      "title": "Teaching Transformers Causal Reasoning through Axiomatic Training",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "For text-based AI systems to interact in the real world, causal reasoning is an essential skill. Since active interventions are costly to execute, we study to what extent an agent can learn  causal reasoning from symbolic demonstrations of causal axioms. Specifically, we consider an axiomatic training setup where an agent learns from multiple demonstrations of a causal axiom (or rule), rather than incorporating the axiom as an inductive bias or inferring it from data values. A key question is whether the agent would learn to generalize from the axiom demonstrations to new scenarios. For example, if a transformer model is trained on demonstrations of the causal transitivity axiom over small graphs, would it generalize to applying the transitivity axiom over large graphs? \nOur results, based on a novel axiomatic training scheme, indicate that such generalization is possible. For the transitivity axiom, we find that a 67 million parameter transformer model, when trained on linear causal chains (along with some noisy variations) can generalize well to new kinds of graphs, including longer causal chains, causal chains with reversed order, and graphs with branching; even when it is not explicitly trained for such settings. We extend axiomatic training to a harder task of inferring causation from correlation statements and find similar generalization. On both tasks, our model performs at par (or even better) than many larger language models such as GPT-4, Gemini Pro, and Phi-3. Overall, our axiomatic training framework provides a new paradigm of learning causal reasoning in language models that can be extended to arbitrary axioms, as long as sufficient demonstrations can be generated.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=te30nmLaFf",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Amit_Sharma3",
        "name": "Amit Sharma",
        "name_site": null,
        "openreview_id": "~Amit_Sharma3",
        "position": 5,
        "gender": "M",
        "homepage_url": "http://amitsharma.in/",
        "dblp_id": "72/2540-7",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=CXgQufgAAAAJ",
        "orcid": "0000-0002-2086-3191",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "te30nmLaFf",
      "title": "Teaching Transformers Causal Reasoning through Axiomatic Training",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "For text-based AI systems to interact in the real world, causal reasoning is an essential skill. Since active interventions are costly to execute, we study to what extent an agent can learn  causal reasoning from symbolic demonstrations of causal axioms. Specifically, we consider an axiomatic training setup where an agent learns from multiple demonstrations of a causal axiom (or rule), rather than incorporating the axiom as an inductive bias or inferring it from data values. A key question is whether the agent would learn to generalize from the axiom demonstrations to new scenarios. For example, if a transformer model is trained on demonstrations of the causal transitivity axiom over small graphs, would it generalize to applying the transitivity axiom over large graphs? \nOur results, based on a novel axiomatic training scheme, indicate that such generalization is possible. For the transitivity axiom, we find that a 67 million parameter transformer model, when trained on linear causal chains (along with some noisy variations) can generalize well to new kinds of graphs, including longer causal chains, causal chains with reversed order, and graphs with branching; even when it is not explicitly trained for such settings. We extend axiomatic training to a harder task of inferring causation from correlation statements and find similar generalization. On both tasks, our model performs at par (or even better) than many larger language models such as GPT-4, Gemini Pro, and Phi-3. Overall, our axiomatic training framework provides a new paradigm of learning causal reasoning in language models that can be extended to arbitrary axioms, as long as sufficient demonstrations can be generated.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=te30nmLaFf",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Balaji_Krishnamurthy1_1",
        "name": "Balaji Krishnamurthy",
        "name_site": null,
        "openreview_id": "~Vineeth_Balasubramanian1",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://people.iith.ac.in/vineethnb/",
        "dblp_id": "88/4691",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=7soDcboAAAAJ",
        "orcid": "0000-0003-2656-0375",
        "linkedin_url": "vineethnb?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 3.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "uBnVA7SeWv",
      "title": "XoRA: Expander adapted LoRA finetuning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Parameter-efficient fine-tuning aims to reduce the computational cost of adapting foundational models to downstream tasks. Low-rank matrix based adaptation (LoRA) techniques are popular for this purpose. We propose XoRA, an efficient fine-tuning scheme, which sparsifies the low-rank matrices even further using expander masks. The mask is generated using extremal expander graphs (Ramanujan graphs) to maintain high edge connectivity even at a very high sparsity. Experimental results demonstrate that this method has comparable performance with the LoRA fine-tuning method while retaining much fewer number of parameters.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=uBnVA7SeWv",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~AMALJITH_E_V1",
        "name": "AMALJITH E V",
        "name_site": null,
        "openreview_id": "~AMALJITH_E_V1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://amaljith.me",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "https://in.linkedin.com/in/amaljithev",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.6,
        "rating_std": 1.3564659966250536,
        "confidence_mean": 4.0,
        "confidence_std": 0.8944271909999159,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "uBnVA7SeWv",
      "title": "XoRA: Expander adapted LoRA finetuning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Parameter-efficient fine-tuning aims to reduce the computational cost of adapting foundational models to downstream tasks. Low-rank matrix based adaptation (LoRA) techniques are popular for this purpose. We propose XoRA, an efficient fine-tuning scheme, which sparsifies the low-rank matrices even further using expander masks. The mask is generated using extremal expander graphs (Ramanujan graphs) to maintain high edge connectivity even at a very high sparsity. Experimental results demonstrate that this method has comparable performance with the LoRA fine-tuning method while retaining much fewer number of parameters.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=uBnVA7SeWv",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arindam_Biswas1",
        "name": "Arindam Biswas",
        "name_site": null,
        "openreview_id": "~Arindam_Biswas1",
        "position": 2,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.6,
        "rating_std": 1.3564659966250536,
        "confidence_mean": 4.0,
        "confidence_std": 0.8944271909999159,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "uBnVA7SeWv",
      "title": "XoRA: Expander adapted LoRA finetuning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Parameter-efficient fine-tuning aims to reduce the computational cost of adapting foundational models to downstream tasks. Low-rank matrix based adaptation (LoRA) techniques are popular for this purpose. We propose XoRA, an efficient fine-tuning scheme, which sparsifies the low-rank matrices even further using expander masks. The mask is generated using extremal expander graphs (Ramanujan graphs) to maintain high edge connectivity even at a very high sparsity. Experimental results demonstrate that this method has comparable performance with the LoRA fine-tuning method while retaining much fewer number of parameters.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=uBnVA7SeWv",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Suryam_Arnav_Kalra1",
        "name": "Suryam Arnav Kalra",
        "name_site": null,
        "openreview_id": "~Suryam_Arnav_Kalra1",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "suryam-arnav-kalra-8ba107193/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Trinity College Dublin (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.6,
        "rating_std": 1.3564659966250536,
        "confidence_mean": 4.0,
        "confidence_std": 0.8944271909999159,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "uBnVA7SeWv",
      "title": "XoRA: Expander adapted LoRA finetuning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Parameter-efficient fine-tuning aims to reduce the computational cost of adapting foundational models to downstream tasks. Low-rank matrix based adaptation (LoRA) techniques are popular for this purpose. We propose XoRA, an efficient fine-tuning scheme, which sparsifies the low-rank matrices even further using expander masks. The mask is generated using extremal expander graphs (Ramanujan graphs) to maintain high edge connectivity even at a very high sparsity. Experimental results demonstrate that this method has comparable performance with the LoRA fine-tuning method while retaining much fewer number of parameters.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=uBnVA7SeWv",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Pabitra_Mitra1",
        "name": "Pabitra Mitra",
        "name_site": null,
        "openreview_id": "~Pabitra_Mitra1",
        "position": 4,
        "gender": "M",
        "homepage_url": "http://cse.iitkgp.ac.in/~pabitra/",
        "dblp_id": "m/PabitraMitra",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=5bXSZPYAAAAJ",
        "orcid": "0000-0002-1908-9813",
        "linkedin_url": "pabitra-mitra-8028235/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.6,
        "rating_std": 1.3564659966250536,
        "confidence_mean": 4.0,
        "confidence_std": 0.8944271909999159,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ubUTIlAH0m",
      "title": "Multi-Physics Operator Network for In-context learning (m-PhOeNIX)",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "We propose a multi-physics operator network for simultaneous and sequential learning of solution operators of multiple heterogeneous parametric partial differential equations. Existing neural operators are adept at learning the solution operator of only a single physical system, and adapting to new physical equations requires training a new surrogate model from scratch with physics-specific intensive hyperparameter tuning. The proposed multi-physics neural operator leverages the recent advancements in wavelet-based kernel integral-induced neural operator modeling and instantiates a memory-based ensembling strategy for projecting heterogeneous physical systems into a common shared feature space. The local channel-level ensembling is supported by context gates, which not only utilize the shared features to embed the features of multiple heterogeneous physical systems into the network parameters but also allow the multi-physics operator to learn new solution operators by transferring knowledge sequentially; this allows the proposed model to continually learn without forgetting. We illustrate the efficacy of our algorithm by simultaneously and sequentially learning six complex time-dependent solution operators of six physical systems. The inference results on the simultaneous and sequentially trained models depict the ability to infer previously seen physical systems without fine-tuning and catastrophic forgetting, indicating the characteristics of a foundation model. The framework also demonstrates the super-resolution property and generalization to out-of-distribution input conditions.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ubUTIlAH0m",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Tapas_Tripura1",
        "name": "Tapas Tripura",
        "name_site": null,
        "openreview_id": "~Tapas_Tripura1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/tapas-tripura/home",
        "dblp_id": "300/4327",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": "0000-0003-0363-2663",
        "linkedin_url": "tripuratapas",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ubUTIlAH0m",
      "title": "Multi-Physics Operator Network for In-context learning (m-PhOeNIX)",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "We propose a multi-physics operator network for simultaneous and sequential learning of solution operators of multiple heterogeneous parametric partial differential equations. Existing neural operators are adept at learning the solution operator of only a single physical system, and adapting to new physical equations requires training a new surrogate model from scratch with physics-specific intensive hyperparameter tuning. The proposed multi-physics neural operator leverages the recent advancements in wavelet-based kernel integral-induced neural operator modeling and instantiates a memory-based ensembling strategy for projecting heterogeneous physical systems into a common shared feature space. The local channel-level ensembling is supported by context gates, which not only utilize the shared features to embed the features of multiple heterogeneous physical systems into the network parameters but also allow the multi-physics operator to learn new solution operators by transferring knowledge sequentially; this allows the proposed model to continually learn without forgetting. We illustrate the efficacy of our algorithm by simultaneously and sequentially learning six complex time-dependent solution operators of six physical systems. The inference results on the simultaneous and sequentially trained models depict the ability to infer previously seen physical systems without fine-tuning and catastrophic forgetting, indicating the characteristics of a foundation model. The framework also demonstrates the super-resolution property and generalization to out-of-distribution input conditions.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ubUTIlAH0m",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Souvik_Chakraborty2",
        "name": "Souvik Chakraborty",
        "name_site": null,
        "openreview_id": "~Souvik_Chakraborty2",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.csccm.in/",
        "dblp_id": "181/0103.html",
        "google_scholar_url": "CoYoAQEAAAAJ",
        "orcid": "0000-0003-2383-2603",
        "linkedin_url": "souvik-chakraborty-998851173/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ulGwcj1egv",
      "title": "FiRST: Finetuning Router-Selective Transformers for Input-Adaptive Latency Reduction",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "Auto-regressive Large Language Models (LLMs) demonstrate remarkable performance across domanins such as vision and language processing. However, due to sequential processing through a stack of transformer layers, autoregressive decoding faces significant computation/latency challenges, particularly in resource-constrained environments like mobile and edge devices. Existing approaches in literature that aim to improve latency via skipping layers have two distinct flavors - 1) Early exit   2) Input-agnostic heuristics where tokens exit at pre-determined layers irrespective of input sequence. Both the above strategies have limitations - the former cannot be applied to handle KV Caching necessary for speed-ups in modern framework and the latter does not capture the variation in layer importance across tasks or more generally, across input sequences.   To address both limitations, we propose \\textsc{FiRST}, an algorithm that reduces inference latency by using layer-specific routers to select a subset of transformer layers adaptively for each input sequence - the prompt (during prefill stage) decides which layers will be skipped during decoding.  \\textsc{FiRST} preserves compatibility with KV caching enabling faster inference while being quality-aware. \\textsc{FiRST} is model-agnostic and can be easily enabled on any pre-trained LLM. We further improve performance by incorporating LoRA adapters for fine-tuning on external datasets, enhancing task-specific accuracy while maintaining latency benefits. Our approach reveals that input adaptivity is critical - indeed, different task-specific middle layers play a crucial role in evolving hidden representations depending on task. Extensive experiments  show that \\textsc{FiRST} significantly reduces latency while retaining competitive performance (as compared to baselines), making our approach an efficient solution for LLM deployment in low-resource environments.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=ulGwcj1egv",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Saransh_Sharma1",
        "name": "Saransh Sharma",
        "name_site": null,
        "openreview_id": "~Saransh_Sharma1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "saransh-sharma-7749b8219",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.0,
        "rating_std": 0.0,
        "confidence_mean": 4.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "uu2CorJCUi",
      "title": "Adaptive Curvature Step Size: A Path Geometry Based Approach to Optimization",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "We propose the Adaptive Curvature Step Size (ACSS) method, which dynamically adjusts the step size based on the local geometry of the optimization path. Our approach computes the normalized radius of curvature using consecutive gradients along the iterate path and sets the step-size equal to this radius. The effectiveness of ACSS stems from its ability to adapt to the local landscape of the optimization problem. In regions of low curvature, where consecutive gradient steps are nearly identical, ACSS allows for larger steps. Conversely, in areas of high curvature, where gradient steps differ significantly in direction, ACSS reduces the step size. This adaptive behavior enables more efficient navigation of complex loss landscapes. A key advantage of ACSS is its adaptive behavior based on local curvature information, which implicitly captures aspects of the function's second-order geometry without requiring additional memory. We provide a generalized framework for incorporating ACSS into various optimization algorithms, including SGD, Adam, AdaGrad, and RMSProp. Through extensive empirical evaluation on 20 diverse datasets, we compare ACSS variants against 12 popular optimization methods. Our results consistently show that ACSS provides performance benefits. Our results consistently show that ACSS provides performance benefits. We provide PyTorch implementations of ACSS versions for popular optimizers at our [anonymized code repository](https://anonymous.4open.science/r/curvatureStep-2a79/README.md).",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=uu2CorJCUi",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 1,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rahul_Madhavan1",
        "name": "Rahul Madhavan",
        "name_site": null,
        "openreview_id": "~Rahul_Madhavan1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "290/2008",
        "google_scholar_url": "HrM2xRcAAAAJ",
        "orcid": null,
        "linkedin_url": "rahul-madhavan/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 3.4,
        "confidence_std": 1.019803902718557,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "v2nEL42Pvb",
      "title": "SSGNN: Simple Yet Effective Spectral Graph Neural Network",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Spectral GNNs leverage graph spectral properties to model graph representations but have been less explored due to their computational challenges, especially compared to the more flexible and scalable spatial GNNs, which have seen broader adoption. However, spatial methods cannot fully exploit the rich information in graph spectra. Current Spectral GNNs, relying on fixed-order polynomials, use scalar-to-scalar filters applied uniformly across eigenvalues, failing to capture key spectral shifts and signal propagation dynamics. Though set-to-set filters can capture spectral complexity, methods that employ them frequently rely on Transformers, which add considerable computational burden. Our analysis indicates that applying Transformers to these filters provides minimal advantage in the spectral domain. We demonstrate that effective spectral filtering can be achieved without the need for transformers, offering a more efficient and spectrum-aware alternative. To this end, we propose a $\\textit{Simple Yet Effective Spectral Graph Neural Network}$ (SSGNN), which leverages the graph spectrum to adaptively filter using a simplified set-to-set approach that captures key spectral features. Moreover, we introduce a novel, parameter-free $\\textit{Relative Gaussian Amplifier}$ (ReGA) module, which adaptively learns spectral filtering while maintaining robustness against structural perturbations, ensuring stability. Extensive experiments on 20 real-world graph datasets, spanning both node-level and graph-level tasks along with a synthetic graph dataset, show that SSGNN matches or surpasses the performance of state-of-the-art (SOTA) spectral-based GNNs and graph transformers while using significantly fewer parameters and GFLOPs. Specifically, SSGNN achieves performance comparable to the current SOTA Graph Transformer model, Polynormer, with an average 55x reduction in parameters and 100x reduction in GFLOPs across all datasets. Our code will be made public upon acceptance.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=v2nEL42Pvb",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ram_Samarth_B_B1",
        "name": "Ram Samarth B B",
        "name_site": null,
        "openreview_id": "~Ram_Samarth_B_B1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "plOcPdkAAAAJ",
        "orcid": null,
        "linkedin_url": "ram-samarth-b-b-340731243/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Information Technology Kottayam (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "v2nEL42Pvb",
      "title": "SSGNN: Simple Yet Effective Spectral Graph Neural Network",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Spectral GNNs leverage graph spectral properties to model graph representations but have been less explored due to their computational challenges, especially compared to the more flexible and scalable spatial GNNs, which have seen broader adoption. However, spatial methods cannot fully exploit the rich information in graph spectra. Current Spectral GNNs, relying on fixed-order polynomials, use scalar-to-scalar filters applied uniformly across eigenvalues, failing to capture key spectral shifts and signal propagation dynamics. Though set-to-set filters can capture spectral complexity, methods that employ them frequently rely on Transformers, which add considerable computational burden. Our analysis indicates that applying Transformers to these filters provides minimal advantage in the spectral domain. We demonstrate that effective spectral filtering can be achieved without the need for transformers, offering a more efficient and spectrum-aware alternative. To this end, we propose a $\\textit{Simple Yet Effective Spectral Graph Neural Network}$ (SSGNN), which leverages the graph spectrum to adaptively filter using a simplified set-to-set approach that captures key spectral features. Moreover, we introduce a novel, parameter-free $\\textit{Relative Gaussian Amplifier}$ (ReGA) module, which adaptively learns spectral filtering while maintaining robustness against structural perturbations, ensuring stability. Extensive experiments on 20 real-world graph datasets, spanning both node-level and graph-level tasks along with a synthetic graph dataset, show that SSGNN matches or surpasses the performance of state-of-the-art (SOTA) spectral-based GNNs and graph transformers while using significantly fewer parameters and GFLOPs. Specifically, SSGNN achieves performance comparable to the current SOTA Graph Transformer model, Polynormer, with an average 55x reduction in parameters and 100x reduction in GFLOPs across all datasets. Our code will be made public upon acceptance.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=v2nEL42Pvb",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rishabh_Sabharwal1",
        "name": "Rishabh Sabharwal",
        "name_site": null,
        "openreview_id": "~Rishabh_Sabharwal1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0009-0001-6055-4246",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "v2nEL42Pvb",
      "title": "SSGNN: Simple Yet Effective Spectral Graph Neural Network",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Spectral GNNs leverage graph spectral properties to model graph representations but have been less explored due to their computational challenges, especially compared to the more flexible and scalable spatial GNNs, which have seen broader adoption. However, spatial methods cannot fully exploit the rich information in graph spectra. Current Spectral GNNs, relying on fixed-order polynomials, use scalar-to-scalar filters applied uniformly across eigenvalues, failing to capture key spectral shifts and signal propagation dynamics. Though set-to-set filters can capture spectral complexity, methods that employ them frequently rely on Transformers, which add considerable computational burden. Our analysis indicates that applying Transformers to these filters provides minimal advantage in the spectral domain. We demonstrate that effective spectral filtering can be achieved without the need for transformers, offering a more efficient and spectrum-aware alternative. To this end, we propose a $\\textit{Simple Yet Effective Spectral Graph Neural Network}$ (SSGNN), which leverages the graph spectrum to adaptively filter using a simplified set-to-set approach that captures key spectral features. Moreover, we introduce a novel, parameter-free $\\textit{Relative Gaussian Amplifier}$ (ReGA) module, which adaptively learns spectral filtering while maintaining robustness against structural perturbations, ensuring stability. Extensive experiments on 20 real-world graph datasets, spanning both node-level and graph-level tasks along with a synthetic graph dataset, show that SSGNN matches or surpasses the performance of state-of-the-art (SOTA) spectral-based GNNs and graph transformers while using significantly fewer parameters and GFLOPs. Specifically, SSGNN achieves performance comparable to the current SOTA Graph Transformer model, Polynormer, with an average 55x reduction in parameters and 100x reduction in GFLOPs across all datasets. Our code will be made public upon acceptance.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=v2nEL42Pvb",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sundeep_Prabhakar_Chepuri1",
        "name": "Sundeep Prabhakar Chepuri",
        "name_site": null,
        "openreview_id": "~Sundeep_Prabhakar_Chepuri1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://ece.iisc.ac.in/~spchepuri/",
        "dblp_id": "72/10237.html",
        "google_scholar_url": "Gu8FjdwAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "v2nEL42Pvb",
      "title": "SSGNN: Simple Yet Effective Spectral Graph Neural Network",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Spectral GNNs leverage graph spectral properties to model graph representations but have been less explored due to their computational challenges, especially compared to the more flexible and scalable spatial GNNs, which have seen broader adoption. However, spatial methods cannot fully exploit the rich information in graph spectra. Current Spectral GNNs, relying on fixed-order polynomials, use scalar-to-scalar filters applied uniformly across eigenvalues, failing to capture key spectral shifts and signal propagation dynamics. Though set-to-set filters can capture spectral complexity, methods that employ them frequently rely on Transformers, which add considerable computational burden. Our analysis indicates that applying Transformers to these filters provides minimal advantage in the spectral domain. We demonstrate that effective spectral filtering can be achieved without the need for transformers, offering a more efficient and spectrum-aware alternative. To this end, we propose a $\\textit{Simple Yet Effective Spectral Graph Neural Network}$ (SSGNN), which leverages the graph spectrum to adaptively filter using a simplified set-to-set approach that captures key spectral features. Moreover, we introduce a novel, parameter-free $\\textit{Relative Gaussian Amplifier}$ (ReGA) module, which adaptively learns spectral filtering while maintaining robustness against structural perturbations, ensuring stability. Extensive experiments on 20 real-world graph datasets, spanning both node-level and graph-level tasks along with a synthetic graph dataset, show that SSGNN matches or surpasses the performance of state-of-the-art (SOTA) spectral-based GNNs and graph transformers while using significantly fewer parameters and GFLOPs. Specifically, SSGNN achieves performance comparable to the current SOTA Graph Transformer model, Polynormer, with an average 55x reduction in parameters and 100x reduction in GFLOPs across all datasets. Our code will be made public upon acceptance.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=v2nEL42Pvb",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Punit_Rathore1",
        "name": "Punit Rathore",
        "name_site": null,
        "openreview_id": "~Punit_Rathore1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.com.au/citations?hl=en",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "v3DwQlyGbv",
      "title": "Paramanu-Ganita: An Efficient Pre-trained Generative Mathematics Language Model with Chain-of-Thought Instruction Fine-Tuning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "In this paper, we pose the following question: whether domain specific pretraining of tiny generative language models from scratch with domain specialized tokenizer and Chain-of-Thought (CoT) instruction fine-tuning results in very competitive performance on mathematical reasoning than LLMs which are trained on trillion of tokens and humongous parameters? Secondly, we pose our second RQ: whether domain specific pretraining from scratch is environmentally sustainable, highly cost efficient? To address these research questions, we present Paramanu-Ganita, a 208 million-parameter novel Auto Regressive (AR) decoder based language model on mathematics. We performed pretraining from scratch on 31.5 billion tokens using a context size of 4096 on a mixed mathematical corpus consisting of mathematical web pages, mathematics related source code such as AlgebraStack, mathematical textbooks, Chain-of-Thought (CoT) templatised mathematical StackOverflow question answers pairs, and mathematical lecture notes in LaTeX curated by us. We also trained a math and code specialised BPE tokenizer. We proposed and performed Chain-of-Thought instruction fine-tuning of Paramanu-Ganita on the MetaMathQA dataset. We evaluate our model on GSM8K and MATH mathematical benchmarks, and on logical deductive reasoning (LogiQA) and multiple choice high school and college level math questions from SAT (AGIEVAL-SAT-Math), GRE/GMAT questions (AGIEVAL-AQuA-RAT), college and high school level math questions from MMLU.\nOur model Paramanu-Ganita, despite being 34 times smaller than the 7B LLMs, outperforms general LLMs by approximately 30% points, and even math-specialised LLMs by 3-23% points in GSM8K test accuracy metric. On MATH benchmark, Paramanu-Ganita outperformed the various models by 6-8% points. On other benchmarks such as LogiQA logical deductive reasoning benchmark, mathematical high school level multi-choice questions (MMLU-math-high-school), GRE-GMAT level quantitative questions (AGIEVAL-AQuA-RAT), SAT level math questions, Paramanu-Ganita was better than the others by about 1-4% points. The large significant margin improvement in performance of our math model over the existing LLMs signifies that reasoning capabilities of language models are just not restricted to those with humongous number of parameters. Paramanu-Ganita took only 170 hours of A100 training whereas large LLMs such as the math-specialised LLM, LLEMMA 7B, was trained for 23,000 A100 equivalent hours. Thus, our approach of pretraining powerful domain-specialised language models from scratch for domain adaptation is much more cost-effective and environmental friendly than performing continual training of LLMs.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=v3DwQlyGbv",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arnab_Bhattacharya1",
        "name": "Arnab Bhattacharya",
        "name_site": null,
        "openreview_id": "~Arnab_Bhattacharya1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.cse.iitk.ac.in/users/arnabb/",
        "dblp_id": "48/2626-1",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=Sk-JV9QAAAAJ",
        "orcid": "0000-0001-7331-0788",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.3333333333333335,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 4.666666666666667,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "v44CUwEeDY",
      "title": "Proper Orthogonal Decomposition for Scalable Training of Graph Neural Networks",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "As large-scale graphs become ubiquitous in real-world applications, there is growing concern about \nthe memory and time requirement to train a graph neural network (GNN) model for such datasets.\nStoring the entire adjacency and node embedding matrices in memory is infeasible in such a scenario. Standard sampling-based methods for addressing the memory constraint suffer from the dependence of the number of mini-batches on the graph size. Existing sketch-based methods and graph compression techniques operate at higher sketch ratios, with the graph compression techniques showing poor generalization, implying that different GNNs trained on the same synthetic graph have performance gaps. Sketch-based methods necessitate online learning of sketches, further increasing the complexity. In this paper, we propose a new sketch-based algorithm, PGNN, employing the Proper orthogonal decomposition (POD) method to craft update rules to train GNNs, improving the memory requirement and training time without the complication of updating the sketches during training. Experiments on standard graph datasets show that PGNN can reach much lower sketch ratios without compromising the performance. We prove the optimality of the POD update rule for the linearized GNN (SGC). Empirical findings validate our approach, demonstrating superior performance at reduced sketch ratios and adaptability across various GNN architectures.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=v44CUwEeDY",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manohar_Kaul1",
        "name": "Manohar Kaul",
        "name_site": null,
        "openreview_id": "~Manohar_Kaul1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://manukaul.github.io/",
        "dblp_id": "29/10735",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=jNroyK4AAAAJ",
        "orcid": null,
        "linkedin_url": "manu-k-72b936287/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Fujitsu Research and Development Center (Japan)",
        "countries": [
          "Japan"
        ],
        "country_codes": [
          "JP"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "v4Bl6tfaaO",
      "title": "Bayesian-LoRA: LoRA based Parameter Efficient Fine-Tuning using Optimal Quantization levels and Rank Values trough Differentiable Bayesian Gates",
      "status": "Desk Reject",
      "normalized_status": "rejected",
      "abstract": "It is a common practice in natural language processing to pre-train a single model on a general domain and then fine-tune it for downstream tasks. However, when it comes to Large Language Models, fine-tuning the entire model can be computationally expensive, resulting in very intensive energy consumption. As a result, several Parameter Efficient Fine-Tuning (PEFT) approaches were recently proposed. One of the most popular approaches is low-rank adaptation (LoRA), where the key insight is decomposing the updated weights of the pre-trained model into two low-rank matrices. However, the proposed approaches either use the same rank value across all different weight matrices, which has been shown to be a sub-optimal choice, or do not use any quantization technique, one of the most important factors when it comes to a model's energy consumption. In this work, we propose Bayesian-LoRA, a new method that approaches low-rank adaptation and quantization from a Bayesian perspective by employing a prior distribution on both quantization levels and rank values. As a result, B-LoRA is able to fine-tune a pre-trained model on a specific downstream task, finding the optimal rank values and quantization levels for every low-rank matrix. We validate the proposed model by fine-tuning a pre-trained DeBERTaV3 on the GLUE benchmark. Additionally, we fine-tune Phi-2 and Qwen, and evaluate them on few-shot and zero-shot MMLU. We compare our proposed method with relevant baselines and present both qualitative and quantitative results, showing its ability to learn optimal-rank quantized matrices. B-LoRA performs on par with or better than the baselines while reducing the total number of bit operations by roughly 70\\% compared to the baseline methods.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=v4Bl6tfaaO",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Di_He1_1",
        "name": "Di He",
        "name_site": null,
        "openreview_id": "~Anirudh_Goyal1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://anirudh9119.github.io/",
        "dblp_id": "172/1039",
        "google_scholar_url": "krrh6OUAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Cambridge (United Kingdom)",
        "countries": [
          "United Kingdom"
        ],
        "country_codes": [
          "GB"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 0.0,
        "rating_std": 0.0,
        "confidence_mean": 0.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "vAoyZWyDEc",
      "title": "Approximating Optima of Nonconvex Functions",
      "status": "Withdraw",
      "normalized_status": "withdrawn",
      "abstract": "We study the computability of approximating optima of non-convex functions. We give a simple proof to show that the problem of finding the optimal value (and optimal point) or its approximation is not even computable in the oracle setting. We also give a property a function has to satisfy if its global optima can be approximated. Next we give an example of such a global property we call basin of attraction. Then we give a simple algorithm which converges to the global optima when this is known. Finally, we give some numerical results.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=vAoyZWyDEc",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 1,
      "track_name": "Main Conference",
      "author": {
        "id": "~K_Lakshmanan1",
        "name": "K Lakshmanan",
        "name_site": null,
        "openreview_id": "~K_Lakshmanan1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://iitbhu.ac.in/dept/cse/people/lakshmanankcse",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Benaras Hindu University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "vKJ8YH0iNp",
      "title": "MGD$^3$: Mode-Guided Dataset Distillation using Diffusion Models",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Dataset distillation aims to distill a smaller training dataset from a larger one so that a model trained on this smaller set performs similarly to one trained on the full dataset. Traditional methods are costly and lack sample diversity. Recent approaches utilizing generative models, particularly diffusion models, show promise in capturing data distribution, but they often oversample prominent modes, limiting sample diversity.\nTo address these limitations in this work, we propose a mode-guided diffusion model. Unlike existing works that fine-tune the diffusion models for dataset distillation, we propose to use a pre-trained model without the need for fine-tuning. Our novel approach consists of three stages: Mode Discovery, Mode Guidance, and Stop Guidance. In the first stage, we discover distinct modes in the data distribution of a class to build a representative set. In the second stage, we use a pre-trained diffusion model and guide the diffusion process toward the discovered modes to generate distinct samples, ensuring intra-class diversity. However, mode-guided sampling can introduce artifacts in the synthetic sample, which affect the performance. To control the fidelity of the synthetic dataset, we introduce the stop guidance. \nWe evaluate our method on multiple benchmark datasets, including ImageNette, ImageIDC, ImageNet-100, and ImageNet-1K; \nOur method improved $4.4\\%$, $2.9\\%$, $1.6\\%$, and $1.6\\%$ over the current state-of-the-art on the respective datasets.\nIn addition, our method does not require retraining of the diffusion model, which leads to reduced computational requirements. \nWe also demonstrate that our approach is effective with general-purpose diffusion models such as Text-to Image Stable Diffusion, showing promising performance towards eliminating the need for a pre-trained model in the target dataset.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=vKJ8YH0iNp",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Gaurav_Kumar_Nayak2",
        "name": "Gaurav Kumar Nayak",
        "name_site": null,
        "openreview_id": "~Gaurav_Kumar_Nayak2",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/gauravnayak",
        "dblp_id": "241/6244",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=cLCeKTkAAAAJ",
        "orcid": "0000-0002-6406-6178",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Roorkee (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 2.1213203435596424,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "vKgDbYKZrH",
      "title": "MOGIC: METADATA-INFUSED ORACLE GUIDANCE FOR IMPROVED EXTREME CLASSIFICATION",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Retrieval-augmented classification and generation  models significantly benefit from the *early-stage fusion* of high-quality text-based auxiliary metadata, often called memory, but they suffer from high inference latency and poor robustness to noise. In classifications tasks, particularly the extreme classification (XC) setting, where low latency is critical, existing methods incorporate metadata for context enrichment via an XC-based retriever and obtain the representations of the relevant memory items to perform *late-stage fusion* to achieve low latency. With an aim of achieving higher accuracy while meeting the low latency constraints, in this paper, we propose MOGIC, an approach for metadata-infused Oracle guidance for XC tasks. In particular, we train an early-fusion Oracle classifier with access to both query-side and label-side ground-truth metadata in the textual form. The Oracle is subsequently used to guide the training of any existing memory-based XC Disciple model via regularization. The MOGIC algorithm, when applied to memory-based XC Disciple models such as OAK, improves precision@1 and propensity-scored precision@1 by ~2% on four standard datasets, at no additional inference-time costs to the Disciple model. We also show the feasibility of applying the MOGIC algorithm to improve the performance of state-of-the-art memory-free XC approaches such as NGAME or DEXA, demonstrating that the MOGIC algorithm can be used atop any existing XC-based approach in a *plug-and-play* manner. Finally, we also show the robustness of the MOGIC method to missing and noisy metadata settings. We will release code on acceptance.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=vKgDbYKZrH",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 14,
      "track_name": "Main Conference",
      "author": {
        "id": "~Suchith_Chidananda_Prabhu1",
        "name": "Suchith Chidananda Prabhu",
        "name_site": null,
        "openreview_id": "~Suchith_Chidananda_Prabhu1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://suchith720.github.io",
        "dblp_id": null,
        "google_scholar_url": "-UmeTCYAAAAJ",
        "orcid": "0009-0007-4647-3304",
        "linkedin_url": "suchith-chidananda-prabhu-9a65a9158/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "vKgDbYKZrH",
      "title": "MOGIC: METADATA-INFUSED ORACLE GUIDANCE FOR IMPROVED EXTREME CLASSIFICATION",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Retrieval-augmented classification and generation  models significantly benefit from the *early-stage fusion* of high-quality text-based auxiliary metadata, often called memory, but they suffer from high inference latency and poor robustness to noise. In classifications tasks, particularly the extreme classification (XC) setting, where low latency is critical, existing methods incorporate metadata for context enrichment via an XC-based retriever and obtain the representations of the relevant memory items to perform *late-stage fusion* to achieve low latency. With an aim of achieving higher accuracy while meeting the low latency constraints, in this paper, we propose MOGIC, an approach for metadata-infused Oracle guidance for XC tasks. In particular, we train an early-fusion Oracle classifier with access to both query-side and label-side ground-truth metadata in the textual form. The Oracle is subsequently used to guide the training of any existing memory-based XC Disciple model via regularization. The MOGIC algorithm, when applied to memory-based XC Disciple models such as OAK, improves precision@1 and propensity-scored precision@1 by ~2% on four standard datasets, at no additional inference-time costs to the Disciple model. We also show the feasibility of applying the MOGIC algorithm to improve the performance of state-of-the-art memory-free XC approaches such as NGAME or DEXA, demonstrating that the MOGIC algorithm can be used atop any existing XC-based approach in a *plug-and-play* manner. Finally, we also show the robustness of the MOGIC method to missing and noisy metadata settings. We will release code on acceptance.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=vKgDbYKZrH",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 14,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anshul_Mittal2",
        "name": "Anshul Mittal",
        "name_site": null,
        "openreview_id": "~Anshul_Mittal2",
        "position": 3,
        "gender": "M",
        "homepage_url": "http://anshulmittal.org",
        "dblp_id": null,
        "google_scholar_url": "8TDNQMQAAAAJ",
        "orcid": "0000-0002-4137-0126",
        "linkedin_url": "anshumitts/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "vKgDbYKZrH",
      "title": "MOGIC: METADATA-INFUSED ORACLE GUIDANCE FOR IMPROVED EXTREME CLASSIFICATION",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Retrieval-augmented classification and generation  models significantly benefit from the *early-stage fusion* of high-quality text-based auxiliary metadata, often called memory, but they suffer from high inference latency and poor robustness to noise. In classifications tasks, particularly the extreme classification (XC) setting, where low latency is critical, existing methods incorporate metadata for context enrichment via an XC-based retriever and obtain the representations of the relevant memory items to perform *late-stage fusion* to achieve low latency. With an aim of achieving higher accuracy while meeting the low latency constraints, in this paper, we propose MOGIC, an approach for metadata-infused Oracle guidance for XC tasks. In particular, we train an early-fusion Oracle classifier with access to both query-side and label-side ground-truth metadata in the textual form. The Oracle is subsequently used to guide the training of any existing memory-based XC Disciple model via regularization. The MOGIC algorithm, when applied to memory-based XC Disciple models such as OAK, improves precision@1 and propensity-scored precision@1 by ~2% on four standard datasets, at no additional inference-time costs to the Disciple model. We also show the feasibility of applying the MOGIC algorithm to improve the performance of state-of-the-art memory-free XC approaches such as NGAME or DEXA, demonstrating that the MOGIC algorithm can be used atop any existing XC-based approach in a *plug-and-play* manner. Finally, we also show the robustness of the MOGIC method to missing and noisy metadata settings. We will release code on acceptance.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=vKgDbYKZrH",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 14,
      "track_name": "Main Conference",
      "author": {
        "id": "~Siddarth_Asokan1",
        "name": "Siddarth Asokan",
        "name_site": null,
        "openreview_id": "~Siddarth_Asokan1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://siddarthasokan.com",
        "dblp_id": "277/5532",
        "google_scholar_url": "tM4SYUQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "vKgDbYKZrH",
      "title": "MOGIC: METADATA-INFUSED ORACLE GUIDANCE FOR IMPROVED EXTREME CLASSIFICATION",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Retrieval-augmented classification and generation  models significantly benefit from the *early-stage fusion* of high-quality text-based auxiliary metadata, often called memory, but they suffer from high inference latency and poor robustness to noise. In classifications tasks, particularly the extreme classification (XC) setting, where low latency is critical, existing methods incorporate metadata for context enrichment via an XC-based retriever and obtain the representations of the relevant memory items to perform *late-stage fusion* to achieve low latency. With an aim of achieving higher accuracy while meeting the low latency constraints, in this paper, we propose MOGIC, an approach for metadata-infused Oracle guidance for XC tasks. In particular, we train an early-fusion Oracle classifier with access to both query-side and label-side ground-truth metadata in the textual form. The Oracle is subsequently used to guide the training of any existing memory-based XC Disciple model via regularization. The MOGIC algorithm, when applied to memory-based XC Disciple models such as OAK, improves precision@1 and propensity-scored precision@1 by ~2% on four standard datasets, at no additional inference-time costs to the Disciple model. We also show the feasibility of applying the MOGIC algorithm to improve the performance of state-of-the-art memory-free XC approaches such as NGAME or DEXA, demonstrating that the MOGIC algorithm can be used atop any existing XC-based approach in a *plug-and-play* manner. Finally, we also show the robustness of the MOGIC method to missing and noisy metadata settings. We will release code on acceptance.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=vKgDbYKZrH",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 14,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manish_Gupta1",
        "name": "Manish Gupta",
        "name_site": null,
        "openreview_id": "~Manish_Gupta1",
        "position": 12,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/manishg/",
        "dblp_id": "g/ManishGupta1.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=eX9PSu0AAAAJ",
        "orcid": "0000-0002-2843-3110",
        "linkedin_url": "manishsgupta/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "wLR9d5ZFpY",
      "title": "No Training Data, No Cry: Model Editing without Training Data or Fine-tuning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Model Editing(ME)--such as classwise unlearning and structured pruning--is a nascent field that deals with identifying editable components that, when modified, significantly change the model's behaviour, typically requiring fine-tuning to regain performance.\nThe challenge of model editing increases when dealing with multi-branch networks(e.g. ResNets) in the data-free regime, where the training data and the loss function are not available.\nIdentifying editable components is more difficult in multi-branch networks due to the coupling of individual components across layers through skip connections. \nThis paper addresses these issues through the following contributions.\nFirst, we hypothesize that in a well-trained model, there exists a small set of channels, which we call HiFi channels, whose input contributions strongly correlate with the output feature map of that layer.\nFinding such subsets can be naturally posed as an expected reconstruction error problem. To solve this, we provide an efficient heuristic called RowSum.\nSecond, to understand how to regain accuracy after editing, we prove, for the first time, an upper bound on the loss function post-editing in terms of the change in the stored BatchNorm(BN) statistics.  With this result, we derive BNFix, a simple algorithm to restore accuracy by updating the BN statistics using distributional access to the data distribution.\nWith these insights, we propose retraining free algorithms for structured pruning and classwise unlearning, CoBRA-P and CoBRA-U, that identify HiFi components and retains(structured pruning) or discards(classwise unlearning) them. CoBRA-P achieves at least 50% larger reduction in FLOPS and at least 10% larger reduction in parameters for similar drop in accuracy in the training free regime. In the training regime, for ImageNet, it achieves 60% larger parameter reduction. CoBRA-U achieves, on average, a 94% reduction in forget-class accuracy with a minimal drop in remaining class accuracy.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=wLR9d5ZFpY",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Tanay_Narshana1",
        "name": "Tanay Narshana",
        "name_site": "Tanay Narshana, Chaitanya Murti, Chiranjib Bhattacharyya",
        "openreview_id": "~Tanay_Narshana1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "350/3876",
        "google_scholar_url": "d4YFxEcAAAAJ",
        "orcid": null,
        "linkedin_url": "tanay-narshana/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "wLR9d5ZFpY",
      "title": "No Training Data, No Cry: Model Editing without Training Data or Fine-tuning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Model Editing(ME)--such as classwise unlearning and structured pruning--is a nascent field that deals with identifying editable components that, when modified, significantly change the model's behaviour, typically requiring fine-tuning to regain performance.\nThe challenge of model editing increases when dealing with multi-branch networks(e.g. ResNets) in the data-free regime, where the training data and the loss function are not available.\nIdentifying editable components is more difficult in multi-branch networks due to the coupling of individual components across layers through skip connections. \nThis paper addresses these issues through the following contributions.\nFirst, we hypothesize that in a well-trained model, there exists a small set of channels, which we call HiFi channels, whose input contributions strongly correlate with the output feature map of that layer.\nFinding such subsets can be naturally posed as an expected reconstruction error problem. To solve this, we provide an efficient heuristic called RowSum.\nSecond, to understand how to regain accuracy after editing, we prove, for the first time, an upper bound on the loss function post-editing in terms of the change in the stored BatchNorm(BN) statistics.  With this result, we derive BNFix, a simple algorithm to restore accuracy by updating the BN statistics using distributional access to the data distribution.\nWith these insights, we propose retraining free algorithms for structured pruning and classwise unlearning, CoBRA-P and CoBRA-U, that identify HiFi components and retains(structured pruning) or discards(classwise unlearning) them. CoBRA-P achieves at least 50% larger reduction in FLOPS and at least 10% larger reduction in parameters for similar drop in accuracy in the training free regime. In the training regime, for ImageNet, it achieves 60% larger parameter reduction. CoBRA-U achieves, on average, a 94% reduction in forget-class accuracy with a minimal drop in remaining class accuracy.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=wLR9d5ZFpY",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Chaitanya_Murti1",
        "name": "Chaitanya Murti",
        "name_site": null,
        "openreview_id": "~Chaitanya_Murti1",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "wLR9d5ZFpY",
      "title": "No Training Data, No Cry: Model Editing without Training Data or Fine-tuning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Model Editing(ME)--such as classwise unlearning and structured pruning--is a nascent field that deals with identifying editable components that, when modified, significantly change the model's behaviour, typically requiring fine-tuning to regain performance.\nThe challenge of model editing increases when dealing with multi-branch networks(e.g. ResNets) in the data-free regime, where the training data and the loss function are not available.\nIdentifying editable components is more difficult in multi-branch networks due to the coupling of individual components across layers through skip connections. \nThis paper addresses these issues through the following contributions.\nFirst, we hypothesize that in a well-trained model, there exists a small set of channels, which we call HiFi channels, whose input contributions strongly correlate with the output feature map of that layer.\nFinding such subsets can be naturally posed as an expected reconstruction error problem. To solve this, we provide an efficient heuristic called RowSum.\nSecond, to understand how to regain accuracy after editing, we prove, for the first time, an upper bound on the loss function post-editing in terms of the change in the stored BatchNorm(BN) statistics.  With this result, we derive BNFix, a simple algorithm to restore accuracy by updating the BN statistics using distributional access to the data distribution.\nWith these insights, we propose retraining free algorithms for structured pruning and classwise unlearning, CoBRA-P and CoBRA-U, that identify HiFi components and retains(structured pruning) or discards(classwise unlearning) them. CoBRA-P achieves at least 50% larger reduction in FLOPS and at least 10% larger reduction in parameters for similar drop in accuracy in the training free regime. In the training regime, for ImageNet, it achieves 60% larger parameter reduction. CoBRA-U achieves, on average, a 94% reduction in forget-class accuracy with a minimal drop in remaining class accuracy.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=wLR9d5ZFpY",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Chiranjib_Bhattacharyya1",
        "name": "Chiranjib Bhattacharyya",
        "name_site": null,
        "openreview_id": "~Chiranjib_Bhattacharyya1",
        "position": 4,
        "gender": "M",
        "homepage_url": "http://www.csa.iisc.ac.in/~chiru/",
        "dblp_id": "b/CBhattacharyya",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "wgnMdxS2nZ",
      "title": "MQFL-FHE: Multimodal Quantum Federated Learning Framework with Fully Homomorphic Encryption",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "The integration of fully homomorphic encryption (FHE) in federated learning (FL) has led to significant advances in data privacy. However, during the aggregation phase, it often results in performance degradation of the aggregated model, hindering the development of robust representational generalization. In this work, we propose a novel multimodal quantum federated learning framework that utilizes quantum computing to counteract the performance drop resulting from FHE. For the first time in FL, our framework combines a multimodal quantum mixture of experts (MQMoE) model with FHE, incorporating multimodal datasets for enriched representation and task-specific learning. Our MQMoE framework enhances performance on multimodal datasets and combined genomics and brain MRI scans, especially for underrepresented categories. Our results also demonstrate that the quantum-enhanced approach mitigates the performance degradation associated with FHE and improves classification accuracy across diverse datasets, validating the potential of quantum interventions in enhancing privacy in FL.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=wgnMdxS2nZ",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Siddhant_Dutta1",
        "name": "Siddhant Dutta",
        "name_site": null,
        "openreview_id": "~Siddhant_Dutta1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://elucidator8918.github.io/",
        "dblp_id": "356/3781",
        "google_scholar_url": "-TXOxzIAAAAJ",
        "orcid": "0009-0000-5120-7114",
        "linkedin_url": "siddhant-dutta-30260315a/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Dwarkadas J. Sanghvi College of Engineering (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.4,
        "rating_std": 0.8,
        "confidence_mean": 2.8,
        "confidence_std": 0.7483314773547882,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xEDB5sSIK0",
      "title": "Label Informativeness-based Minority Oversampling in Graphs (LIMO)",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Class imbalance is a pervasive issue in many real-world datasets, particularly in graph-structured data, where certain classes are significantly underrepresented. This imbalance can severely impact the performance of Graph Neural Networks (GNNs), leading to biased learning or over-fitting. The existing oversampling techniques often overlook the intrinsic properties of graphs, such as Label Informativeness (LI), which measures the amount of information a neighbor's label provides about a node's label. To address this, we propose Label Informativeness-based Minority Oversampling (LIMO), a novel algorithm that strategically oversamples minority class nodes by augmenting edges to maximize LI. This technique generates a balanced, synthetic graph that enhances GNN performance without significantly increasing data volume. Our theoretical analysis shows that the effectiveness of GNNs is directly proportional to label informativeness, with mutual information as a mediator. Additionally, we provide insights into how variations in the number of inter-class edges influence the LI by analyzing its derivative. Experimental results on various homophilous and heterophilous benchmark datasets demonstrate the effectiveness of LIMO in improving the performance of node classification for different imbalance ratios, with particularly significant improvements observed in heterophilous graph datasets. Our code is available at \\url{https://anonymous.4open.science/r/limo-12CC/}",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=xEDB5sSIK0",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rishav_Das1",
        "name": "Rishav Das",
        "name_site": null,
        "openreview_id": "~Rishav_Das1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "rishav-das-333a4132b",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "National Institute of Science Education and Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xEDB5sSIK0",
      "title": "Label Informativeness-based Minority Oversampling in Graphs (LIMO)",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Class imbalance is a pervasive issue in many real-world datasets, particularly in graph-structured data, where certain classes are significantly underrepresented. This imbalance can severely impact the performance of Graph Neural Networks (GNNs), leading to biased learning or over-fitting. The existing oversampling techniques often overlook the intrinsic properties of graphs, such as Label Informativeness (LI), which measures the amount of information a neighbor's label provides about a node's label. To address this, we propose Label Informativeness-based Minority Oversampling (LIMO), a novel algorithm that strategically oversamples minority class nodes by augmenting edges to maximize LI. This technique generates a balanced, synthetic graph that enhances GNN performance without significantly increasing data volume. Our theoretical analysis shows that the effectiveness of GNNs is directly proportional to label informativeness, with mutual information as a mediator. Additionally, we provide insights into how variations in the number of inter-class edges influence the LI by analyzing its derivative. Experimental results on various homophilous and heterophilous benchmark datasets demonstrate the effectiveness of LIMO in improving the performance of node classification for different imbalance ratios, with particularly significant improvements observed in heterophilous graph datasets. Our code is available at \\url{https://anonymous.4open.science/r/limo-12CC/}",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=xEDB5sSIK0",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sikta_Mohanty1",
        "name": "Sikta Mohanty",
        "name_site": null,
        "openreview_id": "~Sikta_Mohanty1",
        "position": 2,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "sikta-mohanty",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Christ University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xEDB5sSIK0",
      "title": "Label Informativeness-based Minority Oversampling in Graphs (LIMO)",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Class imbalance is a pervasive issue in many real-world datasets, particularly in graph-structured data, where certain classes are significantly underrepresented. This imbalance can severely impact the performance of Graph Neural Networks (GNNs), leading to biased learning or over-fitting. The existing oversampling techniques often overlook the intrinsic properties of graphs, such as Label Informativeness (LI), which measures the amount of information a neighbor's label provides about a node's label. To address this, we propose Label Informativeness-based Minority Oversampling (LIMO), a novel algorithm that strategically oversamples minority class nodes by augmenting edges to maximize LI. This technique generates a balanced, synthetic graph that enhances GNN performance without significantly increasing data volume. Our theoretical analysis shows that the effectiveness of GNNs is directly proportional to label informativeness, with mutual information as a mediator. Additionally, we provide insights into how variations in the number of inter-class edges influence the LI by analyzing its derivative. Experimental results on various homophilous and heterophilous benchmark datasets demonstrate the effectiveness of LIMO in improving the performance of node classification for different imbalance ratios, with particularly significant improvements observed in heterophilous graph datasets. Our code is available at \\url{https://anonymous.4open.science/r/limo-12CC/}",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=xEDB5sSIK0",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rucha_Bhalchandra_Joshi1",
        "name": "Rucha Bhalchandra Joshi",
        "name_site": null,
        "openreview_id": "~Rucha_Bhalchandra_Joshi1",
        "position": 3,
        "gender": "F",
        "homepage_url": "https://ruchajoshi.github.io/",
        "dblp_id": "266/5932",
        "google_scholar_url": "Xfxu5jQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Cyprus Institute (Cyprus)",
        "countries": [
          "Cyprus"
        ],
        "country_codes": [
          "UN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xEDB5sSIK0",
      "title": "Label Informativeness-based Minority Oversampling in Graphs (LIMO)",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Class imbalance is a pervasive issue in many real-world datasets, particularly in graph-structured data, where certain classes are significantly underrepresented. This imbalance can severely impact the performance of Graph Neural Networks (GNNs), leading to biased learning or over-fitting. The existing oversampling techniques often overlook the intrinsic properties of graphs, such as Label Informativeness (LI), which measures the amount of information a neighbor's label provides about a node's label. To address this, we propose Label Informativeness-based Minority Oversampling (LIMO), a novel algorithm that strategically oversamples minority class nodes by augmenting edges to maximize LI. This technique generates a balanced, synthetic graph that enhances GNN performance without significantly increasing data volume. Our theoretical analysis shows that the effectiveness of GNNs is directly proportional to label informativeness, with mutual information as a mediator. Additionally, we provide insights into how variations in the number of inter-class edges influence the LI by analyzing its derivative. Experimental results on various homophilous and heterophilous benchmark datasets demonstrate the effectiveness of LIMO in improving the performance of node classification for different imbalance ratios, with particularly significant improvements observed in heterophilous graph datasets. Our code is available at \\url{https://anonymous.4open.science/r/limo-12CC/}",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=xEDB5sSIK0",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Subhankar_Mishra1",
        "name": "Subhankar Mishra",
        "name_site": null,
        "openreview_id": "~Subhankar_Mishra1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://www.niser.ac.in/~smishra/",
        "dblp_id": "147/8391",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "National Institute of Science Education and Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.8,
        "rating_std": 0.9797958971132712,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xW4J2QlqRx",
      "title": "Context Matters: Leveraging Contextual Features for Time Series Forecasting",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Time series forecasts are often influenced by exogenous contextual features in addition to their corresponding history. For example, in financial settings, it is hard to accurately predict a stock price without considering public sentiments and policy decisions in the form of news articles, tweets, etc. Though this is common knowledge, the current state-of-the-art (SOTA) forecasting models fail to incorporate such contextual information, owing to its heterogeneity and multimodal nature. To address this, we introduce ContextFormer, a novel plug-and-play method to surgically integrate multimodal contextual information into existing pre-trained forecasting models. ContextFormer effectively distills forecast-specific information from rich multimodal contexts, including categorical, continuous, time-varying, and even textual information, to significantly enhance the performance of existing base forecasters. ContextFormer outperforms SOTA forecasting models by up to 30% on a range of real-world datasets spanning energy, traffic, environmental, and financial domains.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=xW4J2QlqRx",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sameep_Chattopadhyay1",
        "name": "Sameep Chattopadhyay",
        "name_site": null,
        "openreview_id": "~Sameep_Chattopadhyay1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "-lFhkOQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xnWikQRJBR",
      "title": "M3CoL: Harnessing Shared Relations via Multimodal Mixup Contrastive Learning for Multimodal Classification",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Deep multimodal learning has shown remarkable success by leveraging contrastive learning to capture explicit one-to-one relations across modalities. However, real-world data often exhibits shared relations beyond simple pairwise associations. We propose M3CoL, a Multimodal Mixup Contrastive Learning approach to capture nuanced shared relations inherent in multimodal data. Our key contribution is a Mixup-based contrastive loss that learns robust representations by aligning mixed samples from one modality with their corresponding samples from other modalities thereby capturing shared relations between them. For multimodal classification tasks, we introduce a framework that integrates a fusion module with unimodal prediction modules for auxiliary supervision during training, complemented by our proposed Mixup-based contrastive loss. Through extensive experiments on diverse datasets (N24News, ROSMAP, BRCA, and Food-101), we demonstrate that M3CoL effectively captures shared multimodal relations and generalizes across domains. It outperforms state-of-the-art methods on N24News, ROSMAP, and BRCA, while achieving comparable performance on Food-101. Our work highlights the significance of learning shared relations for robust multimodal learning, opening up promising avenues for future research.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=xnWikQRJBR",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Deval_Mehta1",
        "name": "Deval Mehta",
        "name_site": null,
        "openreview_id": "~Kshitij_Sharad_Jadhav1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://www.kcdh.iitb.ac.in/people/",
        "dblp_id": "350/5493.html",
        "google_scholar_url": "VY8oCm0AAAAJ",
        "orcid": "0000-0001-9795-8335",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xsmlrhoQzC",
      "title": "Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "User prompts for generative AI models are often underspecified or open-ended, which may lead to sub-optimal responses. This prompt underspecification problem is particularly evident in text-to-image (T2I) generation, where users commonly struggle to articulate their precise intent. This disconnect between the user's vision and the model's interpretation often forces users to painstakingly and repeatedly refine their prompts. To address this, we propose a design for proactive T2I agents equipped with an interface to actively ask clarification questions when uncertain, and present their understanding of user intent as an interpretable **belief graph** that a user can edit. We build simple prototypes for such agents and verify their effectiveness through both human studies and automated evaluation. We observed that at least 90\\% of human subjects found these agents and their belief graphs helpful for their T2I workflow. Moreover, we use a scalable automated evaluation approach using two agents, one with a ground truth image and the other tries to ask as few questions as possible to align with the ground truth. On DesignBench, a benchmark we created for artists and designers, the COCO dataset (Lin et al.,2014) and ImageInWords (Garg et al., 2024), we observed that these T2I agents were able to ask informative questions and elicit crucial information to achieve successful alignment with at least 2 times higher VQAScore (Lin et al., 2024) than the standard single-turn T2I generation.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=xsmlrhoQzC",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Alex_Lamb1_1",
        "name": "Alex Lamb",
        "name_site": null,
        "openreview_id": "~Kartikeya_Badola1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://kartikeya-badola.github.io/",
        "dblp_id": null,
        "google_scholar_url": "1bXieIsAAAAJ",
        "orcid": "0000-0002-2020-9173",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.5,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "yYxEFC3Ep4",
      "title": "Where Do Images Come From? Analyzing Captions to Geographically Profile Datasets",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Building on studies documenting gender and racial biases in vision-language models, recent works show that such models often fail to generate geographically-representative images that accurately reflect different regions around the world. A common concern is that the data used to train these models is not representative, prompting the question: *which parts of the world do these training examples come from?* To answer this question, we develop a system, *GeoProfiler*, which geographically profiles multimodal datasets by mapping image-caption pairs to countries. Using location information from captions, GeoProfiler maps examples to countries with a high precision ($0.86$). We then apply *GeoProfiler* to geographically profile the English captions of the LAION dataset for $10$ common entities (e.g., house, flag, etc.). We observe the geographical distribution of $8$ entities to obey the power law distribution. The United States, the United Kingdom, and India are most represented, appearing in 53.7% of samples. Problematically, African and South American countries are severely under-represented with only 2.0 % and 4.3 % of images respectively. We also observe a high correlation between a country's GDP and frequency ($\\rho=0.79$). Lastly, we analyze the diversity of images from individual countries, and find that more images does not imply higher diversity.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=yYxEFC3Ep4",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abhipsa_Basu1",
        "name": "Abhipsa Basu",
        "name_site": null,
        "openreview_id": "~Abhipsa_Basu1",
        "position": 1,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "203/8816",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=tmn0akEAAAAJ",
        "orcid": null,
        "linkedin_url": "abhipsa-basu-526ba0152/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "yYxEFC3Ep4",
      "title": "Where Do Images Come From? Analyzing Captions to Geographically Profile Datasets",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Building on studies documenting gender and racial biases in vision-language models, recent works show that such models often fail to generate geographically-representative images that accurately reflect different regions around the world. A common concern is that the data used to train these models is not representative, prompting the question: *which parts of the world do these training examples come from?* To answer this question, we develop a system, *GeoProfiler*, which geographically profiles multimodal datasets by mapping image-caption pairs to countries. Using location information from captions, GeoProfiler maps examples to countries with a high precision ($0.86$). We then apply *GeoProfiler* to geographically profile the English captions of the LAION dataset for $10$ common entities (e.g., house, flag, etc.). We observe the geographical distribution of $8$ entities to obey the power law distribution. The United States, the United Kingdom, and India are most represented, appearing in 53.7% of samples. Problematically, African and South American countries are severely under-represented with only 2.0 % and 4.3 % of images respectively. We also observe a high correlation between a country's GDP and frequency ($\\rho=0.79$). Lastly, we analyze the diversity of images from individual countries, and find that more images does not imply higher diversity.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=yYxEFC3Ep4",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Yugam_Bahl1",
        "name": "Yugam Bahl",
        "name_site": null,
        "openreview_id": "~Yugam_Bahl1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://github.com/yugambahl",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "yugam-bahl-3a3236172/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "yYxEFC3Ep4",
      "title": "Where Do Images Come From? Analyzing Captions to Geographically Profile Datasets",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Building on studies documenting gender and racial biases in vision-language models, recent works show that such models often fail to generate geographically-representative images that accurately reflect different regions around the world. A common concern is that the data used to train these models is not representative, prompting the question: *which parts of the world do these training examples come from?* To answer this question, we develop a system, *GeoProfiler*, which geographically profiles multimodal datasets by mapping image-caption pairs to countries. Using location information from captions, GeoProfiler maps examples to countries with a high precision ($0.86$). We then apply *GeoProfiler* to geographically profile the English captions of the LAION dataset for $10$ common entities (e.g., house, flag, etc.). We observe the geographical distribution of $8$ entities to obey the power law distribution. The United States, the United Kingdom, and India are most represented, appearing in 53.7% of samples. Problematically, African and South American countries are severely under-represented with only 2.0 % and 4.3 % of images respectively. We also observe a high correlation between a country's GDP and frequency ($\\rho=0.79$). Lastly, we analyze the diversity of images from individual countries, and find that more images does not imply higher diversity.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=yYxEFC3Ep4",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Kirti_Bhagat1",
        "name": "Kirti Bhagat",
        "name_site": null,
        "openreview_id": "~Kirti_Bhagat1",
        "position": 3,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "kirti-bhagat-158a3a150/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of California, Irvine (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "yYxEFC3Ep4",
      "title": "Where Do Images Come From? Analyzing Captions to Geographically Profile Datasets",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Building on studies documenting gender and racial biases in vision-language models, recent works show that such models often fail to generate geographically-representative images that accurately reflect different regions around the world. A common concern is that the data used to train these models is not representative, prompting the question: *which parts of the world do these training examples come from?* To answer this question, we develop a system, *GeoProfiler*, which geographically profiles multimodal datasets by mapping image-caption pairs to countries. Using location information from captions, GeoProfiler maps examples to countries with a high precision ($0.86$). We then apply *GeoProfiler* to geographically profile the English captions of the LAION dataset for $10$ common entities (e.g., house, flag, etc.). We observe the geographical distribution of $8$ entities to obey the power law distribution. The United States, the United Kingdom, and India are most represented, appearing in 53.7% of samples. Problematically, African and South American countries are severely under-represented with only 2.0 % and 4.3 % of images respectively. We also observe a high correlation between a country's GDP and frequency ($\\rho=0.79$). Lastly, we analyze the diversity of images from individual countries, and find that more images does not imply higher diversity.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=yYxEFC3Ep4",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Preethi_Seshadri2",
        "name": "Preethi Seshadri",
        "name_site": null,
        "openreview_id": "~Preethi_Seshadri2",
        "position": 4,
        "gender": "F",
        "homepage_url": "https://preethiseshadri518.github.io/",
        "dblp_id": "175/6462.html",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "preethi-seshadri/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "yYxEFC3Ep4",
      "title": "Where Do Images Come From? Analyzing Captions to Geographically Profile Datasets",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Building on studies documenting gender and racial biases in vision-language models, recent works show that such models often fail to generate geographically-representative images that accurately reflect different regions around the world. A common concern is that the data used to train these models is not representative, prompting the question: *which parts of the world do these training examples come from?* To answer this question, we develop a system, *GeoProfiler*, which geographically profiles multimodal datasets by mapping image-caption pairs to countries. Using location information from captions, GeoProfiler maps examples to countries with a high precision ($0.86$). We then apply *GeoProfiler* to geographically profile the English captions of the LAION dataset for $10$ common entities (e.g., house, flag, etc.). We observe the geographical distribution of $8$ entities to obey the power law distribution. The United States, the United Kingdom, and India are most represented, appearing in 53.7% of samples. Problematically, African and South American countries are severely under-represented with only 2.0 % and 4.3 % of images respectively. We also observe a high correlation between a country's GDP and frequency ($\\rho=0.79$). Lastly, we analyze the diversity of images from individual countries, and find that more images does not imply higher diversity.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=yYxEFC3Ep4",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Venkatesh_Babu_Radhakrishnan2",
        "name": "Venkatesh Babu Radhakrishnan",
        "name_site": null,
        "openreview_id": "~Venkatesh_Babu_Radhakrishnan2",
        "position": 5,
        "gender": "M",
        "homepage_url": "http://cds.iisc.ac.in/faculty/venky",
        "dblp_id": "20/6289",
        "google_scholar_url": "cVg7HrEAAAAJ",
        "orcid": "0000-0002-1926-1804",
        "linkedin_url": "venkatesh-babu-radhakrishnan-16568939",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "z4bfNsrum4",
      "title": "Decoding Generalization from Memorization in Deep Neural Networks",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Overparameterized Deep Neural Networks that generalize well have been key to the dramatic success of Deep Learning in recent years. The reasons for their remarkable ability to generalize are not well understood yet. It has also been known that deep networks possess the ability to memorize training data, as evidenced by perfect or high training accuracies on models trained with corrupted data that have class labels shuffled to varying degrees. Concomitantly, such models are known to generalize poorly, i.e. they suffer from poor test accuracies, due to which it is thought that the act of memorizing substantially degrades the ability to generalize. It has, however, been unclear why the poor generalization that accompanies such memorization, comes about. One possibility is that in the process of training with corrupted data, the layers of the network irretrievably re-organize their representations in a manner that makes generalization difficult. The other possibility is that the network retains significant ability to generalize, but the trained network somehow “chooses” to readout in a manner that is detrimental to generalization. Here, we provide evidence for the latter possibility by demonstrating, empirically, that such models possess information in their representations for substantially improved generalization, even in the face of memorization. Furthermore, such generalization abilities can be easily decoded from the internals of the trained model, and we build a technique to do so from the outputs of specific layers of the network. We demonstrate results on multiple models trained with a number of standard datasets.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=z4bfNsrum4",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Simran_Ketha1",
        "name": "Simran Ketha",
        "name_site": null,
        "openreview_id": "~Simran_Ketha1",
        "position": 1,
        "gender": "F",
        "homepage_url": "https://simranketha.github.io/",
        "dblp_id": null,
        "google_scholar_url": "3k_akr4AAAAJ",
        "orcid": null,
        "linkedin_url": "simranketha",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.8,
        "rating_std": 1.9390719429665315,
        "confidence_mean": 3.8,
        "confidence_std": 0.39999999999999997,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "z4bfNsrum4",
      "title": "Decoding Generalization from Memorization in Deep Neural Networks",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Overparameterized Deep Neural Networks that generalize well have been key to the dramatic success of Deep Learning in recent years. The reasons for their remarkable ability to generalize are not well understood yet. It has also been known that deep networks possess the ability to memorize training data, as evidenced by perfect or high training accuracies on models trained with corrupted data that have class labels shuffled to varying degrees. Concomitantly, such models are known to generalize poorly, i.e. they suffer from poor test accuracies, due to which it is thought that the act of memorizing substantially degrades the ability to generalize. It has, however, been unclear why the poor generalization that accompanies such memorization, comes about. One possibility is that in the process of training with corrupted data, the layers of the network irretrievably re-organize their representations in a manner that makes generalization difficult. The other possibility is that the network retains significant ability to generalize, but the trained network somehow “chooses” to readout in a manner that is detrimental to generalization. Here, we provide evidence for the latter possibility by demonstrating, empirically, that such models possess information in their representations for substantially improved generalization, even in the face of memorization. Furthermore, such generalization abilities can be easily decoded from the internals of the trained model, and we build a technique to do so from the outputs of specific layers of the network. We demonstrate results on multiple models trained with a number of standard datasets.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=z4bfNsrum4",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Venkatakrishnan_Ramaswamy1",
        "name": "Venkatakrishnan Ramaswamy",
        "name_site": null,
        "openreview_id": "~Venkatakrishnan_Ramaswamy1",
        "position": 2,
        "gender": "M",
        "homepage_url": "http://brain.bits-hyderabad.ac.in/venkat/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 3.8,
        "rating_std": 1.9390719429665315,
        "confidence_mean": 3.8,
        "confidence_std": 0.39999999999999997,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "zHeHIIFQVF",
      "title": "Train once and generalize: Zero-shot quantum state preparation with RL",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Quantum state preparation forms an essential cornerstone of quantum information science and quantum algorithms. Designing efficient and scalable methods for approximate state preparation on near-term quantum devices remains a significant challenge, with worst-case hardness results compounding this difficulty. In this work, we propose a deep reinforcement learning framework for quantum state preparation, capable of immediate inference of arbitrary stabilizer states at a fixed system size post a training phase. Our approach scales substantially beyond previous works by leveraging a novel reward function. In our experiments on stabilizer states up to nine qubits, our trained agent successfully prepares nearly all previously unseen states, despite being trained on less than $10^{-3}$\\% of the state space -- demonstrating significant generalization to novel states. Benchmarking shows our model produces stabilizer circuits with size $60$\\% that of existing algorithms, setting a new state of the art in circuit efficiency. Furthermore, we show that this performance advantage is consistent across states with varying entanglement content. We also analyze the rate of increase of entanglement entropy across the prepared circuit, obtaining insight into the quantum entanglement dynamics generated by our trained agent. Finally, we prove our agent generalizes to (almost) the entire space of stabilizer states.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=zHeHIIFQVF",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Krishna_Agaram1",
        "name": "Krishna Agaram",
        "name_site": null,
        "openreview_id": "~Krishna_Agaram1",
        "position": 1,
        "gender": null,
        "homepage_url": "https://mathismusic.github.io/website2024/about",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "krishna-n-agaram-5a4753324/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.333333333333333,
        "rating_std": 1.3743685418725535,
        "confidence_mean": 4.166666666666667,
        "confidence_std": 0.6871842709362768,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "zb1UI74kxA",
      "title": "How Many Van Goghs Does It Take to Van Gogh? Finding the Imitation Threshold",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Text-to-image models are trained using large datasets collected by scraping image-text pairs from the internet. These datasets often include private, copyrighted, and licensed material. Training models on such datasets enables them to generate images with such content, which might violate copyright laws and individual privacy. This phenomenon is termed imitation -- generation of images with content that has recognizable similarity to its training images. In this work we study the relationship between a concept's frequency in the training dataset and the ability of a model to imitate it. We seek to determine the point at which a model was trained on enough instances to imitate a concept -- the imitation threshold. We posit this question as a new problem: Finding the Imitation Threshold (FIT) and propose an efficient approach that estimates the imitation threshold without incurring the colossal cost of training multiple models from scratch. We experiment with two domains -- human faces and art styles -- for which we create four datasets, and evaluate three text-to-image models which were trained on two pretraining datasets. Our results estimate that the imitation threshold of these models is in the range of 200-600 images, depending on the domain and the model. The imitation threshold can provide an empirical basis for copyright violation claims and acts as a guiding principle for text-to-image model developers that aim to comply with copyright and privacy laws. Code will be released upon publication.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=zb1UI74kxA",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Preethi_Seshadri2",
        "name": "Preethi Seshadri",
        "name_site": null,
        "openreview_id": "~Preethi_Seshadri2",
        "position": 5,
        "gender": "F",
        "homepage_url": "https://preethiseshadri518.github.io/",
        "dblp_id": "175/6462.html",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "preethi-seshadri/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of California, Irvine (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 4.333333333333333,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "zqA19DirIT",
      "title": "REAL-TIME LAYOUT ADAPTATION USING GENERATIVE AI",
      "status": "Desk Reject",
      "normalized_status": "rejected",
      "abstract": "In modern web design, ensuring adaptability and user engagement through dynamic layouts is increasingly important. With the growing demand for personalized user experiences, traditional static web layouts are insufficient for meeting user preferences. This paper introduces an innovative approach that leverages generative AI to dynamically adapt web layouts in real-time. With the help of data that is collected under the banner of user interactions through technologies such as JavaScript and Node.js, we are able to save those interactions, which not only include the click patterns but also the timestamps, user’s name, day and date, and number of clicks.\n\nThese clicks correspond to interactions of users with different React components. This data is being stored as a CSV file, as it is easier to read when it comes to parsing it to an AI model. Once every designated cycle, the data is fed to a Python script which does an API call to the $Chat GPT 4o$ model, which then analyzes the data and rewrites the CSS to create a new web layout based on the user’s interactions. \n\nThis successfully gives a web interface that adapts its layout in real-time, which is somewhat similar to many recommendation systems of popular applications like Netflix and Amazon Prime. Its significance extends across multiple fields, as this approach can enhance user engagement by dynamically displaying components based on user interaction patterns. Additionally, it offers potential revenue growth for companies, allowing them to charge higher rates for ads strategically placed in high-engagement areas of the layout, based on inferred user data.\n\nFor example, let the number of clicks be represented as $N_c$ and the user interaction patterns as $P_u$. The revenue potential $R$ can be expressed as:\n$$\nR = k \\cdot N_c \\cdot P_u,\n$$\nwhere $k$ is a constant representing the ad placement value.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=zqA19DirIT",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sanshray_Singh_Langeh1",
        "name": "Sanshray Singh Langeh",
        "name_site": null,
        "openreview_id": "~Sanshray_Singh_Langeh1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "sanshray-langeh-024383241/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "National Institute of Technology, Srinagar (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 0.0,
        "rating_std": 0.0,
        "confidence_mean": 0.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    }
  ]
}