{
  "conference": "NeurIPS 2021",
  "focus_country": "India",
  "total_papers": 107,
  "generated_at": "2025-07-06T10:39:19.861576",
  "config": {
    "first_author_weight": 3.0,
    "last_author_weight": 2.0,
    "middle_author_weight": 1.0,
    "status_weights": {
      "oral": 10.0,
      "spotlight": 7.5,
      "poster": 5.0,
      "unknown": 1.0
    },
    "output_format": "json",
    "include_review_details": true,
    "include_citation_data": true
  },
  "papers": [
    {
      "paper_id": "e2gqGkFjDHg",
      "title": "Redesigning the Transformer Architecture with Insights from Multi-particle Dynamical Systems",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "The Transformer and its variants have been proven to be efficient sequence learners in many different domains. Despite their staggering success, a critical issue has been the enormous number of parameters that must be trained (ranging from $10^7$ to $10^{11}$) along with the quadratic complexity of dot-product attention. In this work, we investigate the problem of approximating the two central components of the Transformer --- multi-head self-attention and point-wise feed-forward transformation, with reduced parameter space and computational complexity. We build upon recent developments in analyzing deep neural networks as numerical solvers of ordinary differential equations. Taking advantage of an analogy between Transformer stages and the evolution of a dynamical system of multiple interacting particles, we formulate a temporal evolution scheme, \\name, to bypass costly dot-product attention over multiple stacked layers.  We perform exhaustive experiments with \\name\\ on well-known encoder-decoder as well as encoder-only tasks. We observe that the degree of approximation (or inversely, the degree of parameter reduction) has different effects on the performance, depending on the task. While in the encoder-decoder regime, \\name\\ delivers performances comparable to the original Transformer, in encoder-only tasks it consistently outperforms Transformer along with several subsequent variants.",
      "tldr": "A dynamical system motivated Transformer-variant that can achieves state-of-the-art performance with astoundingly fewer parameters.",
      "site_url": "https://nips.cc/virtual/2021/poster/27270",
      "pdf_url": "https://openreview.net/pdf?id=e2gqGkFjDHg",
      "github_url": "https://github.com/LCS2-IIITD/TransEvolve",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Subhabrata_Dutta1",
        "name": "Subhabrata Dutta",
        "name_site": "Subhabrata Dutta, Tanya Gautam, Soumen Chakrabarti, Tanmoy Chakraborty",
        "openreview_id": "~Subhabrata_Dutta1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "204/6929.html",
        "google_scholar_url": "aoaCs08AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Jadavpur University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 22.5,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 0.7071067811865476,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 15,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "iFadi3f5V5I",
      "title": "Statistical Regeneration Guarantees of the Wasserstein Autoencoder with Latent Space Consistency",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "The introduction of Variational Autoencoders (VAE) has been marked as a breakthrough in the history of representation learning models. Besides having several accolades of its own, VAE has successfully flagged off a series of inventions in the form of its immediate successors. Wasserstein Autoencoder (WAE), being an heir to that realm carries with it all of the goodness and heightened generative promises, matching even the generative adversarial networks (GANs). Needless to say, recent years have witnessed a remarkable resurgence in statistical analyses of the GANs. Similar examinations for Autoencoders however, despite their diverse applicability and notable empirical performance, remain largely absent. To close this gap, in this paper, we investigate the statistical properties of WAE. Firstly, we provide statistical guarantees that WAE achieves the target distribution in the latent space, utilizing the Vapnikâ€“Chervonenkis (VC) theory. The main result, consequently ensures the regeneration of the input distribution, harnessing the potential offered by Optimal Transport of measures under the Wasserstein metric. This study, in turn, hints at the class of distributions WAE can reconstruct after suffering a compression in the form of a latent law. ",
      "tldr": "",
      "site_url": "https://nips.cc/virtual/2021/poster/27496",
      "pdf_url": "https://openreview.net/pdf?id=iFadi3f5V5I",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anish_Chakrabarty1",
        "name": "Anish Chakrabarty",
        "name_site": "Anish Chakrabarty, Swagatam Das",
        "openreview_id": "~Anish_Chakrabarty1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "304/5289",
        "google_scholar_url": "KfCQY5oAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Statistical Institute (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 22.5,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 9,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "4wVlNqBJXg",
      "title": "Optimal Best-Arm Identification Methods for Tail-Risk Measures",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Conditional value-at-risk (CVaR) and value-at-risk (VaR) are popular tail-risk measures in finance and insurance industries as well as in highly reliable, safety-critical uncertain environments where often the underlying probability distributions are heavy-tailed. We use the multi-armed bandit best-arm identification framework and consider the problem of identifying the arm from amongst finitely many that has the smallest CVaR, VaR, or weighted sum of CVaR and mean. The latter captures the risk-return trade-off common in finance. Our main contribution is an optimal $\\delta$-correct algorithm that acts on general arms, including heavy-tailed distributions, and matches the lower bound on the expected number of samples needed, asymptotically (as $ \\delta$ approaches $0$). The algorithm requires solving a non-convex optimization problem in the space of probability measures, that requires delicate analysis. En-route, we develop new non-asymptotic, anytime-valid, empirical-likelihood-based concentration inequalities for tail-risk measures. ",
      "tldr": "We consider the best-arm identification problem in the multi-armed bandit framework where an arm with the smallest tail-risk measure is identified. ",
      "site_url": "https://nips.cc/virtual/2021/poster/26325",
      "pdf_url": "https://openreview.net/pdf?id=4wVlNqBJXg",
      "github_url": "/attachment/0330a775cffa6156f4aa134eaba674f1dd17291e.zip",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Shubhada_Agrawal1",
        "name": "Shubhada Agrawal",
        "name_site": "Shubhada Agrawal, Wouter Koolen, Sandeep Juneja",
        "openreview_id": "~Shubhada_Agrawal1",
        "position": 1,
        "gender": "F",
        "homepage_url": "https://sites.google.com/view/shubhada-agrawal/home",
        "dblp_id": "247/9653",
        "google_scholar_url": "RQGMXiYAAAAJ",
        "orcid": null,
        "linkedin_url": "shubhada-agrawal-55561867/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tata Institute of Fundamental Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 0.0,
        "confidence_mean": 3.0,
        "confidence_std": 0.6324555320336759,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 53,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "6veB3MCD-bu",
      "title": "A Law of Iterated Logarithm for Multi-Agent Reinforcement Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In Multi-Agent Reinforcement Learning (MARL), multiple agents interact with a common environment, as also with each other, for solving a shared problem in sequential decision-making. It has wide-ranging applications in gaming, robotics, finance, communication, etc. In this work, we derive a novel law of iterated logarithm for a family of  distributed nonlinear stochastic approximation schemes that is useful in MARL. In particular, our result describes the convergence rate on almost every sample path where the algorithm converges. This result is the first of its kind in the distributed setup and provides deeper insights than the existing ones, which only discuss convergence rates in the expected or the CLT sense. Importantly, our result holds under significantly weaker assumptions: neither the gossip matrix needs to be doubly stochastic nor the stepsizes square summable. As an application, we show  that, for the stepsize $n^{-\\gamma}$ with $\\gamma \\in (0, 1),$ the distributed TD(0) algorithm with linear function approximation has a convergence rate of $O(\\sqrt{n^{-\\gamma} \\ln n })$ a.s.; for the $1/n$ type stepsize, the same is $O(\\sqrt{n^{-1} \\ln \\ln n})$ a.s. These decay rates do not depend on the graph depicting the interactions among the different agents. ",
      "tldr": "Almost sure convergence rates for multi-agent reinforcement learning algorithms ",
      "site_url": "https://nips.cc/virtual/2021/poster/26344",
      "pdf_url": "https://openreview.net/pdf?id=6veB3MCD-bu",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Gugan_Thoppe1",
        "name": "Gugan Thoppe",
        "name_site": "Gugan Chandrashekhar Thoppe, Bhumesh Kumar",
        "openreview_id": "~Gugan_Thoppe1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "117/3710",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=X5zV3s8AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "79QNAeS8pd",
      "title": "Bandit Quickest Changepoint Detection",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Many industrial and security applications employ a suite of sensors for detecting abrupt changes in temporal behavior patterns. These abrupt changes typically manifest locally, rendering only a small subset of sensors informative. Continuous monitoring of every sensor can be expensive due to resource constraints, and serves as a motivation for the bandit quickest changepoint detection problem, where sensing actions (or sensors) are sequentially chosen, and only measurements corresponding to chosen actions are observed. We derive an information-theoretic lower bound on the detection delay for a general class of finitely parameterized probability distributions. We then propose a computationally efficient online sensing scheme, which seamlessly balances the need for exploration of different sensing options with exploitation of querying informative actions. We derive expected delay bounds for the proposed scheme and show that these bounds match our information-theoretic lower bounds at low false alarm rates, establishing optimality of the proposed method. We then perform a number of experiments on synthetic and real datasets demonstrating the effectiveness of our proposed method.",
      "tldr": "Approaches for adaptively monitoring a system to rapidly detect local change ",
      "site_url": "https://nips.cc/virtual/2021/poster/27461",
      "pdf_url": "https://openreview.net/pdf?id=79QNAeS8pd",
      "github_url": "/attachment/3b6ed1336987a3e0d84aa1f7cce9c94a7a403abb.zip",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aditya_Gopalan1",
        "name": "Aditya Gopalan",
        "name_site": "Aditya Gopalan, Braghadeesh Lakshminarayanan, Venkatesh Saligrama",
        "openreview_id": "~Aditya_Gopalan1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://ece.iisc.ac.in/~aditya/",
        "dblp_id": "90/9826",
        "google_scholar_url": "dM5_1NsAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 11,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "7CKWdq2yQv",
      "title": "Active Assessment of Prediction Services as Accuracy Surface Over Attribute Combinations",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Our goal is to evaluate the accuracy of a black-box classification model, not as a single aggregate on a given test data distribution, but as a surface over a large number of combinations of attributes characterizing multiple test data distributions.  Such attributed accuracy measures become important as machine learning models get deployed as a service, where the training data distribution is hidden from clients, and different clients may be interested in diverse regions of the data distribution. We present Attributed Accuracy Assay (AAA) --- a Gaussian Process (GP)-based probabilistic estimator for such an accuracy surface. Each attribute combination, called an 'arm' is associated with a Beta density from which the service's accuracy is sampled.  We expect the GP to smooth the parameters of the Beta density over related arms to mitigate sparsity. We show that obvious application of GPs cannot address the challenge of heteroscedastic uncertainty over a huge attribute space that is sparsely and unevenly populated. In response, we present two enhancements: pooling sparse observations, and regularizing the scale parameter of the Beta densities. After introducing these innovations, we establish the effectiveness of AAA both in terms of its estimation accuracy and exploration efficiency, through extensive experiments and analysis.",
      "tldr": "Prediction Services should go beyond scalar accuracy and instead report performance on attribute combinations characterizing a clientâ€™s utility. Read our paper for how we can estimate accuracy for combinatorially large attribute combinations.",
      "site_url": "https://nips.cc/virtual/2021/poster/27414",
      "pdf_url": "https://openreview.net/pdf?id=7CKWdq2yQv",
      "github_url": "https://github.com/vihari/AAA",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vihari_Piratla1",
        "name": "Vihari Piratla",
        "name_site": "Vihari Piratla, Soumen Chakrabarti, Sunita Sarawagi",
        "openreview_id": "~Vihari_Piratla1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://vihari.github.io/",
        "dblp_id": "161/3626",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=DQddccYAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 5,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "90EVPQ7uCV",
      "title": "Memory-Efficient Approximation Algorithms for Max-k-Cut and Correlation Clustering",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Max-k-Cut and correlation clustering are fundamental graph partitioning problems. For a graph $G=(V,E)$ with $n$ vertices, the methods with the best approximation guarantees for Max-k-Cut and the Max-Agree variant of correlation clustering involve solving SDPs with $\\mathcal{O}(n^2)$ constraints and variables. Large-scale instances of SDPs, thus, present a memory bottleneck. In this paper, we develop simple polynomial-time Gaussian sampling-based algorithms for these two problems that use $\\mathcal{O}(n+|E|)$ memory and nearly achieve the best existing approximation guarantees. For dense graphs arriving in a stream, we eliminate the dependence on $|E|$ in the storage complexity at the cost of a slightly worse approximation ratio by combining our approach with sparsification.",
      "tldr": "We generate approximation solutions to Max-k-Cut and correlation clustering using memory linear in the size of the input graph",
      "site_url": "https://nips.cc/virtual/2021/poster/28336",
      "pdf_url": "https://openreview.net/pdf?id=90EVPQ7uCV",
      "github_url": "/attachment/3de102b430499d333123554b4873b294a5c3df77.zip",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Nimita_Rajendra_Shinde1",
        "name": "Nimita Rajendra Shinde",
        "name_site": "Nimita Shinde, Vishnu Narayanan, James Saunderson",
        "openreview_id": "~Nimita_Rajendra_Shinde1",
        "position": 1,
        "gender": "F",
        "homepage_url": "https://sites.google.com/view/nimitashinde",
        "dblp_id": "304/0987",
        "google_scholar_url": "https://scholar.google.com.eg/citations?user=JwVUMxsAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 2.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 6,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "AIQOddM5Xm",
      "title": "Non-local Latent Relation Distillation for Self-Adaptive 3D Human Pose Estimation",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Available 3D human pose estimation approaches leverage different forms of strong (2D/3D pose) or weak (multi-view or depth) paired supervision. Barring synthetic or in-studio domains, acquiring such supervision for each new target environment is highly inconvenient. To this end, we cast 3D pose learning as a self-supervised adaptation problem that aims to transfer the task knowledge from a labeled source domain to a completely unpaired target. We propose to infer image-to-pose via two explicit mappings viz. image-to-latent and latent-to-pose where the latter is a pre-learned decoder obtained from a prior-enforcing generative adversarial auto-encoder. Next, we introduce relation distillation as a means to align the unpaired cross-modal samples i.e., the unpaired target videos and unpaired 3D pose sequences. To this end, we propose a new set of non-local relations in order to characterize long-range latent pose interactions, unlike general contrastive relations where positive couplings are limited to a local neighborhood structure. Further, we provide an objective way to quantify non-localness in order to select the most effective relation set. We evaluate different self-adaptation settings and demonstrate state-of-the-art 3D human pose estimation performance on standard benchmarks.",
      "tldr": "We introduce relation distillation as a means to align the unpaired cross-modal samples i.e., unpaired target videos and unpaired 3D pose sequences for self-adapting 3D human pose estimation.",
      "site_url": "https://nips.cc/virtual/2021/poster/26641",
      "pdf_url": "https://openreview.net/pdf?id=AIQOddM5Xm",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jogendra_Nath_Kundu2",
        "name": "Jogendra Nath Kundu",
        "name_site": "Jogendra Nath Kundu, Siddharth Seth, Anirudh Jamkhandi, Pradyumna YM, Varun Jampani, Anirban Chakraborty, Venkatesh Babu R",
        "openreview_id": "~Jogendra_Nath_Kundu2",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/jogendra",
        "dblp_id": "185/0812",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=Xa44GDEAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 12,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "MLT9wFYMlJ9",
      "title": "Why Spectral Normalization Stabilizes GANs: Analysis and Improvements",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Spectral normalization (SN) is a widely-used technique for improving the stability and sample quality of Generative Adversarial Networks (GANs). However, current understanding of SN's efficacy is limited. In this work, we show that SN controls two important failure modes of GAN training: exploding and vanishing gradients. Our proofs illustrate a (perhaps unintentional) connection with the successful LeCun initialization. This connection helps to explain why the most popular implementation of SN for GANs requires no hyper-parameter tuning, whereas stricter implementations of SN have poor empirical performance out-of-the-box. Unlike LeCun initialization which only controls gradient vanishing at the beginning of training, SN preserves this property throughout training. Building on this theoretical understanding, we propose a new spectral normalization technique: Bidirectional Scaled Spectral Normalization (BSSN), which incorporates insights from later improvements to LeCun initialization: Xavier initialization and Kaiming initialization. Theoretically, we show that BSSN gives better gradient control than SN. Empirically, we demonstrate that it outperforms SN in sample quality and training stability on several benchmark datasets.",
      "tldr": "We study theoretically how spectral normalization stabilizes GANs.",
      "site_url": "https://nips.cc/virtual/2021/poster/28621",
      "pdf_url": "https://openreview.net/pdf?id=MLT9wFYMlJ9",
      "github_url": "https://github.com/fjxmlzn/BSN",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Zinan_Lin1",
        "name": "Zinan Lin",
        "name_site": "Zinan Lin, Vyas Sekar, Giulia Fanti",
        "openreview_id": "~Zinan_Lin1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://zinanlin.me/",
        "dblp_id": "64/237-1",
        "google_scholar_url": "67nE-wQ_g_cC",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Carnegie Mellon University (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 0.7071067811865476,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 69,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "MqCzSKCQ1QB",
      "title": "Adversarial Robustness without Adversarial Training: A Teacher-Guided Curriculum Learning Approach",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Current SOTA adversarially robust models are mostly based on adversarial training (AT) and differ only by some regularizers either at inner maximization or outer minimization steps. Being repetitive in nature during the inner maximization step, they take a huge time to train. We propose a non-iterative method that enforces the following ideas during training. Attribution maps are more aligned to the actual object in the image for adversarially robust models compared to naturally trained models. Also, the allowed set of pixels to perturb an image (that changes model decision) should be restricted to the object pixels only, which reduces the attack strength by limiting the attack space. Our method achieves significant performance gains with a little extra effort (10-20%) over existing AT models and outperforms all other methods in terms of adversarial as well as natural accuracy. We have performed extensive experimentation with CIFAR-10, CIFAR-100, and TinyImageNet datasets and reported results against many popular strong adversarial attacks to prove the effectiveness of our method.",
      "tldr": "We propose a non-iterative robust training technique which takes 10-20% time over existing adversarial training (AT) based models and outperforms strong baselines for both adversarial as well as natural accuracies.",
      "site_url": "https://nips.cc/virtual/2021/poster/26314",
      "pdf_url": "https://openreview.net/pdf?id=MqCzSKCQ1QB",
      "github_url": "https://github.com/sowgali/Get-Fooled-for-the-Right-Reason",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anindya_Sarkar2",
        "name": "Anindya Sarkar",
        "name_site": "Anindya Sarkar, Anirban Sarkar, Sowrya Gali, Vineeth N Balasubramanian",
        "openreview_id": "~Anindya_Sarkar2",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/anindya-sarkar/home",
        "dblp_id": null,
        "google_scholar_url": "2hQyYz0AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 8,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Sl0WX9H6ZJg",
      "title": "NeuroMLR: Robust & Reliable Route Recommendation on Road Networks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Predicting the most likely route from a source location to a destination is a core functionality in mapping services. Although the problem has been studied in the literature, two key limitations remain to be addressed. First, our study reveals that a significant portion of the routes recommended by existing methods fail to reach the destination. Second, existing techniques are transductive in nature; hence, they fail to recommend routes if unseen roads are encountered at inference time. In this paper, we address these limitations through an inductive algorithm called NeuroMLR. NeuroMLR learns a generative model from historical trajectories by conditioning on three explanatory factors: the current location, the destination, and real-time traffic conditions. The conditional distributions are learned through a novel combination of Lipschitz embedding with Graph Convolutional Networks (GCN) using historical trajectory data. Through in-depth experiments on real-world datasets, we establish that NeuroMLR imparts significant improvement in accuracy over the state of the art. More importantly, NeuroMLR generalizes dramatically better to unseen data and the recommended routes reach the destination with much higher likelihood than existing techniques.",
      "tldr": "Predicting the most likely route in a road network via Lipschitz embedding and GCN, achieving significantly high reachability and better generalisation to unseen data.",
      "site_url": "https://nips.cc/virtual/2021/poster/26807",
      "pdf_url": "https://openreview.net/pdf?id=Sl0WX9H6ZJg",
      "github_url": "https://github.com/idea-iitd/NeuroMLR",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jayant_Jain1",
        "name": "Jayant Jain",
        "name_site": "Jayant Jain, Vrittika Bagadia, Sahil Manchanda, Sayan Ranu",
        "openreview_id": "~Jayant_Jain1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "jayantjain100/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 27,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "U7SBcmRf65",
      "title": "Training for the Future: A Simple Gradient Interpolation Loss to Generalize Along Time",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In several real world applications, machine learning models are deployed to make predictions on data whose distribution changes gradually along time, leading to a drift between the train and test distributions. Such models are often re-trained on new data periodically, and they hence need to generalize to data not too far into the future. In this context, there is much prior work on enhancing temporal generalization, e.g. continuous transportation of past data, kernel smoothed time-sensitive parameters and more recently, adversarial learning of time-invariant features. However, these methods share several limitations, e.g, poor scalability, training instability, and dependence on unlabeled data from the future. Responding to the above limitations, we propose a simple method that starts with a model with time-sensitive parameters but regularizes its temporal complexity using a Gradient Interpolation  (GI) loss. GI allows the decision boundary to change along time and can still prevent overfitting to the limited training time snapshots  by allowing task-specific control over changes along time. We compare our method to existing baselines on multiple real-world datasets, which show that GI outperforms more complicated generative and adversarial approaches on the one hand, and simpler gradient regularization methods on the other.",
      "tldr": "We propose a simple gradient interpolation loss to enable models to generalize to unseen future data.",
      "site_url": "https://nips.cc/virtual/2021/poster/27251",
      "pdf_url": "https://openreview.net/pdf?id=U7SBcmRf65",
      "github_url": "https://github.com/anshuln/Training-for-the-Future",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anshul_Nasery2",
        "name": "Anshul Nasery",
        "name_site": "Anshul Nasery, Soumyadeep Thakur, Vihari Piratla, Abir De, Sunita Sarawagi",
        "openreview_id": "~Anshul_Nasery2",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://cse.iitb.ac.in/~anshuln",
        "dblp_id": "268/5650",
        "google_scholar_url": "lmvY2SMAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 31,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "a1wQOh27zcy",
      "title": "Contrast and Mix: Temporal Contrastive Video Domain Adaptation with Background Mixing",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Unsupervised domain adaptation which aims to adapt models trained on a labeled source domain to a completely unlabeled target domain has attracted much attention in recent years. While many domain adaptation techniques have been proposed for images, the problem of unsupervised domain adaptation in videos remains largely underexplored. In this paper, we introduce Contrast and Mix (CoMix), a new contrastive learning framework that aims to learn discriminative invariant feature representations for unsupervised video domain adaptation. First, unlike existing methods that rely on adversarial learning for feature alignment, we utilize temporal contrastive learning to bridge the domain gap by maximizing the similarity between encoded representations of an unlabeled video at two different speeds as well as minimizing the similarity between different videos played at different speeds. Second, we propose a novel extension to the temporal contrastive loss by using background mixing that allows additional positives per anchor, thus adapting contrastive learning to leverage action semantics shared across both domains. Moreover, we also integrate a supervised contrastive learning objective using target pseudo-labels to enhance discriminability of the latent space for video domain adaptation. Extensive experiments on several benchmark datasets demonstrate the superiority of our proposed approach over state-of-the-art methods. Project page: https://cvir.github.io/projects/comix.",
      "tldr": "A new temporal contrastive learning approach for unsupervised video domain adaptation.",
      "site_url": "https://nips.cc/virtual/2021/poster/26751",
      "pdf_url": "https://openreview.net/pdf?id=a1wQOh27zcy",
      "github_url": "https://cvir.github.io/projects/comix",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aadarsh_Sahoo1",
        "name": "Aadarsh Sahoo",
        "name_site": "Aadarsh Sahoo, Rutav Shah, Rameswar Panda, Kate Saenko, Abir Das",
        "openreview_id": "~Aadarsh_Sahoo1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://aadsah.github.io/",
        "dblp_id": "272/5285",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=1nPhcH0AAAAJ",
        "orcid": null,
        "linkedin_url": "aadsah/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 81,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "bayZPpw9lM",
      "title": "Counterexample Guided RL Policy Refinement Using Bayesian Optimization",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Constructing Reinforcement Learning (RL) policies that adhere to safety requirements is an emerging field of study. RL agents learn via trial and error with an objective to optimize a reward signal. Often policies that are designed to accumulate rewards do not satisfy safety specifications. We present a methodology for counterexample guided refinement of a trained RL policy against a given safety specification. Our approach has two main components. The first component is an approach to discover failure trajectories using Bayesian optimization over multiple parameters of uncertainty from a policy learnt in a model-free setting. The second component selectively modifies the failure points of the policy using gradient-based updates. The approach has been tested on several RL environments, and we demonstrate that the policy can be made to respect the safety specifications through such targeted changes.",
      "tldr": "A methodology to discover counter-examples from a trained RL policy and revise the policy to a safer new policy not having the counter-examples. ",
      "site_url": "https://nips.cc/virtual/2021/poster/27698",
      "pdf_url": "https://openreview.net/pdf?id=bayZPpw9lM",
      "github_url": "https://github.com/britig/policy-refinement-bo",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Briti_Gangopadhyay1",
        "name": "Briti Gangopadhyay",
        "name_site": "Briti Gangopadhyay, Pallab Dasgupta",
        "openreview_id": "~Briti_Gangopadhyay1",
        "position": 1,
        "gender": "F",
        "homepage_url": "https://sites.google.com/view/britigangopadhyay/home",
        "dblp_id": "254/6480",
        "google_scholar_url": "JSHb52gAAAAJ",
        "orcid": "0000-0002-6488-9326",
        "linkedin_url": "briti-gangopadhyay-a988008a/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 12,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "hA-PHQGOjqQ",
      "title": "Look at the Variance! Efficient Black-box Explanations with Sobol-based Sensitivity Analysis",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We describe a novel attribution method which is grounded in Sensitivity Analysis and uses  Sobol indices. Beyond modeling the individual contributions of image regions,  Sobol indices provide an efficient way to capture higher-order interactions between image regions and their contributions to a neural network's prediction through the lens of variance.\nWe describe an approach that makes the computation of these indices efficient for high-dimensional problems by using perturbation masks coupled with efficient estimators to handle the high dimensionality of images.\nImportantly, we show that the proposed method leads to favorable scores on standard benchmarks for vision (and language models) while drastically reducing the computing time compared to other black-box methods -- even surpassing the accuracy of state-of-the-art white-box methods which require access to internal representations. Our code is freely available:\ngithub.com/fel-thomas/Sobol-Attribution-Method.",
      "tldr": "We explain black-box models by measuring how their predictions vary when we perturb their input at various location using Sobol.",
      "site_url": "https://nips.cc/virtual/2021/poster/26522",
      "pdf_url": "https://openreview.net/pdf?id=hA-PHQGOjqQ",
      "github_url": "https://github.com/fel-thomas/Sobol-Attribution-Method",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Thomas_FEL1",
        "name": "Thomas FEL",
        "name_site": "Thomas FEL, Remi Cadene, Mathieu Chalvidal, Matthieu Cord, David Vigouroux, Thomas Serre",
        "openreview_id": "~Thomas_FEL1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://thomasfel.me",
        "dblp_id": "274/2390",
        "google_scholar_url": "1m5Mlx4AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Brown University (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.666666666666667,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.9428090415820634,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 84,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "iFadi3f5V5I",
      "title": "Statistical Regeneration Guarantees of the Wasserstein Autoencoder with Latent Space Consistency",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "The introduction of Variational Autoencoders (VAE) has been marked as a breakthrough in the history of representation learning models. Besides having several accolades of its own, VAE has successfully flagged off a series of inventions in the form of its immediate successors. Wasserstein Autoencoder (WAE), being an heir to that realm carries with it all of the goodness and heightened generative promises, matching even the generative adversarial networks (GANs). Needless to say, recent years have witnessed a remarkable resurgence in statistical analyses of the GANs. Similar examinations for Autoencoders however, despite their diverse applicability and notable empirical performance, remain largely absent. To close this gap, in this paper, we investigate the statistical properties of WAE. Firstly, we provide statistical guarantees that WAE achieves the target distribution in the latent space, utilizing the Vapnikâ€“Chervonenkis (VC) theory. The main result, consequently ensures the regeneration of the input distribution, harnessing the potential offered by Optimal Transport of measures under the Wasserstein metric. This study, in turn, hints at the class of distributions WAE can reconstruct after suffering a compression in the form of a latent law. ",
      "tldr": "",
      "site_url": "https://nips.cc/virtual/2021/poster/27496",
      "pdf_url": "https://openreview.net/pdf?id=iFadi3f5V5I",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Swagatam_Das2_1",
        "name": "Swagatam Das",
        "name_site": null,
        "openreview_id": "~Swagatam_Das1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.isical.ac.in/~swagatam.das/",
        "dblp_id": "00/3298.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=L8XYpAwAAAAJ",
        "orcid": "0000-0001-6843-4508",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Statistical Institute (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 9,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "kuK2VARZGnI",
      "title": "Towards Efficient and Effective Adversarial Training",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The vulnerability of Deep Neural Networks to adversarial attacks has spurred immense interest towards improving their robustness. However, present state-of-the-art adversarial defenses involve the use of 10-step adversaries during training, which renders them computationally infeasible for application to large-scale datasets. While the recent single-step defenses show promising direction, their robustness is not on par with multi-step training methods. In this work, we bridge this performance gap by introducing a novel Nuclear-Norm regularizer on network predictions to enforce function smoothing in the vicinity of data samples.  While prior works consider each data sample independently, the proposed regularizer uses the joint statistics of adversarial samples across a training minibatch to enhance optimization during both attack generation and training, obtaining state-of-the-art results amongst efficient defenses. We achieve further gains by incorporating exponential averaging of network weights over training iterations. We finally introduce a Hybrid training approach that combines the effectiveness of a two-step variant of the proposed defense with the efficiency of a single-step defense. We demonstrate superior results when compared to multi-step defenses such as TRADES and PGD-AT as well, at a significantly lower computational cost.",
      "tldr": "We propose methods to improve the efficiency and effectiveness of Adversarial Training",
      "site_url": "https://nips.cc/virtual/2021/poster/26270",
      "pdf_url": "https://openreview.net/pdf?id=kuK2VARZGnI",
      "github_url": "https://github.com/val-iisc/NuAT",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Gaurang_Sriramanan1",
        "name": "Gaurang Sriramanan",
        "name_site": "Gaurang Sriramanan, Sravanti Addepalli, Arya Baburaj, Venkatesh Babu R",
        "openreview_id": "~Gaurang_Sriramanan1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://gaurangsriramanan.github.io/",
        "dblp_id": "262/3916",
        "google_scholar_url": "t76Uk8oAAAAJ",
        "orcid": null,
        "linkedin_url": "gaurang-sriramanan-16141a1a3/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 0.0,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 84,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nqutwR1WDBY",
      "title": "On The Structure of Parametric Tournaments with Application to Ranking from Pairwise Comparisons",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": " We consider the classical problem of finding the minimum feedback arc set on tournaments (MFAST). The problem is NP-hard in general and we study it for important classes of tournaments that arise naturally in the problem of learning to rank from pairwise comparisons. Specifically, we consider tournaments classes that arise out of parametric preference matrices that can lead to cyclic preference relations. We investigate their structural properties via forbidden sub tournament configurations.  Towards this, we introduce \\emph{Tournament Dimension} - a combinatorial parameter that characterizes the size of a forbidden configuration for rank $r$ tournament classes i.e., classes that arise out pairwise preference matrices which lead to rank $r$ skew-symmetric matrices under a suitable link function. Our main result is a polynomial-time algorithm - \\texttt{Rank2Rank} - that solves the MFAST problem for the rank $2$ tournament class. This is achieved via a  geometric characterization that relies on our explicit construction of a forbidden configuration for this class. \n \n Building on our understanding of the rank-$2$ tournament class, we propose a very general and flexible parametric pairwise preference model called the local-global model which subsumes the popular Bradley-Terry-Luce/Thurstone classes to capture locally cyclic as well as globally acyclic preference relations. We develop a polynomial-time algorithm - \\texttt{BlockRank2Rank}- to solve the MFAST problem on the associated Block-Rank $2$ tournament class.\n \n As an application, we study the problem of learning to rank from pairwise comparisons under the proposed local-global preference model. Exploiting our structural characterization, we propose  \\texttt{PairwiseBlockRank} - a pairwise ranking algorithm for this class. We show sample complexity bounds of \\texttt{PairwiseBlockRank}  to learn a good ranking under the proposed model.  Finally, we conduct experiments on synthetic and real-world datasets to show the efficacy of the proposed algorithm.",
      "tldr": "We solve the minimum feedback arc set in poly-time for a class of tournaments that arise in learning to rank and use it to develop flexible parametric pairwise preference models that can model intransitivity.",
      "site_url": "https://nips.cc/virtual/2021/poster/26683",
      "pdf_url": "https://openreview.net/pdf?id=nqutwR1WDBY",
      "github_url": "https://github.com/Vishnu-Veerathu/br2r)",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vishnu_Veerathu1",
        "name": "Vishnu Veerathu",
        "name_site": "Vishnu Veerathu, Arun Rajkumar",
        "openreview_id": "~Vishnu_Veerathu1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/vishnuveerathu/home",
        "dblp_id": null,
        "google_scholar_url": "6SMwj7oAAAAJ",
        "orcid": null,
        "linkedin_url": "vishnu-veerathu-3a61b814b/?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "rsNBA9gtDf4",
      "title": "Aligning Silhouette Topology for Self-Adaptive 3D Human Pose Recovery",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Articulation-centric 2D/3D pose supervision forms the core training objective in most existing 3D human pose estimation techniques. Except for synthetic source environments, acquiring such rich supervision for each real target domain at deployment is highly inconvenient. However, we realize that standard foreground silhouette estimation techniques (on static camera feeds) remain unaffected by domain-shifts. Motivated by this, we propose a novel target adaptation framework that relies only on silhouette supervision to adapt a source-trained model-based regressor. However, in the absence of any auxiliary cue (multi-view, depth, or 2D pose), an isolated silhouette loss fails to provide a reliable pose-specific gradient and requires to be employed in tandem with a topology-centric loss. To this end, we develop a series of convolution-friendly spatial transformations in order to disentangle a topological-skeleton representation from the raw silhouette. Such a design paves the way to devise a Chamfer-inspired spatial topological-alignment loss via distance field computation, while effectively avoiding any gradient hindering spatial-to-pointset mapping. Experimental results demonstrate our superiority against prior-arts in self-adapting a source trained model to diverse unlabeled target domains, such as a) in-the-wild datasets, b) low-resolution image domains, and c) adversarially perturbed image domains (via UAP). ",
      "tldr": "A self-supervised domain adaptation framework for 3D human pose recovery using only silhouettes via topological alignment.",
      "site_url": "https://nips.cc/virtual/2021/poster/26665",
      "pdf_url": "https://openreview.net/pdf?id=rsNBA9gtDf4",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jogendra_Nath_Kundu2",
        "name": "Jogendra Nath Kundu",
        "name_site": "Jogendra Nath Kundu, Siddharth Seth, Anirudh Jamkhandi, Pradyumna YM, Varun Jampani, Anirban Chakraborty, Venkatesh Babu R",
        "openreview_id": "~Jogendra_Nath_Kundu2",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/jogendra",
        "dblp_id": "185/0812",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=Xa44GDEAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.5,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 11,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sKWgT8WppC3",
      "title": "Multi-Armed Bandits with Bounded Arm-Memory: Near-Optimal Guarantees for Best-Arm Identification and Regret Minimization",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We study the Stochastic Multi-armed Bandit problem under bounded arm-memory. In this setting, the arms arrive in a stream, and the number of arms that can be stored in the memory at any time, is bounded. The decision-maker can only pull arms that are present in the memory.  \nWe address the problem from the perspective of two standard objectives: 1) regret minimization, and 2) best-arm identification. For regret minimization, we settle an important open question by showing an almost tight guarantee. We show $\\Omega(T^{2/3})$ cumulative regret in expectation for single-pass algorithms for arm-memory size of $(n-1)$, where $n$ is the number of arms. For best-arm identification, we provide an $(\\varepsilon, \\delta)$-PAC algorithm with arm memory size of $O(\\log^*n)$ and $O(\\frac{n}{\\varepsilon^2}\\cdot \\log(\\frac{1}{\\delta}))$ optimal sample complexity. ",
      "tldr": "",
      "site_url": "https://nips.cc/virtual/2021/poster/28714",
      "pdf_url": "https://openreview.net/pdf?id=sKWgT8WppC3",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arnab_Maiti1",
        "name": "Arnab Maiti",
        "name_site": "Arnab Maiti, Vishakha Patil, Arindam Khan",
        "openreview_id": "~Arnab_Maiti1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/arnab-maiti/home",
        "dblp_id": "279/6554",
        "google_scholar_url": "cy9QSHoAAAAJ",
        "orcid": "0000-0002-9142-6255",
        "linkedin_url": "arnab-maiti-ab9446203/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 1.118033988749895,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 19,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "yrmvFIh_e5o",
      "title": "$\\texttt{LeadCache}$: Regret-Optimal Caching in Networks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We consider an online prediction problem in the context of network caching. Assume that multiple users are connected to several caches via a bipartite network. At any time slot, each user may request an arbitrary file chosen from a large catalog. A user's request at a slot is met if the requested file is cached in at least one of the caches connected to the user. Our objective is to predict, prefetch, and optimally distribute the files on the caches at each slot to maximize the total number of cache hits. The problem is non-trivial due to the non-convex and non-smooth nature of the objective function. In this paper, we propose $\\texttt{LeadCache}$ - an efficient online caching policy based on the Follow-the-Perturbed-Leader paradigm. We show that $\\texttt{LeadCache}$ is regret-optimal up to a factor of $\\tilde{O}(n^{3/8}),$ where $n$ is the number of users. We design two efficient implementations of the $\\texttt{LeadCache}$ policy, one based on Pipage rounding and the other based on Madow's sampling, each of which makes precisely one call to an LP-solver per iteration. Furthermore, with a Strong-Law-type assumption, we show that the total number of file fetches under $\\texttt{LeadCache}$ remains almost surely finite over an infinite horizon. Finally, we derive an approximately tight regret lower bound using results from graph coloring. We conclude that the learning-based $\\texttt{LeadCache}$ policy decisively outperforms the state-of-the-art caching policies both theoretically and empirically.",
      "tldr": "We design a new online network caching policy.",
      "site_url": "https://nips.cc/virtual/2021/poster/28203",
      "pdf_url": "https://openreview.net/pdf?id=yrmvFIh_e5o",
      "github_url": "https://github.com/AbhishekMITIITM/LeadCache-NeurIPS21",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Debjit_Paria1",
        "name": "Debjit Paria",
        "name_site": "Debjit Paria, Abhishek Sinha",
        "openreview_id": "~Debjit_Paria1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "4PVsh5gAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Chennai Mathematical Institute (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 1.118033988749895,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "4wVlNqBJXg",
      "title": "Optimal Best-Arm Identification Methods for Tail-Risk Measures",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Conditional value-at-risk (CVaR) and value-at-risk (VaR) are popular tail-risk measures in finance and insurance industries as well as in highly reliable, safety-critical uncertain environments where often the underlying probability distributions are heavy-tailed. We use the multi-armed bandit best-arm identification framework and consider the problem of identifying the arm from amongst finitely many that has the smallest CVaR, VaR, or weighted sum of CVaR and mean. The latter captures the risk-return trade-off common in finance. Our main contribution is an optimal $\\delta$-correct algorithm that acts on general arms, including heavy-tailed distributions, and matches the lower bound on the expected number of samples needed, asymptotically (as $ \\delta$ approaches $0$). The algorithm requires solving a non-convex optimization problem in the space of probability measures, that requires delicate analysis. En-route, we develop new non-asymptotic, anytime-valid, empirical-likelihood-based concentration inequalities for tail-risk measures. ",
      "tldr": "We consider the best-arm identification problem in the multi-armed bandit framework where an arm with the smallest tail-risk measure is identified. ",
      "site_url": "https://nips.cc/virtual/2021/poster/26325",
      "pdf_url": "https://openreview.net/pdf?id=4wVlNqBJXg",
      "github_url": "/attachment/0330a775cffa6156f4aa134eaba674f1dd17291e.zip",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sandeep_Kumar_Juneja1",
        "name": "Sandeep Kumar Juneja",
        "name_site": null,
        "openreview_id": "~Sandeep_Kumar_Juneja1",
        "position": 3,
        "gender": "M",
        "homepage_url": "http://www.tcs.tifr.res.in/~sandeepj/",
        "dblp_id": "98/5399.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=Tfgv6VgAAAAJ",
        "orcid": null,
        "linkedin_url": "sandeep-juneja-937b44b/?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tata Institute of Fundamental Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 0.0,
        "confidence_mean": 3.0,
        "confidence_std": 0.6324555320336759,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 53,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "7CKWdq2yQv",
      "title": "Active Assessment of Prediction Services as Accuracy Surface Over Attribute Combinations",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Our goal is to evaluate the accuracy of a black-box classification model, not as a single aggregate on a given test data distribution, but as a surface over a large number of combinations of attributes characterizing multiple test data distributions.  Such attributed accuracy measures become important as machine learning models get deployed as a service, where the training data distribution is hidden from clients, and different clients may be interested in diverse regions of the data distribution. We present Attributed Accuracy Assay (AAA) --- a Gaussian Process (GP)-based probabilistic estimator for such an accuracy surface. Each attribute combination, called an 'arm' is associated with a Beta density from which the service's accuracy is sampled.  We expect the GP to smooth the parameters of the Beta density over related arms to mitigate sparsity. We show that obvious application of GPs cannot address the challenge of heteroscedastic uncertainty over a huge attribute space that is sparsely and unevenly populated. In response, we present two enhancements: pooling sparse observations, and regularizing the scale parameter of the Beta densities. After introducing these innovations, we establish the effectiveness of AAA both in terms of its estimation accuracy and exploration efficiency, through extensive experiments and analysis.",
      "tldr": "Prediction Services should go beyond scalar accuracy and instead report performance on attribute combinations characterizing a clientâ€™s utility. Read our paper for how we can estimate accuracy for combinatorially large attribute combinations.",
      "site_url": "https://nips.cc/virtual/2021/poster/27414",
      "pdf_url": "https://openreview.net/pdf?id=7CKWdq2yQv",
      "github_url": "https://github.com/vihari/AAA",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sunita_Sarawagi1",
        "name": "Sunita Sarawagi",
        "name_site": null,
        "openreview_id": "~Sunita_Sarawagi1",
        "position": 3,
        "gender": "F",
        "homepage_url": "https://www.cse.iitb.ac.in/~sunita/",
        "dblp_id": "s/SunitaSarawagi",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=Hg4HmTAAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 5,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "AIQOddM5Xm",
      "title": "Non-local Latent Relation Distillation for Self-Adaptive 3D Human Pose Estimation",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Available 3D human pose estimation approaches leverage different forms of strong (2D/3D pose) or weak (multi-view or depth) paired supervision. Barring synthetic or in-studio domains, acquiring such supervision for each new target environment is highly inconvenient. To this end, we cast 3D pose learning as a self-supervised adaptation problem that aims to transfer the task knowledge from a labeled source domain to a completely unpaired target. We propose to infer image-to-pose via two explicit mappings viz. image-to-latent and latent-to-pose where the latter is a pre-learned decoder obtained from a prior-enforcing generative adversarial auto-encoder. Next, we introduce relation distillation as a means to align the unpaired cross-modal samples i.e., the unpaired target videos and unpaired 3D pose sequences. To this end, we propose a new set of non-local relations in order to characterize long-range latent pose interactions, unlike general contrastive relations where positive couplings are limited to a local neighborhood structure. Further, we provide an objective way to quantify non-localness in order to select the most effective relation set. We evaluate different self-adaptation settings and demonstrate state-of-the-art 3D human pose estimation performance on standard benchmarks.",
      "tldr": "We introduce relation distillation as a means to align the unpaired cross-modal samples i.e., unpaired target videos and unpaired 3D pose sequences for self-adapting 3D human pose estimation.",
      "site_url": "https://nips.cc/virtual/2021/poster/26641",
      "pdf_url": "https://openreview.net/pdf?id=AIQOddM5Xm",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Venkatesh_Babu_Radhakrishnan2",
        "name": "Venkatesh Babu Radhakrishnan",
        "name_site": null,
        "openreview_id": "~Varun_Jampani1",
        "position": 7,
        "gender": "M",
        "homepage_url": "https://varunjampani.github.io/",
        "dblp_id": "124/2785",
        "google_scholar_url": "1Cv6Sf4AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 12,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "CsV-Gms_JKy",
      "title": "Optimal Rates for Nonparametric Density Estimation under Communication Constraints",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We consider density estimation for Besov spaces when the estimator is restricted to use only a limited number of bits about each sample. We provide a noninteractive adaptive estimator which exploits the sparsity of wavelet bases, along with a simulate-and-infer technique from parametric estimation under communication constraints. We show that our estimator is nearly rate-optimal by deriving minmax lower bounds that hold even when interactive protocols are allowed. Interestingly, while our wavelet-based estimator is almost rate-optimal for Sobolev spaces as well, it is unclear whether the standard Fourier basis, which arise naturally for those spaces, can be used to achieve the same performance.",
      "tldr": "We prove (nearly) optimal minimax bounds for nonparametric density estimation under communication (bandwidth) constraints.",
      "site_url": "https://nips.cc/virtual/2021/poster/27671",
      "pdf_url": "https://openreview.net/pdf?id=CsV-Gms_JKy",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Himanshu_Tyagi1",
        "name": "Himanshu Tyagi",
        "name_site": null,
        "openreview_id": "~Himanshu_Tyagi1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "11/4803",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.5,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 14,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "GfVeFihyLRe",
      "title": "Distributed Estimation with Multiple Samples per User: Sharp Rates and Phase Transition",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We obtain tight minimax rates for the problem of distributed estimation of discrete distributions under communication constraints, where $n$ users observing $m $ samples each can broadcast only $\\ell$  bits. Our main result is a tight characterization (up to logarithmic factors) of the error rate as a function of $m$, $\\ell$, the domain size, and the number of users under most regimes of interest. While previous work focused on the setting where each user only holds one sample, we show that as $m$ grows the $\\ell_1$ error rate gets reduced by a factor of $\\sqrt{m}$ for small $m$. However, for large $m$ we observe an interesting phase transition: the dependence of the error rate on the communication constraint $\\ell$ changes from $1/\\sqrt{2^{\\ell}}$ to $1/\\sqrt{\\ell}$.",
      "tldr": "We provide tight upper and lower bounds for distributed estimation of discrete probability distributions as a function of all parameters, when each of n users holds m samples but can only send L bits.",
      "site_url": "https://nips.cc/virtual/2021/poster/26526",
      "pdf_url": "https://openreview.net/pdf?id=GfVeFihyLRe",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Himanshu_Tyagi1",
        "name": "Himanshu Tyagi",
        "name_site": null,
        "openreview_id": "~Himanshu_Tyagi1",
        "position": 5,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "11/4803",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.5,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 13,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "MckiHYXsBT",
      "title": "Learning to Select Exogenous Events for Marked Temporal Point Process",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Marked temporal point processes (MTPPs) have emerged as a powerful modeling\ntool for a wide variety of applications which are characterized using discrete\nevents localized in continuous time. In this context, the events are of two types\nendogenous events which occur due to the influence of the previous events and\nexogenous events which occur due to the effect of the externalities. However, in\npractice, the events do not come with endogenous or exogenous labels. To this\nend, our goal in this paper is to identify the set of exogenous events from a set of\nunlabelled events. To do so, we first formulate the parameter estimation problem\nin conjunction with exogenous event set selection problem and show that this\nproblem is NP hard. Next, we prove that the underlying objective is a monotone\nand \\alpha-submodular set function, with respect to the candidate set of exogenous\nevents. Such a characterization subsequently allows us to use a stochastic greedy\nalgorithm which was originally proposed in~\\cite{greedy}for submodular maximization.\nHowever, we show that it also admits an approximation guarantee for maximizing\n\\alpha-submodular set function, even when the learning algorithm provides an imperfect\nestimates of the trained parameters. Finally, our experiments with synthetic and\nreal data show that our method performs better than the existing approaches built\nupon superposition of endogenous and exogenous MTPPs.",
      "tldr": "It learns to select exogenous events from a set of  events in the context of marked temporal point processes",
      "site_url": "https://nips.cc/virtual/2021/poster/26623",
      "pdf_url": "https://openreview.net/pdf?id=MckiHYXsBT",
      "github_url": "https://github.com/noilreed/TPP-Select",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abir_De1",
        "name": "Abir De",
        "name_site": null,
        "openreview_id": "~Abir_De1",
        "position": 5,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "118/7174",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=_9ZKKbIAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 10,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "MqCzSKCQ1QB",
      "title": "Adversarial Robustness without Adversarial Training: A Teacher-Guided Curriculum Learning Approach",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Current SOTA adversarially robust models are mostly based on adversarial training (AT) and differ only by some regularizers either at inner maximization or outer minimization steps. Being repetitive in nature during the inner maximization step, they take a huge time to train. We propose a non-iterative method that enforces the following ideas during training. Attribution maps are more aligned to the actual object in the image for adversarially robust models compared to naturally trained models. Also, the allowed set of pixels to perturb an image (that changes model decision) should be restricted to the object pixels only, which reduces the attack strength by limiting the attack space. Our method achieves significant performance gains with a little extra effort (10-20%) over existing AT models and outperforms all other methods in terms of adversarial as well as natural accuracy. We have performed extensive experimentation with CIFAR-10, CIFAR-100, and TinyImageNet datasets and reported results against many popular strong adversarial attacks to prove the effectiveness of our method.",
      "tldr": "We propose a non-iterative robust training technique which takes 10-20% time over existing adversarial training (AT) based models and outperforms strong baselines for both adversarial as well as natural accuracies.",
      "site_url": "https://nips.cc/virtual/2021/poster/26314",
      "pdf_url": "https://openreview.net/pdf?id=MqCzSKCQ1QB",
      "github_url": "https://github.com/sowgali/Get-Fooled-for-the-Right-Reason",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vineeth_N._Balasubramanian2",
        "name": "Vineeth N. Balasubramanian",
        "name_site": null,
        "openreview_id": "~Vineeth_Balasubramanian1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://people.iith.ac.in/vineethnb/",
        "dblp_id": "88/4691",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=7soDcboAAAAJ",
        "orcid": "0000-0003-2656-0375",
        "linkedin_url": "vineethnb?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 8,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Sl0WX9H6ZJg",
      "title": "NeuroMLR: Robust & Reliable Route Recommendation on Road Networks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Predicting the most likely route from a source location to a destination is a core functionality in mapping services. Although the problem has been studied in the literature, two key limitations remain to be addressed. First, our study reveals that a significant portion of the routes recommended by existing methods fail to reach the destination. Second, existing techniques are transductive in nature; hence, they fail to recommend routes if unseen roads are encountered at inference time. In this paper, we address these limitations through an inductive algorithm called NeuroMLR. NeuroMLR learns a generative model from historical trajectories by conditioning on three explanatory factors: the current location, the destination, and real-time traffic conditions. The conditional distributions are learned through a novel combination of Lipschitz embedding with Graph Convolutional Networks (GCN) using historical trajectory data. Through in-depth experiments on real-world datasets, we establish that NeuroMLR imparts significant improvement in accuracy over the state of the art. More importantly, NeuroMLR generalizes dramatically better to unseen data and the recommended routes reach the destination with much higher likelihood than existing techniques.",
      "tldr": "Predicting the most likely route in a road network via Lipschitz embedding and GCN, achieving significantly high reachability and better generalisation to unseen data.",
      "site_url": "https://nips.cc/virtual/2021/poster/26807",
      "pdf_url": "https://openreview.net/pdf?id=Sl0WX9H6ZJg",
      "github_url": "https://github.com/idea-iitd/NeuroMLR",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sayan_Ranu2",
        "name": "Sayan Ranu",
        "name_site": null,
        "openreview_id": "~Sayan_Ranu2",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://www.cse.iitd.ac.in/~sayan/index.html",
        "dblp_id": "38/768",
        "google_scholar_url": "K4w5qYUAAAAJ",
        "orcid": "0000-0003-4147-9372",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 27,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "T1f0YKPP_K",
      "title": "Robust Visual Reasoning via Language Guided Neural Module Networks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Neural module networks (NMN) are a popular approach for solving multi-modal tasks such as visual question answering (VQA) and visual referring expression recognition (REF). A key limitation in prior implementations of NMN is that the neural modules do not effectively capture the association between the visual input and the relevant neighbourhood context of the textual input. This limits their generalizability. For instance, NMN fail to understand new concepts such as â€œyellow sphere to the left\" even when it is a combination of known concepts from train data: â€œblue sphere\", â€œyellow cube\", and â€œmetallic cube to the left\". In this paper, we address this limitation by introducing a language-guided adaptive convolution layer (LG-Conv) into NMN, in which the filter weights of convolutions are explicitly multiplied with a spatially varying language-guided kernel. Our model allows the neural module to adaptively co-attend over potential objects of interest from the visual and textual inputs. Extensive experiments on VQA and REF tasks demonstrate the effectiveness of our approach. Additionally, we propose a new challenging out-of-distribution test split for REF task, which we call C3-Ref+, for explicitly evaluating the NMNâ€™s ability to generalize well to adversarial perturbations and unseen combinations of known concepts. Experiments on C3-Ref+ further demonstrate the generalization capabilities of our approach.",
      "tldr": "Robust Visual Reasoning via Language Guided Neural Module Networks",
      "site_url": "https://nips.cc/virtual/2021/poster/26971",
      "pdf_url": "https://openreview.net/pdf?id=T1f0YKPP_K",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Venkatesh_Babu_Radhakrishnan2",
        "name": "Venkatesh Babu Radhakrishnan",
        "name_site": null,
        "openreview_id": "~Varun_Jampani1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://varunjampani.github.io/",
        "dblp_id": "124/2785",
        "google_scholar_url": "1Cv6Sf4AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.0,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 27,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "U7SBcmRf65",
      "title": "Training for the Future: A Simple Gradient Interpolation Loss to Generalize Along Time",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In several real world applications, machine learning models are deployed to make predictions on data whose distribution changes gradually along time, leading to a drift between the train and test distributions. Such models are often re-trained on new data periodically, and they hence need to generalize to data not too far into the future. In this context, there is much prior work on enhancing temporal generalization, e.g. continuous transportation of past data, kernel smoothed time-sensitive parameters and more recently, adversarial learning of time-invariant features. However, these methods share several limitations, e.g, poor scalability, training instability, and dependence on unlabeled data from the future. Responding to the above limitations, we propose a simple method that starts with a model with time-sensitive parameters but regularizes its temporal complexity using a Gradient Interpolation  (GI) loss. GI allows the decision boundary to change along time and can still prevent overfitting to the limited training time snapshots  by allowing task-specific control over changes along time. We compare our method to existing baselines on multiple real-world datasets, which show that GI outperforms more complicated generative and adversarial approaches on the one hand, and simpler gradient regularization methods on the other.",
      "tldr": "We propose a simple gradient interpolation loss to enable models to generalize to unseen future data.",
      "site_url": "https://nips.cc/virtual/2021/poster/27251",
      "pdf_url": "https://openreview.net/pdf?id=U7SBcmRf65",
      "github_url": "https://github.com/anshuln/Training-for-the-Future",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sunita_Sarawagi1",
        "name": "Sunita Sarawagi",
        "name_site": null,
        "openreview_id": "~Sunita_Sarawagi1",
        "position": 5,
        "gender": "F",
        "homepage_url": "https://www.cse.iitb.ac.in/~sunita/",
        "dblp_id": "s/SunitaSarawagi",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=Hg4HmTAAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 31,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "a1wQOh27zcy",
      "title": "Contrast and Mix: Temporal Contrastive Video Domain Adaptation with Background Mixing",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Unsupervised domain adaptation which aims to adapt models trained on a labeled source domain to a completely unlabeled target domain has attracted much attention in recent years. While many domain adaptation techniques have been proposed for images, the problem of unsupervised domain adaptation in videos remains largely underexplored. In this paper, we introduce Contrast and Mix (CoMix), a new contrastive learning framework that aims to learn discriminative invariant feature representations for unsupervised video domain adaptation. First, unlike existing methods that rely on adversarial learning for feature alignment, we utilize temporal contrastive learning to bridge the domain gap by maximizing the similarity between encoded representations of an unlabeled video at two different speeds as well as minimizing the similarity between different videos played at different speeds. Second, we propose a novel extension to the temporal contrastive loss by using background mixing that allows additional positives per anchor, thus adapting contrastive learning to leverage action semantics shared across both domains. Moreover, we also integrate a supervised contrastive learning objective using target pseudo-labels to enhance discriminability of the latent space for video domain adaptation. Extensive experiments on several benchmark datasets demonstrate the superiority of our proposed approach over state-of-the-art methods. Project page: https://cvir.github.io/projects/comix.",
      "tldr": "A new temporal contrastive learning approach for unsupervised video domain adaptation.",
      "site_url": "https://nips.cc/virtual/2021/poster/26751",
      "pdf_url": "https://openreview.net/pdf?id=a1wQOh27zcy",
      "github_url": "https://cvir.github.io/projects/comix",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abir_Das4",
        "name": "Abir Das",
        "name_site": null,
        "openreview_id": "~Abir_Das4",
        "position": 5,
        "gender": "M",
        "homepage_url": "http://cse.iitkgp.ac.in/~adas/",
        "dblp_id": "141/1311",
        "google_scholar_url": "L4yEk2UAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 81,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "bayZPpw9lM",
      "title": "Counterexample Guided RL Policy Refinement Using Bayesian Optimization",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Constructing Reinforcement Learning (RL) policies that adhere to safety requirements is an emerging field of study. RL agents learn via trial and error with an objective to optimize a reward signal. Often policies that are designed to accumulate rewards do not satisfy safety specifications. We present a methodology for counterexample guided refinement of a trained RL policy against a given safety specification. Our approach has two main components. The first component is an approach to discover failure trajectories using Bayesian optimization over multiple parameters of uncertainty from a policy learnt in a model-free setting. The second component selectively modifies the failure points of the policy using gradient-based updates. The approach has been tested on several RL environments, and we demonstrate that the policy can be made to respect the safety specifications through such targeted changes.",
      "tldr": "A methodology to discover counter-examples from a trained RL policy and revise the policy to a safer new policy not having the counter-examples. ",
      "site_url": "https://nips.cc/virtual/2021/poster/27698",
      "pdf_url": "https://openreview.net/pdf?id=bayZPpw9lM",
      "github_url": "https://github.com/britig/policy-refinement-bo",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Pallab_Dasgupta1",
        "name": "Pallab Dasgupta",
        "name_site": null,
        "openreview_id": "~Pallab_Dasgupta1",
        "position": 2,
        "gender": "M",
        "homepage_url": "http://cse.iitkgp.ac.in/~pallab/",
        "dblp_id": "39/2452.html",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=Pw4jS9sAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 12,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "fATZNtA1-V0",
      "title": "Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Decomposing a scene into its shape, reflectance and illumination is a fundamental problem in computer vision and graphics. Neural approaches such as NeRF have achieved remarkable success in view synthesis, but do not explicitly perform decomposition and instead operate exclusively on radiance (the product of reflectance and illumination). Extensions to NeRF, such as NeRD, can perform decomposition but struggle to accurately recover detailed illumination, thereby significantly limiting realism. We propose a novel reflectance decomposition network that can estimate shape, BRDF, and per-image illumination given a set of object images captured under varying illumination. Our key technique is a novel illumination integration network called Neural-PIL that replaces a costly illumination integral operation in the rendering with a simple network query. In addition, we also learn deep low-dimensional priors on BRDF and illumination representations using novel smooth manifold auto-encoders. Our decompositions can result in considerably better BRDF and light estimates enabling more accurate novel view-synthesis and relighting compared to prior art. Project page: https://markboss.me/publication/2021-neural-pil/",
      "tldr": "A method that decomposes multiple images of a scene into shape, reflectance and illumination using a neural illumination model.",
      "site_url": "https://nips.cc/virtual/2021/poster/26700",
      "pdf_url": "https://openreview.net/pdf?id=fATZNtA1-V0",
      "github_url": "https://github.com/cgtuebingen/Neural-PIL",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Venkatesh_Babu_Radhakrishnan2",
        "name": "Venkatesh Babu Radhakrishnan",
        "name_site": null,
        "openreview_id": "~Varun_Jampani1",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://varunjampani.github.io/",
        "dblp_id": "124/2785",
        "google_scholar_url": "1Cv6Sf4AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 4.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 217,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "h7aSBWbX7S4",
      "title": "Information-constrained optimization: can adaptive processing of gradients help?",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We revisit first-order optimization under local information constraints such as local privacy, gradient quantization, and computational constraints limiting access to a few coordinates of the gradient. In this setting, the optimization algorithm is not allowed to directly access the complete output of the gradient oracle, but only gets limited information about it subject to the local information constraints.   We study the role of adaptivity in processing the gradient output to obtain this limited information from it, and obtain tight or nearly tight bounds for both convex and strongly convex optimization when adaptive gradient processing is allowed.",
      "tldr": "We prove tight bounds on the convergence rate of first-order optimization when the gradients cannot be fully observed (information constraints), but the algorithm can still choose adaptively how to perform those limited observations.",
      "site_url": "https://nips.cc/virtual/2021/poster/28855",
      "pdf_url": "https://openreview.net/pdf?id=h7aSBWbX7S4",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Himanshu_Tyagi1",
        "name": "Himanshu Tyagi",
        "name_site": null,
        "openreview_id": "~Himanshu_Tyagi1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "11/4803",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 13,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "jHAAHg8T7Nx",
      "title": "Stochastic Multi-Armed Bandits with Control Variates",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "This paper studies a new variant of the stochastic multi-armed bandits problem where auxiliary information about the arm rewards is available in the form of control variates. In many applications like queuing and wireless networks, the arm rewards are functions of some exogenous variables. The mean values of these variables are known a priori from historical data and can be used as control variates.  Leveraging the theory of control variates, we obtain mean estimates with smaller variance and tighter confidence bounds. We develop an upper confidence bound based algorithm named UCB-CV and characterize the regret bounds in terms of the correlation between rewards and control variates when they follow a multivariate normal distribution. We also extend UCB-CV to other distributions using resampling methods like Jackknifing and Splitting. Experiments on synthetic problem instances validate performance guarantees of the proposed algorithms.\n\n",
      "tldr": "Multi-Armed Bandits with Control Variates",
      "site_url": "https://nips.cc/virtual/2021/poster/26935",
      "pdf_url": "https://openreview.net/pdf?id=jHAAHg8T7Nx",
      "github_url": "https://github.com/arunv3rma/NeurIPS-2021",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manjesh_Kumar_Hanawal1",
        "name": "Manjesh Kumar Hanawal",
        "name_site": null,
        "openreview_id": "~Manjesh_Kumar_Hanawal1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.ieor.iitb.ac.in/mlions",
        "dblp_id": "01/8397",
        "google_scholar_url": "vtVK3KUAAAAJ",
        "orcid": "0000-0002-1807-5487",
        "linkedin_url": "manjesh-kumar-hanawal-a260055/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "jSz59N8NvUP",
      "title": "RETRIEVE: Coreset Selection for Efficient and Robust Semi-Supervised Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Semi-supervised learning (SSL) algorithms have had great success in recent years in limited labeled data regimes. However, the current state-of-the-art SSL algorithms are computationally expensive and entail significant compute time and energy requirements. This can prove to be a huge limitation for many smaller companies and academic groups. Our main insight is that training on a subset of unlabeled data instead of entire unlabeled data enables the current SSL algorithms to converge faster, significantly reducing computational costs. In this work, we propose RETRIEVE, a coreset selection framework for efficient and robust semi-supervised learning. RETRIEVE selects the coreset by solving a mixed discrete-continuous bi-level optimization problem such that the selected coreset minimizes the labeled set loss. We use a one-step gradient approximation and show that the discrete optimization problem is approximately submodular, enabling simple greedy algorithms to obtain the coreset. We empirically demonstrate on several real-world datasets that existing SSL algorithms like VAT, Mean-Teacher, FixMatch, when used with RETRIEVE, achieve a) faster training times,  b) better performance when unlabeled data consists of Out-of-Distribution (OOD) data and imbalance. More specifically, we show that with minimal accuracy degradation, RETRIEVE achieves a speedup of around $3\\times$ in the traditional SSL setting and achieves a speedup of $5\\times$ compared to state-of-the-art (SOTA) robust SSL algorithms in the case of imbalance and OOD data. RETRIEVE is available as a part of the CORDS toolkit: https://github.com/decile-team/cords.",
      "tldr": "Training Semi-supervised algorithms on a Coreset of Unlabeled data for faster convergence and robust learning.",
      "site_url": "https://nips.cc/virtual/2021/poster/26930",
      "pdf_url": "https://openreview.net/pdf?id=jSz59N8NvUP",
      "github_url": "https://github.com/decile-team/cords",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rishabh_K_Iyer2",
        "name": "Rishabh K Iyer",
        "name_site": null,
        "openreview_id": "~Rishabh_K_Iyer2",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://www.rishiyer.com",
        "dblp_id": "37/10544.html",
        "google_scholar_url": "l_XxJ1kAAAAJ",
        "orcid": null,
        "linkedin_url": "rishabh-iyer-36893717/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.5,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 98,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "kuK2VARZGnI",
      "title": "Towards Efficient and Effective Adversarial Training",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The vulnerability of Deep Neural Networks to adversarial attacks has spurred immense interest towards improving their robustness. However, present state-of-the-art adversarial defenses involve the use of 10-step adversaries during training, which renders them computationally infeasible for application to large-scale datasets. While the recent single-step defenses show promising direction, their robustness is not on par with multi-step training methods. In this work, we bridge this performance gap by introducing a novel Nuclear-Norm regularizer on network predictions to enforce function smoothing in the vicinity of data samples.  While prior works consider each data sample independently, the proposed regularizer uses the joint statistics of adversarial samples across a training minibatch to enhance optimization during both attack generation and training, obtaining state-of-the-art results amongst efficient defenses. We achieve further gains by incorporating exponential averaging of network weights over training iterations. We finally introduce a Hybrid training approach that combines the effectiveness of a two-step variant of the proposed defense with the efficiency of a single-step defense. We demonstrate superior results when compared to multi-step defenses such as TRADES and PGD-AT as well, at a significantly lower computational cost.",
      "tldr": "We propose methods to improve the efficiency and effectiveness of Adversarial Training",
      "site_url": "https://nips.cc/virtual/2021/poster/26270",
      "pdf_url": "https://openreview.net/pdf?id=kuK2VARZGnI",
      "github_url": "https://github.com/val-iisc/NuAT",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anirban_Chakraborty1",
        "name": "Anirban Chakraborty",
        "name_site": null,
        "openreview_id": "~Venkatesh_Babu_Radhakrishnan2",
        "position": 4,
        "gender": "M",
        "homepage_url": "http://cds.iisc.ac.in/faculty/venky",
        "dblp_id": "20/6289",
        "google_scholar_url": "cVg7HrEAAAAJ",
        "orcid": "0000-0002-1926-1804",
        "linkedin_url": "venkatesh-babu-radhakrishnan-16568939",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 0.0,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 84,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nqutwR1WDBY",
      "title": "On The Structure of Parametric Tournaments with Application to Ranking from Pairwise Comparisons",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": " We consider the classical problem of finding the minimum feedback arc set on tournaments (MFAST). The problem is NP-hard in general and we study it for important classes of tournaments that arise naturally in the problem of learning to rank from pairwise comparisons. Specifically, we consider tournaments classes that arise out of parametric preference matrices that can lead to cyclic preference relations. We investigate their structural properties via forbidden sub tournament configurations.  Towards this, we introduce \\emph{Tournament Dimension} - a combinatorial parameter that characterizes the size of a forbidden configuration for rank $r$ tournament classes i.e., classes that arise out pairwise preference matrices which lead to rank $r$ skew-symmetric matrices under a suitable link function. Our main result is a polynomial-time algorithm - \\texttt{Rank2Rank} - that solves the MFAST problem for the rank $2$ tournament class. This is achieved via a  geometric characterization that relies on our explicit construction of a forbidden configuration for this class. \n \n Building on our understanding of the rank-$2$ tournament class, we propose a very general and flexible parametric pairwise preference model called the local-global model which subsumes the popular Bradley-Terry-Luce/Thurstone classes to capture locally cyclic as well as globally acyclic preference relations. We develop a polynomial-time algorithm - \\texttt{BlockRank2Rank}- to solve the MFAST problem on the associated Block-Rank $2$ tournament class.\n \n As an application, we study the problem of learning to rank from pairwise comparisons under the proposed local-global preference model. Exploiting our structural characterization, we propose  \\texttt{PairwiseBlockRank} - a pairwise ranking algorithm for this class. We show sample complexity bounds of \\texttt{PairwiseBlockRank}  to learn a good ranking under the proposed model.  Finally, we conduct experiments on synthetic and real-world datasets to show the efficacy of the proposed algorithm.",
      "tldr": "We solve the minimum feedback arc set in poly-time for a class of tournaments that arise in learning to rank and use it to develop flexible parametric pairwise preference models that can model intransitivity.",
      "site_url": "https://nips.cc/virtual/2021/poster/26683",
      "pdf_url": "https://openreview.net/pdf?id=nqutwR1WDBY",
      "github_url": "https://github.com/Vishnu-Veerathu/br2r)",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arun_Rajkumar4",
        "name": "Arun Rajkumar",
        "name_site": null,
        "openreview_id": "~Arun_Rajkumar4",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "32/11350",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "rsNBA9gtDf4",
      "title": "Aligning Silhouette Topology for Self-Adaptive 3D Human Pose Recovery",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Articulation-centric 2D/3D pose supervision forms the core training objective in most existing 3D human pose estimation techniques. Except for synthetic source environments, acquiring such rich supervision for each real target domain at deployment is highly inconvenient. However, we realize that standard foreground silhouette estimation techniques (on static camera feeds) remain unaffected by domain-shifts. Motivated by this, we propose a novel target adaptation framework that relies only on silhouette supervision to adapt a source-trained model-based regressor. However, in the absence of any auxiliary cue (multi-view, depth, or 2D pose), an isolated silhouette loss fails to provide a reliable pose-specific gradient and requires to be employed in tandem with a topology-centric loss. To this end, we develop a series of convolution-friendly spatial transformations in order to disentangle a topological-skeleton representation from the raw silhouette. Such a design paves the way to devise a Chamfer-inspired spatial topological-alignment loss via distance field computation, while effectively avoiding any gradient hindering spatial-to-pointset mapping. Experimental results demonstrate our superiority against prior-arts in self-adapting a source trained model to diverse unlabeled target domains, such as a) in-the-wild datasets, b) low-resolution image domains, and c) adversarially perturbed image domains (via UAP). ",
      "tldr": "A self-supervised domain adaptation framework for 3D human pose recovery using only silhouettes via topological alignment.",
      "site_url": "https://nips.cc/virtual/2021/poster/26665",
      "pdf_url": "https://openreview.net/pdf?id=rsNBA9gtDf4",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Venkatesh_Babu_Radhakrishnan2",
        "name": "Venkatesh Babu Radhakrishnan",
        "name_site": null,
        "openreview_id": "~Varun_Jampani1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://varunjampani.github.io/",
        "dblp_id": "124/2785",
        "google_scholar_url": "1Cv6Sf4AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.5,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 11,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sKWgT8WppC3",
      "title": "Multi-Armed Bandits with Bounded Arm-Memory: Near-Optimal Guarantees for Best-Arm Identification and Regret Minimization",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We study the Stochastic Multi-armed Bandit problem under bounded arm-memory. In this setting, the arms arrive in a stream, and the number of arms that can be stored in the memory at any time, is bounded. The decision-maker can only pull arms that are present in the memory.  \nWe address the problem from the perspective of two standard objectives: 1) regret minimization, and 2) best-arm identification. For regret minimization, we settle an important open question by showing an almost tight guarantee. We show $\\Omega(T^{2/3})$ cumulative regret in expectation for single-pass algorithms for arm-memory size of $(n-1)$, where $n$ is the number of arms. For best-arm identification, we provide an $(\\varepsilon, \\delta)$-PAC algorithm with arm memory size of $O(\\log^*n)$ and $O(\\frac{n}{\\varepsilon^2}\\cdot \\log(\\frac{1}{\\delta}))$ optimal sample complexity. ",
      "tldr": "",
      "site_url": "https://nips.cc/virtual/2021/poster/28714",
      "pdf_url": "https://openreview.net/pdf?id=sKWgT8WppC3",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arindam_Khan1",
        "name": "Arindam Khan",
        "name_site": null,
        "openreview_id": "~Arindam_Khan1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.csa.iisc.ac.in/~arindamkhan/",
        "dblp_id": "https://dblp.uni-trier.de/pid/96/9083-1.html",
        "google_scholar_url": "yRsbV0AAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 1.118033988749895,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 19,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "x_n34KpwAvI",
      "title": "SIMILAR: Submodular Information Measures Based Active Learning In Realistic Scenarios",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Active  learning  has  proven  to  be  useful  for  minimizing  labeling  costs  by selecting  the  most  informative  samples. However,  existing  active  learning methods do not work well in realistic scenarios such as imbalance or rare classes,out-of-distribution data in the unlabeled set, and redundancy.  In this work, we propose SIMILAR (Submodular Information Measures based actIve LeARning), a unified active learning framework using recently proposed submodular information measures (SIM) as acquisition functions. We argue that SIMILAR not only works in standard active learning but also easily extends to the realistic settings considered above and acts as a one-stop solution for active learning that is scalable to large real-world datasets. Empirically, we show that SIMILAR significantly outperforms existing active learning algorithms by as much as ~5%âˆ’18%in the case of rare classes and ~5%âˆ’10%in the case of out-of-distribution data on several image classification tasks like CIFAR-10, MNIST, and ImageNet.",
      "tldr": "A unified active learning framework for active learning in realistic scenarios.",
      "site_url": "https://nips.cc/virtual/2021/poster/26574",
      "pdf_url": "https://openreview.net/pdf?id=x_n34KpwAvI",
      "github_url": "https://github.com/decile-team/distil",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rishabh_K_Iyer2",
        "name": "Rishabh K Iyer",
        "name_site": null,
        "openreview_id": "~Rishabh_K_Iyer2",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://www.rishiyer.com",
        "dblp_id": "37/10544.html",
        "google_scholar_url": "l_XxJ1kAAAAJ",
        "orcid": null,
        "linkedin_url": "rishabh-iyer-36893717/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.5,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 115,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "yrmvFIh_e5o",
      "title": "$\\texttt{LeadCache}$: Regret-Optimal Caching in Networks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We consider an online prediction problem in the context of network caching. Assume that multiple users are connected to several caches via a bipartite network. At any time slot, each user may request an arbitrary file chosen from a large catalog. A user's request at a slot is met if the requested file is cached in at least one of the caches connected to the user. Our objective is to predict, prefetch, and optimally distribute the files on the caches at each slot to maximize the total number of cache hits. The problem is non-trivial due to the non-convex and non-smooth nature of the objective function. In this paper, we propose $\\texttt{LeadCache}$ - an efficient online caching policy based on the Follow-the-Perturbed-Leader paradigm. We show that $\\texttt{LeadCache}$ is regret-optimal up to a factor of $\\tilde{O}(n^{3/8}),$ where $n$ is the number of users. We design two efficient implementations of the $\\texttt{LeadCache}$ policy, one based on Pipage rounding and the other based on Madow's sampling, each of which makes precisely one call to an LP-solver per iteration. Furthermore, with a Strong-Law-type assumption, we show that the total number of file fetches under $\\texttt{LeadCache}$ remains almost surely finite over an infinite horizon. Finally, we derive an approximately tight regret lower bound using results from graph coloring. We conclude that the learning-based $\\texttt{LeadCache}$ policy decisively outperforms the state-of-the-art caching policies both theoretically and empirically.",
      "tldr": "We design a new online network caching policy.",
      "site_url": "https://nips.cc/virtual/2021/poster/28203",
      "pdf_url": "https://openreview.net/pdf?id=yrmvFIh_e5o",
      "github_url": "https://github.com/AbhishekMITIITM/LeadCache-NeurIPS21",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abhishek_Sinha3",
        "name": "Abhishek Sinha",
        "name_site": null,
        "openreview_id": "~Abhishek_Sinha3",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.tifr.res.in/~abhishek.sinha/",
        "dblp_id": "47/9175",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=Oc7BRX0AAAAJ",
        "orcid": "0000-0001-7220-0691",
        "linkedin_url": "abhishek-sinha-a645291b/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 1.118033988749895,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "e2gqGkFjDHg",
      "title": "Redesigning the Transformer Architecture with Insights from Multi-particle Dynamical Systems",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "The Transformer and its variants have been proven to be efficient sequence learners in many different domains. Despite their staggering success, a critical issue has been the enormous number of parameters that must be trained (ranging from $10^7$ to $10^{11}$) along with the quadratic complexity of dot-product attention. In this work, we investigate the problem of approximating the two central components of the Transformer --- multi-head self-attention and point-wise feed-forward transformation, with reduced parameter space and computational complexity. We build upon recent developments in analyzing deep neural networks as numerical solvers of ordinary differential equations. Taking advantage of an analogy between Transformer stages and the evolution of a dynamical system of multiple interacting particles, we formulate a temporal evolution scheme, \\name, to bypass costly dot-product attention over multiple stacked layers.  We perform exhaustive experiments with \\name\\ on well-known encoder-decoder as well as encoder-only tasks. We observe that the degree of approximation (or inversely, the degree of parameter reduction) has different effects on the performance, depending on the task. While in the encoder-decoder regime, \\name\\ delivers performances comparable to the original Transformer, in encoder-only tasks it consistently outperforms Transformer along with several subsequent variants.",
      "tldr": "A dynamical system motivated Transformer-variant that can achieves state-of-the-art performance with astoundingly fewer parameters.",
      "site_url": "https://nips.cc/virtual/2021/poster/27270",
      "pdf_url": "https://openreview.net/pdf?id=e2gqGkFjDHg",
      "github_url": "https://github.com/LCS2-IIITD/TransEvolve",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Tanya_Gautam1",
        "name": "Tanya Gautam",
        "name_site": null,
        "openreview_id": "~Tanya_Gautam1",
        "position": 2,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "gautam-tanya/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 5.000000000000001,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 0.7071067811865476,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 15,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xQGYquca0gB",
      "title": "Neural Production Systems",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Visual environments are structured, consisting of distinct  objects or entities. These entities have properties---visible or latent---that determine the manner in which they interact with one another. To partition images into entities, deep-learning researchers have proposed structural inductive biases such as slot-based architectures. To model interactions among entities, equivariant graph neural nets (GNNs) are used, but these are not particularly well suited to the task for two reasons. First, GNNs do not predispose interactions to be sparse, as relationships among independent entities are likely to be.  Second, GNNs do not factorize knowledge about  interactions in an entity-conditional manner. As an alternative, we take inspiration from cognitive science and resurrect a classic approach, production systems, which consist of a set of rule templates that are applied by binding placeholder  variables in the rules to specific entities. Rules are scored on their match to entities, and the best fitting rules are applied to update entity properties. In a series of experiments, we demonstrate that this architecture achieves a flexible, dynamic flow of control and serves to factorize entity-specific and rule-based information. This disentangling of knowledge achieves robust future-state prediction in rich visual environments, outperforming state-of-the-art methods using GNNs, and allows for the extrapolation from simple (few object) environments to more complex environments.\n",
      "tldr": "Modelling sparse interactions among seperate entities using dynamically selected rules",
      "site_url": "https://nips.cc/virtual/2021/poster/26838",
      "pdf_url": "https://openreview.net/pdf?id=xQGYquca0gB",
      "github_url": "/attachment/3138e5559fa0468a9b8dfd17006f74e5c4546983.zip",
      "total_authors": 8,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aniket_Rajiv_Didolkar1",
        "name": "Aniket Rajiv Didolkar",
        "name_site": null,
        "openreview_id": "~Aniket_Rajiv_Didolkar1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://github.com/dido1998/",
        "dblp_id": "245/8589",
        "google_scholar_url": "https://scholar.google.ca/citations?user=ekvl5o0AAAAJ",
        "orcid": null,
        "linkedin_url": "aniket-didolkar-7a9b8912a",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Manipal Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 4.2857142857142865,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.0,
        "confidence_std": 1.224744871391589,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 96,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "AIQOddM5Xm",
      "title": "Non-local Latent Relation Distillation for Self-Adaptive 3D Human Pose Estimation",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Available 3D human pose estimation approaches leverage different forms of strong (2D/3D pose) or weak (multi-view or depth) paired supervision. Barring synthetic or in-studio domains, acquiring such supervision for each new target environment is highly inconvenient. To this end, we cast 3D pose learning as a self-supervised adaptation problem that aims to transfer the task knowledge from a labeled source domain to a completely unpaired target. We propose to infer image-to-pose via two explicit mappings viz. image-to-latent and latent-to-pose where the latter is a pre-learned decoder obtained from a prior-enforcing generative adversarial auto-encoder. Next, we introduce relation distillation as a means to align the unpaired cross-modal samples i.e., the unpaired target videos and unpaired 3D pose sequences. To this end, we propose a new set of non-local relations in order to characterize long-range latent pose interactions, unlike general contrastive relations where positive couplings are limited to a local neighborhood structure. Further, we provide an objective way to quantify non-localness in order to select the most effective relation set. We evaluate different self-adaptation settings and demonstrate state-of-the-art 3D human pose estimation performance on standard benchmarks.",
      "tldr": "We introduce relation distillation as a means to align the unpaired cross-modal samples i.e., unpaired target videos and unpaired 3D pose sequences for self-adapting 3D human pose estimation.",
      "site_url": "https://nips.cc/virtual/2021/poster/26641",
      "pdf_url": "https://openreview.net/pdf?id=AIQOddM5Xm",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Siddharth_Seth1",
        "name": "Siddharth Seth",
        "name_site": null,
        "openreview_id": "~Siddharth_Seth1",
        "position": 2,
        "gender": null,
        "homepage_url": null,
        "dblp_id": "97/3775",
        "google_scholar_url": "QDEa50oAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 4.166666666666667,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 12,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "7X_sBjIwtm9",
      "title": "IA-RED$^2$: Interpretability-Aware Redundancy Reduction for Vision Transformers",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The self-attention-based model, transformer, is recently becoming the leading backbone in the field of computer vision. In spite of the impressive success made by transformers in a variety of vision tasks, it still suffers from heavy computation and intensive memory costs. To address this limitation, this paper presents an Interpretability-Aware REDundancy REDuction framework (IA-RED$^2$). We start by observing a large amount of redundant computation, mainly spent on uncorrelated input patches, and then introduce an interpretable module to dynamically and gracefully drop these redundant patches. This novel framework is then extended to a hierarchical structure, where uncorrelated tokens at different stages are gradually removed, resulting in a considerable shrinkage of computational cost. We include extensive experiments on both image and video tasks, where our method could deliver up to 1.4x speed-up for state-of-the-art models like DeiT and TimeSformer, by only sacrificing less than 0.7% accuracy. More importantly, contrary to other acceleration approaches, our method is inherently interpretable with substantial visual evidence, making vision transformer closer to a more human-understandable architecture while being lighter. We demonstrate that the interpretability that naturally emerged in our framework can outperform the raw attention learned by the original visual transformer, as well as those generated by off-the-shelf interpretation methods, with both qualitative and quantitative results. Project Page: http://people.csail.mit.edu/bpan/ia-red/.",
      "tldr": "An input-dependent and interpretable dynamic inference framework for vision transformer, which adaptively decides the patch tokens to compute per input instance.",
      "site_url": "https://nips.cc/virtual/2021/poster/26873",
      "pdf_url": "https://openreview.net/pdf?id=7X_sBjIwtm9",
      "github_url": "http://people.csail.mit.edu/bpan/",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rameswar_Panda1",
        "name": "Rameswar Panda",
        "name_site": null,
        "openreview_id": "~Rameswar_Panda1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://rpand002.github.io/",
        "dblp_id": "126/0986",
        "google_scholar_url": "_ySuu6gAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Massachusetts Institute of Technology (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 4.0,
      "reviews": {
        "rating_mean": 5.666666666666667,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 183,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "2r6F9duQ6o5",
      "title": "CAM-GAN: Continual Adaptation Modules for Generative Adversarial Networks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We present a continual learning approach for generative adversarial networks (GANs), by designing and leveraging parameter-efficient feature map transformations. Our approach is based on learning a set of global and task-specific parameters. The global parameters are fixed across tasks whereas the task-specific parameters act as local adapters for each task, and help in efficiently obtaining task-specific feature maps. Moreover, we propose an element-wise addition of residual bias in the transformed feature space, which further helps stabilize GAN training in such settings. Our approach also leverages task similarities based on the Fisher information matrix. Leveraging this knowledge from previous tasks significantly improves the model performance. In addition, the similarity measure also helps reduce the parameter growth in continual adaptation and helps to learn a compact model. In contrast to the recent approaches for continually-learned GANs, the proposed approach provides a memory-efficient way to perform effective continual data generation. Through extensive experiments on challenging and diverse datasets, we show that the feature-map-transformation approach outperforms state-of-the-art methods for continually-learned GANs, with substantially fewer parameters. The proposed method generates high-quality samples that can also improve the generative-replay-based continual learning for discriminative tasks.",
      "tldr": "CAM-GAN: Continual Adaptation Modules for Generative Adversarial Networks",
      "site_url": "https://nips.cc/virtual/2021/poster/26910",
      "pdf_url": "https://openreview.net/pdf?id=2r6F9duQ6o5",
      "github_url": "https://github.com/sakshivarshney/CAM-GAN",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vinay_Kumar_Verma4",
        "name": "Vinay Kumar Verma",
        "name_site": null,
        "openreview_id": "~Vinay_Kumar_Verma4",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/vinaycse/home",
        "dblp_id": "138/3106.html",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.75,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 32,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "MckiHYXsBT",
      "title": "Learning to Select Exogenous Events for Marked Temporal Point Process",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Marked temporal point processes (MTPPs) have emerged as a powerful modeling\ntool for a wide variety of applications which are characterized using discrete\nevents localized in continuous time. In this context, the events are of two types\nendogenous events which occur due to the influence of the previous events and\nexogenous events which occur due to the effect of the externalities. However, in\npractice, the events do not come with endogenous or exogenous labels. To this\nend, our goal in this paper is to identify the set of exogenous events from a set of\nunlabelled events. To do so, we first formulate the parameter estimation problem\nin conjunction with exogenous event set selection problem and show that this\nproblem is NP hard. Next, we prove that the underlying objective is a monotone\nand \\alpha-submodular set function, with respect to the candidate set of exogenous\nevents. Such a characterization subsequently allows us to use a stochastic greedy\nalgorithm which was originally proposed in~\\cite{greedy}for submodular maximization.\nHowever, we show that it also admits an approximation guarantee for maximizing\n\\alpha-submodular set function, even when the learning algorithm provides an imperfect\nestimates of the trained parameters. Finally, our experiments with synthetic and\nreal data show that our method performs better than the existing approaches built\nupon superposition of endogenous and exogenous MTPPs.",
      "tldr": "It learns to select exogenous events from a set of  events in the context of marked temporal point processes",
      "site_url": "https://nips.cc/virtual/2021/poster/26623",
      "pdf_url": "https://openreview.net/pdf?id=MckiHYXsBT",
      "github_url": "https://github.com/noilreed/TPP-Select",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rishabh_K_Iyer2",
        "name": "Rishabh K Iyer",
        "name_site": null,
        "openreview_id": "~Rishabh_K_Iyer2",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.rishiyer.com",
        "dblp_id": "37/10544.html",
        "google_scholar_url": "l_XxJ1kAAAAJ",
        "orcid": null,
        "linkedin_url": "rishabh-iyer-36893717/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 3.75,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 10,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "U7SBcmRf65",
      "title": "Training for the Future: A Simple Gradient Interpolation Loss to Generalize Along Time",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In several real world applications, machine learning models are deployed to make predictions on data whose distribution changes gradually along time, leading to a drift between the train and test distributions. Such models are often re-trained on new data periodically, and they hence need to generalize to data not too far into the future. In this context, there is much prior work on enhancing temporal generalization, e.g. continuous transportation of past data, kernel smoothed time-sensitive parameters and more recently, adversarial learning of time-invariant features. However, these methods share several limitations, e.g, poor scalability, training instability, and dependence on unlabeled data from the future. Responding to the above limitations, we propose a simple method that starts with a model with time-sensitive parameters but regularizes its temporal complexity using a Gradient Interpolation  (GI) loss. GI allows the decision boundary to change along time and can still prevent overfitting to the limited training time snapshots  by allowing task-specific control over changes along time. We compare our method to existing baselines on multiple real-world datasets, which show that GI outperforms more complicated generative and adversarial approaches on the one hand, and simpler gradient regularization methods on the other.",
      "tldr": "We propose a simple gradient interpolation loss to enable models to generalize to unseen future data.",
      "site_url": "https://nips.cc/virtual/2021/poster/27251",
      "pdf_url": "https://openreview.net/pdf?id=U7SBcmRf65",
      "github_url": "https://github.com/anshuln/Training-for-the-Future",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Soumyadeep_Thakur1",
        "name": "Soumyadeep Thakur",
        "name_site": null,
        "openreview_id": "~Soumyadeep_Thakur1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0000-0001-9540-2755",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.75,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 31,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "a1wQOh27zcy",
      "title": "Contrast and Mix: Temporal Contrastive Video Domain Adaptation with Background Mixing",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Unsupervised domain adaptation which aims to adapt models trained on a labeled source domain to a completely unlabeled target domain has attracted much attention in recent years. While many domain adaptation techniques have been proposed for images, the problem of unsupervised domain adaptation in videos remains largely underexplored. In this paper, we introduce Contrast and Mix (CoMix), a new contrastive learning framework that aims to learn discriminative invariant feature representations for unsupervised video domain adaptation. First, unlike existing methods that rely on adversarial learning for feature alignment, we utilize temporal contrastive learning to bridge the domain gap by maximizing the similarity between encoded representations of an unlabeled video at two different speeds as well as minimizing the similarity between different videos played at different speeds. Second, we propose a novel extension to the temporal contrastive loss by using background mixing that allows additional positives per anchor, thus adapting contrastive learning to leverage action semantics shared across both domains. Moreover, we also integrate a supervised contrastive learning objective using target pseudo-labels to enhance discriminability of the latent space for video domain adaptation. Extensive experiments on several benchmark datasets demonstrate the superiority of our proposed approach over state-of-the-art methods. Project page: https://cvir.github.io/projects/comix.",
      "tldr": "A new temporal contrastive learning approach for unsupervised video domain adaptation.",
      "site_url": "https://nips.cc/virtual/2021/poster/26751",
      "pdf_url": "https://openreview.net/pdf?id=a1wQOh27zcy",
      "github_url": "https://cvir.github.io/projects/comix",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rutav_Shah1",
        "name": "Rutav Shah",
        "name_site": null,
        "openreview_id": "~Rutav_Shah1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://shahrutav.github.io",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "rutav-shah-01a2941a7",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.75,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 81,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "AIQOddM5Xm",
      "title": "Non-local Latent Relation Distillation for Self-Adaptive 3D Human Pose Estimation",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Available 3D human pose estimation approaches leverage different forms of strong (2D/3D pose) or weak (multi-view or depth) paired supervision. Barring synthetic or in-studio domains, acquiring such supervision for each new target environment is highly inconvenient. To this end, we cast 3D pose learning as a self-supervised adaptation problem that aims to transfer the task knowledge from a labeled source domain to a completely unpaired target. We propose to infer image-to-pose via two explicit mappings viz. image-to-latent and latent-to-pose where the latter is a pre-learned decoder obtained from a prior-enforcing generative adversarial auto-encoder. Next, we introduce relation distillation as a means to align the unpaired cross-modal samples i.e., the unpaired target videos and unpaired 3D pose sequences. To this end, we propose a new set of non-local relations in order to characterize long-range latent pose interactions, unlike general contrastive relations where positive couplings are limited to a local neighborhood structure. Further, we provide an objective way to quantify non-localness in order to select the most effective relation set. We evaluate different self-adaptation settings and demonstrate state-of-the-art 3D human pose estimation performance on standard benchmarks.",
      "tldr": "We introduce relation distillation as a means to align the unpaired cross-modal samples i.e., unpaired target videos and unpaired 3D pose sequences for self-adapting 3D human pose estimation.",
      "site_url": "https://nips.cc/virtual/2021/poster/26641",
      "pdf_url": "https://openreview.net/pdf?id=AIQOddM5Xm",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anirudh_Gururaj_Jamkhandi1",
        "name": "Anirudh Gururaj Jamkhandi",
        "name_site": null,
        "openreview_id": "~Anirudh_Gururaj_Jamkhandi1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "244/4015",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": "anirudhgj",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "ZOZO Inc (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 12,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "MqCzSKCQ1QB",
      "title": "Adversarial Robustness without Adversarial Training: A Teacher-Guided Curriculum Learning Approach",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Current SOTA adversarially robust models are mostly based on adversarial training (AT) and differ only by some regularizers either at inner maximization or outer minimization steps. Being repetitive in nature during the inner maximization step, they take a huge time to train. We propose a non-iterative method that enforces the following ideas during training. Attribution maps are more aligned to the actual object in the image for adversarially robust models compared to naturally trained models. Also, the allowed set of pixels to perturb an image (that changes model decision) should be restricted to the object pixels only, which reduces the attack strength by limiting the attack space. Our method achieves significant performance gains with a little extra effort (10-20%) over existing AT models and outperforms all other methods in terms of adversarial as well as natural accuracy. We have performed extensive experimentation with CIFAR-10, CIFAR-100, and TinyImageNet datasets and reported results against many popular strong adversarial attacks to prove the effectiveness of our method.",
      "tldr": "We propose a non-iterative robust training technique which takes 10-20% time over existing adversarial training (AT) based models and outperforms strong baselines for both adversarial as well as natural accuracies.",
      "site_url": "https://nips.cc/virtual/2021/poster/26314",
      "pdf_url": "https://openreview.net/pdf?id=MqCzSKCQ1QB",
      "github_url": "https://github.com/sowgali/Get-Fooled-for-the-Right-Reason",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anirban_Sarkar2",
        "name": "Anirban Sarkar",
        "name_site": null,
        "openreview_id": "~Anirban_Sarkar2",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://anirbansarkar-cs.github.io",
        "dblp_id": "67/6486-1",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=YYIjsG4AAAAJ",
        "orcid": "0000-0003-0992-961X",
        "linkedin_url": "anirbanmca2007",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 8,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Sl0WX9H6ZJg",
      "title": "NeuroMLR: Robust & Reliable Route Recommendation on Road Networks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Predicting the most likely route from a source location to a destination is a core functionality in mapping services. Although the problem has been studied in the literature, two key limitations remain to be addressed. First, our study reveals that a significant portion of the routes recommended by existing methods fail to reach the destination. Second, existing techniques are transductive in nature; hence, they fail to recommend routes if unseen roads are encountered at inference time. In this paper, we address these limitations through an inductive algorithm called NeuroMLR. NeuroMLR learns a generative model from historical trajectories by conditioning on three explanatory factors: the current location, the destination, and real-time traffic conditions. The conditional distributions are learned through a novel combination of Lipschitz embedding with Graph Convolutional Networks (GCN) using historical trajectory data. Through in-depth experiments on real-world datasets, we establish that NeuroMLR imparts significant improvement in accuracy over the state of the art. More importantly, NeuroMLR generalizes dramatically better to unseen data and the recommended routes reach the destination with much higher likelihood than existing techniques.",
      "tldr": "Predicting the most likely route in a road network via Lipschitz embedding and GCN, achieving significantly high reachability and better generalisation to unseen data.",
      "site_url": "https://nips.cc/virtual/2021/poster/26807",
      "pdf_url": "https://openreview.net/pdf?id=Sl0WX9H6ZJg",
      "github_url": "https://github.com/idea-iitd/NeuroMLR",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vrittika_Bagadia1",
        "name": "Vrittika Bagadia",
        "name_site": null,
        "openreview_id": "~Vrittika_Bagadia1",
        "position": 2,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "vrittika-bagadia/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 27,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "kuK2VARZGnI",
      "title": "Towards Efficient and Effective Adversarial Training",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The vulnerability of Deep Neural Networks to adversarial attacks has spurred immense interest towards improving their robustness. However, present state-of-the-art adversarial defenses involve the use of 10-step adversaries during training, which renders them computationally infeasible for application to large-scale datasets. While the recent single-step defenses show promising direction, their robustness is not on par with multi-step training methods. In this work, we bridge this performance gap by introducing a novel Nuclear-Norm regularizer on network predictions to enforce function smoothing in the vicinity of data samples.  While prior works consider each data sample independently, the proposed regularizer uses the joint statistics of adversarial samples across a training minibatch to enhance optimization during both attack generation and training, obtaining state-of-the-art results amongst efficient defenses. We achieve further gains by incorporating exponential averaging of network weights over training iterations. We finally introduce a Hybrid training approach that combines the effectiveness of a two-step variant of the proposed defense with the efficiency of a single-step defense. We demonstrate superior results when compared to multi-step defenses such as TRADES and PGD-AT as well, at a significantly lower computational cost.",
      "tldr": "We propose methods to improve the efficiency and effectiveness of Adversarial Training",
      "site_url": "https://nips.cc/virtual/2021/poster/26270",
      "pdf_url": "https://openreview.net/pdf?id=kuK2VARZGnI",
      "github_url": "https://github.com/val-iisc/NuAT",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sravanti_Addepalli1",
        "name": "Sravanti Addepalli",
        "name_site": null,
        "openreview_id": "~Sravanti_Addepalli1",
        "position": 2,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "127/7715",
        "google_scholar_url": "MOO12i0AAAAJ",
        "orcid": null,
        "linkedin_url": "sravanti-addepalli/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 0.0,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 84,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "r2uzPR4AYo",
      "title": "Accurately Solving Rod Dynamics with Graph Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Iterative solvers are widely used to accurately simulate physical systems. These solvers require initial guesses to generate a sequence of improving approximate solutions. In this contribution, we introduce a novel method to accelerate iterative solvers for rod dynamics with graph networks (GNs) by predicting the initial guesses to reduce the number of iterations. Unlike existing methods that aim to learn physical systems in an end-to-end manner, our approach guarantees long-term stability and therefore leads to more accurate solutions. Furthermore, our method improves the run time performance of traditional iterative solvers for rod dynamics. To explore our method we make use of position-based dynamics (PBD) as a common solver for physical systems and evaluate it by simulating the dynamics of elastic rods. Our approach is able to generalize across different initial conditions, discretizations, and realistic material properties. We demonstrate that it also performs well when taking discontinuous effects into account such as collisions between individual rods. Finally, to illustrate the scalability of our approach, we simulate complex 3D tree models composed of over a thousand individual branch segments swaying in wind fields.",
      "tldr": "We introduce a novel method to accelerate iterative solvers for physical systems with graph networks by predicting the initial guesses to reduce the number of iterations.",
      "site_url": "https://nips.cc/virtual/2021/poster/28850",
      "pdf_url": "https://openreview.net/pdf?id=r2uzPR4AYo",
      "github_url": "/attachment/502dabe763ff71fbfac1ea27476fac17beaa52fd.zip",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "torsten.hadrich@kaust.edu.sa",
        "name": "Torsten HÃ¤drich",
        "name_site": null,
        "openreview_id": "torsten.hadrich@kaust.edu.sa",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Aligarh Muslim University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 23,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "rsNBA9gtDf4",
      "title": "Aligning Silhouette Topology for Self-Adaptive 3D Human Pose Recovery",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Articulation-centric 2D/3D pose supervision forms the core training objective in most existing 3D human pose estimation techniques. Except for synthetic source environments, acquiring such rich supervision for each real target domain at deployment is highly inconvenient. However, we realize that standard foreground silhouette estimation techniques (on static camera feeds) remain unaffected by domain-shifts. Motivated by this, we propose a novel target adaptation framework that relies only on silhouette supervision to adapt a source-trained model-based regressor. However, in the absence of any auxiliary cue (multi-view, depth, or 2D pose), an isolated silhouette loss fails to provide a reliable pose-specific gradient and requires to be employed in tandem with a topology-centric loss. To this end, we develop a series of convolution-friendly spatial transformations in order to disentangle a topological-skeleton representation from the raw silhouette. Such a design paves the way to devise a Chamfer-inspired spatial topological-alignment loss via distance field computation, while effectively avoiding any gradient hindering spatial-to-pointset mapping. Experimental results demonstrate our superiority against prior-arts in self-adapting a source trained model to diverse unlabeled target domains, such as a) in-the-wild datasets, b) low-resolution image domains, and c) adversarially perturbed image domains (via UAP). ",
      "tldr": "A self-supervised domain adaptation framework for 3D human pose recovery using only silhouettes via topological alignment.",
      "site_url": "https://nips.cc/virtual/2021/poster/26665",
      "pdf_url": "https://openreview.net/pdf?id=rsNBA9gtDf4",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anirban_Chakraborty1",
        "name": "Anirban Chakraborty",
        "name_site": null,
        "openreview_id": "~Venkatesh_Babu_Radhakrishnan2",
        "position": 2,
        "gender": "M",
        "homepage_url": "http://cds.iisc.ac.in/faculty/venky",
        "dblp_id": "20/6289",
        "google_scholar_url": "cVg7HrEAAAAJ",
        "orcid": "0000-0002-1926-1804",
        "linkedin_url": "venkatesh-babu-radhakrishnan-16568939",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.5,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 11,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "_4VxORHq-0g",
      "title": "Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with Unlabeled Data",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Most existing works in few-shot learning rely on meta-learning the network on a large base dataset which is typically from the same domain as the target dataset. We tackle the problem of cross-domain few-shot learning where there is a large shift between the base and target domain. The problem of cross-domain few-shot recognition with unlabeled target data is largely unaddressed in the literature. STARTUP was the first method that tackles this problem using self-training. However, it uses a fixed teacher pretrained on a labeled base dataset to create soft labels for the unlabeled target samples. As the base dataset and unlabeled dataset are from different domains, projecting the target images in the class-domain of the base dataset with a fixed pretrained model might be sub-optimal. We propose a simple dynamic distillation-based approach to facilitate unlabeled images from the novel/base dataset. We impose consistency regularization by calculating predictions from the weakly-augmented versions of the unlabeled images from a teacher network and matching it with the strongly augmented versions of the same images from a student network. The parameters of the teacher network are updated as exponential moving average of the parameters of the student network. We show that the proposed network learns representation that can be easily adapted to the target domain even though it has not been trained with target-specific classes during the pretraining phase. Our model outperforms the current state-of-the art method by 4.4% for 1-shot and 3.6% for 5-shot classification in the BSCD-FSL benchmark, and also shows competitive performance on traditional in-domain few-shot learning task.",
      "tldr": "We tackle the problem of cross-domain few-shot learning where there is a large shift between the base and target domain by proposing a simple distillation-based method to facilitate unlabeled images from the novel dataset",
      "site_url": "https://nips.cc/virtual/2021/poster/27455",
      "pdf_url": "https://openreview.net/pdf?id=_4VxORHq-0g",
      "github_url": "https://git.io/Jilgs",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rameswar_Panda1",
        "name": "Rameswar Panda",
        "name_site": null,
        "openreview_id": "~Rameswar_Panda1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://rpand002.github.io/",
        "dblp_id": "126/0986",
        "google_scholar_url": "_ySuu6gAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Massachusetts Institute of Technology (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 3.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 98,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "e2gqGkFjDHg",
      "title": "Redesigning the Transformer Architecture with Insights from Multi-particle Dynamical Systems",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "The Transformer and its variants have been proven to be efficient sequence learners in many different domains. Despite their staggering success, a critical issue has been the enormous number of parameters that must be trained (ranging from $10^7$ to $10^{11}$) along with the quadratic complexity of dot-product attention. In this work, we investigate the problem of approximating the two central components of the Transformer --- multi-head self-attention and point-wise feed-forward transformation, with reduced parameter space and computational complexity. We build upon recent developments in analyzing deep neural networks as numerical solvers of ordinary differential equations. Taking advantage of an analogy between Transformer stages and the evolution of a dynamical system of multiple interacting particles, we formulate a temporal evolution scheme, \\name, to bypass costly dot-product attention over multiple stacked layers.  We perform exhaustive experiments with \\name\\ on well-known encoder-decoder as well as encoder-only tasks. We observe that the degree of approximation (or inversely, the degree of parameter reduction) has different effects on the performance, depending on the task. While in the encoder-decoder regime, \\name\\ delivers performances comparable to the original Transformer, in encoder-only tasks it consistently outperforms Transformer along with several subsequent variants.",
      "tldr": "A dynamical system motivated Transformer-variant that can achieves state-of-the-art performance with astoundingly fewer parameters.",
      "site_url": "https://nips.cc/virtual/2021/poster/27270",
      "pdf_url": "https://openreview.net/pdf?id=e2gqGkFjDHg",
      "github_url": "https://github.com/LCS2-IIITD/TransEvolve",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Soumen_Chakrabarti1",
        "name": "Soumen Chakrabarti",
        "name_site": null,
        "openreview_id": "~Soumen_Chakrabarti1",
        "position": 3,
        "gender": "Not Specified",
        "homepage_url": "https://www.cse.iitb.ac.in/~soumen/",
        "dblp_id": "c/SChakrabarti",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=LfF2zfQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5000000000000004,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 0.7071067811865476,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 15,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "7CKWdq2yQv",
      "title": "Active Assessment of Prediction Services as Accuracy Surface Over Attribute Combinations",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Our goal is to evaluate the accuracy of a black-box classification model, not as a single aggregate on a given test data distribution, but as a surface over a large number of combinations of attributes characterizing multiple test data distributions.  Such attributed accuracy measures become important as machine learning models get deployed as a service, where the training data distribution is hidden from clients, and different clients may be interested in diverse regions of the data distribution. We present Attributed Accuracy Assay (AAA) --- a Gaussian Process (GP)-based probabilistic estimator for such an accuracy surface. Each attribute combination, called an 'arm' is associated with a Beta density from which the service's accuracy is sampled.  We expect the GP to smooth the parameters of the Beta density over related arms to mitigate sparsity. We show that obvious application of GPs cannot address the challenge of heteroscedastic uncertainty over a huge attribute space that is sparsely and unevenly populated. In response, we present two enhancements: pooling sparse observations, and regularizing the scale parameter of the Beta densities. After introducing these innovations, we establish the effectiveness of AAA both in terms of its estimation accuracy and exploration efficiency, through extensive experiments and analysis.",
      "tldr": "Prediction Services should go beyond scalar accuracy and instead report performance on attribute combinations characterizing a clientâ€™s utility. Read our paper for how we can estimate accuracy for combinatorially large attribute combinations.",
      "site_url": "https://nips.cc/virtual/2021/poster/27414",
      "pdf_url": "https://openreview.net/pdf?id=7CKWdq2yQv",
      "github_url": "https://github.com/vihari/AAA",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Soumen_Chakrabarti1",
        "name": "Soumen Chakrabarti",
        "name_site": null,
        "openreview_id": "~Soumen_Chakrabarti1",
        "position": 2,
        "gender": "Not Specified",
        "homepage_url": "https://www.cse.iitb.ac.in/~soumen/",
        "dblp_id": "c/SChakrabarti",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=LfF2zfQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 5,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "90EVPQ7uCV",
      "title": "Memory-Efficient Approximation Algorithms for Max-k-Cut and Correlation Clustering",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Max-k-Cut and correlation clustering are fundamental graph partitioning problems. For a graph $G=(V,E)$ with $n$ vertices, the methods with the best approximation guarantees for Max-k-Cut and the Max-Agree variant of correlation clustering involve solving SDPs with $\\mathcal{O}(n^2)$ constraints and variables. Large-scale instances of SDPs, thus, present a memory bottleneck. In this paper, we develop simple polynomial-time Gaussian sampling-based algorithms for these two problems that use $\\mathcal{O}(n+|E|)$ memory and nearly achieve the best existing approximation guarantees. For dense graphs arriving in a stream, we eliminate the dependence on $|E|$ in the storage complexity at the cost of a slightly worse approximation ratio by combining our approach with sparsification.",
      "tldr": "We generate approximation solutions to Max-k-Cut and correlation clustering using memory linear in the size of the input graph",
      "site_url": "https://nips.cc/virtual/2021/poster/28336",
      "pdf_url": "https://openreview.net/pdf?id=90EVPQ7uCV",
      "github_url": "/attachment/3de102b430499d333123554b4873b294a5c3df77.zip",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vishnu_Narayanan1",
        "name": "Vishnu Narayanan",
        "name_site": null,
        "openreview_id": "~Vishnu_Narayanan1",
        "position": 2,
        "gender": "M",
        "homepage_url": "http://www.ieor.iitb.ac.in",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 2.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 6,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "M5h1l1SldlF",
      "title": "Counterfactual Explanations in Sequential Decision Making Under Uncertainty",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Methods to find counterfactual explanations have predominantly focused on one-step decision making processes. In this work, we initiate the development of methods to find counterfactual explanations for decision making processes in which multiple, dependent actions are taken sequentially over time. We start by formally characterizing a sequence of actions and states using finite horizon Markov decision processes and the Gumbel-Max structural causal model. Building upon this characterization, we formally state the problem of finding counterfactual explanations for sequential decision making processes. In our problem formulation, the counterfactual explanation specifies an alternative sequence of actions differing in at most k actions from the observed sequence that could have led the observed process realization to a better outcome. Then, we introduce a polynomial time algorithm based on dynamic programming to build a counterfactual policy that is guaranteed to always provide the optimal counterfactual explanation on every possible realization of the counterfactual environment dynamics. We validate our algorithm using both synthetic and real data from cognitive behavioral therapy and show that the counterfactual explanations our algorithm finds can provide valuable insights to enhance sequential decision making under uncertainty.",
      "tldr": "The paper introduces a method to find counterfactual explanations for decision making processes in which multiple, dependent actions are taken sequentially over time",
      "site_url": "https://nips.cc/virtual/2021/poster/27361",
      "pdf_url": "https://openreview.net/pdf?id=M5h1l1SldlF",
      "github_url": "https://github.com/Networks-Learning/counterfactual-explanations-mdp",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abir_De1",
        "name": "Abir De",
        "name_site": null,
        "openreview_id": "~Abir_De1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "118/7174",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=_9ZKKbIAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.479019945774904,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 56,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "MckiHYXsBT",
      "title": "Learning to Select Exogenous Events for Marked Temporal Point Process",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Marked temporal point processes (MTPPs) have emerged as a powerful modeling\ntool for a wide variety of applications which are characterized using discrete\nevents localized in continuous time. In this context, the events are of two types\nendogenous events which occur due to the influence of the previous events and\nexogenous events which occur due to the effect of the externalities. However, in\npractice, the events do not come with endogenous or exogenous labels. To this\nend, our goal in this paper is to identify the set of exogenous events from a set of\nunlabelled events. To do so, we first formulate the parameter estimation problem\nin conjunction with exogenous event set selection problem and show that this\nproblem is NP hard. Next, we prove that the underlying objective is a monotone\nand \\alpha-submodular set function, with respect to the candidate set of exogenous\nevents. Such a characterization subsequently allows us to use a stochastic greedy\nalgorithm which was originally proposed in~\\cite{greedy}for submodular maximization.\nHowever, we show that it also admits an approximation guarantee for maximizing\n\\alpha-submodular set function, even when the learning algorithm provides an imperfect\nestimates of the trained parameters. Finally, our experiments with synthetic and\nreal data show that our method performs better than the existing approaches built\nupon superposition of endogenous and exogenous MTPPs.",
      "tldr": "It learns to select exogenous events from a set of  events in the context of marked temporal point processes",
      "site_url": "https://nips.cc/virtual/2021/poster/26623",
      "pdf_url": "https://openreview.net/pdf?id=MckiHYXsBT",
      "github_url": "https://github.com/noilreed/TPP-Select",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ashish_V._Tendulkar1",
        "name": "Ashish V. Tendulkar",
        "name_site": null,
        "openreview_id": "~Ashish_V._Tendulkar1",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": "08/1521",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 10,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "U7SBcmRf65",
      "title": "Training for the Future: A Simple Gradient Interpolation Loss to Generalize Along Time",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In several real world applications, machine learning models are deployed to make predictions on data whose distribution changes gradually along time, leading to a drift between the train and test distributions. Such models are often re-trained on new data periodically, and they hence need to generalize to data not too far into the future. In this context, there is much prior work on enhancing temporal generalization, e.g. continuous transportation of past data, kernel smoothed time-sensitive parameters and more recently, adversarial learning of time-invariant features. However, these methods share several limitations, e.g, poor scalability, training instability, and dependence on unlabeled data from the future. Responding to the above limitations, we propose a simple method that starts with a model with time-sensitive parameters but regularizes its temporal complexity using a Gradient Interpolation  (GI) loss. GI allows the decision boundary to change along time and can still prevent overfitting to the limited training time snapshots  by allowing task-specific control over changes along time. We compare our method to existing baselines on multiple real-world datasets, which show that GI outperforms more complicated generative and adversarial approaches on the one hand, and simpler gradient regularization methods on the other.",
      "tldr": "We propose a simple gradient interpolation loss to enable models to generalize to unseen future data.",
      "site_url": "https://nips.cc/virtual/2021/poster/27251",
      "pdf_url": "https://openreview.net/pdf?id=U7SBcmRf65",
      "github_url": "https://github.com/anshuln/Training-for-the-Future",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vihari_Piratla1",
        "name": "Vihari Piratla",
        "name_site": "Vihari Piratla, Soumen Chakrabarti, Sunita Sarawagi",
        "openreview_id": "~Vihari_Piratla1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://vihari.github.io/",
        "dblp_id": "161/3626",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=DQddccYAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 31,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "a1wQOh27zcy",
      "title": "Contrast and Mix: Temporal Contrastive Video Domain Adaptation with Background Mixing",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Unsupervised domain adaptation which aims to adapt models trained on a labeled source domain to a completely unlabeled target domain has attracted much attention in recent years. While many domain adaptation techniques have been proposed for images, the problem of unsupervised domain adaptation in videos remains largely underexplored. In this paper, we introduce Contrast and Mix (CoMix), a new contrastive learning framework that aims to learn discriminative invariant feature representations for unsupervised video domain adaptation. First, unlike existing methods that rely on adversarial learning for feature alignment, we utilize temporal contrastive learning to bridge the domain gap by maximizing the similarity between encoded representations of an unlabeled video at two different speeds as well as minimizing the similarity between different videos played at different speeds. Second, we propose a novel extension to the temporal contrastive loss by using background mixing that allows additional positives per anchor, thus adapting contrastive learning to leverage action semantics shared across both domains. Moreover, we also integrate a supervised contrastive learning objective using target pseudo-labels to enhance discriminability of the latent space for video domain adaptation. Extensive experiments on several benchmark datasets demonstrate the superiority of our proposed approach over state-of-the-art methods. Project page: https://cvir.github.io/projects/comix.",
      "tldr": "A new temporal contrastive learning approach for unsupervised video domain adaptation.",
      "site_url": "https://nips.cc/virtual/2021/poster/26751",
      "pdf_url": "https://openreview.net/pdf?id=a1wQOh27zcy",
      "github_url": "https://cvir.github.io/projects/comix",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rameswar_Panda1",
        "name": "Rameswar Panda",
        "name_site": null,
        "openreview_id": "~Rameswar_Panda1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://rpand002.github.io/",
        "dblp_id": "126/0986",
        "google_scholar_url": "_ySuu6gAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Massachusetts Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 81,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "bdA60x7yG0T",
      "title": "Differentiable Learning Under Triage",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Multiple lines of evidence suggest that predictive models may benefit from algorithmic triage. Under algorithmic triage, a predictive model does not predict all instances but instead defers some of them to human experts. However, the interplay between the prediction accuracy of the model and the human experts under algorithmic triage is not well understood. In this work, we start by formally characterizing under which circumstances a predictive model may benefit from algorithmic triage. In doing so, we also demonstrate that models trained for full automation may be suboptimal under triage. Then, given any model and desired level of triage, we show that the optimal triage policy is a deterministic threshold rule in which triage decisions are derived deterministically by thresholding the difference between the model and human errors on a per-instance level. Building upon these results, we introduce a practical gradient-based algorithm that is guaranteed to find a sequence of predictive models and triage policies of increasing performance. Experiments on a wide variety of supervised learning tasks using synthetic and real data from two important applications---content moderation and scientific discovery---illustrate our theoretical results and show that the models and triage policies provided by our gradient-based algorithm outperform those provided by several competitive baselines.",
      "tldr": "The paper introduces a algorithm to learn differentiable models under algorithmic triage",
      "site_url": "https://nips.cc/virtual/2021/poster/28375",
      "pdf_url": "https://openreview.net/pdf?id=bdA60x7yG0T",
      "github_url": "https://github.com/Networks-Learning/differentiable-learning-under-triage",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abir_De1",
        "name": "Abir De",
        "name_site": null,
        "openreview_id": "~Abir_De1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "118/7174",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=_9ZKKbIAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.5,
        "confidence_mean": 2.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 70,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "rqEoV-bub4E-",
      "title": "Charting and Navigating the Space of Solutions for Recurrent Neural Networks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In recent years Recurrent Neural Networks (RNNs) were successfully used to model the way neural activity drives task-related behavior in animals, operating under the implicit assumption that the obtained solutions are universal. Observations in both neuroscience and machine learning challenge this assumption. Animals can approach a given task with a variety of strategies, and training machine learning algorithms introduces the phenomenon of underspecification. These observations imply that every task is associated with a space of solutions. To date, the structure of this space is not understood, limiting the approach of comparing RNNs with neural data.\nHere, we characterize the space of solutions associated with various tasks. We first study a simple two-neuron network on a task that leads to multiple solutions. We trace the nature of the final solution back to the networkâ€™s initial connectivity and identify discrete dynamical regimes that underlie this diversity. We then examine three neuroscience-inspired tasks: Delayed discrimination, Interval discrimination, and Time reproduction. For each task, we find a rich set of solutions. One layer of variability can be found directly in the neural activity of the networks. An additional layer is uncovered by testing the trained networks' ability to extrapolate, as a perturbation to a system often reveals hidden structure. Furthermore, we relate extrapolation patterns to specific dynamical objects and effective algorithms found by the networks. We introduce a tool to derive the reduced dynamics of networks by generating a compact directed graph describing the essence of the dynamics with regards to behavioral inputs and outputs. Using this representation, we can partition the solutions to each task into a handful of types and show that neural features can partially predict them.\nTaken together, our results shed light on the concept of the space of solutions and its uses both in Machine learning and in Neuroscience.",
      "tldr": "RNNs can produce a diverse set of qualitatively different solutions to the same computational tasks",
      "site_url": "https://nips.cc/virtual/2021/poster/27168",
      "pdf_url": "https://openreview.net/pdf?id=rqEoV-bub4E-",
      "github_url": "https://github.com/eliaturner/space-of-solutions-RNN",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Kabir_Vinay_Dabholkar1",
        "name": "Kabir Vinay Dabholkar",
        "name_site": null,
        "openreview_id": "~Kabir_Vinay_Dabholkar1",
        "position": 2,
        "gender": null,
        "homepage_url": "https://github.com/kabirdabholkar/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science Education and Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 23,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sKWgT8WppC3",
      "title": "Multi-Armed Bandits with Bounded Arm-Memory: Near-Optimal Guarantees for Best-Arm Identification and Regret Minimization",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We study the Stochastic Multi-armed Bandit problem under bounded arm-memory. In this setting, the arms arrive in a stream, and the number of arms that can be stored in the memory at any time, is bounded. The decision-maker can only pull arms that are present in the memory.  \nWe address the problem from the perspective of two standard objectives: 1) regret minimization, and 2) best-arm identification. For regret minimization, we settle an important open question by showing an almost tight guarantee. We show $\\Omega(T^{2/3})$ cumulative regret in expectation for single-pass algorithms for arm-memory size of $(n-1)$, where $n$ is the number of arms. For best-arm identification, we provide an $(\\varepsilon, \\delta)$-PAC algorithm with arm memory size of $O(\\log^*n)$ and $O(\\frac{n}{\\varepsilon^2}\\cdot \\log(\\frac{1}{\\delta}))$ optimal sample complexity. ",
      "tldr": "",
      "site_url": "https://nips.cc/virtual/2021/poster/28714",
      "pdf_url": "https://openreview.net/pdf?id=sKWgT8WppC3",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vishakha_Patil1",
        "name": "Vishakha Patil",
        "name_site": null,
        "openreview_id": "~Vishakha_Patil1",
        "position": 2,
        "gender": "F",
        "homepage_url": "https://sites.google.com/view/vishakha-patil/home",
        "dblp_id": "https://dblp.uni-trier.de/pid/241/9383.html",
        "google_scholar_url": "NWGBeoYAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 1.118033988749895,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 19,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "AIQOddM5Xm",
      "title": "Non-local Latent Relation Distillation for Self-Adaptive 3D Human Pose Estimation",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Available 3D human pose estimation approaches leverage different forms of strong (2D/3D pose) or weak (multi-view or depth) paired supervision. Barring synthetic or in-studio domains, acquiring such supervision for each new target environment is highly inconvenient. To this end, we cast 3D pose learning as a self-supervised adaptation problem that aims to transfer the task knowledge from a labeled source domain to a completely unpaired target. We propose to infer image-to-pose via two explicit mappings viz. image-to-latent and latent-to-pose where the latter is a pre-learned decoder obtained from a prior-enforcing generative adversarial auto-encoder. Next, we introduce relation distillation as a means to align the unpaired cross-modal samples i.e., the unpaired target videos and unpaired 3D pose sequences. To this end, we propose a new set of non-local relations in order to characterize long-range latent pose interactions, unlike general contrastive relations where positive couplings are limited to a local neighborhood structure. Further, we provide an objective way to quantify non-localness in order to select the most effective relation set. We evaluate different self-adaptation settings and demonstrate state-of-the-art 3D human pose estimation performance on standard benchmarks.",
      "tldr": "We introduce relation distillation as a means to align the unpaired cross-modal samples i.e., unpaired target videos and unpaired 3D pose sequences for self-adapting 3D human pose estimation.",
      "site_url": "https://nips.cc/virtual/2021/poster/26641",
      "pdf_url": "https://openreview.net/pdf?id=AIQOddM5Xm",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Varun_Jampani2_1",
        "name": "Varun Jampani",
        "name_site": null,
        "openreview_id": "~Anirban_Chakraborty1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://anirbanchakraborty.github.io/",
        "dblp_id": "73/2286-1",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=NtAsZK-2HjcC",
        "orcid": "0000-0002-6946-9152",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 12,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "CsV-Gms_JKy",
      "title": "Optimal Rates for Nonparametric Density Estimation under Communication Constraints",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We consider density estimation for Besov spaces when the estimator is restricted to use only a limited number of bits about each sample. We provide a noninteractive adaptive estimator which exploits the sparsity of wavelet bases, along with a simulate-and-infer technique from parametric estimation under communication constraints. We show that our estimator is nearly rate-optimal by deriving minmax lower bounds that hold even when interactive protocols are allowed. Interestingly, while our wavelet-based estimator is almost rate-optimal for Sobolev spaces as well, it is unclear whether the standard Fourier basis, which arise naturally for those spaces, can be used to achieve the same performance.",
      "tldr": "We prove (nearly) optimal minimax bounds for nonparametric density estimation under communication (bandwidth) constraints.",
      "site_url": "https://nips.cc/virtual/2021/poster/27671",
      "pdf_url": "https://openreview.net/pdf?id=CsV-Gms_JKy",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aditya_Vikram_Singh1",
        "name": "Aditya Vikram Singh",
        "name_site": null,
        "openreview_id": "~Aditya_Vikram_Singh1",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0000-0002-4957-9370",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.5,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 14,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "MqCzSKCQ1QB",
      "title": "Adversarial Robustness without Adversarial Training: A Teacher-Guided Curriculum Learning Approach",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Current SOTA adversarially robust models are mostly based on adversarial training (AT) and differ only by some regularizers either at inner maximization or outer minimization steps. Being repetitive in nature during the inner maximization step, they take a huge time to train. We propose a non-iterative method that enforces the following ideas during training. Attribution maps are more aligned to the actual object in the image for adversarially robust models compared to naturally trained models. Also, the allowed set of pixels to perturb an image (that changes model decision) should be restricted to the object pixels only, which reduces the attack strength by limiting the attack space. Our method achieves significant performance gains with a little extra effort (10-20%) over existing AT models and outperforms all other methods in terms of adversarial as well as natural accuracy. We have performed extensive experimentation with CIFAR-10, CIFAR-100, and TinyImageNet datasets and reported results against many popular strong adversarial attacks to prove the effectiveness of our method.",
      "tldr": "We propose a non-iterative robust training technique which takes 10-20% time over existing adversarial training (AT) based models and outperforms strong baselines for both adversarial as well as natural accuracies.",
      "site_url": "https://nips.cc/virtual/2021/poster/26314",
      "pdf_url": "https://openreview.net/pdf?id=MqCzSKCQ1QB",
      "github_url": "https://github.com/sowgali/Get-Fooled-for-the-Right-Reason",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sowrya_Gali1",
        "name": "Sowrya Gali",
        "name_site": null,
        "openreview_id": "~Sowrya_Gali1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.sowgali.github.io",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "sowrya-gali-72911939",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 8,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Sl0WX9H6ZJg",
      "title": "NeuroMLR: Robust & Reliable Route Recommendation on Road Networks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Predicting the most likely route from a source location to a destination is a core functionality in mapping services. Although the problem has been studied in the literature, two key limitations remain to be addressed. First, our study reveals that a significant portion of the routes recommended by existing methods fail to reach the destination. Second, existing techniques are transductive in nature; hence, they fail to recommend routes if unseen roads are encountered at inference time. In this paper, we address these limitations through an inductive algorithm called NeuroMLR. NeuroMLR learns a generative model from historical trajectories by conditioning on three explanatory factors: the current location, the destination, and real-time traffic conditions. The conditional distributions are learned through a novel combination of Lipschitz embedding with Graph Convolutional Networks (GCN) using historical trajectory data. Through in-depth experiments on real-world datasets, we establish that NeuroMLR imparts significant improvement in accuracy over the state of the art. More importantly, NeuroMLR generalizes dramatically better to unseen data and the recommended routes reach the destination with much higher likelihood than existing techniques.",
      "tldr": "Predicting the most likely route in a road network via Lipschitz embedding and GCN, achieving significantly high reachability and better generalisation to unseen data.",
      "site_url": "https://nips.cc/virtual/2021/poster/26807",
      "pdf_url": "https://openreview.net/pdf?id=Sl0WX9H6ZJg",
      "github_url": "https://github.com/idea-iitd/NeuroMLR",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sahil_Manchanda1",
        "name": "Sahil Manchanda",
        "name_site": null,
        "openreview_id": "~Sahil_Manchanda1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.cse.iitd.ac.in/~sahilm",
        "dblp_id": "200/8052",
        "google_scholar_url": "OPyjQHwAAAAJ",
        "orcid": "0000-0001-7437-9891",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 27,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "amH9JxZN7C",
      "title": "PreferenceNet: Encoding Human Preferences in Auction Design with Deep Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The design of optimal auctions is a problem of interest in economics, game theory and computer science. Despite decades of effort, strategyproof, revenue-maximizing auction designs are still not known outside of restricted settings. However, recent methods using deep learning have shown some success in approximating optimal auctions, recovering several known solutions and outperforming strong baselines when optimal auctions are not known. In addition to maximizing revenue, auction mechanisms may also seek to encourage socially desirable constraints such as allocation fairness or diversity. However, these philosophical notions neither have standardization nor do they have widely accepted formal definitions. In this paper, we propose PreferenceNet, an extension of existing neural-network-based auction mechanisms to encode constraints using (potentially human-provided) exemplars of desirable allocations. In addition, we introduce a new metric to evaluate an auction allocations' adherence to such socially desirable constraints and demonstrate that our proposed method is competitive with current state-of-the-art neural-network based auction designs. We validate our approach through human subject research and show that we are able to effectively capture real human preferences.",
      "tldr": "We extend RegretNet to capture human preferences in optimal auction mechanisms.",
      "site_url": "https://nips.cc/virtual/2021/poster/27429",
      "pdf_url": "https://openreview.net/pdf?id=amH9JxZN7C",
      "github_url": "https://github.com/neeharperi/PreferenceNet",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Samuel_Dooley1",
        "name": "Samuel Dooley",
        "name_site": null,
        "openreview_id": "~Samuel_Dooley1",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Maryland (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.7071067811865476,
        "confidence_mean": 2.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 41,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "h7aSBWbX7S4",
      "title": "Information-constrained optimization: can adaptive processing of gradients help?",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We revisit first-order optimization under local information constraints such as local privacy, gradient quantization, and computational constraints limiting access to a few coordinates of the gradient. In this setting, the optimization algorithm is not allowed to directly access the complete output of the gradient oracle, but only gets limited information about it subject to the local information constraints.   We study the role of adaptivity in processing the gradient output to obtain this limited information from it, and obtain tight or nearly tight bounds for both convex and strongly convex optimization when adaptive gradient processing is allowed.",
      "tldr": "We prove tight bounds on the convergence rate of first-order optimization when the gradients cannot be fully observed (information constraints), but the algorithm can still choose adaptively how to perform those limited observations.",
      "site_url": "https://nips.cc/virtual/2021/poster/28855",
      "pdf_url": "https://openreview.net/pdf?id=h7aSBWbX7S4",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Prathamesh_Mayekar1",
        "name": "Prathamesh Mayekar",
        "name_site": null,
        "openreview_id": "~Prathamesh_Mayekar1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://prathamesh220.github.io/",
        "dblp_id": null,
        "google_scholar_url": "pRRAEMEAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 13,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "kuK2VARZGnI",
      "title": "Towards Efficient and Effective Adversarial Training",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The vulnerability of Deep Neural Networks to adversarial attacks has spurred immense interest towards improving their robustness. However, present state-of-the-art adversarial defenses involve the use of 10-step adversaries during training, which renders them computationally infeasible for application to large-scale datasets. While the recent single-step defenses show promising direction, their robustness is not on par with multi-step training methods. In this work, we bridge this performance gap by introducing a novel Nuclear-Norm regularizer on network predictions to enforce function smoothing in the vicinity of data samples.  While prior works consider each data sample independently, the proposed regularizer uses the joint statistics of adversarial samples across a training minibatch to enhance optimization during both attack generation and training, obtaining state-of-the-art results amongst efficient defenses. We achieve further gains by incorporating exponential averaging of network weights over training iterations. We finally introduce a Hybrid training approach that combines the effectiveness of a two-step variant of the proposed defense with the efficiency of a single-step defense. We demonstrate superior results when compared to multi-step defenses such as TRADES and PGD-AT as well, at a significantly lower computational cost.",
      "tldr": "We propose methods to improve the efficiency and effectiveness of Adversarial Training",
      "site_url": "https://nips.cc/virtual/2021/poster/26270",
      "pdf_url": "https://openreview.net/pdf?id=kuK2VARZGnI",
      "github_url": "https://github.com/val-iisc/NuAT",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Arya_Baburaj1",
        "name": "Arya Baburaj",
        "name_site": null,
        "openreview_id": "~Arya_Baburaj1",
        "position": 3,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "250/5727.html",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 0.0,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 84,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "rsNBA9gtDf4",
      "title": "Aligning Silhouette Topology for Self-Adaptive 3D Human Pose Recovery",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Articulation-centric 2D/3D pose supervision forms the core training objective in most existing 3D human pose estimation techniques. Except for synthetic source environments, acquiring such rich supervision for each real target domain at deployment is highly inconvenient. However, we realize that standard foreground silhouette estimation techniques (on static camera feeds) remain unaffected by domain-shifts. Motivated by this, we propose a novel target adaptation framework that relies only on silhouette supervision to adapt a source-trained model-based regressor. However, in the absence of any auxiliary cue (multi-view, depth, or 2D pose), an isolated silhouette loss fails to provide a reliable pose-specific gradient and requires to be employed in tandem with a topology-centric loss. To this end, we develop a series of convolution-friendly spatial transformations in order to disentangle a topological-skeleton representation from the raw silhouette. Such a design paves the way to devise a Chamfer-inspired spatial topological-alignment loss via distance field computation, while effectively avoiding any gradient hindering spatial-to-pointset mapping. Experimental results demonstrate our superiority against prior-arts in self-adapting a source trained model to diverse unlabeled target domains, such as a) in-the-wild datasets, b) low-resolution image domains, and c) adversarially perturbed image domains (via UAP). ",
      "tldr": "A self-supervised domain adaptation framework for 3D human pose recovery using only silhouettes via topological alignment.",
      "site_url": "https://nips.cc/virtual/2021/poster/26665",
      "pdf_url": "https://openreview.net/pdf?id=rsNBA9gtDf4",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Varun_Jampani2_3",
        "name": "Varun Jampani",
        "name_site": null,
        "openreview_id": "~Mugalodi_R_Rakesh1",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": "262/6075",
        "google_scholar_url": "bUF2QlIAAAAJ",
        "orcid": null,
        "linkedin_url": "rakesh-m-179476191/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.5,
        "confidence_mean": 4.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 11,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "MckiHYXsBT",
      "title": "Learning to Select Exogenous Events for Marked Temporal Point Process",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Marked temporal point processes (MTPPs) have emerged as a powerful modeling\ntool for a wide variety of applications which are characterized using discrete\nevents localized in continuous time. In this context, the events are of two types\nendogenous events which occur due to the influence of the previous events and\nexogenous events which occur due to the effect of the externalities. However, in\npractice, the events do not come with endogenous or exogenous labels. To this\nend, our goal in this paper is to identify the set of exogenous events from a set of\nunlabelled events. To do so, we first formulate the parameter estimation problem\nin conjunction with exogenous event set selection problem and show that this\nproblem is NP hard. Next, we prove that the underlying objective is a monotone\nand \\alpha-submodular set function, with respect to the candidate set of exogenous\nevents. Such a characterization subsequently allows us to use a stochastic greedy\nalgorithm which was originally proposed in~\\cite{greedy}for submodular maximization.\nHowever, we show that it also admits an approximation guarantee for maximizing\n\\alpha-submodular set function, even when the learning algorithm provides an imperfect\nestimates of the trained parameters. Finally, our experiments with synthetic and\nreal data show that our method performs better than the existing approaches built\nupon superposition of endogenous and exogenous MTPPs.",
      "tldr": "It learns to select exogenous events from a set of  events in the context of marked temporal point processes",
      "site_url": "https://nips.cc/virtual/2021/poster/26623",
      "pdf_url": "https://openreview.net/pdf?id=MckiHYXsBT",
      "github_url": "https://github.com/noilreed/TPP-Select",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Gaurav_Aggarwal4",
        "name": "Gaurav Aggarwal",
        "name_site": null,
        "openreview_id": "~Gaurav_Aggarwal4",
        "position": 4,
        "gender": null,
        "homepage_url": null,
        "dblp_id": "14/5218",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=9XiIwDQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 1.25,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 10,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "U7SBcmRf65",
      "title": "Training for the Future: A Simple Gradient Interpolation Loss to Generalize Along Time",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In several real world applications, machine learning models are deployed to make predictions on data whose distribution changes gradually along time, leading to a drift between the train and test distributions. Such models are often re-trained on new data periodically, and they hence need to generalize to data not too far into the future. In this context, there is much prior work on enhancing temporal generalization, e.g. continuous transportation of past data, kernel smoothed time-sensitive parameters and more recently, adversarial learning of time-invariant features. However, these methods share several limitations, e.g, poor scalability, training instability, and dependence on unlabeled data from the future. Responding to the above limitations, we propose a simple method that starts with a model with time-sensitive parameters but regularizes its temporal complexity using a Gradient Interpolation  (GI) loss. GI allows the decision boundary to change along time and can still prevent overfitting to the limited training time snapshots  by allowing task-specific control over changes along time. We compare our method to existing baselines on multiple real-world datasets, which show that GI outperforms more complicated generative and adversarial approaches on the one hand, and simpler gradient regularization methods on the other.",
      "tldr": "We propose a simple gradient interpolation loss to enable models to generalize to unseen future data.",
      "site_url": "https://nips.cc/virtual/2021/poster/27251",
      "pdf_url": "https://openreview.net/pdf?id=U7SBcmRf65",
      "github_url": "https://github.com/anshuln/Training-for-the-Future",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abir_De1",
        "name": "Abir De",
        "name_site": null,
        "openreview_id": "~Abir_De1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "118/7174",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=_9ZKKbIAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.25,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 31,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "AIQOddM5Xm",
      "title": "Non-local Latent Relation Distillation for Self-Adaptive 3D Human Pose Estimation",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Available 3D human pose estimation approaches leverage different forms of strong (2D/3D pose) or weak (multi-view or depth) paired supervision. Barring synthetic or in-studio domains, acquiring such supervision for each new target environment is highly inconvenient. To this end, we cast 3D pose learning as a self-supervised adaptation problem that aims to transfer the task knowledge from a labeled source domain to a completely unpaired target. We propose to infer image-to-pose via two explicit mappings viz. image-to-latent and latent-to-pose where the latter is a pre-learned decoder obtained from a prior-enforcing generative adversarial auto-encoder. Next, we introduce relation distillation as a means to align the unpaired cross-modal samples i.e., the unpaired target videos and unpaired 3D pose sequences. To this end, we propose a new set of non-local relations in order to characterize long-range latent pose interactions, unlike general contrastive relations where positive couplings are limited to a local neighborhood structure. Further, we provide an objective way to quantify non-localness in order to select the most effective relation set. We evaluate different self-adaptation settings and demonstrate state-of-the-art 3D human pose estimation performance on standard benchmarks.",
      "tldr": "We introduce relation distillation as a means to align the unpaired cross-modal samples i.e., unpaired target videos and unpaired 3D pose sequences for self-adapting 3D human pose estimation.",
      "site_url": "https://nips.cc/virtual/2021/poster/26641",
      "pdf_url": "https://openreview.net/pdf?id=AIQOddM5Xm",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anirban_Chakraborty1",
        "name": "Anirban Chakraborty",
        "name_site": null,
        "openreview_id": "~Venkatesh_Babu_Radhakrishnan2",
        "position": 6,
        "gender": "M",
        "homepage_url": "http://cds.iisc.ac.in/faculty/venky",
        "dblp_id": "20/6289",
        "google_scholar_url": "cVg7HrEAAAAJ",
        "orcid": "0000-0002-1926-1804",
        "linkedin_url": "venkatesh-babu-radhakrishnan-16568939",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.8333333333333331,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 12,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "1Y9fPheTgpp",
      "title": "Robustness Disparities in Commercial Face Detection",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Facial detection and analysis systems have been deployed by large companies and critiqued by scholars and activists for the past decade. Critiques that focus on system performance analyze disparity of the system's output, i.e., how frequently is a face detected for different Fitzpatrick skin types or perceived genders. However, we focus on the robustness of these system outputs under noisy natural perturbations. We present the first of its kind detailed benchmark of the robustness of two such systems: Amazon Rekognition and Microsoft Azure. We use both standard and recently released academic facial datasets to quantitatively analyze trends in robustness for each. Qualitatively across all the datasets and systems, we find that photos of individuals who are \\emph{older}, \\emph{masculine presenting}, of \\emph{darker skin type}, or have \\emph{dim lighting} are more susceptible to errors than their counterparts in other identities.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=1Y9fPheTgpp",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Samuel_Dooley1",
        "name": "Samuel Dooley",
        "name_site": null,
        "openreview_id": "~Samuel_Dooley1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Maryland (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 19,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "BlcUQYxknbX",
      "title": "What Ails One-Shot Image Segmentation: A Data Perspective",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "One-shot image segmentation (OSS) methods enable semantic labeling of image pixels without supervised training with an extensive dataset. They require just one example (image, mask) pair per target class. Most neural-network-based methods train on a large subset of dataset classes and are evaluated on a disjoint subset of classes. We posit that the data used for training induces negative biases and affects the accuracy of these methods. Specifically, we present evidence for a \\textit{Class Negative Bias} (CNB) arising from treating non-target objects as background during training, and \\textit{Salience Bias} (SB), affecting the segmentation accuracy for non-salient target class pixels. We also demonstrate that by eliminating CNB and SB, significant gains can be made over the existing state-of-the-art. Next, we argue that there is a significant disparity between real-world expectations from an OSS method and its accuracy reported on existing benchmarks. To this end, we propose a new evaluation dataset - Tiered One-shot Segmentation (TOSS) - based on the PASCAL $5^i$ and FSS-1000 datasets, and associated metrics for each tier. The dataset enforces uniformity in the measurement of accuracy for existing methods and affords fine-grained insights into the applicability of a method to real applications. The paper includes extensive experiments with the TOSS dataset on several existing OSS methods. The intended impact of this work is to point to biases in training and introduce nuances and uniformity in reporting results for the OSS problem. The evaluation splits of the TOSS dataset and instructions for use are available at \\url{https://github.com/fewshotseg/toss}.",
      "tldr": "We propose training and evaluation improvements for One-shot image segmentation with evidence for negative inductive biases in existing methods as well as a new evaluation dataset for nuanced reporting.",
      "site_url": "https://openreview.net/forum?id=BlcUQYxknbX",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Abhinav_Patel1",
        "name": "Abhinav Patel",
        "name_site": null,
        "openreview_id": "~Abhinav_Patel1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "EnWxZjoAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology (BHU) (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "BlcUQYxknbX",
      "title": "What Ails One-Shot Image Segmentation: A Data Perspective",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "One-shot image segmentation (OSS) methods enable semantic labeling of image pixels without supervised training with an extensive dataset. They require just one example (image, mask) pair per target class. Most neural-network-based methods train on a large subset of dataset classes and are evaluated on a disjoint subset of classes. We posit that the data used for training induces negative biases and affects the accuracy of these methods. Specifically, we present evidence for a \\textit{Class Negative Bias} (CNB) arising from treating non-target objects as background during training, and \\textit{Salience Bias} (SB), affecting the segmentation accuracy for non-salient target class pixels. We also demonstrate that by eliminating CNB and SB, significant gains can be made over the existing state-of-the-art. Next, we argue that there is a significant disparity between real-world expectations from an OSS method and its accuracy reported on existing benchmarks. To this end, we propose a new evaluation dataset - Tiered One-shot Segmentation (TOSS) - based on the PASCAL $5^i$ and FSS-1000 datasets, and associated metrics for each tier. The dataset enforces uniformity in the measurement of accuracy for existing methods and affords fine-grained insights into the applicability of a method to real applications. The paper includes extensive experiments with the TOSS dataset on several existing OSS methods. The intended impact of this work is to point to biases in training and introduce nuances and uniformity in reporting results for the OSS problem. The evaluation splits of the TOSS dataset and instructions for use are available at \\url{https://github.com/fewshotseg/toss}.",
      "tldr": "We propose training and evaluation improvements for One-shot image segmentation with evidence for negative inductive biases in existing methods as well as a new evaluation dataset for nuanced reporting.",
      "site_url": "https://openreview.net/forum?id=BlcUQYxknbX",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "tej.shimpi@gmail.com",
        "name": "Tejas Shimpi",
        "name_site": null,
        "openreview_id": "tej.shimpi@gmail.com",
        "position": 3,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "R7vr14ffhF9",
      "title": "Synthetic Benchmarks for Scientific Research in Explainable Machine Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "As machine learning models grow more complex and their applications become more high-stakes, tools for explaining model predictions have become increasingly important. This has spurred a flurry of research in model explainability and has given rise to feature attribution methods such as LIME and SHAP. Despite their widespread use, evaluating and comparing different feature attribution methods remains challenging: evaluations ideally require human studies, and empirical evaluation metrics are often data-intensive or computationally prohibitive on real-world datasets. In this work, we address this issue by releasing XAI-BENCH: a suite of synthetic datasets along with a library for benchmarking feature attribution algorithms. Unlike real-world datasets, synthetic datasets allow the efficient computation of conditional expected values that are needed to evaluate ground-truth Shapley values and other metrics. The synthetic datasets we release offer a wide variety of parameters that can be configured to simulate real-world data. We demonstrate the power of our library by benchmarking popular explainability techniques across several evaluation metrics and across a variety of settings. The versatility and efficiency of our library will help researchers bring their explainability methods from development to deployment. Our code is available at https://github.com/abacusai/xai-bench.",
      "tldr": "We release a set of synthetic benchmarks for explainable AI and use it to benchmark existing approaches across a variety of settings.",
      "site_url": "https://openreview.net/forum?id=R7vr14ffhF9",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Sujay_Khandagale1",
        "name": "Sujay Khandagale",
        "name_site": null,
        "openreview_id": "~Sujay_Khandagale1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://suj97.github.io/",
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.fi/citations?user=7fwPm3wAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Abacus.AI (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 0.816496580927726,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.9428090415820634,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 86,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "WH0taVJii5_",
      "title": "Trading Complexity for Sparsity in Random Forest Explanations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Random forests have long been considered as powerful model ensembles in statistical machine learning.  By training multiple decision trees, whose diversity is fostered through bagging and subspace sampling, the resulting random forest can lead to more stable and reliable predictions than a single decision tree. This however comes at the cost of decreased interpretability: although decision trees are often easily interpretable, the predictions made by random forests are much more difficult to understand, as they involve a majority vote among hundreds of decision trees. In this paper, we examine different types of reasons that explain ``why'' an input instance is classified as positive or negative by a Boolean random forest. Notably, as an approximation of sufficient reasons (that take the form of prime implicants of the random forest), we introduce majority reasons which are prime implicants of a strict majority of decision trees. For these different abductive explanations, the tractability of the generation problem (finding one reason) and the minimization problem (finding one shortest reason) are investigated. Experiments conducted on various datasets reveal the existence of a trade-off between runtime complexity and sparsity. In a nutshell, sufficient reasons - for which the identification problem has been proved recently as DP-complete - are slightly shorter than majority reasons that can be generated using a simple polynomial-time greedy algorithm; minimal majority reasons - for which the identification problem is shown NP-complete - are significantly shorter than sufficient reasons and they can be computed using a partial MaxSAT algorithm that turns out to be quite efficient in practice. ",
      "tldr": "We examine several types of explanations for random forest predictions, which together offer a trade-off between runtime complexity and sparsity.",
      "site_url": "https://openreview.net/forum?id=WH0taVJii5_",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Main Conference",
      "author": {
        "id": "~Steve_Bellart1",
        "name": "Steve Bellart",
        "name_site": null,
        "openreview_id": "~Steve_Bellart1",
        "position": 2,
        "gender": "M",
        "homepage_url": "http://www.cril.univ-artois.fr/members/bellart.html",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "CRIL (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 2.8613807855648994,
        "confidence_mean": 4.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 44,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "WH0taVJii5_",
      "title": "Trading Complexity for Sparsity in Random Forest Explanations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Random forests have long been considered as powerful model ensembles in statistical machine learning.  By training multiple decision trees, whose diversity is fostered through bagging and subspace sampling, the resulting random forest can lead to more stable and reliable predictions than a single decision tree. This however comes at the cost of decreased interpretability: although decision trees are often easily interpretable, the predictions made by random forests are much more difficult to understand, as they involve a majority vote among hundreds of decision trees. In this paper, we examine different types of reasons that explain ``why'' an input instance is classified as positive or negative by a Boolean random forest. Notably, as an approximation of sufficient reasons (that take the form of prime implicants of the random forest), we introduce majority reasons which are prime implicants of a strict majority of decision trees. For these different abductive explanations, the tractability of the generation problem (finding one reason) and the minimization problem (finding one shortest reason) are investigated. Experiments conducted on various datasets reveal the existence of a trade-off between runtime complexity and sparsity. In a nutshell, sufficient reasons - for which the identification problem has been proved recently as DP-complete - are slightly shorter than majority reasons that can be generated using a simple polynomial-time greedy algorithm; minimal majority reasons - for which the identification problem is shown NP-complete - are significantly shorter than sufficient reasons and they can be computed using a partial MaxSAT algorithm that turns out to be quite efficient in practice. ",
      "tldr": "We examine several types of explanations for random forest predictions, which together offer a trade-off between runtime complexity and sparsity.",
      "site_url": "https://openreview.net/forum?id=WH0taVJii5_",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Main Conference",
      "author": {
        "id": "~Louenas_Bounia1",
        "name": "Louenas Bounia",
        "name_site": null,
        "openreview_id": "~Louenas_Bounia1",
        "position": 3,
        "gender": null,
        "homepage_url": "http://www.cril.univ-artois.fr/members/bounia.html",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Centre for Research in Logic and its Applications (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 2.8613807855648994,
        "confidence_mean": 4.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 44,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "WH0taVJii5_",
      "title": "Trading Complexity for Sparsity in Random Forest Explanations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Random forests have long been considered as powerful model ensembles in statistical machine learning.  By training multiple decision trees, whose diversity is fostered through bagging and subspace sampling, the resulting random forest can lead to more stable and reliable predictions than a single decision tree. This however comes at the cost of decreased interpretability: although decision trees are often easily interpretable, the predictions made by random forests are much more difficult to understand, as they involve a majority vote among hundreds of decision trees. In this paper, we examine different types of reasons that explain ``why'' an input instance is classified as positive or negative by a Boolean random forest. Notably, as an approximation of sufficient reasons (that take the form of prime implicants of the random forest), we introduce majority reasons which are prime implicants of a strict majority of decision trees. For these different abductive explanations, the tractability of the generation problem (finding one reason) and the minimization problem (finding one shortest reason) are investigated. Experiments conducted on various datasets reveal the existence of a trade-off between runtime complexity and sparsity. In a nutshell, sufficient reasons - for which the identification problem has been proved recently as DP-complete - are slightly shorter than majority reasons that can be generated using a simple polynomial-time greedy algorithm; minimal majority reasons - for which the identification problem is shown NP-complete - are significantly shorter than sufficient reasons and they can be computed using a partial MaxSAT algorithm that turns out to be quite efficient in practice. ",
      "tldr": "We examine several types of explanations for random forest predictions, which together offer a trade-off between runtime complexity and sparsity.",
      "site_url": "https://openreview.net/forum?id=WH0taVJii5_",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Main Conference",
      "author": {
        "id": "~Frederic_M_Koriche1",
        "name": "Frederic M Koriche",
        "name_site": null,
        "openreview_id": "~Frederic_M_Koriche1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "70/4456",
        "google_scholar_url": null,
        "orcid": "0000-0002-6952-5775",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Centre for Research in Logic and its Applications (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 2.8613807855648994,
        "confidence_mean": 4.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 44,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "WH0taVJii5_",
      "title": "Trading Complexity for Sparsity in Random Forest Explanations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Random forests have long been considered as powerful model ensembles in statistical machine learning.  By training multiple decision trees, whose diversity is fostered through bagging and subspace sampling, the resulting random forest can lead to more stable and reliable predictions than a single decision tree. This however comes at the cost of decreased interpretability: although decision trees are often easily interpretable, the predictions made by random forests are much more difficult to understand, as they involve a majority vote among hundreds of decision trees. In this paper, we examine different types of reasons that explain ``why'' an input instance is classified as positive or negative by a Boolean random forest. Notably, as an approximation of sufficient reasons (that take the form of prime implicants of the random forest), we introduce majority reasons which are prime implicants of a strict majority of decision trees. For these different abductive explanations, the tractability of the generation problem (finding one reason) and the minimization problem (finding one shortest reason) are investigated. Experiments conducted on various datasets reveal the existence of a trade-off between runtime complexity and sparsity. In a nutshell, sufficient reasons - for which the identification problem has been proved recently as DP-complete - are slightly shorter than majority reasons that can be generated using a simple polynomial-time greedy algorithm; minimal majority reasons - for which the identification problem is shown NP-complete - are significantly shorter than sufficient reasons and they can be computed using a partial MaxSAT algorithm that turns out to be quite efficient in practice. ",
      "tldr": "We examine several types of explanations for random forest predictions, which together offer a trade-off between runtime complexity and sparsity.",
      "site_url": "https://openreview.net/forum?id=WH0taVJii5_",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jean-Marie_Lagniez2",
        "name": "Jean-Marie Lagniez",
        "name_site": null,
        "openreview_id": "~Jean-Marie_Lagniez2",
        "position": 5,
        "gender": "M",
        "homepage_url": "http://www.cril.univ-artois.fr/~lagniez/",
        "dblp_id": "28/7480.html",
        "google_scholar_url": "https://scholar.google.fr/citations?user=xO_Qyr0AAAAJ",
        "orcid": "0000-0002-6557-4115",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Centre for Research in Logic and its Applications (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 2.8613807855648994,
        "confidence_mean": 4.5,
        "confidence_std": 0.8660254037844386,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 44,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "c20jiJ5K2H",
      "title": "Multilingual Spoken Words Corpus",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Multilingual Spoken Words Corpus is a large and growing audio dataset of spoken words in 50 languages collectively spoken by over 5 billion people, for academic research and commercial applications in keyword spotting and spoken term search, licensed under CC-BY 4.0. The dataset contains more than 340,000 keywords, totaling 23.4 million 1-second spoken examples (over 6,000 hours). The dataset has many use cases, ranging from voice-enabled consumer devices to call center automation. We generate this dataset by applying forced alignment on crowd-sourced sentence-level audio to produce per-word timing estimates for extraction. All alignments are included in the dataset. We provide a detailed analysis of the contents of the data and contribute methods for detecting potential outliers. We report baseline accuracy metrics on keyword spotting models trained from our dataset compared to models trained on a manually-recorded keyword dataset. We conclude with our plans for dataset maintenance, updates, and open-sourced code.",
      "tldr": "Multilingual Spoken Words Corpus is a speech dataset of over 340,000 spoken words in 50 languages, with over 23.4 million examples.",
      "site_url": "https://openreview.net/forum?id=c20jiJ5K2H",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Sharad_Chitlangia1",
        "name": "Sharad Chitlangia",
        "name_site": null,
        "openreview_id": "~Sharad_Chitlangia1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://www.sharadchitlang.ai/",
        "dblp_id": "249/9357",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=1GG3RAcAAAAJ",
        "orcid": null,
        "linkedin_url": "sharad-chitlangia/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 7.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 66,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "cB3OdLInAr9",
      "title": "AIT-QA: Question Answering Dataset over Complex Tables in the Airline Industry",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Recent advances in transformers have enabled Table Question Answering (Table QA) systems to achieve high accuracy and SOTA results on open domain datasets like WikiTableQuestions and WikiSQL. Such transformers are frequently pre-trained on open-domain content such as Wikipedia, where they effectively encode questions and corresponding tables from Wikipedia as seen in Table QA dataset. However, web tables in Wikipedia are notably flat in their layout, with the first row as the sole column header. The layout lends to a relational view of tables where each row is a tuple. Whereas, tables in domain-specific business or scientific documents often have a much more complex layout, including hierarchical row and column headers, in addition to having specialized vocabulary terms from that domain. To address this problem, we introduce the domain-specific Table QA dataset AITQA (Airline Industry Table QA). The dataset consists of 515 questions authored by human annotators on 116 tables extracted from public U.S. SEC filings (SEC Filings publicly available at: https://www.sec.gov/edgar.shtml) of major airline companies for the fiscal years 2017-2019. We also provide annotations pertaining to the nature of questions, marking those that require hierarchical headers, domain-specific terminology, and paraphrased forms. Our zero-shot baseline evaluation of three transformer-based SOTA Table QA methods - TaPAS (end-to-end), TaBERT (semantic parsing-based), and RCI (row-column encoding-based) - clearly exposes the limitation of these methods in this practical setting, with the best accuracy at just 51.8% (RCI). We also present pragmatic table pre-processing steps used to pivot and project these complex tables into a layout suitable for the SOTA Table QA models.",
      "tldr": "a real-world table QA dataset of 515 questions and on 116 tables extracted from public U.S. SEC filings of major airline companies for the fiscal years 2017-2019. The tables have a complex layout, numerical cells and domain specific terms. ",
      "site_url": "https://openreview.net/forum?id=cB3OdLInAr9",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Soumen_Chakrabarti1",
        "name": "Soumen Chakrabarti",
        "name_site": null,
        "openreview_id": "~Soumen_Chakrabarti1",
        "position": 11,
        "gender": "Not Specified",
        "homepage_url": "https://www.cse.iitb.ac.in/~soumen/",
        "dblp_id": "c/SChakrabarti",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=LfF2zfQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 40,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "gWIbXsrtOCc",
      "title": "Systematic Evaluation of Causal Discovery in Visual Model Based Reinforcement Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Inducing causal relationships from observations is a classic problem in machine learning. Most work in causality starts from the premise that the causal variables themselves  are observed. However, for AI agents such as robots trying to make sense of their environment, the only observables are low-level variables like pixels in images. To generalize well, an agent must induce high-level variables, particularly those which are causal or are affected by causal variables. A central goal for AI and causality is thus the joint discovery of abstract representations and causal structure. However, we note that existing environments for studying causal induction are poorly suited for this  objective because they have complicated task-specific causal graphs which are impossible to manipulate parametrically (e.g., number of nodes, sparsity, causal chain length, etc.). In this work, our goal is to facilitate research in learning representations of high-level variables as well as causal structures among them. In order  to systematically probe the ability of methods to identify these variables and structures, we design a suite of benchmarking RL environments. We evaluate various representation learning algorithms from the literature and find that explicitly incorporating structure and modularity in models can help causal induction in model-based reinforcement learning.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=gWIbXsrtOCc",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Aniket_Rajiv_Didolkar1",
        "name": "Aniket Rajiv Didolkar",
        "name_site": null,
        "openreview_id": "~Aniket_Rajiv_Didolkar1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://github.com/dido1998/",
        "dblp_id": "245/8589",
        "google_scholar_url": "https://scholar.google.ca/citations?user=ekvl5o0AAAAJ",
        "orcid": null,
        "linkedin_url": "aniket-didolkar-7a9b8912a",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Manipal Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 52,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "iBLHqLgbRn",
      "title": "VISIOCITY: A New Benchmarking Dataset and Evaluation Framework Towards Realistic Video Summarization",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Automatic video summarization has attracted a lot of interest, but is still an unsolved problem due to several challenges. The currently available datasets either have very short videos or have a few long videos of only a particular type. We introduce a new benchmarking video dataset called VISIOCITY (VIdeo SummarIzatiOn based on Continuity, Intent and DiversiTY) which consists of longer videos across six different domains with dense concept annotations capable of supporting different flavors of video summarization and other vision problems. Secondly, supervised video summarization techniques require many human reference summaries as ground truth. Acquiring them is not easy, especially for long videos. We propose a strategy to automatically generate multiple reference summaries using the annotations present in VISIOCITY and show that these are at par with the human summaries. The annotations thus serve as indirect ground truth. Thirdly, due to the highly subjective nature of the task, different ideal reference summaries of long videos can be quite different from each other. Due to this, the current practice of evaluating a summary vis-a-vis a limited set of human summaries and over-dependence on a single measure has its shortcomings. Our proposed evaluation framework overcomes these and offers a better quantitative assessment of a summary's quality. Finally, based on the above observations we present insights into how a mixture model can be easily enhanced to yield better summaries and demonstrate the effectiveness of our recipe in doing so as compared to some of the representative state-of-the-art techniques when tested on VISIOCITY. We make VISIOCITY publicly available via our website (https://visiocity.github.io/).",
      "tldr": "We introduce a new dataset and evaluation framework as a step towards addressing some challenges in realistic video summarization",
      "site_url": "https://openreview.net/forum?id=iBLHqLgbRn",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Rishabh_K_Iyer2",
        "name": "Rishabh K Iyer",
        "name_site": null,
        "openreview_id": "~Rishabh_K_Iyer2",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.rishiyer.com",
        "dblp_id": "37/10544.html",
        "google_scholar_url": "l_XxJ1kAAAAJ",
        "orcid": null,
        "linkedin_url": "rishabh-iyer-36893717/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.816496580927726,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "iBLHqLgbRn",
      "title": "VISIOCITY: A New Benchmarking Dataset and Evaluation Framework Towards Realistic Video Summarization",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Automatic video summarization has attracted a lot of interest, but is still an unsolved problem due to several challenges. The currently available datasets either have very short videos or have a few long videos of only a particular type. We introduce a new benchmarking video dataset called VISIOCITY (VIdeo SummarIzatiOn based on Continuity, Intent and DiversiTY) which consists of longer videos across six different domains with dense concept annotations capable of supporting different flavors of video summarization and other vision problems. Secondly, supervised video summarization techniques require many human reference summaries as ground truth. Acquiring them is not easy, especially for long videos. We propose a strategy to automatically generate multiple reference summaries using the annotations present in VISIOCITY and show that these are at par with the human summaries. The annotations thus serve as indirect ground truth. Thirdly, due to the highly subjective nature of the task, different ideal reference summaries of long videos can be quite different from each other. Due to this, the current practice of evaluating a summary vis-a-vis a limited set of human summaries and over-dependence on a single measure has its shortcomings. Our proposed evaluation framework overcomes these and offers a better quantitative assessment of a summary's quality. Finally, based on the above observations we present insights into how a mixture model can be easily enhanced to yield better summaries and demonstrate the effectiveness of our recipe in doing so as compared to some of the representative state-of-the-art techniques when tested on VISIOCITY. We make VISIOCITY publicly available via our website (https://visiocity.github.io/).",
      "tldr": "We introduce a new dataset and evaluation framework as a step towards addressing some challenges in realistic video summarization",
      "site_url": "https://openreview.net/forum?id=iBLHqLgbRn",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Ganesh_Ramakrishnan1",
        "name": "Ganesh Ramakrishnan",
        "name_site": null,
        "openreview_id": "~Ganesh_Ramakrishnan1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://www.cse.iitb.ac.in/~ganesh/",
        "dblp_id": "r/GaneshRamakrishnan",
        "google_scholar_url": "https://scholar.google.com/scholar?hl=hi",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.816496580927726,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "n-219jrTht",
      "title": "On the Explanatory Power of Decision Trees",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Decision trees have long been recognized as models of choice in sensitive applications where interpretability is of paramount importance. In this paper, we examine the computational ability of Boolean decision trees in deriving, minimizing, and counting sufficient reasons and contrastive explanations. We prove that the set of all sufficient reasons of minimal size for an instance given a decision tree can be exponentially larger than the size of the input (the instance and the decision tree). Therefore, generating the full set of sufficient reasons can be out of reach. In addition, computing a single sufficient reason does not prove enough in general; indeed, two sufficient reasons for the same instance may differ on many features. To deal with this issue and generate synthetic views of the set of all sufficient reasons, we introduce the notions of relevant features and of necessary features that characterize the (possibly negated) features appearing in at least one or in every sufficient reason, and we show that they can be computed in polynomial time. We also introduce the notion of explanatory importance, that indicates how frequent each (possibly negated) feature is in the set of all sufficient reasons. We show how the explanatory importance of a feature and the number of sufficient reasons can be obtained via a model counting operation, which turns out to be practical in many cases. We also explain how to enumerate sufficient reasons of minimal size. We finally show that, unlike sufficient reasons, the set of all contrastive explanations for an instance given a decision tree can be derived, minimized and counted in polynomial time.",
      "tldr": "We focus on the issue of deriving deriving, minimizing, and counting sufficient reasons and contrastive explanations for decision tree classifiers. ",
      "site_url": "https://openreview.net/forum?id=n-219jrTht",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Main Conference",
      "author": {
        "id": "~Steve_Bellart1",
        "name": "Steve Bellart",
        "name_site": null,
        "openreview_id": "~Steve_Bellart1",
        "position": 2,
        "gender": "M",
        "homepage_url": "http://www.cril.univ-artois.fr/members/bellart.html",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "CRIL (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.666666666666667,
        "rating_std": 1.699673171197595,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 11,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "n-219jrTht",
      "title": "On the Explanatory Power of Decision Trees",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Decision trees have long been recognized as models of choice in sensitive applications where interpretability is of paramount importance. In this paper, we examine the computational ability of Boolean decision trees in deriving, minimizing, and counting sufficient reasons and contrastive explanations. We prove that the set of all sufficient reasons of minimal size for an instance given a decision tree can be exponentially larger than the size of the input (the instance and the decision tree). Therefore, generating the full set of sufficient reasons can be out of reach. In addition, computing a single sufficient reason does not prove enough in general; indeed, two sufficient reasons for the same instance may differ on many features. To deal with this issue and generate synthetic views of the set of all sufficient reasons, we introduce the notions of relevant features and of necessary features that characterize the (possibly negated) features appearing in at least one or in every sufficient reason, and we show that they can be computed in polynomial time. We also introduce the notion of explanatory importance, that indicates how frequent each (possibly negated) feature is in the set of all sufficient reasons. We show how the explanatory importance of a feature and the number of sufficient reasons can be obtained via a model counting operation, which turns out to be practical in many cases. We also explain how to enumerate sufficient reasons of minimal size. We finally show that, unlike sufficient reasons, the set of all contrastive explanations for an instance given a decision tree can be derived, minimized and counted in polynomial time.",
      "tldr": "We focus on the issue of deriving deriving, minimizing, and counting sufficient reasons and contrastive explanations for decision tree classifiers. ",
      "site_url": "https://openreview.net/forum?id=n-219jrTht",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Main Conference",
      "author": {
        "id": "~Louenas_Bounia1",
        "name": "Louenas Bounia",
        "name_site": null,
        "openreview_id": "~Louenas_Bounia1",
        "position": 3,
        "gender": null,
        "homepage_url": "http://www.cril.univ-artois.fr/members/bounia.html",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Centre for Research in Logic and its Applications (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.666666666666667,
        "rating_std": 1.699673171197595,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 11,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "n-219jrTht",
      "title": "On the Explanatory Power of Decision Trees",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Decision trees have long been recognized as models of choice in sensitive applications where interpretability is of paramount importance. In this paper, we examine the computational ability of Boolean decision trees in deriving, minimizing, and counting sufficient reasons and contrastive explanations. We prove that the set of all sufficient reasons of minimal size for an instance given a decision tree can be exponentially larger than the size of the input (the instance and the decision tree). Therefore, generating the full set of sufficient reasons can be out of reach. In addition, computing a single sufficient reason does not prove enough in general; indeed, two sufficient reasons for the same instance may differ on many features. To deal with this issue and generate synthetic views of the set of all sufficient reasons, we introduce the notions of relevant features and of necessary features that characterize the (possibly negated) features appearing in at least one or in every sufficient reason, and we show that they can be computed in polynomial time. We also introduce the notion of explanatory importance, that indicates how frequent each (possibly negated) feature is in the set of all sufficient reasons. We show how the explanatory importance of a feature and the number of sufficient reasons can be obtained via a model counting operation, which turns out to be practical in many cases. We also explain how to enumerate sufficient reasons of minimal size. We finally show that, unlike sufficient reasons, the set of all contrastive explanations for an instance given a decision tree can be derived, minimized and counted in polynomial time.",
      "tldr": "We focus on the issue of deriving deriving, minimizing, and counting sufficient reasons and contrastive explanations for decision tree classifiers. ",
      "site_url": "https://openreview.net/forum?id=n-219jrTht",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Main Conference",
      "author": {
        "id": "koriche@cril.fr",
        "name": "FrÃ©dÃ©ric Koriche",
        "name_site": null,
        "openreview_id": "koriche@cril.fr",
        "position": 4,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Centre for Research in Logic and its Applications (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.666666666666667,
        "rating_std": 1.699673171197595,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 11,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "n-219jrTht",
      "title": "On the Explanatory Power of Decision Trees",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Decision trees have long been recognized as models of choice in sensitive applications where interpretability is of paramount importance. In this paper, we examine the computational ability of Boolean decision trees in deriving, minimizing, and counting sufficient reasons and contrastive explanations. We prove that the set of all sufficient reasons of minimal size for an instance given a decision tree can be exponentially larger than the size of the input (the instance and the decision tree). Therefore, generating the full set of sufficient reasons can be out of reach. In addition, computing a single sufficient reason does not prove enough in general; indeed, two sufficient reasons for the same instance may differ on many features. To deal with this issue and generate synthetic views of the set of all sufficient reasons, we introduce the notions of relevant features and of necessary features that characterize the (possibly negated) features appearing in at least one or in every sufficient reason, and we show that they can be computed in polynomial time. We also introduce the notion of explanatory importance, that indicates how frequent each (possibly negated) feature is in the set of all sufficient reasons. We show how the explanatory importance of a feature and the number of sufficient reasons can be obtained via a model counting operation, which turns out to be practical in many cases. We also explain how to enumerate sufficient reasons of minimal size. We finally show that, unlike sufficient reasons, the set of all contrastive explanations for an instance given a decision tree can be derived, minimized and counted in polynomial time.",
      "tldr": "We focus on the issue of deriving deriving, minimizing, and counting sufficient reasons and contrastive explanations for decision tree classifiers. ",
      "site_url": "https://openreview.net/forum?id=n-219jrTht",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jean-Marie_Lagniez2",
        "name": "Jean-Marie Lagniez",
        "name_site": null,
        "openreview_id": "~Jean-Marie_Lagniez2",
        "position": 5,
        "gender": "M",
        "homepage_url": "http://www.cril.univ-artois.fr/~lagniez/",
        "dblp_id": "28/7480.html",
        "google_scholar_url": "https://scholar.google.fr/citations?user=xO_Qyr0AAAAJ",
        "orcid": "0000-0002-6557-4115",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.666666666666667,
        "rating_std": 1.699673171197595,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 11,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "pOf_IV_-XG",
      "title": "Using Dynamic Neural Networks to Model the Speed-Accuracy Trade-Off in People",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Neural networks have been shown to exhibit remarkable object recognition performance. We ask here whether such networks can provide a useful model for how people recognize objects. Human recognition time varies, from 0.1 to 10 s, depending on the stimulus and task. Slowness of recognition is a key feature in some public health issues, such as dyslexia, so it is crucial to create a model of human speed-accuracy trade-offs. This is an essential aspect of any useful computational model of human cognitive behavior. We present a benchmark dataset for human speed-accuracy trade-off in recognizing a CIFAR-10 image~\\cite{Krizhevsky09learningmultiple} from a set of provided class labels. Within a series of trials, a beep sounds at a fixed delay after the target (the desired reaction time), and the response counts only if it occurs near that time. We observe that accuracy grows with reaction time and examine several dynamic neural networks that exhibit a speed-accuracy trade-off as humans do. After limiting the network resources and adding image perturbations (grayscale conversion, noise, blur) to bring the two observers (human and network) into the same accuracy range, humans and networks show very similar dependence on duration or floating point operations (FLOPS). We conclude that dynamic neural networks are a promising model of human reaction time in recognition tasks. Understanding how the brain allocates appropriate resources under time pressure would be a milestone in neuroscience and a first step toward understanding conditions like dyslexia. Our dataset and code are publicly available.\n",
      "tldr": "We collect a human benchmark of the speed-accuracy trade-offs for an object recognition task and model it with neural networks",
      "site_url": "https://openreview.net/forum?id=pOf_IV_-XG",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Ajay_Subramanian1",
        "name": "Ajay Subramanian",
        "name_site": null,
        "openreview_id": "~Ajay_Subramanian1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://ajaysubramanian.com",
        "dblp_id": null,
        "google_scholar_url": "6cyu_EgAAAAJ",
        "orcid": "0000-0003-1017-9000",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.666666666666667,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 1.247219128924647,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "q7XJj9_egih",
      "title": "Particulate Matter Dataset Collected with Vehicle Mounted IoT Devices in Delhi-NCR",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Air pollution is one of the biggest concerns faced by developing countries like India and the world at large. The capital of India, Delhi and the National Capital Region (NCR), sees life threatening air pollution levels. This paper presents a new Particulate Matter (PM) dataset for Delhi-NCR, which contains PM data recorded over three months from November 2020 to January 2021 over an area spanning 559 square Kms. The data has been collected using vehicle-mounted mobile sensors in collaboration with the Delhi Integrated Multi-Modal Transit System (DIMTS) buses. The 13 bus dataset has been compared with the data over the same period obtained from the pre-existing static sensors, which the buses pass by. Several Machine Learning (ML) problems have been outlined, that can be studied using this dataset, two of which, spatio-temporal interpolation and anomaly detection in IoT networks are detailed in this paper. The dataset is public at https://www.cse.iitd.ac.in/pollutiondata, along with appropriate documentation. We will keep augmenting the website as new data get collected, with more buses and other pollutant sensors (SOx, NOx, COx) added to our deployment in future. ",
      "tldr": "A new dataset of air pollutant Particulate Matter (PM) collected using IoT devices on public buses in Delhi. ML problems of \"spatio-temporal interpolation\" and \"anomaly detection in IoT networks\" detailed using the dataset.",
      "site_url": "https://openreview.net/forum?id=q7XJj9_egih",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Ishan_Nangia1",
        "name": "Ishan Nangia",
        "name_site": null,
        "openreview_id": "~Ishan_Nangia1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "ishan-nangia-413571114/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "q7XJj9_egih",
      "title": "Particulate Matter Dataset Collected with Vehicle Mounted IoT Devices in Delhi-NCR",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Air pollution is one of the biggest concerns faced by developing countries like India and the world at large. The capital of India, Delhi and the National Capital Region (NCR), sees life threatening air pollution levels. This paper presents a new Particulate Matter (PM) dataset for Delhi-NCR, which contains PM data recorded over three months from November 2020 to January 2021 over an area spanning 559 square Kms. The data has been collected using vehicle-mounted mobile sensors in collaboration with the Delhi Integrated Multi-Modal Transit System (DIMTS) buses. The 13 bus dataset has been compared with the data over the same period obtained from the pre-existing static sensors, which the buses pass by. Several Machine Learning (ML) problems have been outlined, that can be studied using this dataset, two of which, spatio-temporal interpolation and anomaly detection in IoT networks are detailed in this paper. The dataset is public at https://www.cse.iitd.ac.in/pollutiondata, along with appropriate documentation. We will keep augmenting the website as new data get collected, with more buses and other pollutant sensors (SOx, NOx, COx) added to our deployment in future. ",
      "tldr": "A new dataset of air pollutant Particulate Matter (PM) collected using IoT devices on public buses in Delhi. ML problems of \"spatio-temporal interpolation\" and \"anomaly detection in IoT networks\" detailed using the dataset.",
      "site_url": "https://openreview.net/forum?id=q7XJj9_egih",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Chinmay_Degwekar1",
        "name": "Chinmay Degwekar",
        "name_site": null,
        "openreview_id": "~Chinmay_Degwekar1",
        "position": 2,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "chinmay-degwekar-017182bb/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "q7XJj9_egih",
      "title": "Particulate Matter Dataset Collected with Vehicle Mounted IoT Devices in Delhi-NCR",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Air pollution is one of the biggest concerns faced by developing countries like India and the world at large. The capital of India, Delhi and the National Capital Region (NCR), sees life threatening air pollution levels. This paper presents a new Particulate Matter (PM) dataset for Delhi-NCR, which contains PM data recorded over three months from November 2020 to January 2021 over an area spanning 559 square Kms. The data has been collected using vehicle-mounted mobile sensors in collaboration with the Delhi Integrated Multi-Modal Transit System (DIMTS) buses. The 13 bus dataset has been compared with the data over the same period obtained from the pre-existing static sensors, which the buses pass by. Several Machine Learning (ML) problems have been outlined, that can be studied using this dataset, two of which, spatio-temporal interpolation and anomaly detection in IoT networks are detailed in this paper. The dataset is public at https://www.cse.iitd.ac.in/pollutiondata, along with appropriate documentation. We will keep augmenting the website as new data get collected, with more buses and other pollutant sensors (SOx, NOx, COx) added to our deployment in future. ",
      "tldr": "A new dataset of air pollutant Particulate Matter (PM) collected using IoT devices on public buses in Delhi. ML problems of \"spatio-temporal interpolation\" and \"anomaly detection in IoT networks\" detailed using the dataset.",
      "site_url": "https://openreview.net/forum?id=q7XJj9_egih",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Sagar_Gaddam1",
        "name": "Sagar Gaddam",
        "name_site": null,
        "openreview_id": "~Sagar_Gaddam1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "sagar-gaddam-40908a118/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "q7XJj9_egih",
      "title": "Particulate Matter Dataset Collected with Vehicle Mounted IoT Devices in Delhi-NCR",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Air pollution is one of the biggest concerns faced by developing countries like India and the world at large. The capital of India, Delhi and the National Capital Region (NCR), sees life threatening air pollution levels. This paper presents a new Particulate Matter (PM) dataset for Delhi-NCR, which contains PM data recorded over three months from November 2020 to January 2021 over an area spanning 559 square Kms. The data has been collected using vehicle-mounted mobile sensors in collaboration with the Delhi Integrated Multi-Modal Transit System (DIMTS) buses. The 13 bus dataset has been compared with the data over the same period obtained from the pre-existing static sensors, which the buses pass by. Several Machine Learning (ML) problems have been outlined, that can be studied using this dataset, two of which, spatio-temporal interpolation and anomaly detection in IoT networks are detailed in this paper. The dataset is public at https://www.cse.iitd.ac.in/pollutiondata, along with appropriate documentation. We will keep augmenting the website as new data get collected, with more buses and other pollutant sensors (SOx, NOx, COx) added to our deployment in future. ",
      "tldr": "A new dataset of air pollutant Particulate Matter (PM) collected using IoT devices on public buses in Delhi. ML problems of \"spatio-temporal interpolation\" and \"anomaly detection in IoT networks\" detailed using the dataset.",
      "site_url": "https://openreview.net/forum?id=q7XJj9_egih",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "mcs192571@cse.iitd.ac.in",
        "name": "Saswat Kumar Pujari",
        "name_site": null,
        "openreview_id": "mcs192571@cse.iitd.ac.in",
        "position": 4,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "q7XJj9_egih",
      "title": "Particulate Matter Dataset Collected with Vehicle Mounted IoT Devices in Delhi-NCR",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Air pollution is one of the biggest concerns faced by developing countries like India and the world at large. The capital of India, Delhi and the National Capital Region (NCR), sees life threatening air pollution levels. This paper presents a new Particulate Matter (PM) dataset for Delhi-NCR, which contains PM data recorded over three months from November 2020 to January 2021 over an area spanning 559 square Kms. The data has been collected using vehicle-mounted mobile sensors in collaboration with the Delhi Integrated Multi-Modal Transit System (DIMTS) buses. The 13 bus dataset has been compared with the data over the same period obtained from the pre-existing static sensors, which the buses pass by. Several Machine Learning (ML) problems have been outlined, that can be studied using this dataset, two of which, spatio-temporal interpolation and anomaly detection in IoT networks are detailed in this paper. The dataset is public at https://www.cse.iitd.ac.in/pollutiondata, along with appropriate documentation. We will keep augmenting the website as new data get collected, with more buses and other pollutant sensors (SOx, NOx, COx) added to our deployment in future. ",
      "tldr": "A new dataset of air pollutant Particulate Matter (PM) collected using IoT devices on public buses in Delhi. ML problems of \"spatio-temporal interpolation\" and \"anomaly detection in IoT networks\" detailed using the dataset.",
      "site_url": "https://openreview.net/forum?id=q7XJj9_egih",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "csz158373@cse.iitd.ac.in",
        "name": "Ismi Abidi",
        "name_site": null,
        "openreview_id": "csz158373@cse.iitd.ac.in",
        "position": 5,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "q7XJj9_egih",
      "title": "Particulate Matter Dataset Collected with Vehicle Mounted IoT Devices in Delhi-NCR",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Air pollution is one of the biggest concerns faced by developing countries like India and the world at large. The capital of India, Delhi and the National Capital Region (NCR), sees life threatening air pollution levels. This paper presents a new Particulate Matter (PM) dataset for Delhi-NCR, which contains PM data recorded over three months from November 2020 to January 2021 over an area spanning 559 square Kms. The data has been collected using vehicle-mounted mobile sensors in collaboration with the Delhi Integrated Multi-Modal Transit System (DIMTS) buses. The 13 bus dataset has been compared with the data over the same period obtained from the pre-existing static sensors, which the buses pass by. Several Machine Learning (ML) problems have been outlined, that can be studied using this dataset, two of which, spatio-temporal interpolation and anomaly detection in IoT networks are detailed in this paper. The dataset is public at https://www.cse.iitd.ac.in/pollutiondata, along with appropriate documentation. We will keep augmenting the website as new data get collected, with more buses and other pollutant sensors (SOx, NOx, COx) added to our deployment in future. ",
      "tldr": "A new dataset of air pollutant Particulate Matter (PM) collected using IoT devices on public buses in Delhi. ML problems of \"spatio-temporal interpolation\" and \"anomaly detection in IoT networks\" detailed using the dataset.",
      "site_url": "https://openreview.net/forum?id=q7XJj9_egih",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Sayan_Ranu2",
        "name": "Sayan Ranu",
        "name_site": null,
        "openreview_id": "~Sayan_Ranu2",
        "position": 8,
        "gender": "M",
        "homepage_url": "https://www.cse.iitd.ac.in/~sayan/index.html",
        "dblp_id": "38/768",
        "google_scholar_url": "K4w5qYUAAAAJ",
        "orcid": "0000-0003-4147-9372",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "t1kTABPcp9s",
      "title": "Indian-COVID-19 CT Dataset and Analysis of Chest CT Scans of COVID-19 Patients Using Lightweight CNN",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Indian-COVID-19 CT is the chest Computed Tomography (CT) images from COVID-19 patients from India. It has been collected and curated to aid in the diagnosis of COVID-19 and other chest CT analysis tasks using machine learning algorithms. Currently it consists of 6174 images from 142 patients COVID-19, obtained from a single hospital with same image acquisition clinical settings. The dataset will be regularly updated to include more data and the original 3D volumes of dicoms will also be made available. It does not include normal or any other pneumonia images like other similar repositories. It would provide researchers opportunities to develop generalizable and robust models for COVID-19 detection and for developing models for other lung disease detection tasks. To the best of our knowledge, this is the only dataset available from Indian population making it a valuable addition to other similar repositories. Here we also propose a lightweight Convolutional Neural Network (CNN) model to classify chest CT scans into three classes, viz., Normal, non-Covid Pneumonia and COVID-19. The model has been trained and validated on publicly available dataset COVIDx-CT dataset [1]. Performance of the model is evaluated on both COVIDx-CT and Indian-COVID-19 CT datasets and is observed to be comparable, with accuracy slightly lower on Indian-COVID-19 CT dataset. This is not surprising as it is an external test set not seen by the model during training. The proposed lightweight model for diagnosing COVID-19 is well suited for a clinical setting. However, the model is still a prototype and needs more rigorous testing and re-calibrations before using it for clinical diagnosis. The dataset will be made available at http://aimedhub.iiit.ac.in/datasets/gandhi-hospital-covid-dataset. ",
      "tldr": "Analysis of Chest CT scans of Indian COVID-19 patients using CNN",
      "site_url": "https://openreview.net/forum?id=t1kTABPcp9s",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~S_Suba1",
        "name": "S Suba",
        "name_site": null,
        "openreview_id": "~S_Suba1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0000-0001-6251-5083",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.6666666666666665,
        "rating_std": 1.247219128924647,
        "confidence_mean": 4.333333333333333,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "t1kTABPcp9s",
      "title": "Indian-COVID-19 CT Dataset and Analysis of Chest CT Scans of COVID-19 Patients Using Lightweight CNN",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Indian-COVID-19 CT is the chest Computed Tomography (CT) images from COVID-19 patients from India. It has been collected and curated to aid in the diagnosis of COVID-19 and other chest CT analysis tasks using machine learning algorithms. Currently it consists of 6174 images from 142 patients COVID-19, obtained from a single hospital with same image acquisition clinical settings. The dataset will be regularly updated to include more data and the original 3D volumes of dicoms will also be made available. It does not include normal or any other pneumonia images like other similar repositories. It would provide researchers opportunities to develop generalizable and robust models for COVID-19 detection and for developing models for other lung disease detection tasks. To the best of our knowledge, this is the only dataset available from Indian population making it a valuable addition to other similar repositories. Here we also propose a lightweight Convolutional Neural Network (CNN) model to classify chest CT scans into three classes, viz., Normal, non-Covid Pneumonia and COVID-19. The model has been trained and validated on publicly available dataset COVIDx-CT dataset [1]. Performance of the model is evaluated on both COVIDx-CT and Indian-COVID-19 CT datasets and is observed to be comparable, with accuracy slightly lower on Indian-COVID-19 CT dataset. This is not surprising as it is an external test set not seen by the model during training. The proposed lightweight model for diagnosing COVID-19 is well suited for a clinical setting. However, the model is still a prototype and needs more rigorous testing and re-calibrations before using it for clinical diagnosis. The dataset will be made available at http://aimedhub.iiit.ac.in/datasets/gandhi-hospital-covid-dataset. ",
      "tldr": "Analysis of Chest CT scans of Indian COVID-19 patients using CNN",
      "site_url": "https://openreview.net/forum?id=t1kTABPcp9s",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Nita_Parekh1",
        "name": "Nita Parekh",
        "name_site": null,
        "openreview_id": "~Nita_Parekh1",
        "position": 2,
        "gender": "F",
        "homepage_url": "https://www.iiit.ac.in/people/faculty/nita/",
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=AxoY6h4AAAAJ",
        "orcid": "0000-0002-8737-0260",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.6666666666666665,
        "rating_std": 1.247219128924647,
        "confidence_mean": 4.333333333333333,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "t1kTABPcp9s",
      "title": "Indian-COVID-19 CT Dataset and Analysis of Chest CT Scans of COVID-19 Patients Using Lightweight CNN",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Indian-COVID-19 CT is the chest Computed Tomography (CT) images from COVID-19 patients from India. It has been collected and curated to aid in the diagnosis of COVID-19 and other chest CT analysis tasks using machine learning algorithms. Currently it consists of 6174 images from 142 patients COVID-19, obtained from a single hospital with same image acquisition clinical settings. The dataset will be regularly updated to include more data and the original 3D volumes of dicoms will also be made available. It does not include normal or any other pneumonia images like other similar repositories. It would provide researchers opportunities to develop generalizable and robust models for COVID-19 detection and for developing models for other lung disease detection tasks. To the best of our knowledge, this is the only dataset available from Indian population making it a valuable addition to other similar repositories. Here we also propose a lightweight Convolutional Neural Network (CNN) model to classify chest CT scans into three classes, viz., Normal, non-Covid Pneumonia and COVID-19. The model has been trained and validated on publicly available dataset COVIDx-CT dataset [1]. Performance of the model is evaluated on both COVIDx-CT and Indian-COVID-19 CT datasets and is observed to be comparable, with accuracy slightly lower on Indian-COVID-19 CT dataset. This is not surprising as it is an external test set not seen by the model during training. The proposed lightweight model for diagnosing COVID-19 is well suited for a clinical setting. However, the model is still a prototype and needs more rigorous testing and re-calibrations before using it for clinical diagnosis. The dataset will be made available at http://aimedhub.iiit.ac.in/datasets/gandhi-hospital-covid-dataset. ",
      "tldr": "Analysis of Chest CT scans of Indian COVID-19 patients using CNN",
      "site_url": "https://openreview.net/forum?id=t1kTABPcp9s",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Ramesh_Loganathan1",
        "name": "Ramesh Loganathan",
        "name_site": null,
        "openreview_id": "~Ramesh_Loganathan1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.iiit.ac.in/people/faculty/ramesh.loganathan/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.6666666666666665,
        "rating_std": 1.247219128924647,
        "confidence_mean": 4.333333333333333,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "t1kTABPcp9s",
      "title": "Indian-COVID-19 CT Dataset and Analysis of Chest CT Scans of COVID-19 Patients Using Lightweight CNN",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Indian-COVID-19 CT is the chest Computed Tomography (CT) images from COVID-19 patients from India. It has been collected and curated to aid in the diagnosis of COVID-19 and other chest CT analysis tasks using machine learning algorithms. Currently it consists of 6174 images from 142 patients COVID-19, obtained from a single hospital with same image acquisition clinical settings. The dataset will be regularly updated to include more data and the original 3D volumes of dicoms will also be made available. It does not include normal or any other pneumonia images like other similar repositories. It would provide researchers opportunities to develop generalizable and robust models for COVID-19 detection and for developing models for other lung disease detection tasks. To the best of our knowledge, this is the only dataset available from Indian population making it a valuable addition to other similar repositories. Here we also propose a lightweight Convolutional Neural Network (CNN) model to classify chest CT scans into three classes, viz., Normal, non-Covid Pneumonia and COVID-19. The model has been trained and validated on publicly available dataset COVIDx-CT dataset [1]. Performance of the model is evaluated on both COVIDx-CT and Indian-COVID-19 CT datasets and is observed to be comparable, with accuracy slightly lower on Indian-COVID-19 CT dataset. This is not surprising as it is an external test set not seen by the model during training. The proposed lightweight model for diagnosing COVID-19 is well suited for a clinical setting. However, the model is still a prototype and needs more rigorous testing and re-calibrations before using it for clinical diagnosis. The dataset will be made available at http://aimedhub.iiit.ac.in/datasets/gandhi-hospital-covid-dataset. ",
      "tldr": "Analysis of Chest CT scans of Indian COVID-19 patients using CNN",
      "site_url": "https://openreview.net/forum?id=t1kTABPcp9s",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Vikram_Pudi1",
        "name": "Vikram Pudi",
        "name_site": null,
        "openreview_id": "~Vikram_Pudi1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://www.iiit.ac.in/people/faculty/vikram/",
        "dblp_id": "80/594",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=jH79pJkAAAAJ",
        "orcid": "0000-0002-0589-6366",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 2.6666666666666665,
        "rating_std": 1.247219128924647,
        "confidence_mean": 4.333333333333333,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    }
  ]
}