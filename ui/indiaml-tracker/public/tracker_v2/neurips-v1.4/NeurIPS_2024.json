{
  "conference": "NeurIPS 2024",
  "focus_country": "India",
  "total_papers": 116,
  "generated_at": "2025-07-06T10:39:19.849516",
  "config": {
    "first_author_weight": 3.0,
    "last_author_weight": 2.0,
    "middle_author_weight": 1.0,
    "status_weights": {
      "oral": 10.0,
      "spotlight": 7.5,
      "poster": 5.0,
      "unknown": 1.0
    },
    "output_format": "json",
    "include_review_details": true,
    "include_citation_data": true
  },
  "papers": [
    {
      "paper_id": "FTPDBQuT4G",
      "title": "Generalized Linear Bandits with Limited Adaptivity",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "We study the generalized linear contextual bandit problem within the constraints of limited adaptivity.  In this paper, we present two algorithms, B-GLinCB and RS-GLinCB, that address, respectively, two prevalent limited adaptivity settings. Given a budget $M$ on the number of policy updates, in the first setting, the algorithm needs to decide upfront $M$ rounds at which it will update its policy, while in the second setting it can adaptively perform $M$ policy updates during its course. For the first setting, we design an algorithm B-GLinCB, that incurs $\\tilde{O}(\\sqrt{T})$ regret when $M = \\Omega( \\log{\\log T} )$ and the arm feature vectors are generated stochastically. For the second setting, we design an algorithm RS-GLinCB that updates its policy $\\tilde{O}(\\log^2 T)$ times and achieves a regret of $\\tilde{O}(\\sqrt{T})$ even when the arm feature vectors are adversarially generated. Notably, in these bounds, we manage to eliminate the dependence on a key instance dependent parameter $\\kappa$, that captures non-linearity of the underlying reward model. Our novel approach for removing this dependence for generalized linear contextual bandits might be of independent interest.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95973",
      "pdf_url": "https://openreview.net/pdf?id=FTPDBQuT4G",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ayush_Sawarni1",
        "name": "Ayush Sawarni",
        "name_site": "Ayush Sawarni, Ayush Sawarni, Soumyabrata Pal, Siddharth Barman",
        "openreview_id": "~Ayush_Sawarni1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://sawarniayush.github.io/",
        "dblp_id": null,
        "google_scholar_url": "U8TSPdAAAAAJ",
        "orcid": null,
        "linkedin_url": "ayush-sawarni",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 22.5,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "TxffvJMnBy",
      "title": "Optimal Algorithms for Online Convex Optimization with Adversarial Constraints",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "A well-studied generalization of the standard online convex optimization (OCO) framework is constrained online convex optimization (COCO). In COCO, on every round, a convex cost function and a convex constraint function are revealed to the learner after it chooses the action for that round. The objective is to design an online learning policy that simultaneously achieves a small regret while ensuring a small cumulative constraint violation (CCV) against an adaptive adversary interacting over a horizon of length $T$. A long-standing open question in COCO is whether an online policy can simultaneously achieve $O(\\sqrt{T})$ regret and $\\tilde{O}(\\sqrt{T})$ CCV without any restrictive assumptions. For the first time, we answer this in the affirmative and show that a simple first-order policy can simultaneously achieve these bounds. Furthermore, in the case of strongly convex cost and convex constraint functions, the regret guarantee can be improved to $O(\\log T)$ while keeping the CCV bound the same as above. We establish these results by effectively combining adaptive OCO policies as a blackbox with Lyapunov optimization - a classic tool from control theory. Surprisingly, the analysis is short and elegant.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/94999",
      "pdf_url": "https://openreview.net/pdf?id=TxffvJMnBy",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abhishek_Sinha3",
        "name": "Abhishek Sinha",
        "name_site": null,
        "openreview_id": "~Abhishek_Sinha3",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://www.tifr.res.in/~abhishek.sinha/",
        "dblp_id": "47/9175",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=Oc7BRX0AAAAJ",
        "orcid": "0000-0001-7220-0691",
        "linkedin_url": "abhishek-sinha-a645291b/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tata Institute of Fundamental Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 22.5,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "1po4j1Tv7O",
      "title": "Sample-Efficient Constrained Reinforcement Learning with General Parameterization",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We consider a constrained Markov Decision Problem (CMDP) where the goal of an agent is to maximize the expected discounted sum of rewards over an infinite horizon while ensuring that the expected discounted sum of costs exceeds a certain threshold. Building on the idea of momentum-based acceleration, we develop the Primal-Dual Accelerated Natural Policy Gradient (PD-ANPG) algorithm that ensures an $\\epsilon$ global optimality gap and $\\epsilon$ constraint violation with $\\tilde{\\mathcal{O}}((1-\\gamma)^{-7}\\epsilon^{-2})$ sample complexity for general parameterized policies where $\\gamma$ denotes the discount factor. This improves the state-of-the-art sample complexity in general parameterized CMDPs by a factor of $\\mathcal{O}((1-\\gamma)^{-1}\\epsilon^{-2})$ and achieves the theoretical lower bound in $\\epsilon^{-1}$.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/96849",
      "pdf_url": "https://openreview.net/pdf?id=1po4j1Tv7O",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Washim_Uddin_Mondal1",
        "name": "Washim Uddin Mondal",
        "name_site": "Washim Mondal, Vaneet Aggarwal",
        "openreview_id": "~Washim_Uddin_Mondal1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://home.iitk.ac.in/~wmondal/",
        "dblp_id": "201/9517.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=CQwhdyIAAAAJ",
        "orcid": "0000-0002-2385-6034",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 6,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "3R7Go6WkDm",
      "title": "Post-Hoc Reversal: Are We Selecting Models Prematurely?",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Trained models are often composed with post-hoc transforms such as temperature scaling (TS), ensembling and stochastic weight averaging (SWA) to improve performance, robustness, uncertainty estimation, etc. However, such transforms are typically applied only after the base models have already been finalized by standard means. In this paper, we challenge this practice with an extensive empirical study. In particular, we demonstrate a phenomenon that we call post-hoc reversal, where performance trends are reversed after applying post-hoc transforms. This phenomenon is especially prominent in high-noise settings. For example, while base models overfit badly early in training, both ensembling and SWA favor base models trained for more epochs. Post-hoc reversal can also prevent the appearance of double descent and mitigate mismatches between test loss and test error seen in base models. Preliminary analyses suggest that these transforms induce reversal by suppressing the influence of mislabeled examples, exploiting differences in their learning dynamics from those of clean examples. Based on our findings, we propose post-hoc selection, a simple technique whereby post-hoc metrics inform model development decisions such as early stopping, checkpointing, and broader hyperparameter choices. Our experiments span real-world vision, language, tabular and graph datasets. On an LLM instruction tuning dataset, post-hoc selection results in >1.5x MMLU improvement compared to naive selection.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/96745",
      "pdf_url": "https://openreview.net/pdf?id=3R7Go6WkDm",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rishabh_Ranjan1",
        "name": "Rishabh Ranjan",
        "name_site": "Rishabh Ranjan, Siddharth Grover, Sourav Medya, Venkatesan Chakaravarthy, Yogish Sabharwal, Sayan Ranu",
        "openreview_id": "~Rishabh_Ranjan1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://rishabh-ranjan.github.io",
        "dblp_id": null,
        "google_scholar_url": "NNzQUrcAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Stanford University (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.666666666666667,
        "rating_std": 0.9428090415820634,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "3qH8q02x0n",
      "title": "IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent advancements in text-to-speech (TTS) synthesis show that large-scale models trained with extensive web data produce highly natural-sounding output. However, such data is scarce for Indian languages due to the lack of high-quality, manually subtitled data on platforms like LibriVox or YouTube. To address this gap, we enhance existing large-scale ASR datasets containing natural conversations collected in low-quality environments to generate high-quality TTS training data. Our pipeline leverages the cross-lingual generalization of denoising and speech enhancement models trained on English and applied to Indian languages. This results in IndicVoices-R (IV-R), the largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704 hours of high-quality speech from 10,496 speakers across 22 Indian languages. IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS, and IndicTTS. We also introduce the IV-R Benchmark, the first to assess zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS models on Indian voices, ensuring diversity in age, gender, and style. We demonstrate that fine-tuning an English pre-trained model on a combined dataset of high-quality IndicTTS and our IV-R dataset results in better zero-shot speaker generalization compared to fine-tuning on the IndicTTS dataset alone. Further, our evaluation reveals limited zero-shot generalization for Indian voices in TTS models trained on prior datasets, which we improve by fine-tuning the model on our data containing diverse set of speakers across language families. We open-source code and data for all 22 official Indian languages.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97858",
      "pdf_url": "https://openreview.net/pdf?id=3qH8q02x0n",
      "github_url": "",
      "total_authors": 10,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Ashwin_Sankar1",
        "name": "Ashwin Sankar",
        "name_site": "Ashwin Sankar, Srija Anand, Praveen Varadhan, Sherry Thomas, Mehak Singal, Shridhar Kumar, Deovrat Mehendale, Aditi Krishana, Giri Raju, Mitesh Khapra",
        "openreview_id": "~Ashwin_Sankar1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "328/0752.html",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": "https://linkedin.com/in/ashwin-s2000",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "AI4Bharat (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "7Mo1NOosNT",
      "title": "COLD: Causal reasOning in cLosed Daily activities",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Large Language Models (LLMs) have shown state-of-the-art performance in a variety of tasks, including arithmetic and reasoning; however, to gauge the intellectual capabilities of LLMs, causal reasoning has become a reliable proxy for validating a general understanding of the mechanics and intricacies of the world similar to humans. Previous works in natural language processing (NLP) have either focused on open-ended causal reasoning via causal commonsense reasoning (CCR) or framed a symbolic representation-based question answering for theoretically backed-up analysis via a causal inference engine. The former adds an advantage of real-world grounding but lacks theoretically backed-up analysis/validation, whereas the latter is far from real-world grounding. In this work, we bridge this gap by proposing the COLD (Causal reasOning in cLosed Daily activities) framework, which is built upon human understanding of daily real-world activities to reason about the causal nature of events. We show that the proposed framework facilitates the creation of enormous causal queries (∼ 9 million) and comes close to the mini-turing test, simulating causal reasoning to evaluate the understanding of a daily real-world task. We evaluate multiple LLMs on the created causal queries and find that causal reasoning is challenging even for activities trivial to humans. We further explore (the causal reasoning abilities of LLMs) using the backdoor criterion to determine the causal strength between events.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/96459",
      "pdf_url": "https://openreview.net/pdf?id=7Mo1NOosNT",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abhinav_Joshi1",
        "name": "Abhinav Joshi",
        "name_site": "Abhinav Joshi, areeb ahmad, Ashutosh Modi",
        "openreview_id": "~Abhinav_Joshi1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://www.cse.iitk.ac.in/users/ajoshi/",
        "dblp_id": "308/0603",
        "google_scholar_url": null,
        "orcid": "0000-0001-6756-1126",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "8JauriwDeH",
      "title": "Near-Optimal Streaming Heavy-Tailed Statistical Estimation with Clipped SGD",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "$\\newcommand{\\Tr}{\\mathsf{Tr}}$\nWe consider the problem of high-dimensional heavy-tailed statistical estimation in the streaming setting, which is much harder than the traditional batch setting due to memory constraints. We cast this problem as stochastic convex optimization with heavy tailed stochastic gradients, and prove that the widely used Clipped-SGD algorithm attains near-optimal sub-Gaussian statistical rates whenever the second moment of the stochastic gradient noise is finite. More precisely, with $T$ samples, we show that Clipped-SGD, for smooth and strongly convex objectives, achieves an error of $\\sqrt{\\frac{\\Tr(\\Sigma)+\\sqrt{\\Tr(\\Sigma)\\\\|\\Sigma\\\\|_2}\\ln(\\tfrac{\\ln(T)}{\\delta})}{T}}$ with probability $1-\\delta$, where $\\Sigma$ is the covariance of the clipped gradient. Note that the fluctuations (depending on $\\tfrac{1}{\\delta}$) are of lower order than the term $\\Tr(\\Sigma)$.\nThis improves upon the current best rate of\n$\\sqrt{\\frac{\\Tr(\\Sigma)\\ln(\\tfrac{1}{\\delta})}{T}}$ for Clipped-SGD, known \\emph{only} for smooth and strongly convex objectives. Our results also extend to smooth convex and lipschitz convex objectives. Key to our result is a novel iterative refinement strategy for martingale concentration, improving upon the PAC-Bayes approach of \\citet{catoni2018dimension}.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/96378",
      "pdf_url": "https://openreview.net/pdf?id=8JauriwDeH",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aniket_Das1",
        "name": "Aniket Das",
        "name_site": "Aniket Das, Bernhard Schölkopf, Michael Muehlebach",
        "openreview_id": "~Aniket_Das1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://aniket1998.github.io",
        "dblp_id": "248/8281",
        "google_scholar_url": "o8Dyas0AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.7071067811865476,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "D19UyP4HYk",
      "title": "Metacognitive Capabilities of LLMs: An Exploration in Mathematical Problem Solving",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "\\emph{Metacognitive knowledge} refers to humans' intuitive knowledge of their own thinking and reasoning processes. Today's best LLMs clearly possess some reasoning processes. The paper gives evidence that they also  have metacognitive knowledge, including ability to name skills and procedures to apply given a task. We explore this primarily in context of math reasoning, developing a prompt-guided interaction procedure  to get a powerful  LLM to assign sensible skill labels to math questions, followed by having it perform semantic clustering to obtain coarser families of skill labels. These coarse skill labels look interpretable to humans.\n\nTo validate that these skill labels are meaningful and relevant to the LLM's reasoning processes we perform the following experiments. (a) We ask GPT-4 to assign skill labels to training questions in math datasets GSM8K and MATH.  (b) When using an LLM to solve the test questions, we present it with the full list of skill labels and ask it to identify the skill needed. Then it is presented with randomly selected exemplar solved questions associated with that skill label.  This improves accuracy on GSM8k and MATH for several strong LLMs, including code-assisted models. The methodology presented is domain-agnostic,  even though this article applies it to math problems.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/96107",
      "pdf_url": "https://openreview.net/pdf?id=D19UyP4HYk",
      "github_url": "",
      "total_authors": 10,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aniket_Rajiv_Didolkar1",
        "name": "Aniket Rajiv Didolkar",
        "name_site": null,
        "openreview_id": "~Aniket_Rajiv_Didolkar1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://github.com/dido1998/",
        "dblp_id": "245/8589",
        "google_scholar_url": "https://scholar.google.ca/citations?user=ekvl5o0AAAAJ",
        "orcid": null,
        "linkedin_url": "aniket-didolkar-7a9b8912a",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Manipal Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.7071067811865476,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 43,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "HSJOt2hyDf",
      "title": "Initializing Services in Interactive ML Systems for Diverse Users",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "This paper investigates ML systems serving a group of users, with multiple models/services, each aimed at specializing to a sub-group of users. We consider settings where upon deploying a set of services, users choose the one minimizing their personal losses and the learner iteratively learns by interacting with diverse users. Prior research shows that the outcomes of learning dynamics, which comprise both the services' adjustments and users' service selections, hinge significantly on the initial conditions. However, finding good initial conditions faces two main challenges: (i) \\emph{Bandit feedback:} Typically, data on user preferences are not available before deploying services \nand observing user behavior; (ii) \\emph{Suboptimal local solutions:} The total loss landscape (i.e., the sum of loss functions across all users and services) is not convex and gradient-based algorithms can get stuck in poor local minima.\n\nWe address these challenges with a randomized algorithm to adaptively select a minimal set of users for data collection in order to initialize a set of services. Under mild assumptions on the loss functions, we prove that our initialization leads to a total loss within a factor of the \\textit{globally optimal total loss,with complete user preference data}, and this factor scales logarithmically in the number of services. This result is a generalization of the well-known $k$-means++ guarantee to a broad problem class which is also of independent interest.\nThe theory is complemented by experiments on real as well as semi-synthetic datasets.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95834",
      "pdf_url": "https://openreview.net/pdf?id=HSJOt2hyDf",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Avinandan_Bose1",
        "name": "Avinandan Bose",
        "name_site": "Avinandan Bose, Arunesh Sinha, Tien Mai",
        "openreview_id": "~Avinandan_Bose1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://avinandan22.github.io/",
        "dblp_id": "305/7490",
        "google_scholar_url": "https://scholar.google.com/citations?pli=1",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Unknown Institution (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 2.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 10,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "HwO1mNluoL",
      "title": "Mitigating Biases in Blackbox Feature Extractors for Image Classification Tasks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In image classification, it is common to utilize a pretrained model to extract meaningful features of the input images, and then to train a classifier on top of it to make predictions for any downstream task. Trained on enormous amounts of data, these models have been shown to contain harmful biases which can hurt their performance when adapted for a downstream classification task. Further, very often they may be blackbox, either due to scale, or because of unavailability of model weights or architecture. Thus, during a downstream task, we cannot debias such models by updating the weights of the feature encoder, as only the classifier can be finetuned. In this regard, we investigate the suitability of some existing debiasing techniques and thereby motivate the need for more focused research towards this problem setting. Furthermore, we propose a simple method consisting of a clustering-based adaptive margin loss with a blackbox feature encoder, with no knowledge of the bias attribute. Our experiments demonstrate the effectiveness of our method across multiple benchmarks.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95798",
      "pdf_url": "https://openreview.net/pdf?id=HwO1mNluoL",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abhipsa_Basu1",
        "name": "Abhipsa Basu",
        "name_site": "Abhipsa Basu, Saswat Subhajyoti Mallick, Venkatesh Babu R",
        "openreview_id": "~Abhipsa_Basu1",
        "position": 1,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "203/8816",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=tmn0akEAAAAJ",
        "orcid": null,
        "linkedin_url": "abhipsa-basu-526ba0152/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "JEflV4nRlH",
      "title": "What Makes and Breaks Safety Fine-tuning? A Mechanistic Study",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Safety fine-tuning helps align Large Language Models (LLMs) with human preferences for their safe deployment. To better understand the underlying factors that make models safe via safety fine-tuning, we design a synthetic data generation framework that captures salient aspects of an unsafe input by modeling the interaction between the task the model is asked to perform (e.g., “design”) versus the specific concepts the task is asked to be performed upon (e.g., a “cycle” vs. a “bomb”). Using this, we investigate three well-known safety fine-tuning methods—supervised safety fine-tuning, direct preference optimization, and unlearning—and provide significant evidence demonstrating that these methods minimally transform MLP weights to specifically align unsafe inputs into its weights’ null space. This yields a clustering of inputs based on whether the model deems them safe or not. Correspondingly, when an adversarial input (e.g., a jailbreak) is provided, its activations are closer to safer samples, leading to the model processing such an input as if it were safe. Code is available at https://github.com/fiveai/understanding_safety_finetuning.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95726",
      "pdf_url": "https://openreview.net/pdf?id=JEflV4nRlH",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Samyak_Jain1",
        "name": "Samyak Jain",
        "name_site": null,
        "openreview_id": "~Samyak_Jain1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://samyakjain0112.github.io/",
        "dblp_id": "249/4464.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?hl=en",
        "orcid": "0000-0003-3785-4782",
        "linkedin_url": "samyak-jain-276738178/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Five AI (United Kingdom)",
        "countries": [
          "United Kingdom"
        ],
        "country_codes": [
          "GB"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.75,
        "confidence_std": 1.0897247358851685,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 13,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "JRMSC08gSF",
      "title": "Hints-In-Browser: Benchmarking Language Models for Programming Feedback Generation",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Generative AI and large language models hold great promise in enhancing programming education by generating individualized feedback and hints for learners. Recent works have primarily focused on improving the quality of generated feedback to achieve human tutors' quality. While quality is an important performance criterion, it is not the only criterion to optimize for real-world educational deployments. In this paper, we benchmark language models for programming feedback generation across several performance criteria, including quality, cost, time, and data privacy. The key idea is to leverage recent advances in the new paradigm of in-browser inference that allow running these models directly in the browser, thereby providing direct benefits across cost and data privacy. To boost the feedback quality of small models compatible with in-browser inference engines, we develop a fine-tuning pipeline based on GPT-4 generated synthetic data. We showcase the efficacy of fine-tuned Llama3-8B and Phi3-3.8B 4-bit quantized models using WebLLM's in-browser inference engine on three different Python programming datasets. We will release the full implementation along with a web app and datasets to facilitate further research on in-browser language models.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97759",
      "pdf_url": "https://openreview.net/pdf?id=JRMSC08gSF",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Nachiket_Kotalwar1",
        "name": "Nachiket Kotalwar",
        "name_site": "Nachiket Kotalwar, Alkis Gotovos, Adish Singla",
        "openreview_id": "~Nachiket_Kotalwar1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://nachiketdk.github.io/",
        "dblp_id": "380/3774.html",
        "google_scholar_url": "8ZbAeL8AAAAJ",
        "orcid": "0009-0003-4319-014X",
        "linkedin_url": "nachiket-kotalwar/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 1.224744871391589,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "LYx4w3CAgy",
      "title": "LLM-Check: Investigating Detection of Hallucinations in Large Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "While Large Language Models (LLMs) have become immensely popular due to their outstanding performance on a broad range of tasks, these models are prone to producing hallucinations— outputs that are fallacious or fabricated yet often appear plausible or tenable at a glance. In this paper, we conduct a comprehensive investigation into the nature of hallucinations within LLMs and furthermore explore effective techniques for detecting such inaccuracies in various real-world settings. Prior approaches to detect hallucinations in LLM outputs, such as consistency checks or retrieval-based methods, typically assume access to multiple model responses or large databases. These techniques, however, tend to be computationally expensive in practice, thereby limiting their applicability to real-time analysis. In contrast, in this work, we seek to identify hallucinations within a single response in both white-box and black-box settings by analyzing the internal hidden states, attention maps, and output prediction probabilities of an auxiliary LLM. In addition, we also study hallucination detection in scenarios where ground-truth references are also available, such as in the setting of Retrieval-Augmented Generation (RAG). We demonstrate that the proposed detection methods are extremely compute-efficient, with speedups of up to 45x and 450x over other baselines, while achieving significant improvements in detection performance over diverse datasets.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95584",
      "pdf_url": "https://openreview.net/pdf?id=LYx4w3CAgy",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Gaurang_Sriramanan1",
        "name": "Gaurang Sriramanan",
        "name_site": "Gaurang Sriramanan, Sravanti Addepalli, Arya Baburaj, Venkatesh Babu R",
        "openreview_id": "~Gaurang_Sriramanan1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://gaurangsriramanan.github.io/",
        "dblp_id": "262/3916",
        "google_scholar_url": "t76Uk8oAAAAJ",
        "orcid": null,
        "linkedin_url": "gaurang-sriramanan-16141a1a3/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Maryland (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.5,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 9,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "NhqZpst42I",
      "title": "Understanding Visual Feature Reliance through the Lens of Complexity",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent studies suggest that deep learning models' inductive bias towards favoring simpler features may be an origin of shortcut learning. Yet, there has been limited focus on understanding the complexities of the myriad features that models learn. In this work, we introduce a new metric for quantifying feature complexity, based on V-information and capturing whether a feature requires complex computational transformations to be extracted. Using this V-information metric, we analyze the complexities of 10,000 features—represented as directions in the penultimate layer—that were extracted from a standard ImageNet-trained vision model. Our study addresses four key questions:\n\nFirst, we ask what features look like as a function of complexity, and find a spectrum of simple-to-complex features present within the model. Second, we ask when features are learned during training. We find that simpler features dominate early in training, and more complex features emerge gradually. Third, we investigate where within the network simple and complex features \"flow,\" and find that simpler features tend to bypass the visual hierarchy via residual connections. Fourth, we explore the connection between features' complexity and their importance for driving the network's decision. We find that complex features tend to be less important. Surprisingly, important features become accessible at earlier layers during training, like a \"sedimentation process,\" allowing the model to build upon these foundational elements.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95422",
      "pdf_url": "https://openreview.net/pdf?id=NhqZpst42I",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Thomas_FEL1",
        "name": "Thomas FEL",
        "name_site": "Thomas FEL, Remi Cadene, Mathieu Chalvidal, Matthieu Cord, David Vigouroux, Thomas Serre",
        "openreview_id": "~Thomas_FEL1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://thomasfel.me",
        "dblp_id": "274/2390",
        "google_scholar_url": "1m5Mlx4AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Brown University (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.8,
        "rating_std": 1.6,
        "confidence_mean": 3.0,
        "confidence_std": 1.0954451150103321,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 5,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "SdLOs1FR4h",
      "title": "FUGAL: Feature-fortified Unrestricted Graph Alignment",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The necessity to align two graphs, minimizing a structural distance metric, is prevalent in biology, chemistry, recommender systems, and social network analysis. Due to the problem’s NP-hardness, prevailing graph alignment methods follow a modular and mediated approach, solving the problem by restricting to the domain of intermediary graph representations or products like embeddings, spectra, and graph signals. Restricting the problem to this intermediate space may distort the original problem and are hence predisposed to miss high-quality solutions. In this paper, we propose an unrestricted method, FUGAL, which finds a permutation matrix that maps one graph to another by directly operating on their adjacency matrices with judicious constraint relaxation. Extensive experimentation demonstrates that FUGAL consistently surpasses state-of-the-art graph alignment methods in accuracy across all benchmark datasets without encumbering efficiency.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95090",
      "pdf_url": "https://openreview.net/pdf?id=SdLOs1FR4h",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aditya_Bommakanti1",
        "name": "Aditya Bommakanti",
        "name_site": "Aditya Bommakanti, Harshith Vonteri, Konstantinos Skitsas, Sayan Ranu, Davide Mottin, Panagiotis Karras",
        "openreview_id": "~Aditya_Bommakanti1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": "368/2587",
        "google_scholar_url": null,
        "orcid": "0009-0009-3460-2337",
        "linkedin_url": "aditya-bommakanti-6b035321a/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 1.6583123951777,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "SvmJJJS0q1",
      "title": "Detecting and Measuring Confounding Using Causal Mechanism Shifts",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Detecting and measuring confounding effects from data is a key challenge in causal inference. Existing methods frequently assume causal sufficiency, disregarding the presence of unobserved confounding variables. Causal sufficiency is both unrealistic and empirically untestable. Additionally, existing methods make strong parametric assumptions about the underlying causal generative process to guarantee the identifiability of confounding variables. Relaxing the causal sufficiency and parametric assumptions and leveraging recent advancements in causal discovery and confounding analysis with non-i.i.d. data, we propose a comprehensive approach for detecting and measuring confounding. We consider various definitions of confounding and introduce tailored methodologies to achieve three objectives: (i) detecting and measuring confounding among a set of variables, (ii) separating observed and unobserved confounding effects, and (iii) understanding the relative strengths of confounding bias between different sets of variables. We present useful properties of a confounding measure and present measures that satisfy those properties. Our empirical results support the usefulness of the proposed measures.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95068",
      "pdf_url": "https://openreview.net/pdf?id=SvmJJJS0q1",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abbavaram_Gowtham_Reddy1",
        "name": "Abbavaram Gowtham Reddy",
        "name_site": "Abbavaram Gowtham Reddy, Vineeth N Balasubramanian",
        "openreview_id": "~Abbavaram_Gowtham_Reddy1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://gautam0707.github.io",
        "dblp_id": "294/8798",
        "google_scholar_url": "Iewg-GAAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.5,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "TxffvJMnBy",
      "title": "Optimal Algorithms for Online Convex Optimization with Adversarial Constraints",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "A well-studied generalization of the standard online convex optimization (OCO) framework is constrained online convex optimization (COCO). In COCO, on every round, a convex cost function and a convex constraint function are revealed to the learner after it chooses the action for that round. The objective is to design an online learning policy that simultaneously achieves a small regret while ensuring a small cumulative constraint violation (CCV) against an adaptive adversary interacting over a horizon of length $T$. A long-standing open question in COCO is whether an online policy can simultaneously achieve $O(\\sqrt{T})$ regret and $\\tilde{O}(\\sqrt{T})$ CCV without any restrictive assumptions. For the first time, we answer this in the affirmative and show that a simple first-order policy can simultaneously achieve these bounds. Furthermore, in the case of strongly convex cost and convex constraint functions, the regret guarantee can be improved to $O(\\log T)$ while keeping the CCV bound the same as above. We establish these results by effectively combining adaptive OCO policies as a blackbox with Lyapunov optimization - a classic tool from control theory. Surprisingly, the analysis is short and elegant.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/94999",
      "pdf_url": "https://openreview.net/pdf?id=TxffvJMnBy",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rahul_Vaze1",
        "name": "Rahul Vaze",
        "name_site": null,
        "openreview_id": "~Rahul_Vaze1",
        "position": 2,
        "gender": "M",
        "homepage_url": "http://www.tcs.tifr.res.in/~vaze/",
        "dblp_id": "80/5048",
        "google_scholar_url": "noTrTDYAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tata Institute of Fundamental Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "XukWe15QCi",
      "title": "Pedestrian Trajectory Prediction with Missing Data: Datasets, Imputation, and Benchmarking",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Pedestrian trajectory prediction is crucial for several applications such as robotics and self-driving vehicles. Significant progress has been made in the past decade thanks to the availability of pedestrian trajectory datasets, which enable trajectory prediction methods to learn from pedestrians' past movements and predict future trajectories. However, these datasets and methods typically assume that the observed trajectory sequence is complete, ignoring real-world issues such as sensor failure, occlusion, and limited fields of view that can result in missing values in observed trajectories. To address this challenge, we present TrajImpute, a pedestrian trajectory prediction dataset that simulates missing coordinates in the observed trajectory, enhancing real-world applicability. TrajImpute maintains a uniform distribution of missing data within the observed trajectories. In this work, we comprehensively examine several imputation methods to reconstruct the missing coordinates and benchmark them for imputing pedestrian trajectories. Furthermore, we provide a thorough analysis of recent trajectory prediction methods and evaluate the performance of these models on the imputed trajectories. Our experimental evaluation of the imputation and trajectory prediction methods offers several valuable insights. Our dataset provides a foundational resource for future research on imputation-aware pedestrian trajectory prediction, potentially accelerating the deployment of these methods in real-world applications. Publicly accessible links to the datasets and code files are available at https://github.com/Pranav-chib/TrajImpute.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97642",
      "pdf_url": "https://openreview.net/pdf?id=XukWe15QCi",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Pranav_singh_chib1",
        "name": "Pranav singh chib",
        "name_site": "Pranav Singh Chib, Pravendra Singh",
        "openreview_id": "~Pranav_singh_chib1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.479019945774904,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "YXQW4qQe2U",
      "title": "Optimal Top-Two Method for Best Arm Identification and Fluid Analysis",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Top-2 methods have become popular in solving the best arm identification (BAI) problem. The best arm, or the arm with the largest mean amongst finitely many, is identified through an algorithm that at any sequential step independently pulls the empirical best arm, with a fixed probability $\\beta$, and pulls the best challenger arm otherwise. The probability of incorrect selection is guaranteed to lie below a specified $\\delta>0$. Information theoretic lower bounds on sample complexity are well known for BAI problem and are matched asymptotically as $\\delta\\to 0$ by computationally demanding plug-in methods. The above top 2 algorithm for any $\\beta\\in(0, 1)$ has sample complexity within a constant of the lower bound. However, determining the optimal β that matches the lower bound has proven difficult. In this paper, we address this and propose an optimal top-2 type algorithm. We consider a function of allocations anchored at a threshold. If it exceeds the threshold then the algorithm samples the empirical best arm. Otherwise, it samples the challenger arm. We show that the proposed algorithm is optimal as $\\delta\\to 0$. Our analysis relies on identifying a limiting fluid dynamics of allocations that satisfy a series of ordinary differential equations pasted together and that describe the asymptotic path followed by our algorithm. We rely on the implicit function theorem to show existence and uniqueness of these fluid ode’s and to show that the proposed algorithm remains close to the ode solution.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/94693",
      "pdf_url": "https://openreview.net/pdf?id=YXQW4qQe2U",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Agniv_Bandyopadhyay1",
        "name": "Agniv Bandyopadhyay",
        "name_site": "Agniv Bandyopadhyay, Sandeep Juneja, Shubhada Agrawal",
        "openreview_id": "~Agniv_Bandyopadhyay1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "359/5768",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "agniv-bandyopadhyay99/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tata Institute of Fundamental Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.8,
        "rating_std": 0.7483314773547882,
        "confidence_mean": 3.4,
        "confidence_std": 0.8,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "e6WrwIvgzX",
      "title": "AutoMix: Automatically Mixing Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Large language models (LLMs) are now available from cloud API providers in various sizes and configurations. While this diversity offers a broad spectrum of choices, effectively leveraging the options to optimize computational cost and performance remains challenging. In this work, we present AutoMix, an approach that strategically routes queries to larger LMs, based on the approximate correctness of outputs from a smaller LM. Central to AutoMix are two key technical contributions. First, it has a few-shot self-verification mechanism, which estimates the reliability of its own outputs without requiring extensive training. Second, given that self-verification can be noisy, it employs a POMDP based router that can effectively select an appropriately sized model, based on answer confidence. Experiments across five language models and five challenging datasets show that Automix consistently surpasses strong baselines, reducing computational cost by over 50\\% for comparable performance.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/94293",
      "pdf_url": "https://openreview.net/pdf?id=e6WrwIvgzX",
      "github_url": "",
      "total_authors": 13,
      "track_name": "Main Conference",
      "author": {
        "id": "~Pranjal_Aggarwal1",
        "name": "Pranjal Aggarwal",
        "name_site": "Pranjal Aggarwal, Aman Madaan, Ankit Anand, Srividya Pranavi Potharaju, Swaroop Mishra, Pei Zhou, Aditya Gupta, Dheeraj Rajagopal, Karthik Kappaganthu, Yiming Yang, Shyam Upadhyay, Manaal Faruqui, Mausam",
        "openreview_id": "~Pranjal_Aggarwal1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://github.com/Pranjal2041/",
        "dblp_id": "163/0764",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": "0000-0002-2962-1535",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.8,
        "rating_std": 0.39999999999999997,
        "confidence_mean": 3.8,
        "confidence_std": 0.39999999999999997,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 25,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "fzlMza6dRZ",
      "title": "GraphTrail: Translating GNN Predictions into Human-Interpretable Logical Rules",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Instance-level explanation of graph neural networks (GNNs) is a well-studied area. These explainers, however, only explain an instance (e.g., a graph) and fail to uncover the combinatorial reasoning learned by a GNN from the training data towards making its predictions. In this work, we introduce GraphTrail, the first end-to-end, global, post-hoc GNN explainer that translates the functioning of a black-box GNN model to a boolean formula over the (sub)graph level concepts without relying on local explainers. GraphTrail is unique in automatically mining the discriminative subgraph-level concepts using Shapley values. Subsequently, the GNN predictions are mapped to a human-interpretable boolean formula over these concepts through symbolic regression. Extensive experiments across diverse datasets and GNN architectures demonstrate significant improvement over existing global explainers in mapping GNN predictions to faithful logical formulae. The robust and accurate performance of GraphTrail makes it invaluable for improving GNNs and facilitates adoption in domains with strict transparency requirements.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/94172",
      "pdf_url": "https://openreview.net/pdf?id=fzlMza6dRZ",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Burouj_Armgaan1",
        "name": "Burouj Armgaan",
        "name_site": "Burouj Armgaan, Manthan Dalmia, Sourav Medya, Sayan Ranu",
        "openreview_id": "~Burouj_Armgaan1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://armagaan.github.io/",
        "dblp_id": "349/0229",
        "google_scholar_url": "GaOJrMYAAAAJ",
        "orcid": "0009-0007-2423-1523",
        "linkedin_url": "burouj-armgaan/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "gPCesxD4B4",
      "title": "GOMAA-Geo: GOal Modality Agnostic Active Geo-localization",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We consider the task of active geo-localization (AGL) in which an agent uses a sequence of visual cues observed during aerial navigation to find a target specified through multiple possible modalities. This could emulate a UAV involved in a search-and-rescue operation navigating through an area, observing a stream of aerial images as it goes. The AGL task is associated with two important challenges.  Firstly, an agent must deal with a goal specification in one of multiple modalities (e.g., through a natural language description) while the search cues are provided in other modalities (aerial imagery). The second challenge is limited localization time (e.g., limited battery life, urgency) so that the goal must be localized as efficiently as possible, i.e. the agent must effectively leverage its sequentially observed aerial views when searching for the goal. To address these challenges, we propose GOMAA-Geo -- a goal modality agnostic active geo-localization agent -- for zero-shot generalization between different goal modalities. Our approach combines cross-modality contrastive learning to align representations across modalities with supervised foundation model pretraining and reinforcement learning to obtain highly effective navigation and localization policies. Through extensive evaluations, we show that GOMAA-Geo outperforms alternative learnable approaches and that it generalizes across datasets -- e.g., to disaster-hit areas without seeing a single disaster scenario during training -- and goal modalities -- e.g., to ground-level imagery or textual descriptions, despite only being trained with goals specified as aerial views. Our code is available at: https://github.com/mvrl/GOMAA-Geo.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/94144",
      "pdf_url": "https://openreview.net/pdf?id=gPCesxD4B4",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anindya_Sarkar2",
        "name": "Anindya Sarkar",
        "name_site": "Anindya Sarkar, Anirban Sarkar, Sowrya Gali, Vineeth N Balasubramanian",
        "openreview_id": "~Anindya_Sarkar2",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/anindya-sarkar/home",
        "dblp_id": null,
        "google_scholar_url": "2hQyYz0AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Washington University in St. Louis (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 5.0,
        "rating_std": 0.7071067811865476,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 6,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "hceKrY4dfC",
      "title": "Indoor Air Quality Dataset with Activities of Daily Living in Low to Middle-income Communities",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In recent years, indoor air pollution has posed a significant threat to our society, claiming over 3.2 million lives annually. Developing nations, such as India, are most affected since lack of knowledge, inadequate regulation, and outdoor air pollution lead to severe daily exposure to pollutants. However, only a limited number of studies have attempted to understand how indoor air pollution affects developing countries like India. To address this gap, we present spatiotemporal measurements of air quality from 30 indoor sites over six months during summer and winter seasons. The sites are geographically located across four regions of type: rural, suburban, and urban, covering the typical low to middle-income population in India. The dataset contains various types of indoor environments (e.g., studio apartments, classrooms, research laboratories, food canteens, and residential households), and can provide the basis for data-driven learning model research aimed at coping with unique pollution patterns in developing countries. This unique dataset demands advanced data cleaning and imputation techniques for handling missing data due to power failure or network outages during data collection. Furthermore, through a simple speech-to-text application, we provide real-time indoor activity labels annotated by occupants. Therefore, environmentalists and ML enthusiasts can utilize this dataset to understand the complex patterns of the pollutants under different indoor activities, identify recurring sources of pollution, forecast exposure, improve floor plans and room structures of modern indoor designs, develop pollution-aware recommender systems, etc.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97565",
      "pdf_url": "https://openreview.net/pdf?id=hceKrY4dfC",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Prasenjit_Karmakar2",
        "name": "Prasenjit Karmakar",
        "name_site": "Prasenjit Karmakar, Swadhin Pradhan, Sandip Chakraborty",
        "openreview_id": "~Prasenjit_Karmakar2",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://prasenjit52282.github.io/",
        "dblp_id": "160/8336.html",
        "google_scholar_url": "uK96UkwAAAAJ",
        "orcid": "0000-0002-7345-1406",
        "linkedin_url": "prasenjit52282/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nN6NSd1Qds",
      "title": "UGC: Universal Graph Coarsening",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In the era of big data, graphs have emerged as a natural representation of intricate relationships. However, graph sizes often become unwieldy, leading to storage, computation, and analysis challenges. A crucial demand arises for methods that can effectively downsize large graphs while retaining vital insights. Graph coarsening seeks to simplify large graphs while maintaining the basic statistics of the graphs, such as spectral properties and $\\epsilon$-similarity in the coarsened graph. This ensures that downstream processes are more efficient and effective. Most published methods are suitable for homophilic datasets, limiting their universal use. We propose **U**niversal **G**raph **C**oarsening (UGC), a framework equally suitable for homophilic and heterophilic datasets. UGC integrates node attributes and adjacency information, leveraging the dataset's heterophily factor. Results on benchmark datasets demonstrate that UGC preserves spectral similarity while coarsening. In comparison to existing methods, UGC is 4x to 15x faster, has lower eigen-error, and yields superior performance on downstream processing tasks even at 70% coarsening ratios.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93695",
      "pdf_url": "https://openreview.net/pdf?id=nN6NSd1Qds",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Mohit_Kataria1",
        "name": "Mohit Kataria",
        "name_site": "Mohit Kataria, Sandeep Kumar, Jayadeva Dr",
        "openreview_id": "~Mohit_Kataria1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "passenger/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.7071067811865476,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "sw9iOHGxgm",
      "title": "Learning Action and Reasoning-Centric Image Editing from Videos and Simulation",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "An image editing model should be able to perform diverse edits, ranging from object replacement, changing attributes or style, to performing actions or movement, which require many forms of reasoning. Current *general* instruction-guided editing models have significant shortcomings with action and reasoning-centric edits.\nObject, attribute or stylistic changes can be learned from visually static datasets. On the other hand, high-quality data for action and reasoning-centric edits is scarce and has to come from entirely different sources that cover e.g. physical dynamics, temporality and spatial reasoning.\nTo this end, we meticulously curate the **A**U**RO**R**A** Dataset (**A**ction-**R**easoning-**O**bject-**A**ttribute), a collection of high-quality training data, human-annotated and curated from videos and simulation engines.\nWe focus on a key aspect of quality training data: triplets (source image, prompt, target image) contain a single meaningful visual change described by the prompt, i.e., *truly minimal* changes between source and target images.\nTo demonstrate the value of our dataset, we evaluate an **A**U**RO**R**A**-finetuned model on a new expert-curated benchmark (**A**U**RO**R**A-Bench**) covering 8 diverse editing tasks.\nOur model significantly outperforms previous editing models as judged by human raters.\nFor automatic evaluations, we find important flaws in previous metrics and caution their use for semantically hard editing tasks.\nInstead, we propose a new automatic metric that focuses on discriminative understanding.\nWe hope that our efforts : (1) curating a quality training dataset and an evaluation benchmark, (2) developing critical evaluations, and (3) releasing a state-of-the-art model, will fuel further progress on general image editing.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97473",
      "pdf_url": "https://openreview.net/pdf?id=sw9iOHGxgm",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Venkatesh_Babu_Radhakrishnan2",
        "name": "Venkatesh Babu Radhakrishnan",
        "name_site": null,
        "openreview_id": "~Varun_Jampani1",
        "position": 7,
        "gender": "M",
        "homepage_url": "https://varunjampani.github.io/",
        "dblp_id": "124/2785",
        "google_scholar_url": "1Cv6Sf4AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Stability AI (Canada)",
        "countries": [
          "Canada"
        ],
        "country_codes": [
          "CA"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 8.0,
        "rating_std": 0.7071067811865476,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "tuiqq1G8I5",
      "title": "DisCEdit: Model Editing by Identifying Discriminative Components",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Model editing is a growing area of research that is particularly valuable in contexts where modifying key model components, like neurons or filters, can significantly impact the model’s performance. The key challenge lies in identifying important components useful to the model’s predictions. We apply model editing to address two active areas of research, Structured Pruning, and Selective Class Forgetting. In this work, we adopt a distributional approach to the problem of identifying important components, leveraging the recently proposed discriminative filters hypothesis, which states that well-trained (convolutional) models possess discriminative filters that are essential to prediction. To do so, we define discriminative ability in terms of the Bayes error rate associated with the feature distributions, which is equivalent to computing the Total Variation (TV) distance between the distributions. However, computing the TV distance is intractable, motivating us to derive novel witness function-based lower bounds on the TV distance that require no assumptions on the underlying distributions; using this bound generalizes prior work such as Murti et al. [39] that relied on unrealistic Gaussianity assumptions on the feature distributions. With these bounds, we are able to discover critical subnetworks responsible for classwise predictions, and derive DISCEDIT-SP and DISCEDIT-U , algorithms for structured pruning requiring no access to the training data and loss function, and selective forgetting respectively. We apply DISCEDIT-U to selective class forgetting on models trained on CIFAR10 and CIFAR100, and we show that on average, we can reduce accuracy on a single class by over 80% with a minimal reduction in test accuracy on the remaining classes. Similarly, on Structured pruning problems, we obtain 40.8% sparsity on ResNet50 on Imagenet, with only a 2.6% drop in accuracy with minimal fine-tuning.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93306",
      "pdf_url": "https://openreview.net/pdf?id=tuiqq1G8I5",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Chaitanya_Murti1",
        "name": "Chaitanya Murti",
        "name_site": "Chaitanya Murti, Chiranjib Bhattacharyya",
        "openreview_id": "~Chaitanya_Murti1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "u7JRmrGutT",
      "title": "Graph Edit Distance with General Costs Using Neural Set Divergence",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph Edit Distance (GED) measures the (dis-)similarity between two given graphs in terms of the minimum-cost edit sequence, which transforms one graph to the other.\nGED is related to other notions of graph similarity, such as graph and subgraph isomorphism, maximum common subgraph, etc. However, the computation of exact GED is NP-Hard, which has recently motivated the design of neural models for GED estimation.\nHowever, they do not explicitly account for edit operations with different costs. In response, we propose $\\texttt{GraphEdX}$, a neural GED estimator that can work with general costs specified for the four edit operations, viz., edge deletion, edge addition, node deletion, and node addition.\nWe first present GED as a quadratic assignment problem (QAP) that incorporates these four costs.\nThen, we represent each graph as a set of node and edge embeddings and use them to design a family of neural set divergence surrogates. We replace the QAP terms corresponding to each operation with their surrogates. \nComputing such neural set divergence requires aligning nodes and edges of the two graphs.\nWe learn these alignments using a Gumbel-Sinkhorn permutation generator, additionally ensuring that the node and edge alignments are consistent with each other. Moreover, these alignments are cognizant of both the presence and absence of edges between node pairs.\nThrough extensive experiments on several datasets, along with a variety of edit cost settings, we show that $\\texttt{GraphEdX}$ consistently outperforms state-of-the-art methods and heuristics in terms of prediction error. The code is available at https://github.com/structlearning/GraphEdX.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93292",
      "pdf_url": "https://openreview.net/pdf?id=u7JRmrGutT",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Eeshaan_Jain1",
        "name": "Eeshaan Jain",
        "name_site": "Eeshaan Jain, Tushar Nandy, Gaurav Aggarwal, Ashish Tendulkar, Rishabh Iyer, Abir De",
        "openreview_id": "~Eeshaan_Jain1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://eeshaanjain.github.io",
        "dblp_id": null,
        "google_scholar_url": "r5rqqJEAAAAJ",
        "orcid": null,
        "linkedin_url": "eeshaanjain/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "udTwwF7tks",
      "title": "Iteratively Refined Early Interaction Alignment for Subgraph Matching based Graph Retrieval",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph retrieval based on subgraph isomorphism has several real-world applications such as scene graph retrieval, molecular fingerprint detection and circuit design. Roy et al. [35] proposed IsoNet, a late interaction model for subgraph matching, which first computes the node and edge embeddings of each graph independently of paired graph  and then computes a trainable alignment map. Here, we present $\\texttt{IsoNet++}$, an early interaction graph neural network (GNN), based on several technical innovations. First, we compute embeddings of all nodes by passing messages within and across the two input graphs, guided by an *injective alignment* between their nodes. Second, we update this alignment in a lazy fashion over multiple *rounds*. Within each round, we run a layerwise GNN from scratch, based on the current state of the alignment. After the completion of one round of GNN, we use the last-layer embeddings to update the alignments, and proceed to the next round. Third, $\\texttt{IsoNet++}$ incorporates a novel notion of node-pair partner interaction. Traditional early interaction computes attention between a node and its potential partners in the other graph, the attention then controlling messages passed across graphs. We consider *node pairs* (not single nodes) as potential partners. Existence of an edge between the nodes in one graph and non-existence in the other provide vital signals for refining the alignment. Our experiments on several datasets show that the alignments get progressively refined with successive rounds,\nresulting in significantly better retrieval performance than existing methods. We demonstrate that all three innovations contribute to the enhanced accuracy. Our code and datasets are publicly available at https://github.com/structlearning/isonetpp.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93261",
      "pdf_url": "https://openreview.net/pdf?id=udTwwF7tks",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ashwin_Ramachandran1",
        "name": "Ashwin Ramachandran",
        "name_site": "Ashwin Ramachandran, Vaibhav Raj, Indradyumna Roy, Soumen Chakrabarti, Abir De",
        "openreview_id": "~Ashwin_Ramachandran1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://ashwinramachandran2002.github.io/",
        "dblp_id": "07/1826",
        "google_scholar_url": "y7H-6IgAAAAJ",
        "orcid": null,
        "linkedin_url": "ashwin-ramachandran-042152204/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 15.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "3cL2XDyaEB",
      "title": "EGonc : Energy-based Open-Set Node Classification with substitute Unknowns",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Open-set Classification (OSC) is a critical requirement for safely deploying machine learning models in the open world, which aims to classify samples from known classes and reject samples from out-of-distribution (OOD). \nExisting methods exploit the feature space of trained network and attempt at estimating the uncertainty in the predictions.\nHowever, softmax-based neural networks are found to be overly confident in their predictions even on data they have never seen before and\nthe immense diversity of the OOD examples also makes such methods fragile.\nTo this end, we follow the idea of estimating the underlying density of the training data to decide whether a given input is close to the in-distribution (IND) data and adopt Energy-based models (EBMs) as density estimators. \nA novel energy-based generative open-set node classification method, \\textit{EGonc}, is proposed to achieve open-set graph learning. \nSpecifically, we generate substitute unknowns to mimic the distribution of real open-set samples firstly, based on the information of graph structures. \nThen, an additional energy logit representing the virtual OOD class is learned from the residual of the feature against the principal space, and matched with the original logits by a constant scaling. This virtual logit serves as the indicator of OOD-ness. \nEGonc has nice theoretical properties that guarantee an overall distinguishable margin between the detection scores for IND and OOD samples. \nComprehensive experimental evaluations of EGonc also demonstrate its superiority.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/96733",
      "pdf_url": "https://openreview.net/pdf?id=3cL2XDyaEB",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Xiaojun_Chen4",
        "name": "Xiaojun Chen",
        "name_site": null,
        "openreview_id": "~Xiaojun_Chen4",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://bruce-xjchen.github.io/HomePage/",
        "dblp_id": "20/3215-6",
        "google_scholar_url": "yAjyrwkAAAAJ",
        "orcid": "0000-0002-2818-4652",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Shenzhen University (China)",
        "countries": [
          "China"
        ],
        "country_codes": [
          "CN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.0,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "3qH8q02x0n",
      "title": "IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent advancements in text-to-speech (TTS) synthesis show that large-scale models trained with extensive web data produce highly natural-sounding output. However, such data is scarce for Indian languages due to the lack of high-quality, manually subtitled data on platforms like LibriVox or YouTube. To address this gap, we enhance existing large-scale ASR datasets containing natural conversations collected in low-quality environments to generate high-quality TTS training data. Our pipeline leverages the cross-lingual generalization of denoising and speech enhancement models trained on English and applied to Indian languages. This results in IndicVoices-R (IV-R), the largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704 hours of high-quality speech from 10,496 speakers across 22 Indian languages. IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS, and IndicTTS. We also introduce the IV-R Benchmark, the first to assess zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS models on Indian voices, ensuring diversity in age, gender, and style. We demonstrate that fine-tuning an English pre-trained model on a combined dataset of high-quality IndicTTS and our IV-R dataset results in better zero-shot speaker generalization compared to fine-tuning on the IndicTTS dataset alone. Further, our evaluation reveals limited zero-shot generalization for Indian voices in TTS models trained on prior datasets, which we improve by fine-tuning the model on our data containing diverse set of speakers across language families. We open-source code and data for all 22 official Indian languages.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97858",
      "pdf_url": "https://openreview.net/pdf?id=3qH8q02x0n",
      "github_url": "",
      "total_authors": 10,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Mitesh_M_Khapra1",
        "name": "Mitesh M Khapra",
        "name_site": null,
        "openreview_id": "~Mitesh_M_Khapra1",
        "position": 10,
        "gender": "M",
        "homepage_url": "http://www.cse.iitm.ac.in/~miteshk",
        "dblp_id": "90/7967",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=DV8z8DYAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "HwO1mNluoL",
      "title": "Mitigating Biases in Blackbox Feature Extractors for Image Classification Tasks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In image classification, it is common to utilize a pretrained model to extract meaningful features of the input images, and then to train a classifier on top of it to make predictions for any downstream task. Trained on enormous amounts of data, these models have been shown to contain harmful biases which can hurt their performance when adapted for a downstream classification task. Further, very often they may be blackbox, either due to scale, or because of unavailability of model weights or architecture. Thus, during a downstream task, we cannot debias such models by updating the weights of the feature encoder, as only the classifier can be finetuned. In this regard, we investigate the suitability of some existing debiasing techniques and thereby motivate the need for more focused research towards this problem setting. Furthermore, we propose a simple method consisting of a clustering-based adaptive margin loss with a blackbox feature encoder, with no knowledge of the bias attribute. Our experiments demonstrate the effectiveness of our method across multiple benchmarks.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95798",
      "pdf_url": "https://openreview.net/pdf?id=HwO1mNluoL",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Anirban_Chakraborty1",
        "name": "Anirban Chakraborty",
        "name_site": null,
        "openreview_id": "~Venkatesh_Babu_Radhakrishnan2",
        "position": 3,
        "gender": "M",
        "homepage_url": "http://cds.iisc.ac.in/faculty/venky",
        "dblp_id": "20/6289",
        "google_scholar_url": "cVg7HrEAAAAJ",
        "orcid": "0000-0002-1926-1804",
        "linkedin_url": "venkatesh-babu-radhakrishnan-16568939",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "SvmJJJS0q1",
      "title": "Detecting and Measuring Confounding Using Causal Mechanism Shifts",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Detecting and measuring confounding effects from data is a key challenge in causal inference. Existing methods frequently assume causal sufficiency, disregarding the presence of unobserved confounding variables. Causal sufficiency is both unrealistic and empirically untestable. Additionally, existing methods make strong parametric assumptions about the underlying causal generative process to guarantee the identifiability of confounding variables. Relaxing the causal sufficiency and parametric assumptions and leveraging recent advancements in causal discovery and confounding analysis with non-i.i.d. data, we propose a comprehensive approach for detecting and measuring confounding. We consider various definitions of confounding and introduce tailored methodologies to achieve three objectives: (i) detecting and measuring confounding among a set of variables, (ii) separating observed and unobserved confounding effects, and (iii) understanding the relative strengths of confounding bias between different sets of variables. We present useful properties of a confounding measure and present measures that satisfy those properties. Our empirical results support the usefulness of the proposed measures.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95068",
      "pdf_url": "https://openreview.net/pdf?id=SvmJJJS0q1",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vineeth_N._Balasubramanian2",
        "name": "Vineeth N. Balasubramanian",
        "name_site": null,
        "openreview_id": "~Vineeth_Balasubramanian1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://people.iith.ac.in/vineethnb/",
        "dblp_id": "88/4691",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=7soDcboAAAAJ",
        "orcid": "0000-0003-2656-0375",
        "linkedin_url": "vineethnb?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Hyderabad (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.5,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "YXQW4qQe2U",
      "title": "Optimal Top-Two Method for Best Arm Identification and Fluid Analysis",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Top-2 methods have become popular in solving the best arm identification (BAI) problem. The best arm, or the arm with the largest mean amongst finitely many, is identified through an algorithm that at any sequential step independently pulls the empirical best arm, with a fixed probability $\\beta$, and pulls the best challenger arm otherwise. The probability of incorrect selection is guaranteed to lie below a specified $\\delta>0$. Information theoretic lower bounds on sample complexity are well known for BAI problem and are matched asymptotically as $\\delta\\to 0$ by computationally demanding plug-in methods. The above top 2 algorithm for any $\\beta\\in(0, 1)$ has sample complexity within a constant of the lower bound. However, determining the optimal β that matches the lower bound has proven difficult. In this paper, we address this and propose an optimal top-2 type algorithm. We consider a function of allocations anchored at a threshold. If it exceeds the threshold then the algorithm samples the empirical best arm. Otherwise, it samples the challenger arm. We show that the proposed algorithm is optimal as $\\delta\\to 0$. Our analysis relies on identifying a limiting fluid dynamics of allocations that satisfy a series of ordinary differential equations pasted together and that describe the asymptotic path followed by our algorithm. We rely on the implicit function theorem to show existence and uniqueness of these fluid ode’s and to show that the proposed algorithm remains close to the ode solution.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/94693",
      "pdf_url": "https://openreview.net/pdf?id=YXQW4qQe2U",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Shubhada_Agrawal1",
        "name": "Shubhada Agrawal",
        "name_site": "Shubhada Agrawal, Wouter Koolen, Sandeep Juneja",
        "openreview_id": "~Shubhada_Agrawal1",
        "position": 3,
        "gender": "F",
        "homepage_url": "https://sites.google.com/view/shubhada-agrawal/home",
        "dblp_id": "247/9653",
        "google_scholar_url": "RQGMXiYAAAAJ",
        "orcid": null,
        "linkedin_url": "shubhada-agrawal-55561867/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Georgia Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 5.8,
        "rating_std": 0.7483314773547882,
        "confidence_mean": 3.4,
        "confidence_std": 0.8,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "aNTnHBkw4T",
      "title": "Understanding Hallucinations in Diffusion Models through Mode Interpolation",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Colloquially speaking, image generation models based upon diffusion processes are frequently said to exhibit ''hallucinations'' samples that could never occur in the training data.  But where do such hallucinations come from? In this paper, we study a particular failure mode in diffusion models, which we term ***mode interpolation***.  Specifically, we find that diffusion models smoothly ``interpolate'' between nearby data modes in the training set, to generate samples that are completely outside the support of the original training distribution; this phenomenon leads diffusion models to generate artifacts that never existed in real data (i.e., hallucinations). We systematically study the reasons for, and the manifestation of this phenomenon. Through experiments on 1D and 2D Gaussians, we show how a discontinuous loss landscape in the diffusion model's decoder leads to a region where any smooth approximation will cause such hallucinations. Through experiments on artificial datasets with various shapes, we show how hallucination leads to the generation of combinations of shapes that never existed. We extend the validity of mode interpolation in real-world datasets by explaining the unexpected generation of images with additional or missing fingers similar to those produced by popular text-to-image generative models. Finally, we show that diffusion models in fact ***know*** when they go out of support and hallucinate. This is captured by the high variance in the trajectory of the generated sample towards the final few backward sampling process. Using a simple metric to capture this variance, we can remove over 95\\% of hallucinations at generation time. We conclude our exploration by showing the implications of such hallucination (and its removal) on the collapse (and stabilization) of recursive training on synthetic data with experiments on datasets like MNIST .",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/94558",
      "pdf_url": "https://openreview.net/pdf?id=aNTnHBkw4T",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Venkatesh_Babu_Radhakrishnan2_1",
        "name": "Venkatesh Babu Radhakrishnan",
        "name_site": null,
        "openreview_id": "~Sumukh_Aithal_K1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://sumukhaithal6.github.io/",
        "dblp_id": "299/5911",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": "sumukh-aithal-9801b4189",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Carnegie Mellon University (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 4.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 21,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "fzlMza6dRZ",
      "title": "GraphTrail: Translating GNN Predictions into Human-Interpretable Logical Rules",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Instance-level explanation of graph neural networks (GNNs) is a well-studied area. These explainers, however, only explain an instance (e.g., a graph) and fail to uncover the combinatorial reasoning learned by a GNN from the training data towards making its predictions. In this work, we introduce GraphTrail, the first end-to-end, global, post-hoc GNN explainer that translates the functioning of a black-box GNN model to a boolean formula over the (sub)graph level concepts without relying on local explainers. GraphTrail is unique in automatically mining the discriminative subgraph-level concepts using Shapley values. Subsequently, the GNN predictions are mapped to a human-interpretable boolean formula over these concepts through symbolic regression. Extensive experiments across diverse datasets and GNN architectures demonstrate significant improvement over existing global explainers in mapping GNN predictions to faithful logical formulae. The robust and accurate performance of GraphTrail makes it invaluable for improving GNNs and facilitates adoption in domains with strict transparency requirements.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/94172",
      "pdf_url": "https://openreview.net/pdf?id=fzlMza6dRZ",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sayan_Ranu2",
        "name": "Sayan Ranu",
        "name_site": null,
        "openreview_id": "~Sayan_Ranu2",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://www.cse.iitd.ac.in/~sayan/index.html",
        "dblp_id": "38/768",
        "google_scholar_url": "K4w5qYUAAAAJ",
        "orcid": "0000-0003-4147-9372",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "hceKrY4dfC",
      "title": "Indoor Air Quality Dataset with Activities of Daily Living in Low to Middle-income Communities",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In recent years, indoor air pollution has posed a significant threat to our society, claiming over 3.2 million lives annually. Developing nations, such as India, are most affected since lack of knowledge, inadequate regulation, and outdoor air pollution lead to severe daily exposure to pollutants. However, only a limited number of studies have attempted to understand how indoor air pollution affects developing countries like India. To address this gap, we present spatiotemporal measurements of air quality from 30 indoor sites over six months during summer and winter seasons. The sites are geographically located across four regions of type: rural, suburban, and urban, covering the typical low to middle-income population in India. The dataset contains various types of indoor environments (e.g., studio apartments, classrooms, research laboratories, food canteens, and residential households), and can provide the basis for data-driven learning model research aimed at coping with unique pollution patterns in developing countries. This unique dataset demands advanced data cleaning and imputation techniques for handling missing data due to power failure or network outages during data collection. Furthermore, through a simple speech-to-text application, we provide real-time indoor activity labels annotated by occupants. Therefore, environmentalists and ML enthusiasts can utilize this dataset to understand the complex patterns of the pollutants under different indoor activities, identify recurring sources of pollution, forecast exposure, improve floor plans and room structures of modern indoor designs, develop pollution-aware recommender systems, etc.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97565",
      "pdf_url": "https://openreview.net/pdf?id=hceKrY4dfC",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Sandip_Chakraborty1",
        "name": "Sandip Chakraborty",
        "name_site": null,
        "openreview_id": "~Sandip_Chakraborty1",
        "position": 3,
        "gender": "M",
        "homepage_url": "http://cse.iitkgp.ac.in/~sandipc/",
        "dblp_id": "28/9571",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=dEpbTokAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kharagpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.75,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "l0Ydsl10ci",
      "title": "IMPACT: A Large-scale Integrated Multimodal Patent Analysis and Creation Dataset for Design Patents",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In this paper, we introduce IMPACT (Integrated Multimodal Patent Analysis and Creation Dataset for Design Patents), a large-scale multimodal patent dataset with detailed captions for design patent figures. Our dataset includes half a million design patents comprising 3.61 million figures along with captions from patents granted by the United States Patent and Trademark Office (USPTO) over a 16-year period from 2007 to 2022. We incorporate the metadata of each patent application with elaborate captions that are coherent with multiple viewpoints of designs.  Even though patents themselves contain a variety of design figures, titles, and descriptions of viewpoints, we find that they lack detailed descriptions that are necessary to perform multimodal tasks such as classification and retrieval. IMPACT closes this gap thereby providing researchers with necessary ingredients to instantiate a variety of multimodal tasks. Our dataset has a huge potential for novel design inspiration and can be used with advanced computer vision models in tandem. We perform preliminary evaluations on the dataset on the popular patent analysis tasks such as classification and retrieval. Our results indicate that integrating images with generated captions significantly improves the performance of different models on the corresponding tasks. Given that design patents offer various benefits for modeling novel tasks, we propose two standard computer vision tasks that have not been investigated in analyzing patents as future directions using IMPACT as a benchmark viz., 3D Image Construction and Visual Question Answering (VQA). To facilitate research in these directions, we make our IMPACT dataset and the code/models used in this work publicly available at https://github.com/AI4Patents/IMPACT.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97529",
      "pdf_url": "https://openreview.net/pdf?id=l0Ydsl10ci",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Sourav_Medya1",
        "name": "Sourav Medya",
        "name_site": null,
        "openreview_id": "~Sourav_Medya1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://souravmedya.github.io/",
        "dblp_id": "178/3021",
        "google_scholar_url": "RCFhOM4AAAAJ",
        "orcid": "0000-0003-0996-2807",
        "linkedin_url": "sourav-medya-35987a49/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Illinois at Chicago (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nBQHTBVnfr",
      "title": "Geometric Analysis of Nonlinear Manifold Clustering",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Manifold clustering is an important problem in motion and video segmentation, natural image clustering, and other applications where high-dimensional data lie on multiple, low-dimensional, nonlinear manifolds. While current state-of-the-art methods on large-scale datasets such as CIFAR provide good empirical performance, they do not have any proof of theoretical correctness. In this work, we propose a method that clusters data belonging to a union of nonlinear manifolds. Furthermore, for a given input data sample $y$ belonging to the $l$th manifold $\\mathcal{M}_l$, we provide geometric conditions that guarantee a manifold-preserving representation of $y$ can be recovered from the solution to the proposed model. The geometric conditions require that (i) $\\mathcal{M}_l$ is well-sampled in the neighborhood of $y$, with the sampling density given as a function of the curvature, and (ii) $\\mathcal{M}_l$ is sufficiently separated from the other manifolds. In addition to providing proof of correctness in this setting, a numerical comparison with state-of-the-art methods on CIFAR datasets shows that our method performs competitively although marginally worse than methods without",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93708",
      "pdf_url": "https://openreview.net/pdf?id=nBQHTBVnfr",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Nimita_Rajendra_Shinde1",
        "name": "Nimita Rajendra Shinde",
        "name_site": "Nimita Shinde, Vishnu Narayanan, James Saunderson",
        "openreview_id": "~Nimita_Rajendra_Shinde1",
        "position": 4,
        "gender": "F",
        "homepage_url": "https://sites.google.com/view/nimitashinde",
        "dblp_id": "304/0987",
        "google_scholar_url": "https://scholar.google.com.eg/citations?user=JwVUMxsAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Lehigh University (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 0.816496580927726,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nN6NSd1Qds",
      "title": "UGC: Universal Graph Coarsening",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In the era of big data, graphs have emerged as a natural representation of intricate relationships. However, graph sizes often become unwieldy, leading to storage, computation, and analysis challenges. A crucial demand arises for methods that can effectively downsize large graphs while retaining vital insights. Graph coarsening seeks to simplify large graphs while maintaining the basic statistics of the graphs, such as spectral properties and $\\epsilon$-similarity in the coarsened graph. This ensures that downstream processes are more efficient and effective. Most published methods are suitable for homophilic datasets, limiting their universal use. We propose **U**niversal **G**raph **C**oarsening (UGC), a framework equally suitable for homophilic and heterophilic datasets. UGC integrates node attributes and adjacency information, leveraging the dataset's heterophily factor. Results on benchmark datasets demonstrate that UGC preserves spectral similarity while coarsening. In comparison to existing methods, UGC is 4x to 15x faster, has lower eigen-error, and yields superior performance on downstream processing tasks even at 70% coarsening ratios.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93695",
      "pdf_url": "https://openreview.net/pdf?id=nN6NSd1Qds",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Jayadeva_Jayadeva1",
        "name": "Jayadeva Jayadeva",
        "name_site": null,
        "openreview_id": "~Jayadeva_Jayadeva1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "58/4288",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.7071067811865476,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "tuiqq1G8I5",
      "title": "DisCEdit: Model Editing by Identifying Discriminative Components",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Model editing is a growing area of research that is particularly valuable in contexts where modifying key model components, like neurons or filters, can significantly impact the model’s performance. The key challenge lies in identifying important components useful to the model’s predictions. We apply model editing to address two active areas of research, Structured Pruning, and Selective Class Forgetting. In this work, we adopt a distributional approach to the problem of identifying important components, leveraging the recently proposed discriminative filters hypothesis, which states that well-trained (convolutional) models possess discriminative filters that are essential to prediction. To do so, we define discriminative ability in terms of the Bayes error rate associated with the feature distributions, which is equivalent to computing the Total Variation (TV) distance between the distributions. However, computing the TV distance is intractable, motivating us to derive novel witness function-based lower bounds on the TV distance that require no assumptions on the underlying distributions; using this bound generalizes prior work such as Murti et al. [39] that relied on unrealistic Gaussianity assumptions on the feature distributions. With these bounds, we are able to discover critical subnetworks responsible for classwise predictions, and derive DISCEDIT-SP and DISCEDIT-U , algorithms for structured pruning requiring no access to the training data and loss function, and selective forgetting respectively. We apply DISCEDIT-U to selective class forgetting on models trained on CIFAR10 and CIFAR100, and we show that on average, we can reduce accuracy on a single class by over 80% with a minimal reduction in test accuracy on the remaining classes. Similarly, on Structured pruning problems, we obtain 40.8% sparsity on ResNet50 on Imagenet, with only a 2.6% drop in accuracy with minimal fine-tuning.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93306",
      "pdf_url": "https://openreview.net/pdf?id=tuiqq1G8I5",
      "github_url": "",
      "total_authors": 2,
      "track_name": "Main Conference",
      "author": {
        "id": "~Chiranjib_Bhattacharyya1",
        "name": "Chiranjib Bhattacharyya",
        "name_site": null,
        "openreview_id": "~Chiranjib_Bhattacharyya1",
        "position": 2,
        "gender": "M",
        "homepage_url": "http://www.csa.iisc.ac.in/~chiru/",
        "dblp_id": "b/CBhattacharyya",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": null,
        "countries": [],
        "country_codes": []
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "u7JRmrGutT",
      "title": "Graph Edit Distance with General Costs Using Neural Set Divergence",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph Edit Distance (GED) measures the (dis-)similarity between two given graphs in terms of the minimum-cost edit sequence, which transforms one graph to the other.\nGED is related to other notions of graph similarity, such as graph and subgraph isomorphism, maximum common subgraph, etc. However, the computation of exact GED is NP-Hard, which has recently motivated the design of neural models for GED estimation.\nHowever, they do not explicitly account for edit operations with different costs. In response, we propose $\\texttt{GraphEdX}$, a neural GED estimator that can work with general costs specified for the four edit operations, viz., edge deletion, edge addition, node deletion, and node addition.\nWe first present GED as a quadratic assignment problem (QAP) that incorporates these four costs.\nThen, we represent each graph as a set of node and edge embeddings and use them to design a family of neural set divergence surrogates. We replace the QAP terms corresponding to each operation with their surrogates. \nComputing such neural set divergence requires aligning nodes and edges of the two graphs.\nWe learn these alignments using a Gumbel-Sinkhorn permutation generator, additionally ensuring that the node and edge alignments are consistent with each other. Moreover, these alignments are cognizant of both the presence and absence of edges between node pairs.\nThrough extensive experiments on several datasets, along with a variety of edit cost settings, we show that $\\texttt{GraphEdX}$ consistently outperforms state-of-the-art methods and heuristics in terms of prediction error. The code is available at https://github.com/structlearning/GraphEdX.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93292",
      "pdf_url": "https://openreview.net/pdf?id=u7JRmrGutT",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abir_De1",
        "name": "Abir De",
        "name_site": null,
        "openreview_id": "~Abir_De1",
        "position": 5,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "118/7174",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=_9ZKKbIAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "udTwwF7tks",
      "title": "Iteratively Refined Early Interaction Alignment for Subgraph Matching based Graph Retrieval",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph retrieval based on subgraph isomorphism has several real-world applications such as scene graph retrieval, molecular fingerprint detection and circuit design. Roy et al. [35] proposed IsoNet, a late interaction model for subgraph matching, which first computes the node and edge embeddings of each graph independently of paired graph  and then computes a trainable alignment map. Here, we present $\\texttt{IsoNet++}$, an early interaction graph neural network (GNN), based on several technical innovations. First, we compute embeddings of all nodes by passing messages within and across the two input graphs, guided by an *injective alignment* between their nodes. Second, we update this alignment in a lazy fashion over multiple *rounds*. Within each round, we run a layerwise GNN from scratch, based on the current state of the alignment. After the completion of one round of GNN, we use the last-layer embeddings to update the alignments, and proceed to the next round. Third, $\\texttt{IsoNet++}$ incorporates a novel notion of node-pair partner interaction. Traditional early interaction computes attention between a node and its potential partners in the other graph, the attention then controlling messages passed across graphs. We consider *node pairs* (not single nodes) as potential partners. Existence of an edge between the nodes in one graph and non-existence in the other provide vital signals for refining the alignment. Our experiments on several datasets show that the alignments get progressively refined with successive rounds,\nresulting in significantly better retrieval performance than existing methods. We demonstrate that all three innovations contribute to the enhanced accuracy. Our code and datasets are publicly available at https://github.com/structlearning/isonetpp.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93261",
      "pdf_url": "https://openreview.net/pdf?id=udTwwF7tks",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Abir_De1",
        "name": "Abir De",
        "name_site": null,
        "openreview_id": "~Abir_De1",
        "position": 5,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "118/7174",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=_9ZKKbIAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 10.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nY0BrZdqLt",
      "title": "Time-Reversal Provides Unsupervised Feedback to LLMs",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "Large Language Models (LLMs) are typically trained to predict in the forward direction of time. However, recent works have shown that prompting these models to look back and critique their own generations can produce useful feedback. Motivated by this, we explore the question of whether LLMs can be empowered to think (predict and score) backwards to provide unsupervised feedback that complements forward LLMs. Towards this, we introduce Time Reversed Language Models (TRLMs), which can score and generate queries when conditioned on responses, effectively functioning in the reverse direction of time. Further, to effectively infer in the response to query direction, we pre-train and fine-tune a language model (TRLM-Ba) in the reverse token order from scratch. We show empirically (and theoretically in a stylized setting) that time-reversed models can indeed complement forward model predictions when used to score the query given response for re-ranking multiple forward generations. We obtain up to 5\\% improvement on the widely used AlpacaEval Leaderboard over the competent baseline of best-of-N re-ranking using self log-perplexity scores. We further show that TRLM scoring outperforms conventional forward scoring of response given query, resulting in significant gains in applications such as citation generation and passage retrieval. We next leverage the generative ability of TRLM to augment or provide unsupervised feedback to input safety filters of LLMs, demonstrating a drastic reduction in false negative rate with negligible impact on false positive rates against several attacks published on the popular JailbreakBench leaderboard.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93684",
      "pdf_url": "https://openreview.net/pdf?id=nY0BrZdqLt",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rahul_Madhavan1",
        "name": "Rahul Madhavan",
        "name_site": null,
        "openreview_id": "~Rahul_Madhavan1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "290/2008",
        "google_scholar_url": "HrM2xRcAAAAJ",
        "orcid": null,
        "linkedin_url": "rahul-madhavan/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 6.0,
      "reviews": {
        "rating_mean": 7.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 2.3333333333333335,
        "confidence_std": 0.9428090415820634,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "FTPDBQuT4G",
      "title": "Generalized Linear Bandits with Limited Adaptivity",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "We study the generalized linear contextual bandit problem within the constraints of limited adaptivity.  In this paper, we present two algorithms, B-GLinCB and RS-GLinCB, that address, respectively, two prevalent limited adaptivity settings. Given a budget $M$ on the number of policy updates, in the first setting, the algorithm needs to decide upfront $M$ rounds at which it will update its policy, while in the second setting it can adaptively perform $M$ policy updates during its course. For the first setting, we design an algorithm B-GLinCB, that incurs $\\tilde{O}(\\sqrt{T})$ regret when $M = \\Omega( \\log{\\log T} )$ and the arm feature vectors are generated stochastically. For the second setting, we design an algorithm RS-GLinCB that updates its policy $\\tilde{O}(\\log^2 T)$ times and achieves a regret of $\\tilde{O}(\\sqrt{T})$ even when the arm feature vectors are adversarially generated. Notably, in these bounds, we manage to eliminate the dependence on a key instance dependent parameter $\\kappa$, that captures non-linearity of the underlying reward model. Our novel approach for removing this dependence for generalized linear contextual bandits might be of independent interest.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95973",
      "pdf_url": "https://openreview.net/pdf?id=FTPDBQuT4G",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Nirjhar_Das1",
        "name": "Nirjhar Das",
        "name_site": null,
        "openreview_id": "~Nirjhar_Das1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://nirjhar-das.github.io",
        "dblp_id": "323/5270",
        "google_scholar_url": "Zf3YrgYAAAAJ",
        "orcid": "0000-0001-7753-4391",
        "linkedin_url": "nirjhar-das-874596195/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 5.000000000000001,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "WEFxOm3Aez",
      "title": "RelBench: A Benchmark for Deep Learning on Relational Databases",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We present RelBench, a public benchmark for solving predictive tasks in relational databases with deep learning.  RelBench provides databases and tasks spanning diverse domains, scales, and database dimensions, and is intended to be a foundational infrastructure for future research in this direction. We use RelBench to conduct the first comprehensive empirical study of graph neural network (GNN) based predictive models on relational data, as recently proposed by Fey et al. 2024.  End-to-end learned GNNs are capable fully exploiting the predictive signal encoded in links between entities, marking a significant shift away from the dominant paradigm of manual feature engineering combined with tabular machine learning. To thoroughly evaluate GNNs against the prior gold-standard we conduct a user study, where an experienced data scientist manually engineers features for each task. In this study, GNNs learn better models whilst reducing human work needed by more than an order of magnitude. This result demonstrates the power of GNNs for solving predictive tasks in relational databases, opening up new research opportunities.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97659",
      "pdf_url": "https://openreview.net/pdf?id=WEFxOm3Aez",
      "github_url": "",
      "total_authors": 12,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Rishabh_Ranjan1",
        "name": "Rishabh Ranjan",
        "name_site": "Rishabh Ranjan, Siddharth Grover, Sourav Medya, Venkatesan Chakaravarthy, Yogish Sabharwal, Sayan Ranu",
        "openreview_id": "~Rishabh_Ranjan1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://rishabh-ranjan.github.io",
        "dblp_id": null,
        "google_scholar_url": "NNzQUrcAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Stanford University (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 4.545454545454545,
      "reviews": {
        "rating_mean": 7.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 11,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nY0BrZdqLt",
      "title": "Time-Reversal Provides Unsupervised Feedback to LLMs",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "Large Language Models (LLMs) are typically trained to predict in the forward direction of time. However, recent works have shown that prompting these models to look back and critique their own generations can produce useful feedback. Motivated by this, we explore the question of whether LLMs can be empowered to think (predict and score) backwards to provide unsupervised feedback that complements forward LLMs. Towards this, we introduce Time Reversed Language Models (TRLMs), which can score and generate queries when conditioned on responses, effectively functioning in the reverse direction of time. Further, to effectively infer in the response to query direction, we pre-train and fine-tune a language model (TRLM-Ba) in the reverse token order from scratch. We show empirically (and theoretically in a stylized setting) that time-reversed models can indeed complement forward model predictions when used to score the query given response for re-ranking multiple forward generations. We obtain up to 5\\% improvement on the widely used AlpacaEval Leaderboard over the competent baseline of best-of-N re-ranking using self log-perplexity scores. We further show that TRLM scoring outperforms conventional forward scoring of response given query, resulting in significant gains in applications such as citation generation and passage retrieval. We next leverage the generative ability of TRLM to augment or provide unsupervised feedback to input safety filters of LLMs, demonstrating a drastic reduction in false negative rate with negligible impact on false positive rates against several attacks published on the popular JailbreakBench leaderboard.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93684",
      "pdf_url": "https://openreview.net/pdf?id=nY0BrZdqLt",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sravanti_Addepalli1",
        "name": "Sravanti Addepalli",
        "name_site": null,
        "openreview_id": "~Sravanti_Addepalli1",
        "position": 3,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": "127/7715",
        "google_scholar_url": "MOO12i0AAAAJ",
        "orcid": null,
        "linkedin_url": "sravanti-addepalli/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 4.5,
      "reviews": {
        "rating_mean": 7.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 2.3333333333333335,
        "confidence_std": 0.9428090415820634,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "3qH8q02x0n",
      "title": "IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent advancements in text-to-speech (TTS) synthesis show that large-scale models trained with extensive web data produce highly natural-sounding output. However, such data is scarce for Indian languages due to the lack of high-quality, manually subtitled data on platforms like LibriVox or YouTube. To address this gap, we enhance existing large-scale ASR datasets containing natural conversations collected in low-quality environments to generate high-quality TTS training data. Our pipeline leverages the cross-lingual generalization of denoising and speech enhancement models trained on English and applied to Indian languages. This results in IndicVoices-R (IV-R), the largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704 hours of high-quality speech from 10,496 speakers across 22 Indian languages. IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS, and IndicTTS. We also introduce the IV-R Benchmark, the first to assess zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS models on Indian voices, ensuring diversity in age, gender, and style. We demonstrate that fine-tuning an English pre-trained model on a combined dataset of high-quality IndicTTS and our IV-R dataset results in better zero-shot speaker generalization compared to fine-tuning on the IndicTTS dataset alone. Further, our evaluation reveals limited zero-shot generalization for Indian voices in TTS models trained on prior datasets, which we improve by fine-tuning the model on our data containing diverse set of speakers across language families. We open-source code and data for all 22 official Indian languages.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97858",
      "pdf_url": "https://openreview.net/pdf?id=3qH8q02x0n",
      "github_url": "",
      "total_authors": 10,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Srija_Anand1",
        "name": "Srija Anand",
        "name_site": null,
        "openreview_id": "~Srija_Anand1",
        "position": 2,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "srijaanand",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 4.444444444444445,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "wBzvYh3PRA",
      "title": "FactorSim: Generative Simulation via Factorized Representation",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Generating simulations to train intelligent agents in game-playing and robotics from natural language input, user input, or task documentation remains an open-ended challenge. Existing approaches focus on parts of this challenge, such as generating reward functions or task hyperparameters. Unlike previous work, we introduce FACTORSIM that generates full simulations in code from language input that can be used to train agents. Exploiting the structural modularity specific to coded simulations, we propose to use a factored partially observable Markov decision process representation that allows us to reduce context dependence during each step of the generation. For evaluation, we introduce a generative simulation benchmark that assesses the generated simulation code’s accuracy and effectiveness in facilitating zero-shot transfers in reinforcement learning settings. We show that FACTORSIM outperforms existing methods in generating simulations regarding prompt alignment (i.e., accuracy), zero-shot transfer abilities, and human evaluation. We also demonstrate its effectiveness in generating robotic tasks.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93169",
      "pdf_url": "https://openreview.net/pdf?id=wBzvYh3PRA",
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Harini_S_I1",
        "name": "Harini S I",
        "name_site": null,
        "openreview_id": "~Harini_S_I1",
        "position": 2,
        "gender": "F",
        "homepage_url": "https://harini-si.github.io/",
        "dblp_id": "356/3166",
        "google_scholar_url": "https://scholar.google.com/citations?view_op=list_works",
        "orcid": null,
        "linkedin_url": "harini-s-i-a140b61bb/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 4.375,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "4351SumKS9",
      "title": "Beyond Aesthetics: Cultural Competence in Text-to-Image Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Text-to-Image (T2I) models are being increasingly adopted in diverse global communities where they create visual representations of their unique cultures. Current T2I benchmarks primarily focus on faithfulness, aesthetics, and realism of generated images, overlooking the critical dimension of *cultural competence*. In this work, we introduce a framework to evaluate cultural competence of T2I models along two crucial dimensions: cultural awareness and cultural diversity, and present a scalable approach using a combination of structured knowledge bases and large language models to build a large dataset of cultural artifacts to enable this evaluation. In particular, we apply this approach to build CUBE (CUltural BEnchmark for Text-to-Image models), a first-of-its-kind benchmark to evaluate cultural competence of T2I models. CUBE covers cultural artifacts associated with 8 countries across different geo-cultural regions and along 3 concepts: cuisine, landmarks, and art. CUBE consists of 1) CUBE-1K, a set of high-quality prompts that enable the evaluation of cultural awareness, and 2) CUBE-CSpace, a larger dataset of cultural artifacts that serves as grounding to evaluate cultural diversity. We also introduce cultural diversity as a novel T2I evaluation component, leveraging quality-weighted Vendi score. Our evaluations reveal significant gaps in the cultural awareness of existing models across countries and provide valuable insights into the cultural diversity of T2I outputs for underspecified prompts. Our methodology is extendable to other cultural regions and concepts and can facilitate the development of T2I models that better cater to the global population.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97855",
      "pdf_url": "https://openreview.net/pdf?id=4351SumKS9",
      "github_url": "",
      "total_authors": 8,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Arif_Ahmad1",
        "name": "Arif Ahmad",
        "name_site": null,
        "openreview_id": "~Arif_Ahmad1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://arifahmad-py.github.io/",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "arif-ahmad-iitb/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 4.2857142857142865,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 2.29128784747792,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 10,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "tZRpvLXevU",
      "title": "Latent Representation Matters: Human-like Sketches in One-shot Drawing Tasks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Humans can effortlessly draw new categories from a single exemplar, a feat that has long posed a challenge for generative models. However, this gap has started to close with recent advances in diffusion models. This one-shot drawing task requires powerful inductive biases that have not been systematically investigated. Here, we study how different inductive biases shape the latent space of Latent Diffusion Models (LDMs). Along with standard LDM regularizers (KL and vector quantization), we explore supervised regularizations (including classification and prototype-based representation) and contrastive inductive biases (using  SimCLR and redundancy reduction objectives). We demonstrate that LDMs with redundancy reduction and prototype-based regularizations produce near-human-like drawings (regarding both samples' recognizability and originality) -- better mimicking human perception (as evaluated psychophysically). Overall, our results suggest that the gap between humans and machines in one-shot drawings is almost closed.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93325",
      "pdf_url": "https://openreview.net/pdf?id=tZRpvLXevU",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rishav_Mukherji1",
        "name": "Rishav Mukherji",
        "name_site": null,
        "openreview_id": "~Rishav_Mukherji1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://amapocho.github.io/",
        "dblp_id": "338/9227",
        "google_scholar_url": "s6F4ZKcAAAAJ",
        "orcid": null,
        "linkedin_url": "rishav-mukherji/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 4.166666666666667,
      "reviews": {
        "rating_mean": 4.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "SdLOs1FR4h",
      "title": "FUGAL: Feature-fortified Unrestricted Graph Alignment",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The necessity to align two graphs, minimizing a structural distance metric, is prevalent in biology, chemistry, recommender systems, and social network analysis. Due to the problem’s NP-hardness, prevailing graph alignment methods follow a modular and mediated approach, solving the problem by restricting to the domain of intermediary graph representations or products like embeddings, spectra, and graph signals. Restricting the problem to this intermediate space may distort the original problem and are hence predisposed to miss high-quality solutions. In this paper, we propose an unrestricted method, FUGAL, which finds a permutation matrix that maps one graph to another by directly operating on their adjacency matrices with judicious constraint relaxation. Extensive experimentation demonstrates that FUGAL consistently surpasses state-of-the-art graph alignment methods in accuracy across all benchmark datasets without encumbering efficiency.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95090",
      "pdf_url": "https://openreview.net/pdf?id=SdLOs1FR4h",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Harshith_Reddy_Vonteri1",
        "name": "Harshith Reddy Vonteri",
        "name_site": null,
        "openreview_id": "~Harshith_Reddy_Vonteri1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0009-0000-2147-3956",
        "linkedin_url": "harshith-reddy-vonteri-1a1724216/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 4.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 1.6583123951777,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "TZ5k9IYBBf",
      "title": "RanDumb: Random Representations Outperform Online Continually Learned Representations",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Continual learning has primarily focused on the issue of catastrophic forgetting and the associated stability-plasticity tradeoffs. However, little attention has been paid to the efficacy of continually learned representations, as representations are learned alongside classifiers throughout the learning process. Our primary contribution is empirically demonstrating that existing online continually trained deep networks produce inferior representations compared to a simple pre-defined random transforms. Our approach embeds raw pixels using a fixed random transform, approximating an RBF-Kernel initialized before any data is seen. We then train a simple linear classifier on top without storing any exemplars, processing one sample at a time in an online continual learning setting. This method, called RanDumb,  significantly outperforms state-of-the-art continually learned representations across all standard online continual learning benchmarks. Our study reveals the significant limitations of representation learning, particularly in low-exemplar and online continual learning scenarios. Extending our investigation to popular exemplar-free scenarios with pretrained models, we find that training only a linear classifier on top of pretrained representations surpasses most continual fine-tuning and prompt-tuning strategies. Overall, our investigation challenges the prevailing assumptions about effective representation learning in the online continual learning.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95027",
      "pdf_url": "https://openreview.net/pdf?id=TZ5k9IYBBf",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Shiven_Sinha1",
        "name": "Shiven Sinha",
        "name_site": null,
        "openreview_id": "~Shiven_Sinha1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "368/3856",
        "google_scholar_url": "WO51AfgAAAAJ",
        "orcid": "0009-0000-5259-2683",
        "linkedin_url": "shiven-sinha/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 4.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "3qH8q02x0n",
      "title": "IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent advancements in text-to-speech (TTS) synthesis show that large-scale models trained with extensive web data produce highly natural-sounding output. However, such data is scarce for Indian languages due to the lack of high-quality, manually subtitled data on platforms like LibriVox or YouTube. To address this gap, we enhance existing large-scale ASR datasets containing natural conversations collected in low-quality environments to generate high-quality TTS training data. Our pipeline leverages the cross-lingual generalization of denoising and speech enhancement models trained on English and applied to Indian languages. This results in IndicVoices-R (IV-R), the largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704 hours of high-quality speech from 10,496 speakers across 22 Indian languages. IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS, and IndicTTS. We also introduce the IV-R Benchmark, the first to assess zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS models on Indian voices, ensuring diversity in age, gender, and style. We demonstrate that fine-tuning an English pre-trained model on a combined dataset of high-quality IndicTTS and our IV-R dataset results in better zero-shot speaker generalization compared to fine-tuning on the IndicTTS dataset alone. Further, our evaluation reveals limited zero-shot generalization for Indian voices in TTS models trained on prior datasets, which we improve by fine-tuning the model on our data containing diverse set of speakers across language families. We open-source code and data for all 22 official Indian languages.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97858",
      "pdf_url": "https://openreview.net/pdf?id=3qH8q02x0n",
      "github_url": "",
      "total_authors": 10,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Praveen_Srinivasa_Varadhan1",
        "name": "Praveen Srinivasa Varadhan",
        "name_site": null,
        "openreview_id": "~Praveen_Srinivasa_Varadhan1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "283/5316.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=CpGhZUYAAAAJ",
        "orcid": null,
        "linkedin_url": "svp19/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.888888888888889,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "u7JRmrGutT",
      "title": "Graph Edit Distance with General Costs Using Neural Set Divergence",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph Edit Distance (GED) measures the (dis-)similarity between two given graphs in terms of the minimum-cost edit sequence, which transforms one graph to the other.\nGED is related to other notions of graph similarity, such as graph and subgraph isomorphism, maximum common subgraph, etc. However, the computation of exact GED is NP-Hard, which has recently motivated the design of neural models for GED estimation.\nHowever, they do not explicitly account for edit operations with different costs. In response, we propose $\\texttt{GraphEdX}$, a neural GED estimator that can work with general costs specified for the four edit operations, viz., edge deletion, edge addition, node deletion, and node addition.\nWe first present GED as a quadratic assignment problem (QAP) that incorporates these four costs.\nThen, we represent each graph as a set of node and edge embeddings and use them to design a family of neural set divergence surrogates. We replace the QAP terms corresponding to each operation with their surrogates. \nComputing such neural set divergence requires aligning nodes and edges of the two graphs.\nWe learn these alignments using a Gumbel-Sinkhorn permutation generator, additionally ensuring that the node and edge alignments are consistent with each other. Moreover, these alignments are cognizant of both the presence and absence of edges between node pairs.\nThrough extensive experiments on several datasets, along with a variety of edit cost settings, we show that $\\texttt{GraphEdX}$ consistently outperforms state-of-the-art methods and heuristics in terms of prediction error. The code is available at https://github.com/structlearning/GraphEdX.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93292",
      "pdf_url": "https://openreview.net/pdf?id=u7JRmrGutT",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Indradyumna_Roy1",
        "name": "Indradyumna Roy",
        "name_site": "Indradyumna Roy, Soumen Chakrabarti, Abir De",
        "openreview_id": "~Indradyumna_Roy1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://indradyumna.github.io/",
        "dblp_id": "124/9185.html",
        "google_scholar_url": "qb70i84AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.75,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "udTwwF7tks",
      "title": "Iteratively Refined Early Interaction Alignment for Subgraph Matching based Graph Retrieval",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph retrieval based on subgraph isomorphism has several real-world applications such as scene graph retrieval, molecular fingerprint detection and circuit design. Roy et al. [35] proposed IsoNet, a late interaction model for subgraph matching, which first computes the node and edge embeddings of each graph independently of paired graph  and then computes a trainable alignment map. Here, we present $\\texttt{IsoNet++}$, an early interaction graph neural network (GNN), based on several technical innovations. First, we compute embeddings of all nodes by passing messages within and across the two input graphs, guided by an *injective alignment* between their nodes. Second, we update this alignment in a lazy fashion over multiple *rounds*. Within each round, we run a layerwise GNN from scratch, based on the current state of the alignment. After the completion of one round of GNN, we use the last-layer embeddings to update the alignments, and proceed to the next round. Third, $\\texttt{IsoNet++}$ incorporates a novel notion of node-pair partner interaction. Traditional early interaction computes attention between a node and its potential partners in the other graph, the attention then controlling messages passed across graphs. We consider *node pairs* (not single nodes) as potential partners. Existence of an edge between the nodes in one graph and non-existence in the other provide vital signals for refining the alignment. Our experiments on several datasets show that the alignments get progressively refined with successive rounds,\nresulting in significantly better retrieval performance than existing methods. We demonstrate that all three innovations contribute to the enhanced accuracy. Our code and datasets are publicly available at https://github.com/structlearning/isonetpp.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93261",
      "pdf_url": "https://openreview.net/pdf?id=udTwwF7tks",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Vaibhav_Raj1",
        "name": "Vaibhav Raj",
        "name_site": null,
        "openreview_id": "~Vaibhav_Raj1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "vaibhav-raj-8446421b9/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.75,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "0ZZMUjZJYF",
      "title": "Can LLMs Learn by Teaching for Better Reasoning? A Preliminary Study",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Teaching to improve student models (e.g., knowledge distillation) is an extensively studied methodology in LLMs. However, in human education, teaching enhances not only the students but also the teachers by fostering more rigorous and clearer reasoning, as well as deeper knowledge building. We ask: Can LLMs also learn by teaching (LbT) for better reasoning? If the answer is yes, we can potentially unlock the possibility of continuously advancing the models without solely relying on human-produced data or stronger models. In this paper, we provide a preliminary exploration of this question. We show that LbT ideas can be incorporated into existing LLM training/prompting pipelines and bring improvements. Specifically, we design three methods, each mimicking one of the three levels of LbT: observing students' feedback, learning from the feedback, and learning iteratively, with the goal of improving answer accuracy without training or improving models' inherent capability with fine-tuning. We reveal some findings: (1) Teaching materials that make it easier for students to learn (via in-context learning) have clearer and more accurate logic; (2) Weak-to-strong generalization: LbT might help improve strong models by teaching weak models; (3) Diversity in students might help: teaching multiple students could be better than teaching a single student or the teacher alone. We hope that our exploration can inspire future research on LbT and, more broadly, the adoption of advanced education techniques to improve LLMs. The code and website are at https://github.com/imagination-research/lbt and https://sites.google.com/view/llm-learning-by-teaching.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/96924",
      "pdf_url": "https://openreview.net/pdf?id=0ZZMUjZJYF",
      "github_url": "",
      "total_authors": 10,
      "track_name": "Main Conference",
      "author": {
        "id": "~Zinan_Lin1",
        "name": "Zinan Lin",
        "name_site": "Zinan Lin, Vyas Sekar, Giulia Fanti",
        "openreview_id": "~Zinan_Lin1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://zinanlin.me/",
        "dblp_id": "64/237-1",
        "google_scholar_url": "67nE-wQ_g_cC",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (China)",
        "countries": [
          "China"
        ],
        "country_codes": [
          "CN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "3qH8q02x0n",
      "title": "IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent advancements in text-to-speech (TTS) synthesis show that large-scale models trained with extensive web data produce highly natural-sounding output. However, such data is scarce for Indian languages due to the lack of high-quality, manually subtitled data on platforms like LibriVox or YouTube. To address this gap, we enhance existing large-scale ASR datasets containing natural conversations collected in low-quality environments to generate high-quality TTS training data. Our pipeline leverages the cross-lingual generalization of denoising and speech enhancement models trained on English and applied to Indian languages. This results in IndicVoices-R (IV-R), the largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704 hours of high-quality speech from 10,496 speakers across 22 Indian languages. IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS, and IndicTTS. We also introduce the IV-R Benchmark, the first to assess zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS models on Indian voices, ensuring diversity in age, gender, and style. We demonstrate that fine-tuning an English pre-trained model on a combined dataset of high-quality IndicTTS and our IV-R dataset results in better zero-shot speaker generalization compared to fine-tuning on the IndicTTS dataset alone. Further, our evaluation reveals limited zero-shot generalization for Indian voices in TTS models trained on prior datasets, which we improve by fine-tuning the model on our data containing diverse set of speakers across language families. We open-source code and data for all 22 official Indian languages.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97858",
      "pdf_url": "https://openreview.net/pdf?id=3qH8q02x0n",
      "github_url": "",
      "total_authors": 10,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Sherry_Thomas1",
        "name": "Sherry Thomas",
        "name_site": null,
        "openreview_id": "~Sherry_Thomas1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://sherrys997.github.io",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "fzlMza6dRZ",
      "title": "GraphTrail: Translating GNN Predictions into Human-Interpretable Logical Rules",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Instance-level explanation of graph neural networks (GNNs) is a well-studied area. These explainers, however, only explain an instance (e.g., a graph) and fail to uncover the combinatorial reasoning learned by a GNN from the training data towards making its predictions. In this work, we introduce GraphTrail, the first end-to-end, global, post-hoc GNN explainer that translates the functioning of a black-box GNN model to a boolean formula over the (sub)graph level concepts without relying on local explainers. GraphTrail is unique in automatically mining the discriminative subgraph-level concepts using Shapley values. Subsequently, the GNN predictions are mapped to a human-interpretable boolean formula over these concepts through symbolic regression. Extensive experiments across diverse datasets and GNN architectures demonstrate significant improvement over existing global explainers in mapping GNN predictions to faithful logical formulae. The robust and accurate performance of GraphTrail makes it invaluable for improving GNNs and facilitates adoption in domains with strict transparency requirements.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/94172",
      "pdf_url": "https://openreview.net/pdf?id=fzlMza6dRZ",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Manthan_Dalmia1",
        "name": "Manthan Dalmia",
        "name_site": null,
        "openreview_id": "~Manthan_Dalmia1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "manthan-dalmia-b6a6b520b",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "tZRpvLXevU",
      "title": "Latent Representation Matters: Human-like Sketches in One-shot Drawing Tasks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Humans can effortlessly draw new categories from a single exemplar, a feat that has long posed a challenge for generative models. However, this gap has started to close with recent advances in diffusion models. This one-shot drawing task requires powerful inductive biases that have not been systematically investigated. Here, we study how different inductive biases shape the latent space of Latent Diffusion Models (LDMs). Along with standard LDM regularizers (KL and vector quantization), we explore supervised regularizations (including classification and prototype-based representation) and contrastive inductive biases (using  SimCLR and redundancy reduction objectives). We demonstrate that LDMs with redundancy reduction and prototype-based regularizations produce near-human-like drawings (regarding both samples' recognizability and originality) -- better mimicking human perception (as evaluated psychophysically). Overall, our results suggest that the gap between humans and machines in one-shot drawings is almost closed.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93325",
      "pdf_url": "https://openreview.net/pdf?id=tZRpvLXevU",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aditya_Agrawal3",
        "name": "Aditya Agrawal",
        "name_site": null,
        "openreview_id": "~Aditya_Agrawal3",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://aditya-agrawal-30502.netlify.app/",
        "dblp_id": null,
        "google_scholar_url": "5OP8PEEAAAAJ",
        "orcid": null,
        "linkedin_url": "aditya-agrawal-9aba24208/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 4.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "xUoNgR1Byy",
      "title": "Interpreting Learned Feedback Patterns in Large Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Reinforcement learning from human feedback (RLHF) is widely used to train large language models (LLMs). However, it is unclear whether LLMs accurately learn the underlying preferences in human feedback data. We coin the term **Learned Feedback Pattern** (LFP) for patterns in an LLM's activations learned during RLHF that improve its performance on the fine-tuning task. We hypothesize that LLMs with LFPs accurately aligned to the fine-tuning feedback exhibit consistent activation patterns for outputs that would have received similar feedback during RLHF. To test this, we train probes to estimate the feedback signal implicit in the activations of a fine-tuned LLM. We then compare these estimates to the true feedback, measuring how accurate the LFPs are to the fine-tuning feedback. Our probes are trained on a condensed, sparse and interpretable representation of LLM activations, making it easier to correlate features of the input with our probe's predictions. We validate our probes by comparing the neural features they correlate with positive feedback inputs against the features GPT-4 describes and classifies as related to LFPs. Understanding LFPs can help minimize discrepancies between LLM behavior and training objectives, which is essential for the **safety** and **alignment** of LLMs.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93081",
      "pdf_url": "https://openreview.net/pdf?id=xUoNgR1Byy",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Clement_Neo1",
        "name": "Clement Neo",
        "name_site": null,
        "openreview_id": "~Clement_Neo1",
        "position": 3,
        "gender": null,
        "homepage_url": "https://clementneo.com",
        "dblp_id": "367/9292",
        "google_scholar_url": "Y2-g_2cAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Nanyang Technological University (Singapore)",
        "countries": [
          "Singapore"
        ],
        "country_codes": [
          "SG"
        ]
      },
      "sort_score": 3.333333333333334,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.0,
        "confidence_std": 1.224744871391589,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "SdLOs1FR4h",
      "title": "FUGAL: Feature-fortified Unrestricted Graph Alignment",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The necessity to align two graphs, minimizing a structural distance metric, is prevalent in biology, chemistry, recommender systems, and social network analysis. Due to the problem’s NP-hardness, prevailing graph alignment methods follow a modular and mediated approach, solving the problem by restricting to the domain of intermediary graph representations or products like embeddings, spectra, and graph signals. Restricting the problem to this intermediate space may distort the original problem and are hence predisposed to miss high-quality solutions. In this paper, we propose an unrestricted method, FUGAL, which finds a permutation matrix that maps one graph to another by directly operating on their adjacency matrices with judicious constraint relaxation. Extensive experimentation demonstrates that FUGAL consistently surpasses state-of-the-art graph alignment methods in accuracy across all benchmark datasets without encumbering efficiency.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95090",
      "pdf_url": "https://openreview.net/pdf?id=SdLOs1FR4h",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Konstantinos_Skitsas1",
        "name": "Konstantinos Skitsas",
        "name_site": null,
        "openreview_id": "~Konstantinos_Skitsas1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.linkedin.com/in/constantinos-skitsas/",
        "dblp_id": "228/8067",
        "google_scholar_url": "E8JeOjMAAAAJ",
        "orcid": "0000-0001-5078-6468",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Aarhus University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 1.6583123951777,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "TZ5k9IYBBf",
      "title": "RanDumb: Random Representations Outperform Online Continually Learned Representations",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Continual learning has primarily focused on the issue of catastrophic forgetting and the associated stability-plasticity tradeoffs. However, little attention has been paid to the efficacy of continually learned representations, as representations are learned alongside classifiers throughout the learning process. Our primary contribution is empirically demonstrating that existing online continually trained deep networks produce inferior representations compared to a simple pre-defined random transforms. Our approach embeds raw pixels using a fixed random transform, approximating an RBF-Kernel initialized before any data is seen. We then train a simple linear classifier on top without storing any exemplars, processing one sample at a time in an online continual learning setting. This method, called RanDumb,  significantly outperforms state-of-the-art continually learned representations across all standard online continual learning benchmarks. Our study reveals the significant limitations of representation learning, particularly in low-exemplar and online continual learning scenarios. Extending our investigation to popular exemplar-free scenarios with pretrained models, we find that training only a linear classifier on top of pretrained representations surpasses most continual fine-tuning and prompt-tuning strategies. Overall, our investigation challenges the prevailing assumptions about effective representation learning in the online continual learning.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95027",
      "pdf_url": "https://openreview.net/pdf?id=TZ5k9IYBBf",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ponnurangam_Kumaraguru3",
        "name": "Ponnurangam Kumaraguru",
        "name_site": null,
        "openreview_id": "~Ponnurangam_Kumaraguru3",
        "position": 3,
        "gender": null,
        "homepage_url": "https://precog.iiit.ac.in/",
        "dblp_id": "97/5147.html",
        "google_scholar_url": "MfzQyP8AAAAJ",
        "orcid": null,
        "linkedin_url": "ponguru/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 3.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "3qH8q02x0n",
      "title": "IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent advancements in text-to-speech (TTS) synthesis show that large-scale models trained with extensive web data produce highly natural-sounding output. However, such data is scarce for Indian languages due to the lack of high-quality, manually subtitled data on platforms like LibriVox or YouTube. To address this gap, we enhance existing large-scale ASR datasets containing natural conversations collected in low-quality environments to generate high-quality TTS training data. Our pipeline leverages the cross-lingual generalization of denoising and speech enhancement models trained on English and applied to Indian languages. This results in IndicVoices-R (IV-R), the largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704 hours of high-quality speech from 10,496 speakers across 22 Indian languages. IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS, and IndicTTS. We also introduce the IV-R Benchmark, the first to assess zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS models on Indian voices, ensuring diversity in age, gender, and style. We demonstrate that fine-tuning an English pre-trained model on a combined dataset of high-quality IndicTTS and our IV-R dataset results in better zero-shot speaker generalization compared to fine-tuning on the IndicTTS dataset alone. Further, our evaluation reveals limited zero-shot generalization for Indian voices in TTS models trained on prior datasets, which we improve by fine-tuning the model on our data containing diverse set of speakers across language families. We open-source code and data for all 22 official Indian languages.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97858",
      "pdf_url": "https://openreview.net/pdf?id=3qH8q02x0n",
      "github_url": "",
      "total_authors": 10,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Mehak_Singal1",
        "name": "Mehak Singal",
        "name_site": null,
        "openreview_id": "~Mehak_Singal1",
        "position": 5,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "mehaksingal/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.7777777777777777,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "MtRvzJBsBA",
      "title": "LRM-Zero: Training Large Reconstruction Models with Synthesized Data",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We present LRM-Zero, a Large Reconstruction Model (LRM) trained entirely on synthesized 3D data, achieving high-quality sparse-view 3D reconstruction. The core of LRM-Zero is our procedural 3D dataset, Zeroverse, which is automatically synthesized from simple primitive shapes with random texturing and augmentations (e.g., height fields, boolean differences, and wireframes). Unlike previous 3D datasets (e.g., Objaverse) which are often captured or crafted by humans to approximate real 3D data, Zeroverse completely ignores realistic global semantics but is rich in complex geometric and texture details that are locally similar to or even more intricate than real objects. We demonstrate that our LRM-Zero, trained with our fully synthesized Zeroverse, can achieve high visual quality in the reconstruction of real-world objects, competitive with models trained on Objaverse. We also analyze several critical design choices of Zeroverse that contribute to LRM-Zero's capability and training stability. Our work demonstrates that 3D reconstruction, one of the core tasks in 3D vision, can potentially be addressed without the semantics of real-world objects. The Zeroverse's procedural synthesis code and interactive visualization are available at: https://desaixie.github.io/lrm-zero/.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95485",
      "pdf_url": "https://openreview.net/pdf?id=MtRvzJBsBA",
      "github_url": "",
      "total_authors": 10,
      "track_name": "Main Conference",
      "author": {
        "id": "~Zexiang_Xu1",
        "name": "Zexiang Xu",
        "name_site": null,
        "openreview_id": "~Zexiang_Xu1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://cseweb.ucsd.edu/~zex014/",
        "dblp_id": "154/0366",
        "google_scholar_url": "_RRIYvEAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Adobe (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 2.7777777777777777,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.7071067811865476,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 10,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "FTPDBQuT4G",
      "title": "Generalized Linear Bandits with Limited Adaptivity",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "We study the generalized linear contextual bandit problem within the constraints of limited adaptivity.  In this paper, we present two algorithms, B-GLinCB and RS-GLinCB, that address, respectively, two prevalent limited adaptivity settings. Given a budget $M$ on the number of policy updates, in the first setting, the algorithm needs to decide upfront $M$ rounds at which it will update its policy, while in the second setting it can adaptively perform $M$ policy updates during its course. For the first setting, we design an algorithm B-GLinCB, that incurs $\\tilde{O}(\\sqrt{T})$ regret when $M = \\Omega( \\log{\\log T} )$ and the arm feature vectors are generated stochastically. For the second setting, we design an algorithm RS-GLinCB that updates its policy $\\tilde{O}(\\log^2 T)$ times and achieves a regret of $\\tilde{O}(\\sqrt{T})$ even when the arm feature vectors are adversarially generated. Notably, in these bounds, we manage to eliminate the dependence on a key instance dependent parameter $\\kappa$, that captures non-linearity of the underlying reward model. Our novel approach for removing this dependence for generalized linear contextual bandits might be of independent interest.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95973",
      "pdf_url": "https://openreview.net/pdf?id=FTPDBQuT4G",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Siddharth_Barman1",
        "name": "Siddharth Barman",
        "name_site": null,
        "openreview_id": "~Siddharth_Barman1",
        "position": 3,
        "gender": "M",
        "homepage_url": "http://www.csa.iisc.ac.in/~barman/",
        "dblp_id": "63/478.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=HcGQSKIAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 2.5000000000000004,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 1.247219128924647,
        "confidence_mean": 3.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "3lQgEPRxeu",
      "title": "Learning General Parameterized Policies for Infinite Horizon Average Reward Constrained MDPs via Primal-Dual Policy Gradient Algorithm",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "This paper explores the realm of infinite horizon average reward Constrained Markov Decision Processes (CMDPs). To the best of our knowledge, this work is the first to delve into the regret and constraint violation analysis of average reward CMDPs with a general policy parametrization. To address this challenge, we propose a primal dual-based policy gradient algorithm that adeptly manages the constraints while ensuring a low regret guarantee toward achieving a global optimal policy. In particular, our proposed algorithm achieves $\\tilde{\\mathcal{O}}({T}^{4/5})$ objective regret and $\\tilde{\\mathcal{O}}({T}^{4/5})$ constraint violation bounds.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/96718",
      "pdf_url": "https://openreview.net/pdf?id=3lQgEPRxeu",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Washim_Uddin_Mondal1",
        "name": "Washim Uddin Mondal",
        "name_site": "Washim Mondal, Vaneet Aggarwal",
        "openreview_id": "~Washim_Uddin_Mondal1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://home.iitk.ac.in/~wmondal/",
        "dblp_id": "201/9517.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=CQwhdyIAAAAJ",
        "orcid": "0000-0002-2385-6034",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.2,
        "rating_std": 0.7483314773547882,
        "confidence_mean": 2.8,
        "confidence_std": 0.7483314773547882,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "7Mo1NOosNT",
      "title": "COLD: Causal reasOning in cLosed Daily activities",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Large Language Models (LLMs) have shown state-of-the-art performance in a variety of tasks, including arithmetic and reasoning; however, to gauge the intellectual capabilities of LLMs, causal reasoning has become a reliable proxy for validating a general understanding of the mechanics and intricacies of the world similar to humans. Previous works in natural language processing (NLP) have either focused on open-ended causal reasoning via causal commonsense reasoning (CCR) or framed a symbolic representation-based question answering for theoretically backed-up analysis via a causal inference engine. The former adds an advantage of real-world grounding but lacks theoretically backed-up analysis/validation, whereas the latter is far from real-world grounding. In this work, we bridge this gap by proposing the COLD (Causal reasOning in cLosed Daily activities) framework, which is built upon human understanding of daily real-world activities to reason about the causal nature of events. We show that the proposed framework facilitates the creation of enormous causal queries (∼ 9 million) and comes close to the mini-turing test, simulating causal reasoning to evaluate the understanding of a daily real-world task. We evaluate multiple LLMs on the created causal queries and find that causal reasoning is challenging even for activities trivial to humans. We further explore (the causal reasoning abilities of LLMs) using the backdoor criterion to determine the causal strength between events.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/96459",
      "pdf_url": "https://openreview.net/pdf?id=7Mo1NOosNT",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Areeb_Ahmad2",
        "name": "Areeb Ahmad",
        "name_site": null,
        "openreview_id": "~Ashutosh_Modi1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://ashutosh-modi.github.io/",
        "dblp_id": "139/0873",
        "google_scholar_url": "AWu6f60AAAAJ",
        "orcid": null,
        "linkedin_url": "dr-ashutosh-modi-3907835/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Kanpur (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.25,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "HwO1mNluoL",
      "title": "Mitigating Biases in Blackbox Feature Extractors for Image Classification Tasks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In image classification, it is common to utilize a pretrained model to extract meaningful features of the input images, and then to train a classifier on top of it to make predictions for any downstream task. Trained on enormous amounts of data, these models have been shown to contain harmful biases which can hurt their performance when adapted for a downstream classification task. Further, very often they may be blackbox, either due to scale, or because of unavailability of model weights or architecture. Thus, during a downstream task, we cannot debias such models by updating the weights of the feature encoder, as only the classifier can be finetuned. In this regard, we investigate the suitability of some existing debiasing techniques and thereby motivate the need for more focused research towards this problem setting. Furthermore, we propose a simple method consisting of a clustering-based adaptive margin loss with a blackbox feature encoder, with no knowledge of the bias attribute. Our experiments demonstrate the effectiveness of our method across multiple benchmarks.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95798",
      "pdf_url": "https://openreview.net/pdf?id=HwO1mNluoL",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Saswat_Subhajyoti_Mallick1",
        "name": "Saswat Subhajyoti Mallick",
        "name_site": null,
        "openreview_id": "~Saswat_Subhajyoti_Mallick1",
        "position": 2,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "YXQW4qQe2U",
      "title": "Optimal Top-Two Method for Best Arm Identification and Fluid Analysis",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Top-2 methods have become popular in solving the best arm identification (BAI) problem. The best arm, or the arm with the largest mean amongst finitely many, is identified through an algorithm that at any sequential step independently pulls the empirical best arm, with a fixed probability $\\beta$, and pulls the best challenger arm otherwise. The probability of incorrect selection is guaranteed to lie below a specified $\\delta>0$. Information theoretic lower bounds on sample complexity are well known for BAI problem and are matched asymptotically as $\\delta\\to 0$ by computationally demanding plug-in methods. The above top 2 algorithm for any $\\beta\\in(0, 1)$ has sample complexity within a constant of the lower bound. However, determining the optimal β that matches the lower bound has proven difficult. In this paper, we address this and propose an optimal top-2 type algorithm. We consider a function of allocations anchored at a threshold. If it exceeds the threshold then the algorithm samples the empirical best arm. Otherwise, it samples the challenger arm. We show that the proposed algorithm is optimal as $\\delta\\to 0$. Our analysis relies on identifying a limiting fluid dynamics of allocations that satisfy a series of ordinary differential equations pasted together and that describe the asymptotic path followed by our algorithm. We rely on the implicit function theorem to show existence and uniqueness of these fluid ode’s and to show that the proposed algorithm remains close to the ode solution.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/94693",
      "pdf_url": "https://openreview.net/pdf?id=YXQW4qQe2U",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sandeep_Kumar_Juneja1",
        "name": "Sandeep Kumar Juneja",
        "name_site": null,
        "openreview_id": "~Sandeep_Kumar_Juneja1",
        "position": 2,
        "gender": "M",
        "homepage_url": "http://www.tcs.tifr.res.in/~sandeepj/",
        "dblp_id": "98/5399.html",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=Tfgv6VgAAAAJ",
        "orcid": null,
        "linkedin_url": "sandeep-juneja-937b44b/?originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Tata Institute of Fundamental Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 5.8,
        "rating_std": 0.7483314773547882,
        "confidence_mean": 3.4,
        "confidence_std": 0.8,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "mSHs6C7Nfa",
      "title": "Improving the Training of Rectified Flows",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Diffusion models have shown great promise for image and video generation, but sampling from state-of-the-art models requires expensive numerical integration of a generative ODE.\n    One approach for tackling this problem is rectified flows, which iteratively learn smooth ODE paths that are less susceptible to truncation error.\n    However, rectified flows still require a relatively large number of function evaluations (NFEs).\n    In this work, we propose improved techniques for training rectified flows, allowing them to compete with knowledge distillation methods even in the low NFE setting.\n    Our main insight is that under realistic settings, a single iteration of the Reflow algorithm for training rectified flows is sufficient to learn nearly straight trajectories; hence, the current practice of using multiple Reflow iterations is unnecessary.\n    We thus propose techniques to improve one-round training of rectified flows, including a U-shaped timestep distribution and LPIPS-Huber premetric.\n    With these techniques, we improve the FID of the previous 2-rectified flow by up to 75\\% in the 1 NFE setting on CIFAR-10.\n    On ImageNet 64$\\times$64, our improved rectified flow outperforms the state-of-the-art distillation methods\n    such as consistency distillation and progressive distillation in both one-step and two-step settings and rivals the performance of improved consistency training (iCT) in FID.\n    Code is available at https://github.com/sangyun884/rfpp.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93758",
      "pdf_url": "https://openreview.net/pdf?id=mSHs6C7Nfa",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Zinan_Lin1",
        "name": "Zinan Lin",
        "name_site": "Zinan Lin, Vyas Sekar, Giulia Fanti",
        "openreview_id": "~Zinan_Lin1",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://zinanlin.me/",
        "dblp_id": "64/237-1",
        "google_scholar_url": "67nE-wQ_g_cC",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 2.179449471770337,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 16,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "nN6NSd1Qds",
      "title": "UGC: Universal Graph Coarsening",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "In the era of big data, graphs have emerged as a natural representation of intricate relationships. However, graph sizes often become unwieldy, leading to storage, computation, and analysis challenges. A crucial demand arises for methods that can effectively downsize large graphs while retaining vital insights. Graph coarsening seeks to simplify large graphs while maintaining the basic statistics of the graphs, such as spectral properties and $\\epsilon$-similarity in the coarsened graph. This ensures that downstream processes are more efficient and effective. Most published methods are suitable for homophilic datasets, limiting their universal use. We propose **U**niversal **G**raph **C**oarsening (UGC), a framework equally suitable for homophilic and heterophilic datasets. UGC integrates node attributes and adjacency information, leveraging the dataset's heterophily factor. Results on benchmark datasets demonstrate that UGC preserves spectral similarity while coarsening. In comparison to existing methods, UGC is 4x to 15x faster, has lower eigen-error, and yields superior performance on downstream processing tasks even at 70% coarsening ratios.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93695",
      "pdf_url": "https://openreview.net/pdf?id=nN6NSd1Qds",
      "github_url": "",
      "total_authors": 3,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sandeep_Kumar8",
        "name": "Sandeep Kumar",
        "name_site": null,
        "openreview_id": "~Sandeep_Kumar8",
        "position": 2,
        "gender": "M",
        "homepage_url": "https://sites.google.com/view/sandeepkr/home",
        "dblp_id": null,
        "google_scholar_url": "lycMMW8AAAAJ",
        "orcid": null,
        "linkedin_url": "sandeep-kumar-84463332/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.7071067811865476,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "u7JRmrGutT",
      "title": "Graph Edit Distance with General Costs Using Neural Set Divergence",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph Edit Distance (GED) measures the (dis-)similarity between two given graphs in terms of the minimum-cost edit sequence, which transforms one graph to the other.\nGED is related to other notions of graph similarity, such as graph and subgraph isomorphism, maximum common subgraph, etc. However, the computation of exact GED is NP-Hard, which has recently motivated the design of neural models for GED estimation.\nHowever, they do not explicitly account for edit operations with different costs. In response, we propose $\\texttt{GraphEdX}$, a neural GED estimator that can work with general costs specified for the four edit operations, viz., edge deletion, edge addition, node deletion, and node addition.\nWe first present GED as a quadratic assignment problem (QAP) that incorporates these four costs.\nThen, we represent each graph as a set of node and edge embeddings and use them to design a family of neural set divergence surrogates. We replace the QAP terms corresponding to each operation with their surrogates. \nComputing such neural set divergence requires aligning nodes and edges of the two graphs.\nWe learn these alignments using a Gumbel-Sinkhorn permutation generator, additionally ensuring that the node and edge alignments are consistent with each other. Moreover, these alignments are cognizant of both the presence and absence of edges between node pairs.\nThrough extensive experiments on several datasets, along with a variety of edit cost settings, we show that $\\texttt{GraphEdX}$ consistently outperforms state-of-the-art methods and heuristics in terms of prediction error. The code is available at https://github.com/structlearning/GraphEdX.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93292",
      "pdf_url": "https://openreview.net/pdf?id=u7JRmrGutT",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Saswat_Meher1",
        "name": "Saswat Meher",
        "name_site": null,
        "openreview_id": "~Saswat_Meher1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "udTwwF7tks",
      "title": "Iteratively Refined Early Interaction Alignment for Subgraph Matching based Graph Retrieval",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph retrieval based on subgraph isomorphism has several real-world applications such as scene graph retrieval, molecular fingerprint detection and circuit design. Roy et al. [35] proposed IsoNet, a late interaction model for subgraph matching, which first computes the node and edge embeddings of each graph independently of paired graph  and then computes a trainable alignment map. Here, we present $\\texttt{IsoNet++}$, an early interaction graph neural network (GNN), based on several technical innovations. First, we compute embeddings of all nodes by passing messages within and across the two input graphs, guided by an *injective alignment* between their nodes. Second, we update this alignment in a lazy fashion over multiple *rounds*. Within each round, we run a layerwise GNN from scratch, based on the current state of the alignment. After the completion of one round of GNN, we use the last-layer embeddings to update the alignments, and proceed to the next round. Third, $\\texttt{IsoNet++}$ incorporates a novel notion of node-pair partner interaction. Traditional early interaction computes attention between a node and its potential partners in the other graph, the attention then controlling messages passed across graphs. We consider *node pairs* (not single nodes) as potential partners. Existence of an edge between the nodes in one graph and non-existence in the other provide vital signals for refining the alignment. Our experiments on several datasets show that the alignments get progressively refined with successive rounds,\nresulting in significantly better retrieval performance than existing methods. We demonstrate that all three innovations contribute to the enhanced accuracy. Our code and datasets are publicly available at https://github.com/structlearning/isonetpp.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93261",
      "pdf_url": "https://openreview.net/pdf?id=udTwwF7tks",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Indradyumna_Roy1",
        "name": "Indradyumna Roy",
        "name_site": "Indradyumna Roy, Soumen Chakrabarti, Abir De",
        "openreview_id": "~Indradyumna_Roy1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://indradyumna.github.io/",
        "dblp_id": "124/9185.html",
        "google_scholar_url": "qb70i84AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "ybLXvqJyQA",
      "title": "Predicting Ground State Properties: Constant Sample Complexity and Deep Learning Algorithms",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "A fundamental problem in quantum many-body physics is that of finding ground states of local\nHamiltonians. A number of recent works gave provably efficient machine learning (ML) algorithms\nfor learning ground states. Specifically, [Huang et al. Science 2022], introduced an approach for learning\nproperties of the ground state of an $n$-qubit gapped local Hamiltonian $H$ from only $n^{\\mathcal{O}(1)}$ data\npoints sampled from Hamiltonians in the same phase of matter. This was subsequently improved\nby [Lewis et al. Nature Communications 2024], to $\\mathcal{O}(\\log 𝑛)$ samples when the geometry of the $n$-qubit system is known.\nIn this work, we introduce two approaches that achieve a constant sample complexity, independent\nof system size $n$, for learning ground state properties. Our first algorithm consists of a simple\nmodification of the ML model used by Lewis et al. and applies to a property of interest known beforehand. Our second algorithm, which applies even if a description of\nthe property is not known, is a deep neural network model. While empirical results showing the\nperformance of neural networks have been demonstrated, to our knowledge, this is the first rigorous\nsample complexity bound on a neural network model for predicting ground state properties. We also perform numerical experiments that confirm the improved scaling of our approach compared to earlier results.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93006",
      "pdf_url": "https://openreview.net/pdf?id=ybLXvqJyQA",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Chiranjib_Bhattacharyya1",
        "name": "Chiranjib Bhattacharyya",
        "name_site": null,
        "openreview_id": "~Chiranjib_Bhattacharyya1",
        "position": 3,
        "gender": "M",
        "homepage_url": "http://www.csa.iisc.ac.in/~chiru/",
        "dblp_id": "b/CBhattacharyya",
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.5,
      "reviews": {
        "rating_mean": 5.333333333333333,
        "rating_std": 1.3743685418725535,
        "confidence_mean": 2.5,
        "confidence_std": 0.9574271077563381,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 4,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "3qH8q02x0n",
      "title": "IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent advancements in text-to-speech (TTS) synthesis show that large-scale models trained with extensive web data produce highly natural-sounding output. However, such data is scarce for Indian languages due to the lack of high-quality, manually subtitled data on platforms like LibriVox or YouTube. To address this gap, we enhance existing large-scale ASR datasets containing natural conversations collected in low-quality environments to generate high-quality TTS training data. Our pipeline leverages the cross-lingual generalization of denoising and speech enhancement models trained on English and applied to Indian languages. This results in IndicVoices-R (IV-R), the largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704 hours of high-quality speech from 10,496 speakers across 22 Indian languages. IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS, and IndicTTS. We also introduce the IV-R Benchmark, the first to assess zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS models on Indian voices, ensuring diversity in age, gender, and style. We demonstrate that fine-tuning an English pre-trained model on a combined dataset of high-quality IndicTTS and our IV-R dataset results in better zero-shot speaker generalization compared to fine-tuning on the IndicTTS dataset alone. Further, our evaluation reveals limited zero-shot generalization for Indian voices in TTS models trained on prior datasets, which we improve by fine-tuning the model on our data containing diverse set of speakers across language families. We open-source code and data for all 22 official Indian languages.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97858",
      "pdf_url": "https://openreview.net/pdf?id=3qH8q02x0n",
      "github_url": "",
      "total_authors": 10,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Shridhar_Kumar1",
        "name": "Shridhar Kumar",
        "name_site": null,
        "openreview_id": "~Shridhar_Kumar1",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://www.linkedin.com/in/shridhar-kumar",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.2222222222222223,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "Io1qKqCVIK",
      "title": "DMesh: A Differentiable Mesh Representation",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "We present a differentiable representation, DMesh, for general 3D triangular meshes. DMesh considers both the geometry and connectivity information of a mesh. In our design, we first get a set of convex tetrahedra that compactly tessellates the domain based on Weighted Delaunay Triangulation (WDT), and select triangular faces on the tetrahedra to define the final mesh. We formulate probability of faces to exist on the actual surface in a differentiable manner based on the WDT. This enables DMesh to represent meshes of various topology in a differentiable way, and allows us to reconstruct the mesh under various observations, such as point clouds and multi-view images using gradient-based optimization. We publicize the source code and supplementary material at our project page (https://sonsang.github.io/dmesh-project).",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95753",
      "pdf_url": "https://openreview.net/pdf?id=Io1qKqCVIK",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Zexiang_Xu1",
        "name": "Zexiang Xu",
        "name_site": null,
        "openreview_id": "~Zexiang_Xu1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://cseweb.ucsd.edu/~zex014/",
        "dblp_id": "154/0366",
        "google_scholar_url": "_RRIYvEAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Adobe (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 2.0,
      "reviews": {
        "rating_mean": 6.6,
        "rating_std": 0.8,
        "confidence_mean": 3.4,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "SdLOs1FR4h",
      "title": "FUGAL: Feature-fortified Unrestricted Graph Alignment",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The necessity to align two graphs, minimizing a structural distance metric, is prevalent in biology, chemistry, recommender systems, and social network analysis. Due to the problem’s NP-hardness, prevailing graph alignment methods follow a modular and mediated approach, solving the problem by restricting to the domain of intermediary graph representations or products like embeddings, spectra, and graph signals. Restricting the problem to this intermediate space may distort the original problem and are hence predisposed to miss high-quality solutions. In this paper, we propose an unrestricted method, FUGAL, which finds a permutation matrix that maps one graph to another by directly operating on their adjacency matrices with judicious constraint relaxation. Extensive experimentation demonstrates that FUGAL consistently surpasses state-of-the-art graph alignment methods in accuracy across all benchmark datasets without encumbering efficiency.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95090",
      "pdf_url": "https://openreview.net/pdf?id=SdLOs1FR4h",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sayan_Ranu2",
        "name": "Sayan Ranu",
        "name_site": null,
        "openreview_id": "~Sayan_Ranu2",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://www.cse.iitd.ac.in/~sayan/index.html",
        "dblp_id": "38/768",
        "google_scholar_url": "K4w5qYUAAAAJ",
        "orcid": "0000-0003-4147-9372",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Delhi (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 2.0,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 1.6583123951777,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "3qH8q02x0n",
      "title": "IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent advancements in text-to-speech (TTS) synthesis show that large-scale models trained with extensive web data produce highly natural-sounding output. However, such data is scarce for Indian languages due to the lack of high-quality, manually subtitled data on platforms like LibriVox or YouTube. To address this gap, we enhance existing large-scale ASR datasets containing natural conversations collected in low-quality environments to generate high-quality TTS training data. Our pipeline leverages the cross-lingual generalization of denoising and speech enhancement models trained on English and applied to Indian languages. This results in IndicVoices-R (IV-R), the largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704 hours of high-quality speech from 10,496 speakers across 22 Indian languages. IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS, and IndicTTS. We also introduce the IV-R Benchmark, the first to assess zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS models on Indian voices, ensuring diversity in age, gender, and style. We demonstrate that fine-tuning an English pre-trained model on a combined dataset of high-quality IndicTTS and our IV-R dataset results in better zero-shot speaker generalization compared to fine-tuning on the IndicTTS dataset alone. Further, our evaluation reveals limited zero-shot generalization for Indian voices in TTS models trained on prior datasets, which we improve by fine-tuning the model on our data containing diverse set of speakers across language families. We open-source code and data for all 22 official Indian languages.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97858",
      "pdf_url": "https://openreview.net/pdf?id=3qH8q02x0n",
      "github_url": "",
      "total_authors": 10,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Deovrat_Mehendale1",
        "name": "Deovrat Mehendale",
        "name_site": null,
        "openreview_id": "~Deovrat_Mehendale1",
        "position": 7,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "deovrat-mehendale-40046b163?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "EQHQzRJy75",
      "title": "STONE: A Submodular Optimization Framework for Active 3D Object Detection",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "3D object detection is fundamentally important for various emerging applications, including autonomous driving and robotics. A key requirement for training an accurate 3D object detector is the availability of a large amount of LiDAR-based point cloud data. Unfortunately, labeling point cloud data is extremely challenging, as accurate 3D bounding boxes and semantic labels are required for each potential object. This paper proposes a unified active 3D object detection framework, for greatly reducing the labeling cost of training 3D object detectors. Our framework is based on a novel formulation of submodular optimization, specifically tailored to the problem of active 3D object detection. In particular, we address two fundamental challenges associated with active 3D object detection: data imbalance and the need to cover the distribution of the data, including LiDAR-based point cloud data of varying difficulty levels. Extensive experiments demonstrate that our method achieves state-of-the-art performance with high computational efficiency compared to existing active learning methods. The code is available at [https://github.com/RuiyuM/STONE](https://github.com/RuiyuM/STONE)",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/96033",
      "pdf_url": "https://openreview.net/pdf?id=EQHQzRJy75",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rishabh_K_Iyer2",
        "name": "Rishabh K Iyer",
        "name_site": null,
        "openreview_id": "~Rishabh_K_Iyer2",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.rishiyer.com",
        "dblp_id": "37/10544.html",
        "google_scholar_url": "l_XxJ1kAAAAJ",
        "orcid": null,
        "linkedin_url": "rishabh-iyer-36893717/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.0,
        "confidence_mean": 3.4,
        "confidence_std": 0.4898979485566356,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "fzlMza6dRZ",
      "title": "GraphTrail: Translating GNN Predictions into Human-Interpretable Logical Rules",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Instance-level explanation of graph neural networks (GNNs) is a well-studied area. These explainers, however, only explain an instance (e.g., a graph) and fail to uncover the combinatorial reasoning learned by a GNN from the training data towards making its predictions. In this work, we introduce GraphTrail, the first end-to-end, global, post-hoc GNN explainer that translates the functioning of a black-box GNN model to a boolean formula over the (sub)graph level concepts without relying on local explainers. GraphTrail is unique in automatically mining the discriminative subgraph-level concepts using Shapley values. Subsequently, the GNN predictions are mapped to a human-interpretable boolean formula over these concepts through symbolic regression. Extensive experiments across diverse datasets and GNN architectures demonstrate significant improvement over existing global explainers in mapping GNN predictions to faithful logical formulae. The robust and accurate performance of GraphTrail makes it invaluable for improving GNNs and facilitates adoption in domains with strict transparency requirements.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/94172",
      "pdf_url": "https://openreview.net/pdf?id=fzlMza6dRZ",
      "github_url": "",
      "total_authors": 4,
      "track_name": "Main Conference",
      "author": {
        "id": "~Sourav_Medya1",
        "name": "Sourav Medya",
        "name_site": null,
        "openreview_id": "~Sourav_Medya1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://souravmedya.github.io/",
        "dblp_id": "178/3021",
        "google_scholar_url": "RCFhOM4AAAAJ",
        "orcid": "0000-0003-0996-2807",
        "linkedin_url": "sourav-medya-35987a49/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Illinois at Chicago (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.0897247358851685,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "tZRpvLXevU",
      "title": "Latent Representation Matters: Human-like Sketches in One-shot Drawing Tasks",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Humans can effortlessly draw new categories from a single exemplar, a feat that has long posed a challenge for generative models. However, this gap has started to close with recent advances in diffusion models. This one-shot drawing task requires powerful inductive biases that have not been systematically investigated. Here, we study how different inductive biases shape the latent space of Latent Diffusion Models (LDMs). Along with standard LDM regularizers (KL and vector quantization), we explore supervised regularizations (including classification and prototype-based representation) and contrastive inductive biases (using  SimCLR and redundancy reduction objectives). We demonstrate that LDMs with redundancy reduction and prototype-based regularizations produce near-human-like drawings (regarding both samples' recognizability and originality) -- better mimicking human perception (as evaluated psychophysically). Overall, our results suggest that the gap between humans and machines in one-shot drawings is almost closed.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93325",
      "pdf_url": "https://openreview.net/pdf?id=tZRpvLXevU",
      "github_url": "",
      "total_authors": 7,
      "track_name": "Main Conference",
      "author": {
        "id": "~Thomas_FEL1",
        "name": "Thomas FEL",
        "name_site": "Thomas FEL, Remi Cadene, Mathieu Chalvidal, Matthieu Cord, David Vigouroux, Thomas Serre",
        "openreview_id": "~Thomas_FEL1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://thomasfel.me",
        "dblp_id": "274/2390",
        "google_scholar_url": "1m5Mlx4AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Université de Toulouse (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.666666666666667,
      "reviews": {
        "rating_mean": 4.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.5,
        "confidence_std": 1.118033988749895,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "M2UzLRoqic",
      "title": "Reducing Transformer Key-Value Cache Size with Cross-Layer Attention",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Key-value (KV) caching plays an essential role in accelerating decoding for transformer-based autoregressive large language models (LLMs). However, the amount of memory required to store the KV cache can become prohibitive at long sequence lengths and large batch sizes. Since the invention of the transformer, two of the most effective interventions discovered for reducing the size of the KV cache have been Multi-Query Attention (MQA) and its generalization, Grouped-Query Attention (GQA). MQA and GQA both modify the design of the attention block so that multiple query heads can share a single key/value head, reducing the number of distinct key/value heads by a large factor while only minimally degrading accuracy. In this paper, we show that it is possible to take Multi-Query Attention a step further by also sharing key and value heads between adjacent layers, yielding a new attention design we call Cross-Layer Attention (CLA). With CLA, we find that it is possible to reduce the size of the KV cache by another $2\\times$ while maintaining nearly the same accuracy as unmodified MQA. In experiments training 1B- and 3B-parameter models from scratch, we demonstrate that CLA provides a Pareto improvement over the memory/accuracy tradeoffs which are possible with traditional MQA, potentially enabling future models to operate at longer sequence lengths and larger batch sizes than would otherwise be possible.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95548",
      "pdf_url": "https://openreview.net/pdf?id=M2UzLRoqic",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Rameswar_Panda1",
        "name": "Rameswar Panda",
        "name_site": null,
        "openreview_id": "~Rameswar_Panda1",
        "position": 4,
        "gender": "M",
        "homepage_url": "https://rpand002.github.io/",
        "dblp_id": "126/0986",
        "google_scholar_url": "_ySuu6gAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Massachusetts Institute of Technology (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 1.25,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 0.816496580927726,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 40,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "u7JRmrGutT",
      "title": "Graph Edit Distance with General Costs Using Neural Set Divergence",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph Edit Distance (GED) measures the (dis-)similarity between two given graphs in terms of the minimum-cost edit sequence, which transforms one graph to the other.\nGED is related to other notions of graph similarity, such as graph and subgraph isomorphism, maximum common subgraph, etc. However, the computation of exact GED is NP-Hard, which has recently motivated the design of neural models for GED estimation.\nHowever, they do not explicitly account for edit operations with different costs. In response, we propose $\\texttt{GraphEdX}$, a neural GED estimator that can work with general costs specified for the four edit operations, viz., edge deletion, edge addition, node deletion, and node addition.\nWe first present GED as a quadratic assignment problem (QAP) that incorporates these four costs.\nThen, we represent each graph as a set of node and edge embeddings and use them to design a family of neural set divergence surrogates. We replace the QAP terms corresponding to each operation with their surrogates. \nComputing such neural set divergence requires aligning nodes and edges of the two graphs.\nWe learn these alignments using a Gumbel-Sinkhorn permutation generator, additionally ensuring that the node and edge alignments are consistent with each other. Moreover, these alignments are cognizant of both the presence and absence of edges between node pairs.\nThrough extensive experiments on several datasets, along with a variety of edit cost settings, we show that $\\texttt{GraphEdX}$ consistently outperforms state-of-the-art methods and heuristics in terms of prediction error. The code is available at https://github.com/structlearning/GraphEdX.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93292",
      "pdf_url": "https://openreview.net/pdf?id=u7JRmrGutT",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Soumen_Chakrabarti1",
        "name": "Soumen Chakrabarti",
        "name_site": null,
        "openreview_id": "~Soumen_Chakrabarti1",
        "position": 4,
        "gender": "Not Specified",
        "homepage_url": "https://www.cse.iitb.ac.in/~soumen/",
        "dblp_id": "c/SChakrabarti",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=LfF2zfQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.25,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "udTwwF7tks",
      "title": "Iteratively Refined Early Interaction Alignment for Subgraph Matching based Graph Retrieval",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Graph retrieval based on subgraph isomorphism has several real-world applications such as scene graph retrieval, molecular fingerprint detection and circuit design. Roy et al. [35] proposed IsoNet, a late interaction model for subgraph matching, which first computes the node and edge embeddings of each graph independently of paired graph  and then computes a trainable alignment map. Here, we present $\\texttt{IsoNet++}$, an early interaction graph neural network (GNN), based on several technical innovations. First, we compute embeddings of all nodes by passing messages within and across the two input graphs, guided by an *injective alignment* between their nodes. Second, we update this alignment in a lazy fashion over multiple *rounds*. Within each round, we run a layerwise GNN from scratch, based on the current state of the alignment. After the completion of one round of GNN, we use the last-layer embeddings to update the alignments, and proceed to the next round. Third, $\\texttt{IsoNet++}$ incorporates a novel notion of node-pair partner interaction. Traditional early interaction computes attention between a node and its potential partners in the other graph, the attention then controlling messages passed across graphs. We consider *node pairs* (not single nodes) as potential partners. Existence of an edge between the nodes in one graph and non-existence in the other provide vital signals for refining the alignment. Our experiments on several datasets show that the alignments get progressively refined with successive rounds,\nresulting in significantly better retrieval performance than existing methods. We demonstrate that all three innovations contribute to the enhanced accuracy. Our code and datasets are publicly available at https://github.com/structlearning/isonetpp.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/93261",
      "pdf_url": "https://openreview.net/pdf?id=udTwwF7tks",
      "github_url": "",
      "total_authors": 5,
      "track_name": "Main Conference",
      "author": {
        "id": "~Soumen_Chakrabarti1",
        "name": "Soumen Chakrabarti",
        "name_site": null,
        "openreview_id": "~Soumen_Chakrabarti1",
        "position": 4,
        "gender": "Not Specified",
        "homepage_url": "https://www.cse.iitb.ac.in/~soumen/",
        "dblp_id": "c/SChakrabarti",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=LfF2zfQAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.25,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 0.4330127018922193,
        "confidence_mean": 3.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "zV2GDsZb5a",
      "title": "Neural Gaffer: Relighting Any Object via Diffusion",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Single-image relighting is a challenging task that involves reasoning about the complex interplay between geometry, materials, and lighting. Many prior methods either support only specific categories of images, such as portraits, or require special capture conditions, like using a flashlight. Alternatively, some methods explicitly decompose a scene into intrinsic components, such as normals and BRDFs, which can be inaccurate or under-expressive. In this work, we propose a novel end-to-end 2D relighting diffusion model, called Neural Gaffer, that takes a single image of any object and can synthesize an accurate, high-quality relit image under any novel environmental lighting condition, simply by conditioning an image generator on a target environment map, without an explicit scene decomposition. Our method builds on a pre-trained diffusion model, and fine-tunes it on a synthetic relighting dataset, revealing and harnessing the inherent understanding of lighting present in the diffusion model. We evaluate our model on both synthetic and in-the-wild Internet imagery and demonstrate its advantages in terms of generalization and accuracy. Moreover, by combining with other generative methods, our model enables many downstream 2D tasks, such as text-based relighting and object insertion. Our model can also operate as a strong relighting prior for 3D tasks, such as relighting a radiance field.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/92953",
      "pdf_url": "https://openreview.net/pdf?id=zV2GDsZb5a",
      "github_url": "",
      "total_authors": 9,
      "track_name": "Main Conference",
      "author": {
        "id": "~Zexiang_Xu1",
        "name": "Zexiang Xu",
        "name_site": null,
        "openreview_id": "~Zexiang_Xu1",
        "position": 7,
        "gender": "M",
        "homepage_url": "https://cseweb.ucsd.edu/~zex014/",
        "dblp_id": "154/0366",
        "google_scholar_url": "_RRIYvEAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Georgia (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 1.25,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 1.118033988749895,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 14,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "iEN2linUr8",
      "title": "II-Bench: An Image Implication Understanding Benchmark for Multimodal Large Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The rapid advancements in the development of multimodal large language models (MLLMs) have consistently led to new breakthroughs on various benchmarks. In response, numerous challenging and comprehensive benchmarks have been proposed to more accurately assess the capabilities of MLLMs. However, there is a dearth of exploration of the higher-order perceptual capabilities of MLLMs. To fill this gap, we propose the Image Implication understanding Benchmark, II-Bench, which aims to evaluate the model's higher-order perception of images. Through extensive experiments on II-Bench across multiple MLLMs, we have made significant findings. Initially, a substantial gap is observed between the performance of MLLMs and humans on II-Bench. The pinnacle accuracy of MLLMs attains 74.8%, whereas human accuracy averages 90%, peaking at an impressive 98%. Subsequently, MLLMs perform worse on abstract and complex images, suggesting limitations in their ability to understand high-level semantics and capture image details. Finally, it is observed that most models exhibit enhanced accuracy when image sentiment polarity hints are incorporated into the prompts. This observation underscores a notable deficiency in their inherent understanding of image sentiment. We believe that II-Bench will inspire the community to develop the next generation of MLLMs, advancing the journey towards expert  artificial general intelligence (AGI). II-Bench is publicly available at https://huggingface.co/datasets/m-a-p/II-Bench.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97557",
      "pdf_url": "https://openreview.net/pdf?id=iEN2linUr8",
      "github_url": "",
      "total_authors": 26,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Xiaojun_Chen4",
        "name": "Xiaojun Chen",
        "name_site": null,
        "openreview_id": "~Xiaojun_Chen4",
        "position": 20,
        "gender": "M",
        "homepage_url": "https://bruce-xjchen.github.io/HomePage/",
        "dblp_id": "20/3215-6",
        "google_scholar_url": "yAjyrwkAAAAJ",
        "orcid": "0000-0002-2818-4652",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "University of Waterloo (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.2,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.4142135623730951,
        "confidence_mean": 4.666666666666667,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 7,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "3qH8q02x0n",
      "title": "IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent advancements in text-to-speech (TTS) synthesis show that large-scale models trained with extensive web data produce highly natural-sounding output. However, such data is scarce for Indian languages due to the lack of high-quality, manually subtitled data on platforms like LibriVox or YouTube. To address this gap, we enhance existing large-scale ASR datasets containing natural conversations collected in low-quality environments to generate high-quality TTS training data. Our pipeline leverages the cross-lingual generalization of denoising and speech enhancement models trained on English and applied to Indian languages. This results in IndicVoices-R (IV-R), the largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704 hours of high-quality speech from 10,496 speakers across 22 Indian languages. IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS, and IndicTTS. We also introduce the IV-R Benchmark, the first to assess zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS models on Indian voices, ensuring diversity in age, gender, and style. We demonstrate that fine-tuning an English pre-trained model on a combined dataset of high-quality IndicTTS and our IV-R dataset results in better zero-shot speaker generalization compared to fine-tuning on the IndicTTS dataset alone. Further, our evaluation reveals limited zero-shot generalization for Indian voices in TTS models trained on prior datasets, which we improve by fine-tuning the model on our data containing diverse set of speakers across language families. We open-source code and data for all 22 official Indian languages.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97858",
      "pdf_url": "https://openreview.net/pdf?id=3qH8q02x0n",
      "github_url": "",
      "total_authors": 10,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Aditi_Krishana1",
        "name": "Aditi Krishana",
        "name_site": null,
        "openreview_id": "~Aditi_Krishana1",
        "position": 8,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "krishnaditi?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology, Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 1.1111111111111112,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "QzvWyggrYB",
      "title": "Large Language Models Must Be Taught to Know What They Don’t Know",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "When using large language models (LLMs) in high-stakes applications, we need to know when we can trust their predictions. Some works argue that prompting high-performance LLMs is sufficient to produce calibrated uncertainties, while others introduce sampling methods that can be prohibitively expensive. In this work, we first argue that prompting on its own is insufficient to achieve good calibration and then show that fine-tuning on a small dataset of correct and incorrect answers can create an uncertainty estimate with good generalization and small computational overhead. We show that a thousand graded examples are sufficient to outperform baseline methods and that training through the features of a model is necessary for good performance and tractable for large open-source models when using LoRA. We also investigate the mechanisms that enable reliable LLM uncertainty estimation, finding that many models can be used as general-purpose uncertainty estimators, applicable not just to their own uncertainties but also the uncertainty of other models. Lastly, we show that uncertainty estimates inform human use of LLMs in human-AI collaborative settings through a user study.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95205",
      "pdf_url": "https://openreview.net/pdf?id=QzvWyggrYB",
      "github_url": "",
      "total_authors": 10,
      "track_name": "Main Conference",
      "author": {
        "id": "~Samuel_Dooley1",
        "name": "Samuel Dooley",
        "name_site": null,
        "openreview_id": "~Samuel_Dooley1",
        "position": 8,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "New York University (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 1.1111111111111112,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 1.5491933384829668,
        "confidence_mean": 3.8,
        "confidence_std": 0.39999999999999997,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 18,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "SdLOs1FR4h",
      "title": "FUGAL: Feature-fortified Unrestricted Graph Alignment",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "The necessity to align two graphs, minimizing a structural distance metric, is prevalent in biology, chemistry, recommender systems, and social network analysis. Due to the problem’s NP-hardness, prevailing graph alignment methods follow a modular and mediated approach, solving the problem by restricting to the domain of intermediary graph representations or products like embeddings, spectra, and graph signals. Restricting the problem to this intermediate space may distort the original problem and are hence predisposed to miss high-quality solutions. In this paper, we propose an unrestricted method, FUGAL, which finds a permutation matrix that maps one graph to another by directly operating on their adjacency matrices with judicious constraint relaxation. Extensive experimentation demonstrates that FUGAL consistently surpasses state-of-the-art graph alignment methods in accuracy across all benchmark datasets without encumbering efficiency.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95090",
      "pdf_url": "https://openreview.net/pdf?id=SdLOs1FR4h",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Davide_Mottin1",
        "name": "Davide Mottin",
        "name_site": null,
        "openreview_id": "~Davide_Mottin1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://mott.in",
        "dblp_id": "135/7623",
        "google_scholar_url": "https://scholar.google.it/citations?user=evZ9Q9EAAAAJ",
        "orcid": "0000-0001-8256-2258",
        "linkedin_url": "davide-mottin-67ab7323/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Aarhus University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.9999999999999998,
      "reviews": {
        "rating_mean": 5.5,
        "rating_std": 1.6583123951777,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 1,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "TZ5k9IYBBf",
      "title": "RanDumb: Random Representations Outperform Online Continually Learned Representations",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Continual learning has primarily focused on the issue of catastrophic forgetting and the associated stability-plasticity tradeoffs. However, little attention has been paid to the efficacy of continually learned representations, as representations are learned alongside classifiers throughout the learning process. Our primary contribution is empirically demonstrating that existing online continually trained deep networks produce inferior representations compared to a simple pre-defined random transforms. Our approach embeds raw pixels using a fixed random transform, approximating an RBF-Kernel initialized before any data is seen. We then train a simple linear classifier on top without storing any exemplars, processing one sample at a time in an online continual learning setting. This method, called RanDumb,  significantly outperforms state-of-the-art continually learned representations across all standard online continual learning benchmarks. Our study reveals the significant limitations of representation learning, particularly in low-exemplar and online continual learning scenarios. Extending our investigation to popular exemplar-free scenarios with pretrained models, we find that training only a linear classifier on top of pretrained representations surpasses most continual fine-tuning and prompt-tuning strategies. Overall, our investigation challenges the prevailing assumptions about effective representation learning in the online continual learning.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/95027",
      "pdf_url": "https://openreview.net/pdf?id=TZ5k9IYBBf",
      "github_url": "",
      "total_authors": 6,
      "track_name": "Main Conference",
      "author": {
        "id": "~Ozan_Sener1",
        "name": "Ozan Sener",
        "name_site": "Ozan Sener, Vladlen Koltun",
        "openreview_id": "~Ozan_Sener1",
        "position": 5,
        "gender": "M",
        "homepage_url": "http://ozansener.net",
        "dblp_id": "125/1989",
        "google_scholar_url": "BI8xFr4AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Apple (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.9999999999999998,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.75,
        "confidence_std": 0.82915619758885,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "3qH8q02x0n",
      "title": "IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Recent advancements in text-to-speech (TTS) synthesis show that large-scale models trained with extensive web data produce highly natural-sounding output. However, such data is scarce for Indian languages due to the lack of high-quality, manually subtitled data on platforms like LibriVox or YouTube. To address this gap, we enhance existing large-scale ASR datasets containing natural conversations collected in low-quality environments to generate high-quality TTS training data. Our pipeline leverages the cross-lingual generalization of denoising and speech enhancement models trained on English and applied to Indian languages. This results in IndicVoices-R (IV-R), the largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704 hours of high-quality speech from 10,496 speakers across 22 Indian languages. IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS, and IndicTTS. We also introduce the IV-R Benchmark, the first to assess zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS models on Indian voices, ensuring diversity in age, gender, and style. We demonstrate that fine-tuning an English pre-trained model on a combined dataset of high-quality IndicTTS and our IV-R dataset results in better zero-shot speaker generalization compared to fine-tuning on the IndicTTS dataset alone. Further, our evaluation reveals limited zero-shot generalization for Indian voices in TTS models trained on prior datasets, which we improve by fine-tuning the model on our data containing diverse set of speakers across language families. We open-source code and data for all 22 official Indian languages.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97858",
      "pdf_url": "https://openreview.net/pdf?id=3qH8q02x0n",
      "github_url": "",
      "total_authors": 10,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Giri_Raju1",
        "name": "Giri Raju",
        "name_site": null,
        "openreview_id": "~Giri_Raju1",
        "position": 9,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "giri-raju-787854200",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Madras (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.5555555555555558,
      "reviews": {
        "rating_mean": 5.75,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "a0WAM6q6fV",
      "title": "Croissant: A Metadata Format for ML-Ready Datasets",
      "status": "Spotlight",
      "normalized_status": "spotlight",
      "abstract": "Data is a critical resource for machine learning (ML), yet working with data remains a key friction point. This paper introduces Croissant,  a metadata format for datasets that creates a shared representation across ML tools, frameworks, and platforms. Croissant makes datasets more discoverable, portable, and interoperable, thereby addressing significant challenges in ML data management. Croissant is already supported by several popular dataset repositories, spanning hundreds of thousands of datasets, enabling easy loading into the most commonly-used ML frameworks, regardless of where the data is stored. Our initial evaluation by human raters shows that Croissant metadata is readable, understandable, complete, yet concise.",
      "tldr": "",
      "site_url": "https://neurips.cc/virtual/2024/poster/97627",
      "pdf_url": "https://openreview.net/pdf?id=a0WAM6q6fV",
      "github_url": "",
      "total_authors": 31,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Steffen_Vogler1",
        "name": "Steffen Vogler",
        "name_site": null,
        "openreview_id": "~Steffen_Vogler1",
        "position": 29,
        "gender": "M",
        "homepage_url": "https://vogler.io",
        "dblp_id": null,
        "google_scholar_url": "https://scholar.google.de/citations?user=s6CqZi8AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Duke Kunshan University (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.4999999999999999,
      "reviews": {
        "rating_mean": 7.5,
        "rating_std": 0.5,
        "confidence_mean": 4.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 37,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "5DuSIW6XQo",
      "title": "Benchmarking Self-Supervised Video Representation Learning",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Self-supervised learning is an effective way for label-free model pre-training, especially in the video domain where labeling is expensive. Existing self-supervised works in the video domain use varying experimental setups to demonstrate their effectiveness and comparison across approaches becomes challenging with no standard benchmark. In this work, we first provide a benchmark that enables a comparison of existing approaches on the same ground. Next, we study five different aspects of self-supervised learning important for videos; 1) dataset size, 2) complexity, 3) data distribution, 4) data noise, and, 5) feature analysis. To facilitate this study, we focus on seven different methods along with seven different network architectures and perform an extensive set of experiments on 5 different datasets with an evaluation of two different downstream tasks. We present several interesting insights from this study which span across different properties of pretraining and target datasets, pretext-tasks, and model architectures among others. Furthermore, we extend these findings to Video Foundation models (ViFMs). Finally, we further put some of these insights to the real test and propose an approach that requires a limited amount of training data and outperforms existing state-of-the-art approaches which use 10x pretraining data. We believe this work will pave the way for researchers to a better understanding of self-supervised pretext tasks in video representation learning.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=5DuSIW6XQo",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Ashlesha_Kumar1",
        "name": "Ashlesha Kumar",
        "name_site": null,
        "openreview_id": "~Ashlesha_Kumar1",
        "position": 2,
        "gender": "F",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "akumar-bitsp/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.0,
        "rating_std": 0.7071067811865476,
        "confidence_mean": 4.0,
        "confidence_std": 0.7071067811865476,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 6,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "EqaSEbU4LP",
      "title": "WikiDO: A New Benchmark Evaluating Cross-Modal Retrieval for Vision-Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Cross-modal (image-to-text and text-to-image) retrieval is an established task used in evaluation benchmarks to test the performance of vision-language models (VLMs). Several state-of-the-art VLMs (e.g. CLIP, BLIP-2) have achieved near-perfect performance on widely-used image-text retrieval benchmarks such as MSCOCO-Test-5K and Flickr30K-Test-1K. As a measure of out-of-distribution (OOD) generalization, prior works rely on zero-shot performance evaluated on one dataset (Flickr) using a VLM finetuned on another one (MSCOCO). We argue that such comparisons are insufficient to assess the OOD generalization capability of models due to high visual and linguistic similarity between the evaluation and finetuning datasets. To address this gap, we introduce WikiDO (drawn from Wikipedia Diversity Observatory), a novel cross-modal retrieval benchmark to assess the OOD generalization capabilities of pretrained VLMs. This consists of newly scraped 380K image-text pairs from Wikipedia with domain labels, a carefully curated, human-verified a)in-distribution (ID) test set (3K) and b) OOD test set (3K). The image-text pairs are very diverse in topics and geographical locations. We evaluate different VLMs of varying capacity on the \\wikido benchmark; BLIP-2 achieves zero-shot performance of $R@1\\approx66\\%$ on the OOD test set, compared to $\\approx$ $81\\%$ on COCO and $\\approx95\\%$ on Flickr. When fine-tuned on WikiDO, the $R@1$ improvement is at most $\\approx5\\%$ on OOD instances compared to $\\approx12\\%$ on ID instances. We probe the VLMs with varying finetuning objectives and datasets of varying sizes to identify what aids OOD generalization the most. Our results confirm that WikiDO offers a strong cross-modal benchmark for current VLMs in specifically evaluating for OOD generalization. Our benchmark is hosted as a competition at https://kaggle.com/competitions/wikido24 with public access to dataset and code.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=EqaSEbU4LP",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Pavan_Kalyan_Tankala1",
        "name": "Pavan Kalyan Tankala",
        "name_site": null,
        "openreview_id": "~Pavan_Kalyan_Tankala1",
        "position": 1,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "371/5125",
        "google_scholar_url": "11_GsJAAAAAJ",
        "orcid": null,
        "linkedin_url": "pavan-kalyan-1b88351a0/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "EqaSEbU4LP",
      "title": "WikiDO: A New Benchmark Evaluating Cross-Modal Retrieval for Vision-Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Cross-modal (image-to-text and text-to-image) retrieval is an established task used in evaluation benchmarks to test the performance of vision-language models (VLMs). Several state-of-the-art VLMs (e.g. CLIP, BLIP-2) have achieved near-perfect performance on widely-used image-text retrieval benchmarks such as MSCOCO-Test-5K and Flickr30K-Test-1K. As a measure of out-of-distribution (OOD) generalization, prior works rely on zero-shot performance evaluated on one dataset (Flickr) using a VLM finetuned on another one (MSCOCO). We argue that such comparisons are insufficient to assess the OOD generalization capability of models due to high visual and linguistic similarity between the evaluation and finetuning datasets. To address this gap, we introduce WikiDO (drawn from Wikipedia Diversity Observatory), a novel cross-modal retrieval benchmark to assess the OOD generalization capabilities of pretrained VLMs. This consists of newly scraped 380K image-text pairs from Wikipedia with domain labels, a carefully curated, human-verified a)in-distribution (ID) test set (3K) and b) OOD test set (3K). The image-text pairs are very diverse in topics and geographical locations. We evaluate different VLMs of varying capacity on the \\wikido benchmark; BLIP-2 achieves zero-shot performance of $R@1\\approx66\\%$ on the OOD test set, compared to $\\approx$ $81\\%$ on COCO and $\\approx95\\%$ on Flickr. When fine-tuned on WikiDO, the $R@1$ improvement is at most $\\approx5\\%$ on OOD instances compared to $\\approx12\\%$ on ID instances. We probe the VLMs with varying finetuning objectives and datasets of varying sizes to identify what aids OOD generalization the most. Our results confirm that WikiDO offers a strong cross-modal benchmark for current VLMs in specifically evaluating for OOD generalization. Our benchmark is hosted as a competition at https://kaggle.com/competitions/wikido24 with public access to dataset and code.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=EqaSEbU4LP",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Sahil_Dharod1",
        "name": "Sahil Dharod",
        "name_site": null,
        "openreview_id": "~Sahil_Dharod1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "sahil-dharod-23153b226",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "EqaSEbU4LP",
      "title": "WikiDO: A New Benchmark Evaluating Cross-Modal Retrieval for Vision-Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Cross-modal (image-to-text and text-to-image) retrieval is an established task used in evaluation benchmarks to test the performance of vision-language models (VLMs). Several state-of-the-art VLMs (e.g. CLIP, BLIP-2) have achieved near-perfect performance on widely-used image-text retrieval benchmarks such as MSCOCO-Test-5K and Flickr30K-Test-1K. As a measure of out-of-distribution (OOD) generalization, prior works rely on zero-shot performance evaluated on one dataset (Flickr) using a VLM finetuned on another one (MSCOCO). We argue that such comparisons are insufficient to assess the OOD generalization capability of models due to high visual and linguistic similarity between the evaluation and finetuning datasets. To address this gap, we introduce WikiDO (drawn from Wikipedia Diversity Observatory), a novel cross-modal retrieval benchmark to assess the OOD generalization capabilities of pretrained VLMs. This consists of newly scraped 380K image-text pairs from Wikipedia with domain labels, a carefully curated, human-verified a)in-distribution (ID) test set (3K) and b) OOD test set (3K). The image-text pairs are very diverse in topics and geographical locations. We evaluate different VLMs of varying capacity on the \\wikido benchmark; BLIP-2 achieves zero-shot performance of $R@1\\approx66\\%$ on the OOD test set, compared to $\\approx$ $81\\%$ on COCO and $\\approx95\\%$ on Flickr. When fine-tuned on WikiDO, the $R@1$ improvement is at most $\\approx5\\%$ on OOD instances compared to $\\approx12\\%$ on ID instances. We probe the VLMs with varying finetuning objectives and datasets of varying sizes to identify what aids OOD generalization the most. Our results confirm that WikiDO offers a strong cross-modal benchmark for current VLMs in specifically evaluating for OOD generalization. Our benchmark is hosted as a competition at https://kaggle.com/competitions/wikido24 with public access to dataset and code.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=EqaSEbU4LP",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Azeem_Motiwala1",
        "name": "Azeem Motiwala",
        "name_site": null,
        "openreview_id": "~Azeem_Motiwala1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": "azeem-motiwala-311b6b239/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "EqaSEbU4LP",
      "title": "WikiDO: A New Benchmark Evaluating Cross-Modal Retrieval for Vision-Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Cross-modal (image-to-text and text-to-image) retrieval is an established task used in evaluation benchmarks to test the performance of vision-language models (VLMs). Several state-of-the-art VLMs (e.g. CLIP, BLIP-2) have achieved near-perfect performance on widely-used image-text retrieval benchmarks such as MSCOCO-Test-5K and Flickr30K-Test-1K. As a measure of out-of-distribution (OOD) generalization, prior works rely on zero-shot performance evaluated on one dataset (Flickr) using a VLM finetuned on another one (MSCOCO). We argue that such comparisons are insufficient to assess the OOD generalization capability of models due to high visual and linguistic similarity between the evaluation and finetuning datasets. To address this gap, we introduce WikiDO (drawn from Wikipedia Diversity Observatory), a novel cross-modal retrieval benchmark to assess the OOD generalization capabilities of pretrained VLMs. This consists of newly scraped 380K image-text pairs from Wikipedia with domain labels, a carefully curated, human-verified a)in-distribution (ID) test set (3K) and b) OOD test set (3K). The image-text pairs are very diverse in topics and geographical locations. We evaluate different VLMs of varying capacity on the \\wikido benchmark; BLIP-2 achieves zero-shot performance of $R@1\\approx66\\%$ on the OOD test set, compared to $\\approx$ $81\\%$ on COCO and $\\approx95\\%$ on Flickr. When fine-tuned on WikiDO, the $R@1$ improvement is at most $\\approx5\\%$ on OOD instances compared to $\\approx12\\%$ on ID instances. We probe the VLMs with varying finetuning objectives and datasets of varying sizes to identify what aids OOD generalization the most. Our results confirm that WikiDO offers a strong cross-modal benchmark for current VLMs in specifically evaluating for OOD generalization. Our benchmark is hosted as a competition at https://kaggle.com/competitions/wikido24 with public access to dataset and code.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=EqaSEbU4LP",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Preethi_Jyothi2",
        "name": "Preethi Jyothi",
        "name_site": null,
        "openreview_id": "~Preethi_Jyothi2",
        "position": 5,
        "gender": "F",
        "homepage_url": "http://www.cse.iitb.ac.in/~pjyothi",
        "dblp_id": "01/9014",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=QN_uhu8AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Technology Bombay (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "EqaSEbU4LP",
      "title": "WikiDO: A New Benchmark Evaluating Cross-Modal Retrieval for Vision-Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Cross-modal (image-to-text and text-to-image) retrieval is an established task used in evaluation benchmarks to test the performance of vision-language models (VLMs). Several state-of-the-art VLMs (e.g. CLIP, BLIP-2) have achieved near-perfect performance on widely-used image-text retrieval benchmarks such as MSCOCO-Test-5K and Flickr30K-Test-1K. As a measure of out-of-distribution (OOD) generalization, prior works rely on zero-shot performance evaluated on one dataset (Flickr) using a VLM finetuned on another one (MSCOCO). We argue that such comparisons are insufficient to assess the OOD generalization capability of models due to high visual and linguistic similarity between the evaluation and finetuning datasets. To address this gap, we introduce WikiDO (drawn from Wikipedia Diversity Observatory), a novel cross-modal retrieval benchmark to assess the OOD generalization capabilities of pretrained VLMs. This consists of newly scraped 380K image-text pairs from Wikipedia with domain labels, a carefully curated, human-verified a)in-distribution (ID) test set (3K) and b) OOD test set (3K). The image-text pairs are very diverse in topics and geographical locations. We evaluate different VLMs of varying capacity on the \\wikido benchmark; BLIP-2 achieves zero-shot performance of $R@1\\approx66\\%$ on the OOD test set, compared to $\\approx$ $81\\%$ on COCO and $\\approx95\\%$ on Flickr. When fine-tuned on WikiDO, the $R@1$ improvement is at most $\\approx5\\%$ on OOD instances compared to $\\approx12\\%$ on ID instances. We probe the VLMs with varying finetuning objectives and datasets of varying sizes to identify what aids OOD generalization the most. Our results confirm that WikiDO offers a strong cross-modal benchmark for current VLMs in specifically evaluating for OOD generalization. Our benchmark is hosted as a competition at https://kaggle.com/competitions/wikido24 with public access to dataset and code.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=EqaSEbU4LP",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Aditi_Chaudhary1",
        "name": "Aditi Chaudhary",
        "name_site": null,
        "openreview_id": "~Aditi_Chaudhary1",
        "position": 6,
        "gender": null,
        "homepage_url": null,
        "dblp_id": "225/7684",
        "google_scholar_url": "iNuUxiwAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "EqaSEbU4LP",
      "title": "WikiDO: A New Benchmark Evaluating Cross-Modal Retrieval for Vision-Language Models",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "Cross-modal (image-to-text and text-to-image) retrieval is an established task used in evaluation benchmarks to test the performance of vision-language models (VLMs). Several state-of-the-art VLMs (e.g. CLIP, BLIP-2) have achieved near-perfect performance on widely-used image-text retrieval benchmarks such as MSCOCO-Test-5K and Flickr30K-Test-1K. As a measure of out-of-distribution (OOD) generalization, prior works rely on zero-shot performance evaluated on one dataset (Flickr) using a VLM finetuned on another one (MSCOCO). We argue that such comparisons are insufficient to assess the OOD generalization capability of models due to high visual and linguistic similarity between the evaluation and finetuning datasets. To address this gap, we introduce WikiDO (drawn from Wikipedia Diversity Observatory), a novel cross-modal retrieval benchmark to assess the OOD generalization capabilities of pretrained VLMs. This consists of newly scraped 380K image-text pairs from Wikipedia with domain labels, a carefully curated, human-verified a)in-distribution (ID) test set (3K) and b) OOD test set (3K). The image-text pairs are very diverse in topics and geographical locations. We evaluate different VLMs of varying capacity on the \\wikido benchmark; BLIP-2 achieves zero-shot performance of $R@1\\approx66\\%$ on the OOD test set, compared to $\\approx$ $81\\%$ on COCO and $\\approx95\\%$ on Flickr. When fine-tuned on WikiDO, the $R@1$ improvement is at most $\\approx5\\%$ on OOD instances compared to $\\approx12\\%$ on ID instances. We probe the VLMs with varying finetuning objectives and datasets of varying sizes to identify what aids OOD generalization the most. Our results confirm that WikiDO offers a strong cross-modal benchmark for current VLMs in specifically evaluating for OOD generalization. Our benchmark is hosted as a competition at https://kaggle.com/competitions/wikido24 with public access to dataset and code.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=EqaSEbU4LP",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Krishna_Srinivasan1",
        "name": "Krishna Srinivasan",
        "name_site": null,
        "openreview_id": "~Krishna_Srinivasan1",
        "position": 7,
        "gender": "M",
        "homepage_url": "https://krishna2.com",
        "dblp_id": "50/145.html",
        "google_scholar_url": "aYn5qFUAAAAJ",
        "orcid": "0000-0003-1366-0895",
        "linkedin_url": "krishna2/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Google (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 4.0,
        "confidence_std": 0.816496580927726,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "MbbTN9rPzC",
      "title": "Quantile Activation: Departing from single point estimation for better generalization across distortions",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "A classifier is, in its essence, a function which takes an input and returns the class of the input and implicitly assumes an underlying distribution which does not change. We argue in this article that one has to move away from this basic tenet to obtain generalisation across distributions. Specifically, the class of the sample should depend on the points from its “context distribution” for better generalisation across distributions. \nHow does one achieve this? – The key idea is to “adapt” the outputs of each neuron of the network to its context distribution. We propose quantile activation,QACT, which, in simple terms, outputs the relative quantile of the sample in its context distribution, instead of the actual values in traditional networks. The scope of this article is to validate the proposed activation across several experimental settings, and compare it with conventional techniques. For this, we use the datasets developed to test robustness against distortions – CIFAR10C, CIFAR100C, MNISTC, TinyImagenetC, and show that we achieve a significantly better generalisation across distortions than the conventional classifiers, across different architectures. Although this paper is only a proof of concept, we surprisingly find that this approach outperforms DINOv2(small) at large distortions, even though DINOv2 is trained with a far bigger network on a considerably larger dataset.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=MbbTN9rPzC",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Main Conference",
      "author": {
        "id": "~Aditya_Challa1",
        "name": "Aditya Challa",
        "name_site": null,
        "openreview_id": "~Aditya_Challa1",
        "position": 1,
        "gender": null,
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 2.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "MbbTN9rPzC",
      "title": "Quantile Activation: Departing from single point estimation for better generalization across distortions",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "A classifier is, in its essence, a function which takes an input and returns the class of the input and implicitly assumes an underlying distribution which does not change. We argue in this article that one has to move away from this basic tenet to obtain generalisation across distributions. Specifically, the class of the sample should depend on the points from its “context distribution” for better generalisation across distributions. \nHow does one achieve this? – The key idea is to “adapt” the outputs of each neuron of the network to its context distribution. We propose quantile activation,QACT, which, in simple terms, outputs the relative quantile of the sample in its context distribution, instead of the actual values in traditional networks. The scope of this article is to validate the proposed activation across several experimental settings, and compare it with conventional techniques. For this, we use the datasets developed to test robustness against distortions – CIFAR10C, CIFAR100C, MNISTC, TinyImagenetC, and show that we achieve a significantly better generalisation across distortions than the conventional classifiers, across different architectures. Although this paper is only a proof of concept, we surprisingly find that this approach outperforms DINOv2(small) at large distortions, even though DINOv2 is trained with a far bigger network on a considerably larger dataset.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=MbbTN9rPzC",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Main Conference",
      "author": {
        "id": "~Laurent_Najman1",
        "name": "Laurent Najman",
        "name_site": null,
        "openreview_id": "~Laurent_Najman1",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://laurentnajman.org",
        "dblp_id": "68/4192",
        "google_scholar_url": "https://scholar.google.fr/citations?user=j-2_cT0AAAAJ",
        "orcid": "0000-0002-6190-0235",
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Birla Institute of Technology and Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 2.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "POFf5SGSAL",
      "title": "Wiki Entity Summarization Benchmark",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Entity summarization aims to compute concise summaries for entities in knowledge graphs.  Existing datasets and benchmarks are often limited to a few hundred entities and discard graph structure in source knowledge graphs. This limitation is particularly pronounced when it comes to ground-truth summaries, where there exist only a few labeled summaries for evaluation and training. We propose WikES, a comprehensive benchmark comprising of entities, their summaries,  and their connections. Additionally, WikES features a dataset generator to test entity summarization algorithms in different areas of the knowledge graph. Importantly, our approach combines graph algorithms and NLP models as well as different data sources such that WikES does not require human annotation, rendering the approach cost-effective and generalizable to multiple domains. Finally, WikES is scalable and capable of capturing the complexities of knowledge graphs in terms of topology and semantics. \nWikES features existing datasets for comparison. Empirical studies of entity summarization methods confirm the usefulness of our benchmark. Data, code, and models are available at: https://github.com/msorkhpar/wiki-entity-summarization.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=POFf5SGSAL",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Davide_Mottin1",
        "name": "Davide Mottin",
        "name_site": null,
        "openreview_id": "~Davide_Mottin1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://mott.in",
        "dblp_id": "135/7623",
        "google_scholar_url": "https://scholar.google.it/citations?user=evZ9Q9EAAAAJ",
        "orcid": "0000-0001-8256-2258",
        "linkedin_url": "davide-mottin-67ab7323/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Aarhus University (Denmark)",
        "countries": [
          "Denmark"
        ],
        "country_codes": [
          "DK"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.5,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 2,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "PlBUSoSUJG",
      "title": "Policy Gradient with Tree Expansion",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Policy gradient methods are notorious for having a large variance and high sample complexity. To mitigate this, we introduce SoftTreeMax---a generalization of softmax that employs planning. In SoftTreeMax, we extend the traditional logits with the multi-step discounted cumulative reward, topped with the logits of future states. We analyze SoftTreeMax and explain how tree expansion helps to reduce its gradient variance. We prove that the variance decays exponentially with the planning horizon as a function of the chosen tree-expansion policy. Specifically, we show that the closer the induced transitions are to being state-independent, the stronger the decay. With approximate forward models, we prove that the resulting gradient bias diminishes with the approximation error while retaining the same variance reduction. Ours is the first result to bound the gradient bias for an approximate model. In a practical implementation of SoftTreeMax, we utilize a parallel GPU-based simulator for fast and efficient tree expansion. Using this implementation in Atari, we show that SoftTreeMax reduces the gradient variance by three orders of magnitude. This leads to better sample complexity and improved performance compared to distributed PPO.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=PlBUSoSUJG",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Main Conference",
      "author": {
        "id": "~Gugan_Thoppe1",
        "name": "Gugan Thoppe",
        "name_site": "Gugan Chandrashekhar Thoppe, Bhumesh Kumar",
        "openreview_id": "~Gugan_Thoppe1",
        "position": 2,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": "117/3710",
        "google_scholar_url": "https://scholar.google.co.in/citations?user=X5zV3s8AAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indian Institute of Science (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.5,
        "rating_std": 0.8660254037844386,
        "confidence_mean": 3.75,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "WdA5H9ARaa",
      "title": "Benchmark Inflation: Revealing LLM Performance Gaps Using Retro-Holdouts",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Public benchmarks are compromised, as the training data for many Large Language Models (LLMs) is contaminated with test data, suggesting a performance gap between benchmark scores and actual capabilities. Ideally, a private holdout set could be used to accurately verify scores. Unfortunately, such datasets do not exist for most benchmarks, and post-hoc construction of sufficiently similar datasets is non-trivial. To address these issues, we introduce a systematic methodology for (i) retrospectively constructing a holdout dataset for a target dataset, (ii) demonstrating the statistical indistinguishability of this retro-holdout dataset, and (iii) comparing LLMs on the two datasets to quantify the performance gap due to the dataset's public availability. Applying these methods to TruthfulQA, we construct and release Retro-TruthfulQA, on which we evaluate twenty LLMs and find that some have inflated scores by as much as 16 percentage points. Our results demonstrate that public benchmark scores do not always accurately assess model properties, and underscore the importance of improved data practices in the field.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=WdA5H9ARaa",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Jacob_Haimes1",
        "name": "Jacob Haimes",
        "name_site": null,
        "openreview_id": "~Jacob_Haimes1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://jacob-haimes.github.io",
        "dblp_id": null,
        "google_scholar_url": "F2BtIR0AAAAJ",
        "orcid": null,
        "linkedin_url": "jacob-haimes/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Apart Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "WdA5H9ARaa",
      "title": "Benchmark Inflation: Revealing LLM Performance Gaps Using Retro-Holdouts",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Public benchmarks are compromised, as the training data for many Large Language Models (LLMs) is contaminated with test data, suggesting a performance gap between benchmark scores and actual capabilities. Ideally, a private holdout set could be used to accurately verify scores. Unfortunately, such datasets do not exist for most benchmarks, and post-hoc construction of sufficiently similar datasets is non-trivial. To address these issues, we introduce a systematic methodology for (i) retrospectively constructing a holdout dataset for a target dataset, (ii) demonstrating the statistical indistinguishability of this retro-holdout dataset, and (iii) comparing LLMs on the two datasets to quantify the performance gap due to the dataset's public availability. Applying these methods to TruthfulQA, we construct and release Retro-TruthfulQA, on which we evaluate twenty LLMs and find that some have inflated scores by as much as 16 percentage points. Our results demonstrate that public benchmark scores do not always accurately assess model properties, and underscore the importance of improved data practices in the field.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=WdA5H9ARaa",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Clement_Neo1",
        "name": "Clement Neo",
        "name_site": null,
        "openreview_id": "~Clement_Neo1",
        "position": 5,
        "gender": null,
        "homepage_url": "https://clementneo.com",
        "dblp_id": "367/9292",
        "google_scholar_url": "Y2-g_2cAAAAJ",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Apart Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "WdA5H9ARaa",
      "title": "Benchmark Inflation: Revealing LLM Performance Gaps Using Retro-Holdouts",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Public benchmarks are compromised, as the training data for many Large Language Models (LLMs) is contaminated with test data, suggesting a performance gap between benchmark scores and actual capabilities. Ideally, a private holdout set could be used to accurately verify scores. Unfortunately, such datasets do not exist for most benchmarks, and post-hoc construction of sufficiently similar datasets is non-trivial. To address these issues, we introduce a systematic methodology for (i) retrospectively constructing a holdout dataset for a target dataset, (ii) demonstrating the statistical indistinguishability of this retro-holdout dataset, and (iii) comparing LLMs on the two datasets to quantify the performance gap due to the dataset's public availability. Applying these methods to TruthfulQA, we construct and release Retro-TruthfulQA, on which we evaluate twenty LLMs and find that some have inflated scores by as much as 16 percentage points. Our results demonstrate that public benchmark scores do not always accurately assess model properties, and underscore the importance of improved data practices in the field.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=WdA5H9ARaa",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Esben_Kran1",
        "name": "Esben Kran",
        "name_site": null,
        "openreview_id": "~Esben_Kran1",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://apartresearch.com",
        "dblp_id": null,
        "google_scholar_url": "SH5diRUAAAAJ",
        "orcid": "0000-0003-0710-2635",
        "linkedin_url": "esbenkc/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Apart Research (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 5.25,
        "rating_std": 0.82915619758885,
        "confidence_mean": 3.5,
        "confidence_std": 0.5,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 3,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "aTXhTD44nF",
      "title": "USDC: A Dataset of $\\underline{U}$ser $\\underline{S}$tance and $\\underline{D}$ogmatism in Long $\\underline{C}$onversations",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Identifying user's opinions and stances in long conversation threads on various topics can be extremely critical for enhanced personalization, market research, political campaigns, customer service, conflict resolution, targeted advertising and content moderation. Hence, training language models to automate this task is critical. However, to train such models, gathering manual annotations has multiple challenges: 1) it is both time-consuming and costly; 2) conversation threads could be very long increasing chances of noisy annotations; and 3) interpreting instances where a user changes their opinion within a conversation is difficult because often times such transitions are subtle and not expressed explicitly. Inspired by the recent success of large language models (LLMs) for complex natural language processing (NLP) tasks, we leverage Mistral Large and GPT-4 for automating the human annotation process on the following two tasks while also providing reasoning: i) user Stance detection, which involves labeling a user's stance of a post in a conversation on a five-point scale; ii) user Dogmatism detection, which deals with labeling a user's overall opinion in the conversation on a four-point scale. Majority voting on zero-shot, one-shot, few-shot annotations from these two LLMs on 764 multi-user Reddit conversations helps us curate the USDC dataset. USDC is then used to finetune and instruction-tune multiple deployable small language models for the 5-class stance and 4-class dogmatism classification tasks. We make the code and dataset publicly available [https://anonymous.4open.science/r/USDC-0F7F].",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=aTXhTD44nF",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Venkata_Charan_Chinni1",
        "name": "Venkata Charan Chinni",
        "name_site": null,
        "openreview_id": "~Venkata_Charan_Chinni1",
        "position": 3,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": "yHwdZLcAAAAJ",
        "orcid": null,
        "linkedin_url": "venkata-charan-chinni-4a569615a/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "International Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 4.833333333333333,
        "rating_std": 1.2133516482134197,
        "confidence_mean": 4.166666666666667,
        "confidence_std": 0.37267799624996495,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "fTOw3BzcWs",
      "title": "ExID: Offline RL with Intuitive Expert Insights in Limited-Data Settings",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "With the ability to learn from static datasets, Offline Reinforcement Learning (RL) emerges as a compelling avenue for real-world applications. However, state-of-the-art offline RL algorithms perform sub-optimally when confronted with limited data confined to specific regions within the state space. The performance degradation is attributed to the inability of offline RL algorithms to learn appropriate actions for rare or unseen observations. This paper proposes a novel domain knowledge-based regularization technique and adaptively refines the initial domain knowledge to considerably boost performance in limited data with partially omitted states. The key insight is that the regularization term mitigates erroneous actions for sparse samples and unobserved states covered by domain knowledge. Empirical evaluations on standard discrete environment datasets demonstrate a substantial average performance increase compared to ensemble of domain knowledge and existing offline RL algorithms operating on limited data.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=fTOw3BzcWs",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Main Conference",
      "author": {
        "id": "~Briti_Gangopadhyay1",
        "name": "Briti Gangopadhyay",
        "name_site": "Briti Gangopadhyay, Pallab Dasgupta",
        "openreview_id": "~Briti_Gangopadhyay1",
        "position": 1,
        "gender": "F",
        "homepage_url": "https://sites.google.com/view/britigangopadhyay/home",
        "dblp_id": "254/6480",
        "google_scholar_url": "JSHb52gAAAAJ",
        "orcid": "0000-0002-6488-9326",
        "linkedin_url": "briti-gangopadhyay-a988008a/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Sony Group Corporation (Japan)",
        "countries": [
          "Japan"
        ],
        "country_codes": [
          "JP"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.333333333333333,
        "rating_std": 0.4714045207910317,
        "confidence_mean": 3.6666666666666665,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "mAG68wdggA",
      "title": "RedCode: Risky Code Execution and Generation Benchmark for Code Agents",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "With the rapidly increasing capabilities and adoption of code agents for AI-assisted coding and software development, safety and security concerns, such as generating or executing malicious code, have become significant barriers to the real-world deployment of these agents. To provide comprehensive and practical evaluations on the safety of code agents, we propose RedCode, an evaluation platform with benchmarks grounded in four key principles: real interaction with systems, holistic evaluation of unsafe code generation and execution, diverse input formats, and high-quality safety scenarios and tests. RedCode consists of two parts to evaluate agents’ safety in unsafe code execution and generation: (1) RedCode-Exec provides challenging code prompts in Python as inputs, aiming to evaluate code agents’ ability to recognize and handle unsafe code. We then map the Python code to other programming languages (e.g., Bash) and natural text summaries or descriptions for evaluation, leading to a total of over 4,000 testing instances. We provide 25 types of critical vulnerabilities spanning various domains, such as websites, file systems, and operating systems. We provide a Docker sandbox environment to evaluate the execution capabilities of code agents and design corresponding evaluation metrics to assess their execution results. (2) RedCode-Gen provides 160 prompts with function signatures and docstrings as input to assess whether code agents will follow instructions to generate harmful code or software. Our empirical findings, derived from evaluating three agent frameworks based on 19 LLMs, provide insights into code agents’ vulnerabilities. For instance, evaluations on RedCode-Exec show that agents are more likely to reject executing unsafe operations on the operating system, but are less likely to reject executing technically buggy code, indicating high risks. Unsafe operations described in natural text lead to a lower rejection rate than those in code format. Additionally, evaluations on RedCode-Gen reveal that more capable base models and agents with stronger overall coding abilities, such as GPT4, tend to produce more sophisticated and effective harmful software. Our findings highlight the need for stringent safety evaluations for diverse code agents. Our dataset and code are publicly available at https://github.com/AI-secure/RedCode.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=mAG68wdggA",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Zinan_Lin1",
        "name": "Zinan Lin",
        "name_site": "Zinan Lin, Vyas Sekar, Giulia Fanti",
        "openreview_id": "~Zinan_Lin1",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://zinanlin.me/",
        "dblp_id": "64/237-1",
        "google_scholar_url": "67nE-wQ_g_cC",
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Microsoft (United States)",
        "countries": [
          "United States"
        ],
        "country_codes": [
          "US"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 7.0,
        "rating_std": 0.816496580927726,
        "confidence_mean": 3.3333333333333335,
        "confidence_std": 0.4714045207910317,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 7,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qgzdGyQcDt",
      "title": "EEVR: A Dataset of Paired Physiological Signals and Textual Descriptions for Joint Emotion Representation Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "EEVR (Emotion Elicitation in Virtual Reality) is a novel dataset specifically designed for language supervision-based pre-training of emotion recognition tasks, such as valence and arousal classification. It features high-quality physiological signals, including electrodermal activity (EDA) and photoplethysmography (PPG), acquired through emotion elicitation via 360-degree virtual reality (VR) videos.\nAdditionally, it includes subject-wise textual descriptions of emotions experienced during each stimulus gathered from qualitative interviews. The dataset consists of recordings from 37 participants and is the first dataset to pair raw text with physiological signals, providing additional contextual information that objective labels cannot offer. To leverage this dataset, we introduced the Contrastive Language Signal Pre-training (CLSP) method, which jointly learns representations using pairs of physiological signals and textual descriptions. Our results show that integrating self-reported textual descriptions with physiological signals significantly improves performance on emotion recognition tasks, such as arousal and valence classification. Moreover, our pre-trained CLSP model demonstrates strong zero-shot transferability to existing datasets, outperforming supervised baseline models, suggesting that the representations learned by our method are more contextualized and generalized. The dataset also includes baseline models for arousal, valence, and emotion classification, as well as code for data cleaning and feature extraction. Further details and access to the dataset are available at https://melangelabiiitd.github.io/EEVR/.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qgzdGyQcDt",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Pragya_Singh1",
        "name": "Pragya Singh",
        "name_site": null,
        "openreview_id": "~Pragya_Singh1",
        "position": 1,
        "gender": "F",
        "homepage_url": "https://alchemy18.github.io/pragyasingh/",
        "dblp_id": null,
        "google_scholar_url": "fxfhl98AAAAJ",
        "orcid": "0000-0003-3933-2224",
        "linkedin_url": "pragya-singh-438508113/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 1.699673171197595,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qgzdGyQcDt",
      "title": "EEVR: A Dataset of Paired Physiological Signals and Textual Descriptions for Joint Emotion Representation Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "EEVR (Emotion Elicitation in Virtual Reality) is a novel dataset specifically designed for language supervision-based pre-training of emotion recognition tasks, such as valence and arousal classification. It features high-quality physiological signals, including electrodermal activity (EDA) and photoplethysmography (PPG), acquired through emotion elicitation via 360-degree virtual reality (VR) videos.\nAdditionally, it includes subject-wise textual descriptions of emotions experienced during each stimulus gathered from qualitative interviews. The dataset consists of recordings from 37 participants and is the first dataset to pair raw text with physiological signals, providing additional contextual information that objective labels cannot offer. To leverage this dataset, we introduced the Contrastive Language Signal Pre-training (CLSP) method, which jointly learns representations using pairs of physiological signals and textual descriptions. Our results show that integrating self-reported textual descriptions with physiological signals significantly improves performance on emotion recognition tasks, such as arousal and valence classification. Moreover, our pre-trained CLSP model demonstrates strong zero-shot transferability to existing datasets, outperforming supervised baseline models, suggesting that the representations learned by our method are more contextualized and generalized. The dataset also includes baseline models for arousal, valence, and emotion classification, as well as code for data cleaning and feature extraction. Further details and access to the dataset are available at https://melangelabiiitd.github.io/EEVR/.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qgzdGyQcDt",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Ritvik_Budhiraja1",
        "name": "Ritvik Budhiraja",
        "name_site": null,
        "openreview_id": "~Ritvik_Budhiraja1",
        "position": 2,
        "gender": null,
        "homepage_url": "https://ritvikbudhiraja.in",
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": null,
        "linkedin_url": null,
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 1.699673171197595,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qgzdGyQcDt",
      "title": "EEVR: A Dataset of Paired Physiological Signals and Textual Descriptions for Joint Emotion Representation Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "EEVR (Emotion Elicitation in Virtual Reality) is a novel dataset specifically designed for language supervision-based pre-training of emotion recognition tasks, such as valence and arousal classification. It features high-quality physiological signals, including electrodermal activity (EDA) and photoplethysmography (PPG), acquired through emotion elicitation via 360-degree virtual reality (VR) videos.\nAdditionally, it includes subject-wise textual descriptions of emotions experienced during each stimulus gathered from qualitative interviews. The dataset consists of recordings from 37 participants and is the first dataset to pair raw text with physiological signals, providing additional contextual information that objective labels cannot offer. To leverage this dataset, we introduced the Contrastive Language Signal Pre-training (CLSP) method, which jointly learns representations using pairs of physiological signals and textual descriptions. Our results show that integrating self-reported textual descriptions with physiological signals significantly improves performance on emotion recognition tasks, such as arousal and valence classification. Moreover, our pre-trained CLSP model demonstrates strong zero-shot transferability to existing datasets, outperforming supervised baseline models, suggesting that the representations learned by our method are more contextualized and generalized. The dataset also includes baseline models for arousal, valence, and emotion classification, as well as code for data cleaning and feature extraction. Further details and access to the dataset are available at https://melangelabiiitd.github.io/EEVR/.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qgzdGyQcDt",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Ankush_Gupta3",
        "name": "Ankush Gupta",
        "name_site": null,
        "openreview_id": "~Ankush_Gupta3",
        "position": 3,
        "gender": "M",
        "homepage_url": "https://www.linkedin.com/in/ankush-gupta-9a9211224/",
        "dblp_id": null,
        "google_scholar_url": "6LH_olwAAAAJ",
        "orcid": null,
        "linkedin_url": "ankush-gupta-9a9211224?trk=people-guest_people_search-card&originalSubdomain=in",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 1.699673171197595,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qgzdGyQcDt",
      "title": "EEVR: A Dataset of Paired Physiological Signals and Textual Descriptions for Joint Emotion Representation Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "EEVR (Emotion Elicitation in Virtual Reality) is a novel dataset specifically designed for language supervision-based pre-training of emotion recognition tasks, such as valence and arousal classification. It features high-quality physiological signals, including electrodermal activity (EDA) and photoplethysmography (PPG), acquired through emotion elicitation via 360-degree virtual reality (VR) videos.\nAdditionally, it includes subject-wise textual descriptions of emotions experienced during each stimulus gathered from qualitative interviews. The dataset consists of recordings from 37 participants and is the first dataset to pair raw text with physiological signals, providing additional contextual information that objective labels cannot offer. To leverage this dataset, we introduced the Contrastive Language Signal Pre-training (CLSP) method, which jointly learns representations using pairs of physiological signals and textual descriptions. Our results show that integrating self-reported textual descriptions with physiological signals significantly improves performance on emotion recognition tasks, such as arousal and valence classification. Moreover, our pre-trained CLSP model demonstrates strong zero-shot transferability to existing datasets, outperforming supervised baseline models, suggesting that the representations learned by our method are more contextualized and generalized. The dataset also includes baseline models for arousal, valence, and emotion classification, as well as code for data cleaning and feature extraction. Further details and access to the dataset are available at https://melangelabiiitd.github.io/EEVR/.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qgzdGyQcDt",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Anshul_Goswami1",
        "name": "Anshul Goswami",
        "name_site": null,
        "openreview_id": "~Anshul_Goswami1",
        "position": 4,
        "gender": "M",
        "homepage_url": null,
        "dblp_id": null,
        "google_scholar_url": null,
        "orcid": "0009-0009-6578-4233",
        "linkedin_url": "anshul-goswami-83844b211/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 1.699673171197595,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qgzdGyQcDt",
      "title": "EEVR: A Dataset of Paired Physiological Signals and Textual Descriptions for Joint Emotion Representation Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "EEVR (Emotion Elicitation in Virtual Reality) is a novel dataset specifically designed for language supervision-based pre-training of emotion recognition tasks, such as valence and arousal classification. It features high-quality physiological signals, including electrodermal activity (EDA) and photoplethysmography (PPG), acquired through emotion elicitation via 360-degree virtual reality (VR) videos.\nAdditionally, it includes subject-wise textual descriptions of emotions experienced during each stimulus gathered from qualitative interviews. The dataset consists of recordings from 37 participants and is the first dataset to pair raw text with physiological signals, providing additional contextual information that objective labels cannot offer. To leverage this dataset, we introduced the Contrastive Language Signal Pre-training (CLSP) method, which jointly learns representations using pairs of physiological signals and textual descriptions. Our results show that integrating self-reported textual descriptions with physiological signals significantly improves performance on emotion recognition tasks, such as arousal and valence classification. Moreover, our pre-trained CLSP model demonstrates strong zero-shot transferability to existing datasets, outperforming supervised baseline models, suggesting that the representations learned by our method are more contextualized and generalized. The dataset also includes baseline models for arousal, valence, and emotion classification, as well as code for data cleaning and feature extraction. Further details and access to the dataset are available at https://melangelabiiitd.github.io/EEVR/.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qgzdGyQcDt",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Mohan_Kumar1",
        "name": "Mohan Kumar",
        "name_site": null,
        "openreview_id": "~Mohan_Kumar1",
        "position": 5,
        "gender": "M",
        "homepage_url": "https://www.cs.rit.edu/~mjk/",
        "dblp_id": null,
        "google_scholar_url": "idH8IwYAAAAJ",
        "orcid": "0000-0002-0286-6997",
        "linkedin_url": "mohan-kumar-0b05242/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Rochester Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 1.699673171197595,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "qgzdGyQcDt",
      "title": "EEVR: A Dataset of Paired Physiological Signals and Textual Descriptions for Joint Emotion Representation Learning",
      "status": "Poster",
      "normalized_status": "poster",
      "abstract": "EEVR (Emotion Elicitation in Virtual Reality) is a novel dataset specifically designed for language supervision-based pre-training of emotion recognition tasks, such as valence and arousal classification. It features high-quality physiological signals, including electrodermal activity (EDA) and photoplethysmography (PPG), acquired through emotion elicitation via 360-degree virtual reality (VR) videos.\nAdditionally, it includes subject-wise textual descriptions of emotions experienced during each stimulus gathered from qualitative interviews. The dataset consists of recordings from 37 participants and is the first dataset to pair raw text with physiological signals, providing additional contextual information that objective labels cannot offer. To leverage this dataset, we introduced the Contrastive Language Signal Pre-training (CLSP) method, which jointly learns representations using pairs of physiological signals and textual descriptions. Our results show that integrating self-reported textual descriptions with physiological signals significantly improves performance on emotion recognition tasks, such as arousal and valence classification. Moreover, our pre-trained CLSP model demonstrates strong zero-shot transferability to existing datasets, outperforming supervised baseline models, suggesting that the representations learned by our method are more contextualized and generalized. The dataset also includes baseline models for arousal, valence, and emotion classification, as well as code for data cleaning and feature extraction. Further details and access to the dataset are available at https://melangelabiiitd.github.io/EEVR/.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=qgzdGyQcDt",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Pushpendra_Singh1",
        "name": "Pushpendra Singh",
        "name_site": null,
        "openreview_id": "~Pushpendra_Singh1",
        "position": 6,
        "gender": "M",
        "homepage_url": "https://www.iiitd.edu.in/~pushpendra/",
        "dblp_id": "55/1719-1",
        "google_scholar_url": "https://scholar.google.com.tw/citations?user=qkSEUCMAAAAJ",
        "orcid": "0000-0003-2152-1027",
        "linkedin_url": "pushpendras/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Indraprastha Institute of Information Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.666666666666667,
        "rating_std": 1.699673171197595,
        "confidence_mean": 4.0,
        "confidence_std": 0.0,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    },
    {
      "paper_id": "urgpcr7kFR",
      "title": "Alberta Wells Dataset: Pinpointing Oil and Gas Wells from Satellite Imagery",
      "status": "Reject",
      "normalized_status": "rejected",
      "abstract": "Millions of abandoned oil and gas wells are scattered across the world, leaching methane into the atmosphere and toxic compounds into the groundwater. Many of these locations are unknown, preventing the wells from being plugged and their polluting effects averted. Remote sensing is a relatively unexplored tool for pinpointing abandoned wells at scale. We introduce the first large-scale dataset for this problem, leveraging medium-resolution multi-spectral satellite imagery from Planet Labs. Our curated dataset comprises over 213,000 wells (abandoned, suspended and active) from Alberta, a region with especially high well density, sourced from the Alberta Energy Regulator and verified by domain experts. We evaluate baseline algorithms for well detection and segmentation, showing the promise of computer vision approaches but also significant room for improvement.",
      "tldr": "",
      "site_url": "https://openreview.net/forum?id=urgpcr7kFR",
      "pdf_url": null,
      "github_url": "",
      "total_authors": 0,
      "track_name": "Datasets & Benchmarks",
      "author": {
        "id": "~Pratinav_Seth1",
        "name": "Pratinav Seth",
        "name_site": null,
        "openreview_id": "~Pratinav_Seth1",
        "position": 1,
        "gender": "M",
        "homepage_url": "https://pratinavseth.github.io/",
        "dblp_id": "305/7312",
        "google_scholar_url": "https://scholar.google.com/citations?hl=en",
        "orcid": "0009-0001-4525-4464",
        "linkedin_url": "pratinav-seth/",
        "twitter_url": null,
        "primary_email": null,
        "affiliations": "Manipal Institute of Technology (India)",
        "countries": [
          "India"
        ],
        "country_codes": [
          "IN"
        ]
      },
      "sort_score": 0.0,
      "reviews": {
        "rating_mean": 6.25,
        "rating_std": 1.299038105676658,
        "confidence_mean": 4.25,
        "confidence_std": 0.4330127018922193,
        "total_reviews": null,
        "total_reviewers": null,
        "google_scholar_citations": 0,
        "semantic_scholar_citations": 0
      }
    }
  ]
}