[
  {
    "paper_title": "NextCoder: Robust Adaptation of Code LMs to Diverse Code Edits",
    "paper_id": "3B6fF1PxYD",
    "pdf_url": "https://openreview.net/pdf/e4c45e8d4642143f7bff681474b7ce9634b0db2d.pdf",
    "author_list": [
      {
        "name": "Tushar Aggarwal",
        "openreview_id": "~Tushar_Aggarwal1",
        "affiliation_name": "Microsoft",
        "affiliation_domain": "microsoft.com",
        "affiliation_country": "IN"
      },
      {
        "name": "Swayam Singh",
        "openreview_id": "~Swayam_Singh1",
        "affiliation_name": "Microsoft",
        "affiliation_domain": "microsoft.com",
        "affiliation_country": "IN"
      },
      {
        "name": "Abhijeet Awasthi",
        "openreview_id": "~Abhijeet_Awasthi1",
        "affiliation_name": "Microsoft",
        "affiliation_domain": "microsoft.com",
        "affiliation_country": "IN"
      }
    ],
    "top_author_from_india": true,
    "majority_authors_from_india": true,
    "paper_content": "This paper aims to improve code language models' ability to handle various code editing tasks. It introduces a novel synthetic data generation pipeline and a robust model adaptation algorithm, called SeleKT, to address the challenges of lacking high-quality fine-tuning data and potential loss of pre-trained abilities during adaptation."
  },
  {
    "paper_title": "Teaching Transformers Causal Reasoning through Axiomatic Training",
    "paper_id": "AhebPqDOMI",
    "pdf_url": "https://openreview.net/pdf/aac9925b5ab7b998cbccb8c1e5309f480692e75f.pdf",
    "author_list": [
      {
        "name": "Aniket Vashishtha",
        "openreview_id": "~Aniket_Vashishtha1",
        "affiliation_name": "University of Illinois at Urbana-Champaign",
        "affiliation_domain": "illinois.edu",
        "affiliation_country": "US"
      },
      {
        "name": "Abhinav Kumar",
        "openreview_id": "~Abhinav_Kumar3",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_domain": "mit.edu",
        "affiliation_country": "US"
      }
    ],
    "top_author_from_india": false,
    "majority_authors_from_india": false,
    "paper_content": "This paper investigates whether large language models (LLMs) can learn causal reasoning by directly absorbing symbolic demonstrations of causal axioms, instead of relying on data. The authors specifically examine whether models trained on demonstrations of axioms, such as transitivity and d-separation, generalize to more complex causal scenarios."
  }
]